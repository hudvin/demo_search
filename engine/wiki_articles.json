{"article_name": "Python_(programming_language)", "link": "https://en.wikipedia.org/wiki/Python_(programming_language)", "text_content": "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.\\n\\nHistory\\nPython was conceived in the late 1980s by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL, capable of exception handling and interfacing with the Amoeba operating system. Its implementation began in December 1989. Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python's \"benevolent dictator for life\", a title the Python community bestowed upon him to reflect his long-term commitment as the project's chief decision-maker. In January 2019, active Python core developers elected a five-member Steering Council to lead the project.Python 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support. Python 3.0, released on 3 December 2008, with many of its major features backported to Python 2.6.x and 2.7.x. Releases of Python 3 include the 2to3 utility, which automates the translation of Python 2 code to Python 3.Python 2.7's end-of-life was initially set for 2015, then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3. No further security patches or other improvements will be released for it. Currently only 3.8 and later are supported (2023 security issues were fixed in e.g. 3.7.17, the final 3.7.x release). While Python 2.7 and older is officially unsupported, a different unofficial Python implementation, PyPy, continues to support Python 2, i.e. \"2.7.18+\" (plus 3.9 and 3.10), with the plus meaning (at least some) \"backported security updates\".In 2021 (and again twice in 2022), security updates were expedited, since all Python versions were insecure (including 2.7) because of security issues leading to possible remote code execution and web-cache poisoning. In 2022, Python 3.10.4 and 3.9.12 were expedited and 3.8.13, because of many security issues. When Python 3.9.13 was released in May 2022, it was announced that the 3.9 series (joining the older series 3.8 and 3.7) would only receive security fixes in the future. On 7 September 2022, four new releases were made due to a potential denial-of-service attack: 3.10.7, 3.9.14, 3.8.14, and 3.7.14.As of October 2023, Python 3.12 is the stable release, and 3.12 and 3.11 are the only versions with active (as opposed to just security) support. Notable changes in 3.11 from 3.10 include increased program execution speed and improved error reporting.Python 3.12 adds syntax (and in fact every Python since at least 3.5 adds some syntax) to the language, the new (soft) keyword type (recent releases have added a lot of typing support e.g. new type union operator in 3.10), and 3.11 for exception handling, and 3.10 the match and case (soft) keywords, for structural pattern matching statements. Python 3.12 also drops outdated modules and functionality, and future versions will too, see below in Development section.\\nPython 3.11 claims to be between 10 and 60% faster than Python 3.10, and Python 3.12 adds another 5% on top of that. It also has improved error messages, and many other changes.\\nSince 27 June 2023, Python 3.8 is the oldest supported version of Python (albeit in the 'security support' phase), due to Python 3.7 reaching end-of-life.\\n\\nDesign philosophy and features\\nPython is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of their features support functional programming and aspect-oriented programming (including metaprogramming and metaobjects). Many other paradigms are supported via extensions, including design by contract and logic programming.Python uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management. It uses dynamic name resolution (late binding), which binds method and variable names during program execution.\\nIts design offers some support for functional programming in the Lisp tradition. It has filter,mapandreduce functions; list comprehensions, dictionaries, sets, and generator expressions. The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.Its core philosophy is summarized in the Zen of Python (PEP 20), which includes aphorisms such as:\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\nReadability counts.Rather than building all of its functionality into its core, Python was designed to be highly extensible via modules. This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications. Van Rossum's vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which espoused the opposite approach.Python strives for a simpler, less-cluttered syntax and grammar while giving developers a choice in their coding methodology. In contrast to Perl's \"there is more than one way to do it\" motto, Python embraces a \"there should be one\u2014and preferably only one\u2014obvious way to do it\"  philosophy. Alex Martelli, a Fellow at the Python Software Foundation and Python book author, wrote: \"To describe something as 'clever' is not considered a compliment in the Python culture.\"Python's developers strive to avoid premature optimization and reject patches to non-critical parts of the CPython reference implementation that would offer marginal increases in speed at the cost of clarity. Execution speed can be improved by moving speed-critical functions to extension modules written in languages such as C, or by using a just-in-time compiler like PyPy. It is also possible to cross-compile to other languages, but it either doesn't provide the full speed-up that might be expected, since Python is a very dynamic language, or a restricted subset of Python is compiled, and possibly semantics are slightly changed.\\nPython's developers aim for it to be fun to use. This is reflected in its name\u2014a tribute to the British comedy group Monty Python\u2014and in occasionally playful approaches to tutorials and reference materials, such as the use of the terms \"spam\" and \"eggs\" (a reference to a Monty Python sketch) in examples, instead of the often-used \"foo\" and \"bar\".A common neologism in the Python community is pythonic, which has a wide range of meanings related to program style. \"Pythonic\" code may use Python idioms well, be natural or show fluency in the language, or conform with Python's minimalist philosophy and emphasis on readability. Code that is difficult to understand or reads like a rough transcription from another programming language is called unpythonic.\\n\\nSyntax and semantics\\nPython is meant to be an easily readable language. Its formatting is visually uncluttered and often uses English keywords where other languages use punctuation. Unlike many other languages, it does not use curly brackets to delimit blocks, and semicolons after statements are allowed but rarely used. It has fewer syntactic exceptions and special cases than C or Pascal.\\n\\nIndentation\\nPython uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks. An increase in indentation comes after certain statements; a decrease in indentation signifies the end of the current block. Thus, the program's visual structure accurately represents its semantic structure. This feature is sometimes termed the off-side rule. Some other languages use indentation this way; but in most, indentation has no semantic meaning. The recommended indent size is four spaces.\\n\\nStatements and control flow\\nPython's statements include:\\n\\nThe assignment statement, using a single equals sign =\\nThe if statement, which conditionally executes a block of code, along with else and elif (a contraction of else-if)\\nThe for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block\\nThe while statement, which executes a block of code as long as its condition is true\\nThe try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses (or new syntax except* in Python 3.11 for exception groups); it also ensures that clean-up code in a finally block is always run regardless of how the block exits\\nThe raise statement, used to raise a specified exception or re-raise a caught exception\\nThe class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming\\nThe def statement, which defines a function or method\\nThe with statement, which encloses a code block within a context manager (for example, acquiring a lock before it is run, then releasing the lock; or opening and closing a file), allowing resource-acquisition-is-initialization (RAII)-like behavior and replacing a common try/finally idiom\\nThe break statement, which exits a loop\\nThe continue statement, which skips the rest of the current iteration and continues with the next\\nThe del statement, which removes a variable\u2014deleting the reference from the name to the value, and producing an error if the variable is referred to before it is redefined\\nThe pass statement, serving as a NOP, syntactically needed to create an empty code block\\nThe assert statement, used in debugging to check for conditions that should apply\\nThe yield statement, which returns a value from a generator function (and also an operator); used to implement coroutines\\nThe return statement, used to return a value from a function\\nThe import and from statements, used to import modules whose functions or variables can be used in the current programThe assignment statement (=) binds a name as a reference to a separate, dynamically allocated object. Variables may subsequently be rebound at any time to any object. In Python, a variable name is a generic reference holder without a fixed data type; however, it always refers to some object with a type. This is called dynamic typing\u2014in contrast to statically-typed languages, where each variable may contain only a value of a certain type.\\nPython does not support tail call optimization or first-class continuations, and, according to Van Rossum, it never will. However, better support for coroutine-like functionality is provided by extending Python's generators. Before 2.5, generators were lazy iterators; data was passed unidirectionally out of the generator. From Python 2.5 on, it is possible to pass data back into a generator function; and from version 3.3, it can be passed through multiple stack levels.\\n\\nExpressions\\nPython's expressions include:\\n\\nThe +, -, and * operators for mathematical addition, subtraction, and multiplication are similar to other languages, but the behavior of division differs. There are two types of divisions in Python: floor division (or integer division) // and floating-point/division. Python uses the ** operator for exponentiation.\\nPython uses the + operator for string concatenation. Python uses the * operator for duplicating a string a specified number of times.\\nThe @ infix operator. It is intended to be used by libraries such as NumPy for matrix multiplication.\\nThe syntax :=, called the \"walrus operator\", was introduced in Python 3.8. It assigns values to variables as part of a larger expression.\\nIn Python, == compares by value. Python's is operator may be used to compare object identities (comparison by reference), and comparisons may be chained\u2014for example, a <= b <= c.\\nPython uses and, or, and not as Boolean operators.\\nPython has a type of expression called a list comprehension, as well as a more general expression called a generator expression.\\nAnonymous functions are implemented using lambda expressions; however, there may be only one expression in each body.\\nConditional expressions are written as x if c else y (different in order of operands from the c ? x : y operator common to many other languages).\\nPython makes a distinction between lists and tuples. Lists are written as [1, 2, 3], are mutable, and cannot be used as the keys of dictionaries (dictionary keys must be immutable in Python). Tuples, written as (1, 2, 3), are immutable and thus can be used as keys of dictionaries, provided all of the tuple's elements are immutable. The + operator can be used to concatenate two tuples, which does not directly modify their contents, but produces a new tuple containing the elements of both. Thus, given the variable t initially equal to (1, 2, 3), executing t = t + (4, 5) first evaluates t + (4, 5), which yields (1, 2, 3, 4, 5), which is then assigned back to t\u2014thereby effectively \"modifying the contents\" of t while conforming to the immutable nature of tuple objects. Parentheses are optional for tuples in unambiguous contexts.\\nPython features sequence unpacking where multiple expressions, each evaluating to anything that can be assigned (to a variable, writable property, etc.) are associated in an identical manner to that forming tuple literals\u2014and, as a whole, are put on the left-hand side of the equal sign in an assignment statement. The statement expects an iterable object on the right-hand side of the equal sign that produces the same number of values as the provided writable expressions; when iterated through them, it assigns each of the produced values to the corresponding expression on the left.\\nPython has a \"string format\" operator % that functions analogously to printf format strings in C\u2014e.g. \"spam=%s eggs=%d\" % (\"blah\", 2) evaluates to \"spam=blah eggs=2\". In Python 2.6+ and 3+, this was supplemented by the format() method of the str class, e.g. \"spam={0} eggs={1}\".format(\"blah\", 2). Python 3.6 added \"f-strings\": spam = \"blah\"; eggs = 2; f'spam={spam} eggs={eggs}'.\\nStrings in Python can be concatenated by \"adding\" them (with the same operator as for adding integers and floats), e.g. \"spam\" + \"eggs\" returns \"spameggs\". If strings contain numbers, they are added as strings rather than integers, e.g. \"2\" + \"2\" returns \"22\".\\nPython has various string literals:\\nDelimited by single or double quotes; unlike in Unix shells, Perl, and Perl-influenced languages, single and double quotes work the same. Both use the backslash (\\) as an escape character. String interpolation became available in Python 3.6 as \"formatted string literals\".\\nTriple-quoted (beginning and ending with three single or double quotes), which may span multiple lines and function like here documents in shells, Perl, and Ruby.\\nRaw string varieties, denoted by prefixing the string literal with r. Escape sequences are not interpreted; hence raw strings are useful where literal backslashes are common, such as regular expressions and Windows-style paths. (Compare \"@-quoting\" in C#.)\\nPython has array index and array slicing expressions in lists, denoted as a[key], a[start:stop] or a[start:stop:step]. Indexes are zero-based, and negative indexes are relative to the end. Slices take elements from the start index up to, but not including, the stop index. The third slice parameter called step or stride, allows elements to be skipped and reversed. Slice indexes may be omitted\u2014for example, a[:] returns a copy of the entire list. Each element of a slice is a shallow copy.In Python, a distinction between expressions and statements is rigidly enforced, in contrast to languages such as Common Lisp, Scheme, or Ruby. This leads to duplicating some functionality. For example:\\n\\nList comprehensions vs. for-loops\\nConditional expressions vs. if blocks\\nThe eval() vs. exec() built-in functions (in Python 2, exec is a statement); the former is for expressions, the latter is for statementsStatements cannot be a part of an expression\u2014so list and other comprehensions or lambda expressions, all being expressions, cannot contain statements. A particular case is that an assignment statement such as a = 1 cannot form part of the conditional expression of a conditional statement. This has the advantage of avoiding a classic C error of mistaking an assignment operator = for an equality operator == in conditions: if (c = 1) { ... } is syntactically valid (but probably unintended) C code, but if c = 1: ... causes a syntax error in Python.\\n\\nMethods\\nMethods on objects are functions attached to the object's class; the syntax instance.method(argument) is, for normal methods and functions, syntactic sugar for Class.method(instance, argument). Python methods have an explicit self parameter to access instance data, in contrast to the implicit self (or this) in some other object-oriented programming languages (e.g., C++, Java, Objective-C, Ruby). Python also provides methods, often called dunder methods (due to their names beginning and ending with double-underscores), to allow user-defined classes to modify how they are handled by native operations including length, comparison, in arithmetic operations and type conversion.\\n\\nTyping\\nPython uses duck typing and has typed objects but untyped variable names. Type constraints are not checked at compile time; rather, operations on an object may fail, signifying that it is not of a suitable type. Despite being dynamically typed, Python is strongly typed, forbidding operations that are not well-defined (for example, adding a number to a string) rather than silently attempting to make sense of them.\\nPython allows programmers to define their own types using classes, most often used for object-oriented programming. New instances of classes are constructed by calling the class (for example, SpamClass() or EggsClass()), and the classes are instances of the metaclass type (itself an instance of itself), allowing metaprogramming and reflection.\\nBefore version 3.0, Python had two kinds of classes (both using the same syntax): old-style and new-style, current Python versions only support the semantics new style.\\nPython supports optional type annotations. These annotations are not enforced by the language, but may be used by external tools such as mypy to catch errors. Mypy also supports a Python compiler called mypyc, which leverages type annotations for optimization.\\n\\nArithmetic operations\\nPython has the usual symbols for arithmetic operators (+, -, *, /), the floor division operator // and the modulo operation % (where the remainder can be negative,  e.g. 4 % -3 == -2). It also has ** for exponentiation, e.g. 5**3 == 125 and 9**0.5 == 3.0, and a matrix\u2011multiplication operator @ . These operators work like in traditional math; with the same precedence rules, the operators infix (+ and - can also be unary to represent positive and negative numbers respectively).\\nThe division between integers produces floating-point results. The behavior of division has changed significantly over time:\\nCurrent Python (i.e. since 3.0) changed / to always be floating-point division, e.g. 5/2 == 2.5.\\nThe floor division // operator was introduced. So 7//3 == 2, -7//3 == -3, 7.5//3 == 2.0 and -7.5//3 == -3.0. Adding from __future__ import division causes a module used in Python 2.7 to use Python 3.0 rules for division (see above).In Python terms, / is true division (or simply division), and // is floor division. / before version 3.0 is classic division.Rounding towards negative infinity, though different from most languages, adds consistency. For instance, it means that the equation (a + b)//b == a//b + 1 is always true. It also means that the equation b*(a//b) + a%b == a is valid for both positive and negative values of a. However, maintaining the validity of this equation means that while the result of a%b is, as expected, in the half-open interval [0, b), where b is a positive integer, it has to lie in the interval (b, 0] when b is negative.Python provides a round function for rounding a float to the nearest integer. For tie-breaking, Python 3 uses round to even: round(1.5) and round(2.5) both produce 2. Versions before 3 used round-away-from-zero: round(0.5) is 1.0, round(-0.5) is \u22121.0.Python allows Boolean expressions with multiple equality relations in a manner that is consistent with general use in mathematics. For example, the expression a < b < c tests whether a is less than b and b is less than c. C-derived languages interpret this expression differently: in C, the expression would first evaluate a < b, resulting in 0 or 1, and that result would then be compared with c.Python uses arbitrary-precision arithmetic for all integer operations. The Decimal type/class in the decimal module provides decimal floating-point numbers to a pre-defined arbitrary precision and several rounding modes. The Fraction class in the fractions module provides arbitrary precision for rational numbers.Due to Python's extensive mathematics library, and the third-party library NumPy that further extends the native capabilities, it is frequently used as a scientific scripting language to aid in problems such as numerical data processing and manipulation.\\n\\nProgramming examples\\nHello world program:\\n\\nProgram to calculate the factorial of a positive integer:\\n\\nLibraries\\nPython's large standard library provides tools suited to many tasks and is commonly cited as one of its greatest strengths. For Internet-facing applications, many standard formats and protocols such as MIME and HTTP are supported. It includes modules for creating graphical user interfaces, connecting to relational databases, generating pseudorandom numbers, arithmetic with arbitrary-precision decimals, manipulating regular expressions, and unit testing.\\nSome parts of the standard library are covered by specifications\u2014for example, the Web Server Gateway Interface (WSGI) implementation wsgiref follows PEP 333\u2014but most are specified by their code, internal documentation, and test suites. However, because most of the standard library is cross-platform Python code, only a few modules need altering or rewriting for variant implementations.\\nAs of 14 November 2022, the Python Package Index (PyPI), the official repository for third-party Python software, contains over 415,000 packages with a wide range of functionality, including:\\n\\nDevelopment environments\\nMost Python implementations (including CPython) include a read\u2013eval\u2013print loop (REPL), permitting them to function as a command line interpreter for which users enter statements sequentially and receive results immediately.\\nPython also comes with an Integrated development environment (IDE) called IDLE, which is more beginner-oriented.\\nOther shells, including IDLE and IPython, add further abilities such as improved auto-completion, session state retention, and syntax highlighting.\\nAs well as standard desktop integrated development environments including PyCharm, IntelliJ Idea, Visual Studio Code etc, there are web browser-based IDEs, including SageMath, for developing science- and math-related programs; PythonAnywhere, a browser-based IDE and hosting environment; and Canopy IDE, a commercial IDE emphasizing scientific computing.\\n\\nImplementations\\nReference implementation\\nCPython is the reference implementation of Python. It is written in C, meeting the C89 standard (Python 3.11 uses C11) with several select C99 features. CPython includes its own C extensions, but third-party extensions are not limited to older C versions\u2014e.g. they can be implemented with C11 or C++.) It compiles Python programs into an intermediate bytecode which is then executed by its virtual machine. CPython is distributed with a large standard library written in a mixture of C and native Python, and is available for many platforms, including Windows (starting with Python 3.9, the Python installer deliberately fails to install on Windows 7 and 8; Windows XP was supported until Python 3.5) and most modern Unix-like systems, including macOS (and Apple M1 Macs, since Python 3.9.1, with experimental installer) and unofficial support for e.g. VMS. Platform portability was one of its earliest priorities. (During Python 1 and 2 development, even OS/2 and Solaris were supported, but support has since been dropped for many platforms.)\\n\\nOther implementations\\nPyPy is a fast, compliant interpreter of Python 2.7 and 3.8. Its just-in-time compiler often brings a significant speed improvement over CPython but some libraries written in C cannot be used with it.\\nStackless Python is a significant fork of CPython that implements microthreads; it does not use the call stack in the same way, thus allowing massively concurrent programs. PyPy also has a stackless version.\\nMicroPython and CircuitPython are Python 3 variants optimized for microcontrollers, including Lego Mindstorms EV3.\\nPyston is a variant of the Python runtime that uses just-in-time compilation to speed up the execution of Python programs.\\nCinder is a performance-oriented fork of CPython 3.8 that contains a number of optimizations, including bytecode inline caching, eager evaluation of coroutines, a method-at-a-time JIT, and an experimental bytecode compiler.\\nSnek Embedded Computing Language (supporting e.g. 8-bit AVR microcontrollers such as ATmega 328P-based Arduino, and larger ones that are MicroPython can also support) \"is Python-inspired, but it is not Python. It is possible to write Snek programs that run under a full Python system, but most Python programs will not run under Snek.\" It's an imperative language not including OOP/classes unlike Python, and simplifying to one number type (like JavaScript, except using smaller) 32-bit single-precision \"Integer values of less than 24 bits can be represented exactly in these floating point values\".\\n\\nUnsupported implementations\\nOther just-in-time Python compilers have been developed, but are now unsupported:\\n\\nGoogle began a project named Unladen Swallow in 2009, with the aim of speeding up the Python interpreter fivefold by using the LLVM, and of improving its multithreading ability to scale to thousands of cores, while ordinary implementations suffer from the global interpreter lock.\\nPsyco is a discontinued just-in-time specializing compiler that integrates with CPython and transforms bytecode to machine code at runtime. The emitted code is specialized for certain data types and is faster than the standard Python code. Psyco does not support Python 2.7 or later.\\nPyS60 was a Python 2 interpreter for Series 60 mobile phones released by Nokia in 2005. It implemented many of the modules from the standard library and some additional modules for integrating with the Symbian operating system. The Nokia N900 also supports Python with GTK widget libraries, enabling programs to be written and run on the target device.\\n\\nCross-compilers to other languages\\nThere are several compilers/transpilers to high-level object languages, with either unrestricted Python, a restricted subset of Python, or a language similar to Python as the source language:\\n\\nBrython, Transcrypt and Pyjs (latest release in 2012) compile Python to JavaScript.\\nCodon compiles a subset of statically typed Python to machine code (via LLVM) and supports native multithreading.\\nCython compiles (a superset of) Python  to C. The resulting code is also usable with Python via direct C-level API calls into the Python interpreter.\\nPyJL compiles/transpiles a subset of Python to \"human-readable, maintainable, and high-performance Julia source code\". Despite claiming high performance, no tool can claim to do that for arbitrary Python code; i.e. it's known not possible to compile to a faster language or machine code. Unless semantics of Python are changed, but in many cases speedup is possible with few or no changes in the Python code. The faster Julia source code can then be used from Python, or compiled to machine code, and based that way.\\nNuitka compiles Python into C.\\nNumba uses LLVM to compile a subset of Python to machine code.\\nPythran compiles a subset of Python 3 to C++ (C++11).\\nRPython can be compiled to C, and is used to build the PyPy interpreter of Python.\\nThe Python \u2192 11l \u2192 C++ transpiler compiles a subset of Python 3 to C++ (C++17).Specialized:\\n\\nMyHDL is a Python-based hardware description language (HDL), that converts MyHDL code to Verilog or VHDL code.Older projects (or not to be used with Python 3.x and latest syntax):\\n\\nGoogle's Grumpy (latest release in 2017) transpiles Python 2 to Go.\\nIronPython  allows running Python 2.7 programs (and an alpha, released in 2021, is also available for \"Python 3.4, although features and behaviors from later versions may be included\") on the .NET Common Language Runtime.\\nJython compiles Python 2.7 to Java bytecode, allowing the use of the Java libraries from a Python program.\\nPyrex (latest release in 2010) and Shed Skin (latest release in 2013) compile to C and C++ respectively.\\n\\nPerformance\\nPerformance comparison of various Python implementations on a non-numerical (combinatorial) workload was presented at EuroSciPy '13. Python's performance compared to other programming languages is also benchmarked by The Computer Language Benchmarks Game.\\n\\nDevelopment\\nPython's development is conducted largely through the Python Enhancement Proposal (PEP) process, the primary mechanism for proposing major new features, collecting community input on issues, and documenting Python design decisions. Python coding style is covered in PEP 8. Outstanding PEPs are reviewed and commented on by the Python community and the steering council.Enhancement of the language corresponds with the development of the CPython reference implementation. The mailing list python-dev is the primary forum for the language's development. Specific issues were originally discussed in the Roundup bug tracker hosted at by the foundation. In 2022, all issues and discussions were migrated to GitHub. Development originally took place on a self-hosted source-code repository running Mercurial, until Python moved to GitHub in January 2017.CPython's public releases come in three types, distinguished by which part of the version number is incremented:\\n\\nBackward-incompatible versions, where code is expected to break and needs to be manually ported. The first part of the version number is incremented. These releases happen infrequently\u2014version 3.0 was released 8 years after 2.0. According to Guido van Rossum, a version 4.0 is very unlikely to ever happen.\\nMajor or \"feature\" releases are largely compatible with the previous version but introduce new features. The second part of the version number is incremented. Starting with Python 3.9, these releases are expected to happen annually. Each major version is supported by bug fixes for several years after its release.\\nBugfix releases, which introduce no new features, occur about every 3 months and are made when a sufficient number of bugs have been fixed upstream since the last release. Security vulnerabilities are also patched in these releases. The third and final part of the version number is incremented.Many alpha, beta, and release-candidates are also released as previews and for testing before final releases. Although there is a rough schedule for each release, they are often delayed if the code is not ready. Python's development team monitors the state of the code by running the large unit test suite during development.The major academic conference on Python is PyCon. There are also special Python mentoring programs, such as PyLadies.\\nPython 3.12 removed wstr meaning Python extensions need to be modified, and 3.10 added pattern matching to the language.Python 3.12 dropped some outdated modules, and more will be dropped in the future, deprecated as of 3.13; already deprecated array 'u' format code will emit DeprecationWarning since 3.13 and will be removed in Python 3.16. The 'w' format code should be used instead. Part of ctypes is also deprecated and http.server.CGIHTTPRequestHandler will emit a DeprecationWarning, and will be removed in 3.15. Using that code already has a high potential for both security and functionality bugs. Parts of the typing module are deprecated, e.g. creating a typing.NamedTuple class using keyword arguments to denote the fields and such (and more) will be disallowed in Python 3.15.\\n\\nAPI documentation generators\\nTools that can generate documentation for Python API include pydoc (available as part of the standard library), Sphinx, Pdoc and its forks, Doxygen and Graphviz, among others.\\n\\nNaming\\nPython's name is derived from the British comedy group Monty Python, whom Python creator Guido van Rossum enjoyed while developing the language. Monty Python references appear frequently in Python code and culture; for example, the metasyntactic variables often used in Python literature are spam and eggs instead of the traditional foo and bar. The official Python documentation also contains various references to Monty Python routines. Users of Python are sometimes referred to as \"Pythonistas\".The prefix Py- is used to show that something is related to Python. Examples of the use of this prefix in names of Python applications or libraries include Pygame, a binding of SDL to Python (commonly used to create games); PyQt and PyGTK, which bind Qt and GTK to Python respectively; and PyPy, a Python implementation originally written in Python.\\n\\nPopularity\\nSince 2003, Python has consistently ranked in the top ten most popular programming languages in the TIOBE Programming Community Index where as of December 2022 it was the most popular language (ahead of C, C++, and Java). It was selected Programming Language of the Year (for \"the highest rise in ratings in a year\") in 2007, 2010, 2018, and 2020 (the only language to have done so four times as of 2020).\\nAn empirical study found that scripting languages, such as Python, are more productive than conventional languages, such as C and Java, for programming problems involving string manipulation and search in a dictionary, and determined that memory consumption was often \"better than Java and not much worse than C or C++\".Large organizations that use Python include Wikipedia, Google, Yahoo!, CERN, NASA, Facebook, Amazon, Instagram, Spotify, and some smaller entities like ILM and ITA. The social news networking site Reddit was written mostly in Python.\\n\\nUses\\nPython can serve as a scripting language for web applications, e.g. via mod_wsgi for the Apache webserver. With Web Server Gateway Interface, a standard API has evolved to facilitate these applications. Web frameworks like Django, Pylons, Pyramid, TurboGears, web2py, Tornado, Flask, Bottle, and Zope support developers in the design and maintenance of complex applications. Pyjs and IronPython can be used to develop the client-side of Ajax-based applications. SQLAlchemy can be used as a data mapper to a relational database. Twisted is a framework to program communications between computers, and is used (for example) by Dropbox.\\nLibraries such as NumPy, SciPy, and Matplotlib allow the effective use of Python in scientific computing, with specialized libraries such as Biopython and Astropy providing domain-specific functionality. SageMath is a computer algebra system with a notebook interface programmable in Python: its library covers many aspects of mathematics, including algebra, combinatorics, numerical mathematics, number theory, and calculus. OpenCV has Python bindings with a rich set of features for computer vision and image processing.Python is commonly used in artificial intelligence projects and machine learning projects with the help of libraries like TensorFlow, Keras, Pytorch, and scikit-learn. As a scripting language with a modular architecture, simple syntax, and rich text processing tools, Python is often used for natural language processing.Python can also be used for graphical user interface (GUI) by using libraries like Tkinter.Python can also be used to create games, with libraries such as Pygame, which can make 2D games.\\nPython has been successfully embedded in many software products as a scripting language, including in finite element method software such as Abaqus, 3D parametric modelers like FreeCAD, 3D animation packages such as 3ds Max, Blender, Cinema 4D, Lightwave, Houdini, Maya, modo, MotionBuilder, Softimage, the visual effects compositor Nuke, 2D imaging programs like GIMP, Inkscape, Scribus and Paint Shop Pro, and musical notation programs like scorewriter and capella. GNU Debugger uses Python as a pretty printer to show complex structures such as C++ containers. Esri promotes Python as the best choice for writing scripts in ArcGIS. It has also been used in several video games, and has been adopted as first of the three available programming languages in Google App Engine, the other two being Java and Go.Many operating systems include Python as a standard component. It ships with most Linux distributions, AmigaOS 4 (using Python 2.7), FreeBSD (as a package), NetBSD, and OpenBSD (as a package) and can be used from the command line (terminal). Many Linux distributions use installers written in Python: Ubuntu uses the Ubiquity installer, while Red Hat Linux and Fedora Linux use the Anaconda installer. Gentoo Linux uses Python in its package management system, Portage.\\nPython is used extensively in the information security industry, including in exploit development.Most of the Sugar software for the One Laptop per Child XO, developed at Sugar Labs as of 2008, is written in Python. The Raspberry Pi single-board computer project has adopted Python as its main user-programming language.\\nLibreOffice includes Python and intends to replace Java with Python. Its Python Scripting Provider is a core feature since Version 4.0 from 7 February 2013.\\n\\nLanguages influenced by Python\\nPython's design and philosophy have influenced many other programming languages:\\n\\nBoo uses indentation, a similar syntax, and a similar object model.\\nCobra uses indentation and a similar syntax, and its Acknowledgements document lists Python first among languages that influenced it.\\nCoffeeScript, a programming language that cross-compiles to JavaScript, has Python-inspired syntax.\\nECMAScript/JavaScript borrowed iterators and generators from Python.\\nGDScript, a scripting language very similar to Python, built-in to the Godot game engine.\\nGo is designed for the \"speed of working in a dynamic language like Python\" and shares the same syntax for slicing arrays.\\nGroovy was motivated by the desire to bring the Python design philosophy to Java.\\nJulia was designed to be \"as usable for general programming as Python\".\\nMojo is currently a non-strict (aims to be a strict) superset of Python (e.g. still missing classes, and adding e.g. struct), and is up to 35,000x faster for some code (mandelbrot, since it is embarrassingly parallel), where static typing helps (and MLIR it is implemented with), and, e.g. 4000 times faster for matrix multiplication.\\nNim uses indentation and similar syntax.\\nRuby's creator, Yukihiro Matsumoto, has said: \"I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That's why I decided to design my own language.\"\\nSwift, a programming language developed by Apple, has some Python-inspired syntax.Python's development practices have also been emulated by other languages. For example, the practice of requiring a document describing the rationale for, and issues surrounding, a change to the language (in Python, a PEP) is also used in Tcl, Erlang, and Swift.\\n\\nSee also\\nPython syntax and semantics\\npip (package manager)\\nList of programming languages\\nHistory of programming languages\\nComparison of programming languages\\n\\nReferences\\nSources\\n\"Python for Artificial Intelligence\". Python Wiki. 19 July 2012. Archived from the original on 1 November 2012. Retrieved 3 December 2012.\\nPaine, Jocelyn, ed. (August 2005). \"AI in Python\". AI Expert Newsletter. Amzi!. Archived from the original on 26 March 2012. Retrieved 11 February 2012.\\n\"PyAIML 0.8.5 : Python Package Index\". Pypi.python.org. Retrieved 17 July 2013.\\nRussell, Stuart J. & Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, NJ: Prentice Hall. ISBN 978-0-13-604259-4.\\n\\nFurther reading\\nDowney, Allen B. (May 2012). Think Python: How to Think Like a Computer Scientist (version 1.6.6 ed.). Cambridge University Press. ISBN 978-0-521-72596-5.\\nHamilton, Naomi (5 August 2008). \"The A-Z of Programming Languages: Python\". Computerworld. Archived from the original on 29 December 2008. Retrieved 31 March 2010.\\nLutz, Mark (2013). Learning Python (5th ed.). O'Reilly Media. ISBN 978-0-596-15806-4.\\nSummerfield, Mark (2009). Programming in Python 3 (2nd ed.). Addison-Wesley Professional. ISBN 978-0-321-68056-3.\\nRamalho, Luciano (May 2022). Fluent Python. O'Reilly Media. ISBN 978-1-4920-5632-4.\\n\\nExternal links\\n\\nOfficial website"}
{"article_name": "Artificial_intelligence", "link": "https://en.wikipedia.org/wiki/Artificial_intelligence", "text_content": "Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or other animals. It is a field of study in computer science that develops and studies intelligent machines. Such machines may be called AIs.\\nAI technology is widely used throughout industry, government, and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Google Assistant, Siri, and Alexa), self-driving cars (e.g., Waymo), generative and creative tools (ChatGPT and AI art), and superhuman play and analysis in strategy games (such as chess and Go).Alan Turing was the first person to conduct substantial research in the field that he called Machine Intelligence. Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by disappointment and loss of funding. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI spring of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence (the ability to complete any task performable by a human) is among the field's long-term goals.To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience and other fields.\\n\\nGoals\\nThe general problem of simulating (or creating) intelligence has been broken into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\\n\\nReasoning, problem-solving\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": they became exponentially slower as the problems grew larger. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\\n\\nKnowledge representation\\nKnowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as: objects, properties, categories and relations between objects; situations, events, states and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\\nAmong the most difficult problems in knowledge representation are: the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.\\n\\nPlanning and decision making\\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision making, the agent has preferences \u2013 there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.In classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning) or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain what the outcome will be.\\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g. by iteration), be heuristic, or it can be learned.Game theory describes rational behavior of multiple interacting agents, and is used in AI programs that make decisions that involve other agents.\\n\\nLearning\\nMachine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\\n\\nNatural language processing\\nNatural language processing (NLP) allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning, and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023 these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.\\n\\nPerception\\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.The field includes speech recognition, image classification, facial recognition, object recognition, and robotic perception.\\n\\nSocial intelligence\\nAffective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process or simulate human feeling, emotion and mood. For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human\u2013computer interaction.\\nHowever, this tends to give na\u00efve users an unrealistic conception of the intelligence of existing computer agents. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.\\n\\nGeneral intelligence\\nA machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.\\n\\nTechniques\\nAI research uses a wide variety of techniques to accomplish the goals above.\\n\\nSearch and optimization\\nAI can solve many problems by intelligently searching through many possible solutions. There are two very different kinds of search used in AI: state space search and local search.\\n\\nState space search\\nState space search searches through a tree of possible states to try to find a goal state. For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.Simple exhaustive searches are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. \"Heuristics\" or \"rules of thumb\" can help to prioritize choices that are more likely to reach a goal.Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and counter-moves, looking for a winning position.\\n\\nLocal search\\nLocal search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.Gradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks.Another type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).\\n\\nLogic\\nFormal Logic is used for reasoning and knowledge representation.\\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\")\\nand predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").Logical inference (or deduction) is the process of proving a new statement (conclusion) from other statements that are already known to be true (the premises).\\nA logical knowledge base also handles queries and assertions as a special case of inference.\\nAn inference rule describes what is a valid step in a proof. The most general inference rule is resolution.\\nInference can be reduced to performing a search to find a path that leads from premises to conclusions, where each step is the application of an inference rule.\\nInference performed this way is intractable except for short proofs in restricted domains. No efficient, powerful and general method has been discovered.\\nFuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.Non-monotonic logics are designed to handle default reasoning.\\nOther specialized versions of logic have been developed to describe many complex domains (see knowledge representation above).\\n\\nProbabilistic methods for uncertain reasoning\\nMany problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.Bayesian networks\\nare a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks)\\nand perception (using dynamic Bayesian networks).Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).\\nPrecise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis, and information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.\\n\\nClassifiers and statistical learning methods\\nThe simplest AI applications can be divided into two types: classifiers (e.g. \"if shiny then diamond\"), on one hand, and controllers (e.g. \"if diamond then pick up\"), on the other hand. Classifiers\\nare functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.There are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm. K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\\nThe naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.Neural networks are also used as classifiers.\\n\\nArtificial neural networks\\nAn Artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns, once trained it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses it\u2019s specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.\\nNeural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.In feedforward neural networks the signal passes in only one direction.Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.Perceptrons\\nuse only a single layer of neurons, deep learning uses multiple layers.\\nConvolutional neural networks strengthen the connection between neurons that are \"close\" to each other \u2013 this is especially important in image processing, where a local set of neurons must identify an \"edge\" before the network can identify an object.\\n\\nDeep learning\\nDeep learning\\nuses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.Deep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification\\nand others. The reason that deep learning performs so well in so many applications is not known as of 2023.\\nThe sudden success of deep learning in 2012\u20132015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)\\nbut because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.\\n\\nGPT\\nGenerative pre-trained transformers (GPT) are large language models that are based on the semantic relationships between words in sentences (natural language processing). Text-based GPT models are pre-trained on a large corpus of text which can be from the internet. The pre-training consists in predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pre-training, GPT models accumulate knowledge about the world, and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are still prone to generating falsehoods called \"hallucinations\", although this can be reduced with RLHF and quality data. They are used in chatbots which allow you to ask a question or request a task in simple text.Current models and services include: Bard, ChatGPT, Grok, Claude, Copilot and LLaMA. Multimodal GPT models can process different types of data (modalities) such as images, videos, sound and text.\\n\\nSpecialized hardware and software\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.\\nHistorically, specialized languages, such as Lisp, Prolog, Python and others, had been used.\\n\\nApplications\\nAI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's iPhoto and TikTok).\\n\\nHealth and Medicine\\nThe application of AI in medicine and medical research has the potential to increase patient care and quality of life. Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.\\nFor medical research, AI is an important tool for processing and integrating Big Data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication. \\nIt has been suggested that AI can overcome discrepancies in funding allocated to different fields of research. New AI tools can deepen our understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein. In 2023 it was reported that AI guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.\\n\\nGames\\nGame playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then it defeated Ke Jie in 2017, who at the time continuously held the world No. 1 ranking for two years. Other programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus and Cepheus. DeepMind in the 2010s developed a \"generalized artificial intelligence\" that could learn many diverse Atari games on its own. In 2021 an AI agent competed in a Playstation Gran Turismo competition, winning against four of the world\u2019s best Gran Turismo drivers using deep reinforcement learning. In 2023, there was a study by Deep Mind which used StarCraft II - which is one of the most challenging simulated reinforcement learning environments with multi-agent dynamics, to improve the performance of their agents in complex environments.\\n\\nDMilitary\\nVarious countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams. AI was incorporated into military operations in Iraq and Syria. On November 1, 2024, current US Vice President Kamala Harris disclosed a declaration signed by 31 nations, committing to implementing legal reviews, training, and transparent development to establish guardrails for the military use of AI.\\n\\nGenerative AI\\nIn the early 2020s, generative AI gained widespread prominence. ChatGPT, based on GPT-3, and other large language models, were tried by 14% of Americans adults. The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion sparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat, the fictional arrest of Donald Trump, and a hoax of an attack on the Pentagon, as well as the usage in professional creative arts.\\n\\nIndustry Specific Tasks\\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported they had incorporated \"AI\" in some offerings or processes. A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\\nIn agriculture, AI has helped farmers identify areas that need irrigation, fertilization, pesticide treatments or increasing yield. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\\n\\nEthics\\nAI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified.Anyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning.\\n\\nRisks and harm\\nPrivacy and copyright\\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\\nTechnology companies collect a wide range of data from their users, including online activity, geolocation data, video and audio.\\nFor example, in order to build speech recognition algorithms, Amazon have recorded millions of private conversations and allowed temps to listen to and transcribe some of them.\\nOpinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.AI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy. Since 2016, some privacy experts, such as Cynthia Dwork, began to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\".Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under a rationale of \"fair use\". Also website owners who do not wish to have their copyrighted content be AI indexed or \u2018scraped\u2019 can add code to their site, as you would, if you did not want your website to be indexed by a search engine which is currently available to certain services such as OpenAI. Experts disagree about how well, and under what circumstances, this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\". In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.\\n\\nMisinformation\\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem.\\nIn 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films or human writing. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda. AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.\\n\\nAlgorithmic bias and fairness\\nMachine learning applications will be biased if they learn from biased data.\\nThe developers may not be aware that the bias exists.\\nBias can be introduced by the way training data is selected and by the way a model is deployed. If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.Fairness in machine learning is the study of how to prevent the harm caused by algorithmic bias. It has become serious area of academic study within AI. Researchers have discovered it is not always possible to define \"fairness\" in a way that satisfies all stakeholders.On June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people, a problem called \"sample size disparity\". Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist.\\nIn 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different\u2014the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. In 2017, several researchers showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".\\nMoritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"Criticism of COMPAS highlighted a deeper problem with the misuse of AI. Machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. Unfortunately, if an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist. Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is necessarily descriptive and not proscriptive.Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022) the Association for Computing Machinery, in Seoul, South Korea, presented and published findings recommending that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.\\n\\nLack of transparency\\nMany AI systems are so complex that their designers cannot explain how they reach their decisions. Particularly with deep neural networks, in which there are a large amount of non-linear relationships between inputs and outputs. But some popular explainability techniques exist.There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale. Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.People who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are required to clearly and completely explain the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists. Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.DARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try and solve these problems.There are several potential solutions to the transparency problem. SHAP helps visualise the contribution of each feature to the output. LIME can locally approximate a model with a simpler, interpretable model. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network have learned and produce output that can suggest what the network is learning.\\n\\nConflict, surveillance and weaponized AI\\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. By 2015, over fifty countries were reported to be researching battlefield robots. These weapons are considered especially dangerous for several reasons: if they kill an innocent person it is not clear who should be held accountable, it is unlikely they will reliably choose targets, and, if produced at scale, they are potentially weapons of mass destruction. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.AI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes and generative AI aid in producing misinformation; advanced AI can make authoritarian centralized decision making more competitive with liberal and decentralized systems such as markets.AI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic. Terrorists, criminals and rogue states can use weaponized AI such as advanced digital warfare and lethal autonomous weapons. Machine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.\\n\\nTechnological unemployment\\nFrom the early days of the development of artificial intelligence there have been arguments, for example those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed. Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\". The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.In April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.\\n\\nExistential risk\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\". This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character. These sci-fi scenarios are misleading in several ways.\\nFirst, AI does not require human-like \"sentience\" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager). Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\" In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\".Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. Personalities such as Stephen Hawking, Bill Gates, and Elon Musk have expressed concern about existential risk from AI.In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine. However, after 2016, the study of current and future risks and possible solutions became a serious area of research.AI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI. In 2023, many leading AI experts issued the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".Other researchers, however, spoke in favor of a less dystopian view. AI pioneer Juergen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\" While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\" Andrew Ng also argued that \"it\u2019s a mistake to fall for the doomsday hype on AI\u2014and that regulators who do will only benefit vested interests.\" Yann LeCun \"scoffs at his peers\u2019 dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"\\n\\nLimiting AI\\nPossible options for limiting AI include: using Embedded Ethics or Constitutional AI where companies or governments can add a policy, restricting high levels of compute power in training, restricting the ability to rewrite its own code base, restrict certain AI techniques but not in the training phase, open-source (transparency) vs proprietary (could be more restricted), backup model with redundancy, restricting security, privacy and copyright, restricting or controlling the memory, real-time monitoring, risk analysis, emergency shut-off, rigorous simulation and testing, model certification, assess known vulnerabilities, restrict the training material, restrict access to the internet, issue terms of use.\\n\\nEthical machines and alignment\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\\nThe field of machine ethics is also called computational morality,\\nand was founded at an AAAI symposium in 2005.Other approaches include Wendell Wallach's \"artificial moral agents\"\\nand Stuart J. Russell's three principles for developing provably beneficial machines.\\n\\nFrameworks\\nArtificial Intelligence projects can have their ethical permissibility tested while designing, developing, and implementing an AI system. An AI framework such as the Care and Act Framework containing the SUM values \u2013 developed by the Alan Turing Institute tests projects in four main areas:\\nRESPECT the dignity of individual people\\nCONNECT with other people sincerely, openly and inclusively\\nCARE for the wellbeing of everyone\\nPROTECT social values, justice and the public interestOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others; however, these principles do not go without their criticisms, especially regards to the people chosen contributes to these frameworks.Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\\n\\nRegulation\\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.\\nThe regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.\\nBetween 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.\\nMost EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, US and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.\\nThe Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.\\nIn 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, governments officials and academics.In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.\\nIn a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".In November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks. 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.\\n\\nHistory\\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate both mathematical deduction and formal reasoning, which is known as the Church\u2013Turing thesis. This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \"electronic brain\".Alan Turing was thinking about machine intelligence at least as early as 1941, when he circulated a paper on machine intelligence which could be the earliest paper in the field of AI \u2013 though it is now lost. The first available paper generally recognized as \"AI\" was McCullouch and Pitts design for Turing-complete \"artificial neurons\" in 1943 \u2013 the first mathematical model of a neural network. The paper was influenced by Turing's earlier paper 'On Computable Numbers' from 1936 using similar two-state boolean 'neurons', but was the first to apply it to neuronal function.The term 'Machine Intelligence' was used by Alan Turing during his life which was later often referred to as 'Artificial Intelligence' after his death in 1954. In 1950 Turing published the best known of his papers 'Computing Machinery and Intelligence', the paper introduced his concept of what is now known as the Turing test to the general public. Then followed three radio broadcasts on AI by Turing, the lectures: 'Intelligent Machinery, A Heretical Theory\u2019, \u2018Can Digital Computers Think\u2019? and the panel discussion \u2018Can Automatic Calculating Machines be Said to Think\u2019. By 1956 computer intelligence had been actively pursued for more than a decade in Britain; the earliest AI programmes were written there in 1951\u20131952.In 1951, using a Ferranti Mark 1 computer of the University of Manchester, checkers and chess programs were wrote where you could play against the computer. The field of American AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial Intelligence laboratories were set up at a number of British and US Universities in the latter 1950s and early 1960s.They had, however, underestimated the difficulty of the problem. Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.Many researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches. Robotics researchers, such as Rodney Brooks, rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).\\nBy 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".Several academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.\\nFor many specific tasks, other methods were abandoned.\\nDeep learning's success was based on both hardware improvements (faster computers, graphics processing units, cloud computing)\\nand access to large amounts of data (including curated datasets, such as ImageNet).\\nDeep learning's success led to an enormous increase in interest and funding in AI.\\nThe amount of machine learning research (measured by total publications) increased by 50% in the years 2015\u20132019,\\nand WIPO reported that AI was the most prolific emerging technology in terms of the number of patent applications and granted patents.\\nAccording to 'AI Impacts', about $50 billion annually was invested in \"AI\" around 2022 in the US alone and about 20% of new US Computer Science PhD graduates have specialized in \"AI\";\\nabout 800,000 \"AI\"-related US job openings existed in 2022. The large majority of the advances have occurred within the United States, with its companies, universities, and research labs leading artificial intelligence research.In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\\n\\nPhilosophy\\nDefining artificial intelligence\\nAlan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\" He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\". He devised the Turing test, which measures the ability of a machine to simulate human conversation. Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks\"Russell and Norvig agree with Turing that AI must be defined in terms of \"acting\" and not \"thinking\". However, they are critical that the test compares machines to people. \"Aeronautical engineering texts,\" they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\" AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world.\" Another AI founder, Marvin Minsky similarly defines it as \"the ability to solve hard problems\". These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine\u2014and no other philosophical discussion is required, or may not even be possible.\\nAnother definition has been adopted by Google, a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\\n\\nEvaluating approaches to AI\\nNo established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.\\n\\nSymbolic AI and its limits\\nSymbolic AI (or \"GOFAI\") simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult. Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge. Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\\n\\nNeat vs. scruffy\\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s, but eventually was seen as irrelevant. Modern AI has elements of both.\\n\\nSoft vs. hard computing\\nFinding a provably correct or optimal solution is intractable for many important problems. Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\n\\nNarrow vs. general AI\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals. General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\\n\\nMachine consciousness, sentience and mind\\nThe philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\n\\nConsciousness\\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). Human information processing is easy to explain, however, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.\\n\\nComputationalism and functionalism\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind\u2013body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.Philosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\" Searle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.\\n\\nRobot rights\\nIf a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights. Any hypothetical robot rights would lie on a spectrum with animal rights and human rights. This issue has been considered in fiction for centuries, and is now being considered by, for example, California's Institute for the Future; however, critics argue that the discussion is premature.\\n\\nFuture\\nSuperintelligence and the singularity\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\\n\\nTranshumanism\\nRobot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.Edward Fredkin argues that \"artificial intelligence is the next stage in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.\\n\\nIn fiction\\nThought-capable artificial beings have appeared as storytelling devices since antiquity, and have been a persistent theme in science fiction.A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel \u010capek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\\n\\nSee also\\nAI effect\\nArtificial intelligence detection software \u2013 Software to detect AI-generated contentPages displaying short descriptions of redirect targets\\nArtificial intelligence in healthcare \u2013 Overview of the use of artificial intelligence in healthcare\\nBehavior selection algorithm \u2013 Algorithm that selects actions for intelligent agents\\nBusiness process automation \u2013 Technology-enabled automation of complex business processes\\nCase-based reasoning \u2013 Process of solving new problems based on the solutions of similar past problems\\nEmergent algorithm \u2013 Algorithm exhibiting emergent behavior\\nFemale gendering of AI technologies\\nGlossary of artificial intelligence \u2013 List of definitions of terms and concepts commonly used in the study of artificial intelligence\\nRobotic process automation \u2013 Form of business process automation technology\\nWeak artificial intelligence \u2013 Form of artificial intelligence\\nWetware computer \u2013 Computer composed of organic material\\nIntelligence amplification \u2013 Use of information technology to augment human intelligence\\n\\nExplanatory notes\\nReferences\\nAI textbooks\\nThe two most widely used textbooks in 2023. (See the Open Syllabus).\\n\\nRussell, Stuart J.; Norvig, Peter. (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0134610993. LCCN 20190474.\\nRich, Elaine; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0070087705.These were the four of the most widely used AI textbooks in 2008:\\n\\nHistory of AI\\nOther sources\\nFurther reading\\nExternal links\\n\\n\"Artificial Intelligence\". Internet Encyclopedia of Philosophy.\\nThomason, Richmond. \"Logic and Artificial Intelligence\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\\nArtificial Intelligence. BBC Radio 4 discussion with John Agar, Alison Adam & Igor Aleksander (In Our Time, 8 December 2005).\\nTheranostics and AI\u2014The Next Advance in Cancer Precision Medicine."}
{"article_name": "SpaceX", "link": "https://en.wikipedia.org/wiki/SpaceX", "text_content": "Space Exploration Technologies Corp. commonly referred to as SpaceX, is an American spacecraft manufacturer, launch service provider, defense contractor and satellite communications company headquartered in Hawthorne, California. The company was founded in 2002 by Elon Musk with the goal of reducing space transportation costs and to colonize Mars. The company currently operates the Falcon 9 and Falcon Heavy rockets along with the Dragon and Starship spacecraft.\\nThe company offers internet service via its Starlink satellites, which became the largest-ever satellite constellation in January 2020 and as of November 2023 comprised more than 5,000 small satellites in orbit.Meanwhile, the company is developing Starship, a human-rated, fully-reusable, super heavy-lift launch system for interplanetary and orbital spaceflight. On its first flight in April 2023, it became the largest and most powerful rocket ever flown. The rocket reached space on its second flight that took place in November 2023.\\nSpaceX is the first private company to develop a liquid-propellant rocket that has reached orbit; to launch, orbit, and recover a spacecraft; to send a spacecraft to the International Space Station; and to send astronauts to the International Space Station. It is also the first organization of any type to achieve a vertical propulsive landing of an orbital rocket booster and the first to reuse such a booster. The company's Falcon 9 rockets have landed and reflown more than 200 times. As of December 2023, SpaceX has around $180 billion valuation.\\n\\nHistory\\n2001\u20132004: Founding\\nIn early 2001, Elon Musk met Robert Zubrin and donated US$100,000 to his Mars Society, joining its board of directors for a short time.:\u200a30\u201331\u200a He gave a plenary talk at their fourth convention where he announced Mars Oasis, a project to land a greenhouse and grow plants on Mars. Musk initially attempted to acquire a Dnepr ICBM for the project through Russian contacts from Jim Cantrell.When Musk returned to Moscow, Russia, with Michael Griffin, they found the Russians increasingly unreceptive. On the flight home Musk announced he could start a company to build the affordable rockets they needed instead. By applying vertical integration, using cheap commercial off-the-shelf components when possible, and adopting the modular approach of modern software engineering, Musk believed SpaceX could significantly cut launch price. Griffin would later be appointed NASA administrator, and play a part in the formation of the COTS program.In early 2002, Musk started to look for staff for his company, soon to be named SpaceX. Musk approached five people for the initial positions at the fledgling company, including Michael Griffin who was offered the position of Chief Engineer, Jim Cantrel and John Garvey (Cantrel and Garvey would later found the company Vector Launch), rocket engineer Tom Mueller, and Chris Thompson. SpaceX was first headquartered in a warehouse in El Segundo, California. Early SpaceX employees, such as Tom Mueller (CTO), Gwynne Shotwell (COO), and Chris Thompson (VP of Operations), came from neighboring TRW and Boeing corporations. By November 2005, the company had 160 employees. Musk personally interviewed and approved all of SpaceX's early employees.\\nMusk has stated that one of his goals with SpaceX is to decrease the cost and improve the reliability of access to space, ultimately by a factor of ten.\\n\\n2005\u20132009: Falcon 1 and first orbital launches\\nSpaceX developed its first orbital launch vehicle, the Falcon 1, with internal funding.\\nThe Falcon 1 was an expendable two-stage-to-orbit small-lift launch vehicle.\\nThe total development cost of Falcon 1 was approximately $90 million to $100 million. The Falcon rocket series was named after Star Wars's Millennium Falcon fictional spacecraft.In 2004, SpaceX protested against NASA to the Government Accountability Office (GAO) because of a sole-source contract awarded to Kistler Aerospace. Before the GAO could respond, NASA withdrew the contract, and formed the COTS program. In 2005, SpaceX announced plans to pursue a human-rated commercial space program through the end of the decade, a program that would later become the Dragon spacecraft.\\nIn 2006, the company was selected by NASA and awarded $396 million to provide crew and cargo resupply demonstration contracts to the ISS under the COTS program.The first two Falcon 1 launches were purchased by the United States Department of Defense under the DARPA Falcon Project which evaluated new US launch vehicles suitable for use in hypersonic missile delivery for Prompt Global Strike. The first three launches of the rocket, between 2006 and 2008, all resulted in failures, which almost ended the company. Financing for Tesla Motors had failed, as well, and consequently Tesla, SolarCity, and Musk personally were all nearly bankrupt at the same time. Musk was reportedly \"waking from nightmares, screaming and in physical pain\" because of the stress.The financial situation started to turn around with the first successful launch achieved on the fourth attempt on 28 September 2008. Musk split his remaining $30 million between SpaceX and Tesla, and NASA awarded the first Commercial Resupply Services (CRS) contract awarding $1.6 billion to SpaceX in December, thus financially saving the company. Based on these factors and the further business operations they enabled, the Falcon 1 was soon retired following its second successful, and fifth total, launch in July 2009; this allowed SpaceX to focus company resources on the development of a larger orbital rocket, the Falcon 9. Gwynne Shotwell was also promoted to company president at this time, for her role in successfully negotiating the CRS contract.\\n\\n2010\u20132012: Falcon 9, Dragon, and NASA contracts\\nSpaceX originally intended to follow its light Falcon 1 launch vehicle with an intermediate capacity vehicle, the Falcon 5. The company instead decided in 2005 to proceed with the development of the Falcon 9, a reusable heavier lift vehicle. Development of the Falcon 9 was accelerated by NASA, which committed to purchasing several commercial flights if specific capabilities were demonstrated. This started with seed money from the Commercial Orbital Transportation Services (COTS) program in 2006.\\nThe overall contract award was $278 million to provide development funding for the Dragon spacecraft, Falcon 9, and demonstration launches of Falcon 9 with Dragon.\\nAs part of this contract, the Falcon 9 launched for the first time in June 2010 with the Dragon Spacecraft Qualification Unit, using a mockup of the Dragon spacecraft.\\nThe first operational Dragon spacecraft was launched in December 2010 aboard COTS Demo Flight 1, the Falcon 9's second flight, and safely returned to Earth after two orbits, completing all its mission objectives. By December 2010, the SpaceX production line was manufacturing one Falcon 9 and Dragon every three months.In April 2011, as part of its second-round Commercial Crew Development (CCDev) program, NASA issued a $75 million contract for SpaceX to develop an integrated launch escape system for Dragon in preparation for human-rating it as a crew transport vehicle to the ISS. NASA awarded SpaceX a fixed-price Space Act Agreement (SAA) to produce a detailed design of the crew transportation system in August 2012.In early 2012, approximately two-thirds of SpaceX stock was owned by Musk and his seventy million shares were then estimated to be worth $875 million on private markets, valuing SpaceX at $1.3 billion. In May 2012, with the Dragon C2+ launch Dragon became the first commercial spacecraft to deliver cargo to the International Space Station.\\nAfter the flight, the company private equity valuation nearly doubled to $2.4 billion or $20/share. By that time, SpaceX had operated on total funding of approximately $1 billion over its first decade of operation. Of this, private equity provided approximately $200 million, with Musk investing approximately $100 million and other investors having put in about $100 million.SpaceX's active reusability test program began in late 2012 with testing low-altitude, low-speed aspects of the landing technology. The Falcon 9 prototypes performed vertical takeoffs and landings (VTOL). High-velocity, high-altitude tests of the booster atmospheric return technology began in late 2013.\\n\\n2013\u20132015: Commercial launches and rapid growth\\nSpaceX launched the first commercial mission for a private customer in 2013. In 2014, SpaceX won nine contracts out of the 20 that were openly competed worldwide.\\nThat year Arianespace requested that European governments provide additional subsidies to face the competition from SpaceX.\\nBeginning in 2014, SpaceX capabilities and pricing also began to affect the market for launch of U.S. military payloads, which for nearly a decade had been dominated by the large U.S. launch provider United Launch Alliance (ULA).\\nThe monopoly had allowed launch costs by the U.S. provider to rise to over $400 million over the years.\\nIn September 2014, NASA\u2019s Director of Commercial Spaceflight, Kevin Crigler, awarded SpaceX the Commercial Crew Transportation Capability (CCtCap) contract to finalize the development of the Crew Transportation System. The contract included several technical and certification milestones, an uncrewed flight test, a crewed flight test, and six operational missions after certification.In January 2015, SpaceX raised $1 billion in funding from Google and Fidelity, in exchange for 8.33% of the company, establishing the company valuation at approximately $12 billion.\\nThe same month SpaceX announced the development of a new satellite constellation, called Starlink, to provide global broadband internet service with 4,000 satellites.The Falcon 9 had its first major failure in late June 2015, when the seventh ISS resupply mission, CRS-7 exploded two minutes into the flight. The problem was traced to a failed 2-foot-long steel strut that held a helium pressure vessel, which broke free due to the force of acceleration. This caused a breach and allowed high-pressure helium to escape into the low-pressure propellant tank, causing the failure.\\n\\n2015\u20132017: Reusability milestones\\nSpaceX first achieved a successful landing and recovery of a first stage in December 2015 with Falcon 9 Flight 20.\\nIn April 2016, the company achieved the first successful landing on the autonomous spaceport drone ship (ASDS) Of Course I Still Love You in the Atlantic Ocean.\\nBy October 2016, following the successful landings, SpaceX indicated they were offering their customers a 10% price discount if they choose to fly their payload on a reused Falcon 9 first stage.A second major rocket failure happened in early September 2016, when a Falcon 9 exploded during a propellant fill operation for a standard pre-launch static fire test. The payload, the AMOS-6 communications satellite valued at $200 million, was destroyed. The explosion was caused by the liquid oxygen that is used as propellant turning so cold that it solidified and ignited with carbon composite helium vessels. Though not considered an unsuccessful flight, the rocket explosion sent the company into a four-month launch hiatus while it worked out what went wrong. SpaceX returned to flight in January 2017.Later that year, in March 2017, SpaceX launched a returned Falcon 9 for the SES-10 satellite. This was the first time a re-launch of a payload-carrying orbital rocket went back to space. The first stage was recovered again, also making it the first landing of a reused orbital class rocket.\\n\\n2017\u20132018: Leading global commercial launch provider\\nIn July 2017, the company raised $350 million, which raised its valuation to $21 billion.\\nIn 2017, SpaceX achieved a 45% global market share for awarded commercial launch contracts.\\nBy March 2018, SpaceX had more than 100 launches on its manifest representing about $12 billion in contract revenue. The contracts included both commercial and government (NASA/DOD) customers. This made SpaceX the leading global commercial launch provider measured by manifested launches.In 2017, SpaceX formed a subsidiary, The Boring Company, and began work to construct a short test tunnel on and adjacent to the SpaceX headquarters and manufacturing facility, using a small number of SpaceX employees, which was completed in May 2018, and opened to the public in December 2018. During 2018, The Boring Company was spun out into a separate corporate entity with 6% of the equity going to SpaceX, less than 10% to early employees, and the remainder of the equity to Elon Musk.\\n\\n2019\u2013present: Starship, Starlink, and first crewed launches\\nIn January 2019, SpaceX announced it would lay off 10% of its workforce to help finance the Starship and Starlink projects.\\nConstruction of initial prototypes and tests for Starship started in early 2019 in Florida and Texas. All Starship construction and testing moved to the new SpaceX South Texas launch site later that year.\\nIn May 2019, SpaceX also launched the first large batch of 60 Starlink satellites, beginning to deploy what would become the world's largest commercial satellite constellation the following year.\\nThe company raised $1.33 billion of capital across three funding rounds in 2019.\\nBy May 2019, the valuation of SpaceX had risen to $33.3 billion and reached $36 billion by March 2020.A significant milestone was achieved in May 2020, when SpaceX successfully launched two NASA astronauts (Doug Hurley and Bob Behnken) into orbit on a Crew Dragon spacecraft during Crew Dragon Demo-2, making SpaceX the first private company to send astronauts to the International Space Station and marking the first crewed orbital launch from American soil in 9 years.\\nThe mission launched from Kennedy Space Center Launch Complex 39A (LC-39A) of the Kennedy Space Center in Florida.On 19 August 2020, after a $1.9 billion funding round, one of the largest single fundraising pushes by any privately held company, SpaceX's valuation increased to $46 billion.In February 2021, SpaceX raised an additional $1.61 billion in an equity round from 99 investors at a per share value of approximately $420, raising the company valuation to approximately $74 billion. By 2021, SpaceX had raised more than $6 billion in equity financing. Most of the capital raised since 2019 has been used to support the operational fielding of the Starlink satellite constellation and the development and manufacture of the Starship launch vehicle. By October 2021, the valuation of SpaceX had risen to $100.3 billion. On 16 April 2021, Starship HLS won the contract, and will play a critical role in the Artemis program. By 2021, SpaceX had entered into agreements with Google Cloud Platform and Microsoft Azure to provide on-ground computer and networking services for Starlink. A new round of financing in 2022 values SpaceX at $127 billion.In July 2021, SpaceX unveiled another drone ship named A Shortfall of Gravitas, landing a booster from CRS-23 on it for the first time on 29 August 2021. Within the first 130 days of 2022, SpaceX had 18 rocket launches and two astronaut splashdowns. Most 2022 SpaceX launches have focused on Starlink, a consumer internet business that sends batches of internet-beaming satellites and now has over 2,200 satellites in orbit. On 13 December 2021, company CEO Elon Musk announced that the company was starting a carbon dioxide removal program that would convert captured carbon into rocket fuel, after he announced a $100 million donation to the X Prize Foundation the previous February to provide the monetary rewards to winners in a contest to develop the best carbon capture technology.On 16 July 2021 SpaceX entered an agreement to acquire Swarm Technologies, a private company building a low Earth orbit satellite constellation for communications with Internet of things (IoT) devices, for $524 million.In August 2022, Reuters reported that the European Space Agency (ESA) began initial discussions with SpaceX that could lead to the company's launchers being used temporarily, given that Russia blocked access to Soyuz rockets amid the Russian invasion of Ukraine. Since that same invasion and in the greater war between Russia and Ukraine, Starlink was extensively used.In December 2022, the U.S. Federal Communications Commission (FCC) approved to launch up to 7,500 of SpaceX's next-generation satellites in its Starlink internet network.In 2022, SpaceX's Falcon 9 became the world record holder for the most launches of a single vehicle type in a single year. SpaceX launched a rocket approximately every six days in 2022, with 61 launches in total. All but one (a Falcon Heavy in November) was on a Falcon 9 rocket.On 20 April 2023, Starship's first orbital flight test ended in a mid-air explosion over the Gulf of Mexico before booster separation. After launch, multiple engines in the booster progressively failed, causing the vehicle to reach max q later than planned. Eventually, the vehicle lost control and spun erratically until the automated flight termination system was activated, which intentionally destroyed the rocket. Elon Musk, SpaceX, and other individuals familiar with the space industry have referred to the test flight as a success.Musk said at the time that it would take between \u201csix to eight weeks\u201d to get the infrastructure prepared for another launch. In October 2023, a senior SpaceX executive stated the company had been ready to launch the next test flight since September. He accused government regulators of disrupting the project's progress, adding the delay could lead to China beating US astronauts back to the moon.On November 18, 2023, SpaceX launched its second integrated Starship test, with both vehicles flying for a few minutes before separately exploding.In November 2023, SpaceX announced it would acquire its parachute supplier Pioneer Aerospace out of bankruptcy for $2.2 million.\\n\\nSummary of achievements\\nHardware\\nLaunch vehicles\\nSpaceX has developed three launch vehicles. The small-lift Falcon 1 was the first launch vehicle developed and was retired in 2009. The medium-lift Falcon 9 and the heavy-lift Falcon Heavy are both operational.\\nFalcon 1 was a small rocket capable of placing several hundred kilograms into low Earth orbit. It launched five times between 2006 and 2009, of which 2 were successful. The Falcon 1 was the first privately funded, liquid-fueled rocket to reach orbit.Falcon 9 is a medium-lift launch vehicle capable of delivering up to 22,800 kilograms (50,265 lb) to orbit, competing with the Delta IV and the Atlas V rockets, as well as other launch providers around the world. It has nine Merlin engines in its first stage. The Falcon 9 v1.0 rocket successfully reached orbit on its first attempt on 4 June 2010. Its third flight, COTS Demo Flight 2, launched on 22 May 2012, and launched the first commercial spacecraft to reach and dock with the International Space Station (ISS). The vehicle was upgraded to Falcon 9 v1.1 in 2013, Falcon 9 Full Thrust in 2015, and finally to Falcon 9 Block 5 in 2018. The first stage of Falcon 9 is designed to retropropulsively land, be recovered, and reflown.Falcon Heavy is a heavy-lift launch vehicle capable of delivering up to 63,800 kg (140,700 lb) to Low Earth orbit (LEO) or 26,700 kg (58,900 lb) to geosynchronous transfer orbit (GTO). It uses three slightly modified Falcon 9 first stage cores with a total of 27 Merlin 1D engines. The Falcon Heavy successfully flew its inaugural mission on 6 February 2018, launching Musk's personal Tesla Roadster into heliocentric orbitBoth the Falcon 9 and Falcon Heavy are certified to conduct launches for the National Security Space Launch (NSSL). As of 24 January 2024, the Falcon 9 and Falcon Heavy have been launched 301 times, resulting in 299 full mission successes, one partial success, and one in-flight failure. In addition, a Falcon 9 experienced a pre-flight failure prior to a static fire test in 2016.SpaceX is developing a fully reusable super-heavy lift launch system known as Starship. It comprises a reusable first stage, called Super Heavy, and the reusable Starship second stage space vehicle. The system is intended to supersede the company's existing launch vehicle hardware by the early 2020s.\\n\\nRocket engines\\nSince the founding of SpaceX in 2002, the company has developed several rocket engines \u2013 Merlin, Kestrel, and Raptor \u2013 for use in launch vehicles, Draco for the reaction control system of the Dragon series of spacecraft, and SuperDraco for abort capability in Crew Dragon.Merlin is a family of rocket engines that uses liquid oxygen (LOX) and RP-1 propellants. Merlin was first used to power the Falcon 1's first stage and is now used on both stages of the Falcon 9 and Falcon Heavy vehicles.\\nKestrel uses the same propellants and was used as the Falcon 1 rocket's second stage main engine.Draco and SuperDraco are hypergolic liquid-propellant rocket engines. Draco engines are used on the reaction control system of the Dragon and Dragon 2 spacecraft. The SuperDraco engine is more powerful, and eight SuperDraco engines provide launch escape capability for crewed Dragon 2 spacecraft during an abort scenario.Raptor is a new family of liquid oxygen and liquid methane-fueled full-flow staged combustion cycle engines to power the first and second stages of the in-development Starship launch system. Development versions were test-fired in late 2016, and the engine flew for the first time in 2019, powering the Starhopper vehicle to an altitude of 20 m (66 ft).\\n\\nDragon spacecraft\\nSpaceX has developed the Dragon spacecraft to transport cargo and crew to the International Space Station. The first version of Dragon, used only for cargo, was first launched in 2010. The currently operational second generation Dragon spacecraft, known as Dragon 2, conducted its first flight, without crew, to the ISS in early 2019, followed by a crewed flight of Dragon 2 in 2020.\\nThe cargo variant of Dragon 2 flew for the first time in December 2020, for a resupply to the Space Station as part of the CRS contract with NASA.In March 2020 SpaceX revealed the Dragon XL, designed as a resupply spacecraft for NASA's planned Lunar Gateway space station under a Gateway Logistics Services (GLS) contract. Dragon XL is planned to launch on the Falcon Heavy, and is able to transport over 5,000 kg (11,000 lb) to the Gateway. Dragon XL will be docked at the Gateway for six to twelve months at a time.\\n\\nAutonomous spaceport drone ships\\nSpaceX routinely returns the first stage of Falcon 9 and Falcon Heavy rockets after orbital launches. The rocket flights and land to a predetermined landing site using only its own propulsion systems.\\nWhen propellant margins do not permit a return to launch site (RTLS), rockets return to floating landing platform in the ocean, called autonomous spaceport drone ships (ASDS).SpaceX also plans to introduce floating launch platforms. These are modified oil rigs to use in the 2020s to provide a sea launch option for their second-generation launch vehicle: the heavy-lift Starship system, consisting of the Super Heavy booster and Starship second stage.\\n\\nStarlink\\nStarlink is an internet satellite constellation under development by SpaceX that consists of thousands of cross-linked communications satellites in ~550 km orbits. Owned and operated by SpaceX, its goal is to address the significant unmet demand worldwide for low-cost broadband capabilities.Development began in 2015, and initial prototype test-flight satellites were launched on the SpaceX Paz satellite mission in 2017. In May 2019, SpaceX launched the first batch of 60 satellites aboard a Falcon 9. Initial test operation of the constellation began in late 2020 and first orders were taken in early 2021. Customers were told to expect internet service speeds of 50 Mbit/s to 150 Mbit/s and latency from 20 ms to 40 ms. In December 2022, Starlink reached over 1 million subscribers worldwide.The planned large number of Starlink satellites has been criticized by astronomers due to concerns over light pollution, with the brightness of Starlink satellites in both optical and radio wavelengths interfering with scientific observations. In response, SpaceX has implemented several upgrades to Starlink satellites aimed at reducing their brightness. The large number of satellites employed by Starlink also creates long-term dangers of space debris collisions. However, the satellites are equipped with krypton-fueled Hall thrusters which allow them to de-orbit at the end of their life. They are also designed to autonomously avoid collisions based on uplinked tracking data.In December 2022, SpaceX announced Starshield, a program to incorporate military or government entity payloads on board a Starlink-derived satellite bus. The Space Development Agency is a key customer procuring satellites for a space-based missile defense system.\\n\\nOther projects\\nIn June 2015, SpaceX announced that they would sponsor a Hyperloop competition, and would build a 1.6 km (0.99 mi) long subscale test track near SpaceX's headquarters for the competitive events. The company has held the annual competition since 2017.In collaboration with doctors and academic researchers, SpaceX invited all employees to participate in the creation of a COVID-19 antibody-testing program in 2020. As such, 4300 employees volunteered to provide blood-samples resulting in a peer-reviewed scientific paper crediting eight SpaceX employees as coauthors and suggesting that a certain level of COVID-19 antibodies may provide lasting protection against the virus.In July 2018, Musk arranged for his employees to build a mini-submarine to assist the rescue of children stuck in a flooded cavern in Thailand. Richard Stanton, leader of the international rescue diving team, urged Musk to facilitate the construction of the vehicle as a back-up, in case flooding worsened. Engineers at SpaceX and The Boring Company built the mini-submarine from a Falcon 9 liquid oxygen transfer tube in eight hours and personally delivered it to Thailand. By this time, however, eight of the 12 children had already been rescued using full face masks and oxygen under anesthesia; consequently Thai authorities declined to use the submarine.\\n\\nFacilities\\nSpaceX is headquartered in Hawthorne, California, which also serves as its primary manufacturing plant. The company operates a research and major operation in Redmond, Washington, owns a test site in Texas and operates three launch sites, with another under development. SpaceX also operates regional offices in Texas, Virginia, and Washington, D.C. SpaceX was incorporated in the state of Delaware.\\n\\nHeadquarters, mission control, manufacturing, and refurbishment facilities\\nSpaceX Headquarters is located in the Los Angeles suburb of Hawthorne, California. The large three-story facility, originally built by Northrop Corporation to build Boeing 747 fuselages, houses SpaceX's office space, mission control, and Falcon 9 manufacturing facilities.The area has one of the largest concentrations of space sector headquarters, facilities, and/or subsidiaries in the U.S., including Boeing/McDonnell Douglas main satellite building campuses, The Aerospace Corporation, Raytheon, NASA's Jet Propulsion Laboratory, United States Space Force's Space Systems Command at Los Angeles Air Force Base, Lockheed Martin, BAE Systems, Northrop Grumman, and AECOM, etc., with a large pool of aerospace engineers and recent college engineering graduates.SpaceX uses a high degree of vertical integration in the production of its rockets and rocket engines. SpaceX builds its rocket engines, rocket stages, spacecraft, principal avionics and all software in-house in their Hawthorne facility, which is unusual for the space industry.In January 2015, SpaceX announced it would be entering the satellite production business and global satellite internet business. The first satellite facility is a 30,000 sq ft (2,800 m2) office building located in Redmond, Washington. As of January 2017, a second facility in Redmond was acquired with 40,625 sq ft (3,774.2 m2) and has become a research and development laboratory for the satellites. In July 2016, SpaceX acquired an additional 8,000 sq ft (740 m2) office space in Irvine, California to focus on satellite communications.\\n\\nDevelopment and test facilities\\nSpaceX operates its Rocket Development and Test Facility in McGregor, Texas. All SpaceX rocket engines are tested on rocket test stands, and low-altitude VTVL flight testing of the Falcon 9 Grasshopper in 2012\u20132013 were carried out at McGregor. Testing of the much larger Starship prototypes is conducted at the SpaceX Starbase near Brownsville, Texas.The company purchased the McGregor facilities from Beal Aerospace, where it refitted the largest test stand for Falcon 9 engine testing. SpaceX has made a number of improvements to the facility since its purchase and has also extended the acreage by purchasing several pieces of adjacent farmland. As of October 2012, the McGregor facility had seven test stands that are operated \"18 hours a day, six days a week\" and is building more test stands because production is ramping up and the company has a large manifest in the next several years. In addition to routine testing, Dragon capsules (following recovery after an orbital mission), are shipped to McGregor for de-fueling, cleanup, and refurbishment for reuse in future missions.\\n\\nLaunch facilities\\nSpaceX currently operates four orbital launch sites, at Cape Canaveral Space Force Station and Kennedy Space Center in Florida and Vandenberg Space Force Base in California for Falcon rockets, and Starbase near Brownsville, Texas for Starship. SpaceX has indicated that they see a niche for each of the four orbital facilities and that they have sufficient launch business to fill each pad. The Vandenberg launch site enables highly inclined orbits (66\u2013145\u00b0), while Cape Canaveral and Kennedy enable orbits of medium inclination (28.5\u201355\u00b0). Larger inclinations, including SSO, are possible from Florida by overflying Cuba.Before it was retired, all Falcon 1 launches took place at the Ronald Reagan Ballistic Missile Defense Test Site on Omelek Island of the Marshall Islands.In April 2007, the Pentagon approved the use of Cape Canaveral Space Launch Complex 40 (SLC-40) by SpaceX. The site has been used since 2010 for Falcon 9 launches, mainly to low Earth and geostationary orbits. The former Launch Complex 13 at Cape Canaveral, now renamed Landing Zones 1 and 2, has since 2015 been used for Falcon 9 first-stage booster landings.\\nVandenberg Space Launch Complex 4 (SLC-4E) was leased from the military in 2011 and is used for payloads to polar orbits. The Vandenberg site can launch both Falcon 9 and Falcon Heavy vehicles, but cannot launch to low inclination orbits. The neighboring SLC-4W was converted to Landing Zone 4 in 2015 for booster landings.On 14 April 2014, SpaceX signed a 20-year lease for Kennedy Space Center Launch Complex 39A. The pad was subsequently modified to support Falcon 9 and Falcon Heavy launches. As of 2024 it is the only pad that supports Falcon Heavy launches. SpaceX launched its first crewed mission to the ISS from Launch Pad 39A on 30 May 2020. Pad 39A has been prepared since 2019 to eventually accommodate Starship launches. With delays in launch FAA permits for Boca Chica, the 39A Starship preparation was accelerated in 2022.\\nSpaceX manufactures and flies Starship test vehicles from the SpaceX Starbase in Boca Chica near Brownsville, Texas, having announced first plans for the launch facility in August 2014. The Federal Aviation Administration (FAA) issued the permit in July 2014. SpaceX broke ground on the new launch facility in 2014 with construction ramping up in the latter half of 2015, with the first suborbital launches from the facility in 2019 and orbital launches starting in 2023. Some residents of Boca Chica Village, Brownsville, and environmental activists criticized the site along with Starship development program in various aspects.\\n\\nContracts\\nSpaceX won demonstration and actual supply contracts from NASA for the International Space Station (ISS) with technology the company developed. SpaceX is also certified for U.S. military launches of Evolved Expendable Launch Vehicle-class (EELV) payloads. With approximately thirty missions on the manifest for 2018 alone, SpaceX represents over $12 billion under contract.\\n\\nCargo to ISS\\nIn 2006, SpaceX won a NASA Commercial Orbital Transportation Services (COTS) Phase 1 contract to demonstrate cargo delivery to the International Space Station (ISS), with a possible contract option for crew transport. Through this contract, designed by NASA to provide \"seed money\" through Space Act Agreements for developing new capabilities, NASA paid SpaceX $396 million to develop the cargo configuration of the Dragon spacecraft, while SpaceX developed the Falcon 9 launch vehicle with their own resources. These Space Act Agreements have been shown to have saved NASA millions of dollars in development costs, making rocket development 4\u201310 times cheaper than if produced by NASA alone.In December 2010 the launch of the SpaceX COTS Demo Flight 1 mission, SpaceX became the first private company to successfully launch, orbit and recover a spacecraft. Dragon successfully berthed with the ISS during SpaceX COTS Demo Flight 2 in May 2012, a first for a private spacecraft.Commercial Resupply Services (CRS) are a series of contracts awarded by NASA from 2008 to 2016 for delivery of cargo and supplies to the International Space Station on commercially operated spacecraft. The first CRS contracts were signed in 2008 and awarded $1.6 billion to SpaceX for 12 cargo transport missions, covering deliveries to 2016. SpaceX CRS-1, the first of the 12 planned resupply missions, launched in October 2012, achieved orbit, berthed and remained on station for 20 days, before re-entering the atmosphere and splashing down in the Pacific Ocean.CRS missions have flown approximately twice a year to the ISS since then. In 2015, NASA extended the Phase 1 contracts by ordering an additional three resupply flights from SpaceX, and then extended the contract further for a total of twenty cargo missions to the ISS. The final Dragon 1 mission, SpaceX CRS-20, departed the ISS in April 2020, and Dragon was subsequently retired from service. A second phase of contracts was awarded in January 2016 with SpaceX as one of the awardees. SpaceX will fly up to nine additional CRS flights with the upgraded Dragon 2 spacecraft. In March 2020, NASA contracted SpaceX to develop the Dragon XL spacecraft to send supplies to the Lunar Gateway space station. Dragon XL will be launched on a Falcon Heavy.\\n\\nCrewed\\nSpaceX is responsible for the transportation of NASA astronauts to and from the ISS. The NASA contracts started as part of the Commercial Crew Development (CCDev) program, aimed at developing commercially operated spacecraft capable of delivering astronauts to the ISS. The first contract was awarded to SpaceX in 2011, followed by another in 2012 to continue development and testing of its Dragon 2 spacecraft.In September 2014, NASA chose SpaceX and Boeing as the two companies that would be funded to develop systems to transport U.S. crews to and from the ISS. SpaceX won $2.6 billion to complete and certify Dragon 2 by 2017. The contracts called for at least one crewed flight test with at least one NASA astronaut aboard. Once Crew Dragon received NASA human-spaceflight certification, the contract required SpaceX to conduct at least two, and as many as six, crewed missions to the space station.SpaceX completed the first key flight test of its Crew Dragon spacecraft, a Pad Abort Test, in May 2015, and successfully conducted a full uncrewed test flight in early 2019. The capsule docked to the ISS and then splashed down in the Atlantic Ocean. In January 2020, SpaceX conducted an in-flight abort test, the last test flight before flying crew, in which the Dragon spacecraft fired its launch escape engines in a simulated abort scenario.On 30 May 2020, the Crew Dragon Demo-2 mission was launched to the International Space Station with NASA astronauts Bob Behnken and Doug Hurley, the first time a crewed vehicle had launched from the U.S. since 2011, and the first commercial crewed launch to the ISS.\\nThe Crew-1 mission was successfully launched to the International Space Station on 16 November 2020, with NASA astronauts Michael Hopkins, Victor Glover and Shannon Walker along with JAXA astronaut Soichi Noguchi, all members of the Expedition 64 crew. On 23 April 2021, Crew-2 was launched to the International Space Station with NASA astronauts Shane Kimbrough and K. Megan McArthur, JAXA astronaut Akihiko Hoshide, and ESA astronaut Thomas Pesquet. The Crew-2 mission successfully docked on 24 April 2021.\\nSpaceX also offers paid crewed spaceflights for private individuals. The first of these missions, Inspiration4, launched in 2021 on behalf of Shift4 Payments CEO Jared Isaacman. The mission launched the Crew Dragon Resilience from the Florida Kennedy Space Center's Launch Complex 39A atop a Falcon 9 launch vehicle, placed the Dragon capsule into low Earth orbit, and ended successfully about three days later, when the Resilience splashed down in the Atlantic Ocean. All four crew members received commercial astronaut training from SpaceX. The training included lessons in orbital mechanics, operating in a microgravity environment, stress testing, emergency-preparedness training and mission simulations.\\n\\nNational defense\\nIn 2005, SpaceX announced that it had been awarded an Indefinite Delivery/Indefinite Quantity (IDIQ) contract, allowing the United States Air Force to purchase up to $100 million worth of launches from the company. Three years later, NASA announced that it had awarded an IDIQ Launch Services contract to SpaceX for up to $1 billion, depending on the number of missions awarded. In December 2012, SpaceX announced its first two launch contracts with the United States Department of Defense (DoD). The United States Air Force Space and Missile Systems Center awarded SpaceX two EELV-class missions: Deep Space Climate Observatory (DSCOVR) and Space Test Program 2 (STP-2). DSCOVR was launched on a Falcon 9 launch vehicle in 2015, while STP-2 was launched on a Falcon Heavy on 25 June 2019.The Falcon 9 v1.1 was certified for National Security Space Launch (NSSL) in 2015, allowing SpaceX to contract launch services to the Air Force for any payloads classified under national security.\\nThis broke the monopoly held since 2006 by United Launch Alliance (ULA) over U.S. Air Force launches of classified payloads.\\nIn April 2016, the U.S. Air Force awarded the first such national security launch to SpaceX to launch the second GPS III satellite for $82.7 million. This was approximately 40% less than the estimated cost for similar previous missions. SpaceX also launched the third GPS III launch on 20 June 2020. In March 2018, SpaceX secured an additional $290 million contract from the U.S. Air Force to launch another three GPS III satellites.The U.S. National Reconnaissance Office (NRO) also purchased launches from SpaceX, with the first taking place on 1 May 2017. In February 2019, SpaceX secured a $297 million contract from the U.S. Air Force to launch another three national security missions, all slated to launch no earlier than FY 2021. In August 2020, the U.S. Space Force awarded its National Security Space Launch (NSSL) contracts for the following 5\u20137 years. SpaceX won a contract for $316 million for one launch. In addition, SpaceX will handle 40% of the U.S. military's satellite launch requirements over the period.SpaceX also designs and launches custom military satellites for the Space Development Agency as part of a new missile defense system in low Earth orbit. The constellation would give the United States capabilities to sense, target and potentially intercept nuclear missiles and hypersonic weapons launched from anywhere on Earth. Both China and Russia brought concerns to the United Nations about the program, and various organizations warn it could be destabilizing and trigger an arms race in space.\\n\\nLaunch market competition and pricing pressure\\nSpaceX's low launch prices, especially for communications satellites flying to geostationary transfer orbit (GTO), have resulted in market pressure on its competitors to lower their own prices. Prior to 2013, the openly competed comsat launch market had been dominated by Arianespace (flying the Ariane 5) and International Launch Services (flying the Proton). With a published price of $56.5 million per launch to low Earth orbit, Falcon 9 rockets were the cheapest in the industry. European satellite operators are pushing the ESA to reduce launch prices of the Ariane 5 and the future Ariane 6 rockets as a result of competition from SpaceX.SpaceX ended the United Launch Alliance (ULA) monopoly of U.S. military payloads when it began to compete for national security launches. In 2015, anticipating a slump in domestic, military, and spy launches, ULA stated that it would go out of business unless it won commercial satellite launch orders. To that end, ULA announced a major restructuring of processes and workforce to decrease launch costs by half.Congressional testimony by SpaceX in 2017 suggested that the NASA Space Act Agreement process of \"setting only a high-level requirement for cargo transport to the space station [while] leaving the details to industry\" had allowed SpaceX to design and develop the Falcon 9 rocket on its own at a substantially lower cost. According to NASA's own independently verified numbers, SpaceX's total development cost for the Falcon 9 rocket, including the Falcon 1 rocket, was estimated at $390 million. In 2011, NASA estimated that it would have cost the agency about $4 billion to develop a rocket like the Falcon 9 booster based upon NASA's traditional contracting processes, about ten times more. In May 2020, NASA administrator Jim Bridenstine remarked that thanks to NASA's investments into SpaceX, the United States has 70% of the commercial launch market, a major improvement since 2012 when there were no commercial launches from the country.\\n\\nCorporate affairs\\nBoard of directors\\nLeadership changes\\nIn November 2022, the company announced COO Gwynne Shotwell and vice president Mark Juncosa would oversee Starbase, its Texas launch facility, along with Omead Afshar, who at the time oversaw operations for Tesla in Texas. Shyamal Patel, who was senior director of operations at the site, would shift to its Cape Canaveral site. CNBC reported that these executive moves demonstrated \"the sense of urgency within the company to get Starship flying.\"\\n\\nWorkplace culture\\nAccording to former NASA deputy administrator Lori Garver, the company overall has a male-dominated employee culture,  similar to that of the spaceflight industry in general. In December 2021, claims of workplace sexual harassment from five former SpaceX employees, ranging from interns to full engineers, were published. The former employees claimed to have experienced unwanted advances and uncomfortable interactions. Additionally, the accounts included claims of a culture of sexual harassment existing at the company and one where complaints made to executives, managers, and human resources officers went largely unaddressed.In May 2022, a Business Insider article alleged that Musk engaged in sexual misconduct with a SpaceX flight attendant in a private jet in 2016 citing an anonymous friend of the flight attendant. In response, some employees collaborated on an open letter condemning \"Elon's harmful Twitter behavior\". It also asks the company to clearly define SpaceX's \"no-asshole\" and \"zero tolerance\" policies, which it says is unequally enforced from one employee to the next. The next day, Gwynne Shotwell announced that those employees who were involved with the letter had been terminated and claimed that unsponsored, unsolicited surveys were sent to employees during the work day, and that some felt pressured to sign the letter.The company has also been described as having a work culture that pushes employees to work excessively, and was described as fostering a burnout culture. According to a memo by Blue Origin, a rival aerospace company, SpaceX expected very long work hours, work on weekends, and limited use of holidays.\\n\\nReferences\\nBundled references\\n\\nFurther reading\\nBerger, Eric. Liftoff: Elon Musk and the Desperate Early Days That Launched SpaceX. William Collins (2021). ISBN 978-0008445621\\nDavenport, Christian. The Space Barons; Elon Musk. Jeff Bezos, and the Quest to Colonize the Cosmos. PublicAffairs (2018). ISBN 978-1610398299\\nFernholz, Tim. Rocket Billionaires: Elon Musk, Jeff Bezos, and the New Space Race. Houghton Mifflin Harcourt (2018). ISBN 978-1328662231\\nVance, Ashlee. Elon Musk: How the Billionaire CEO of SpaceX and Tesla is Shaping Our Future. Penguin Random House UK (2015). ISBN 978-0753555620\\n\\nExternal links\\n\\nOfficial website \\nSpaceX \u2013 ISS Docking Simulator"}
{"article_name": "Mars", "link": "https://en.wikipedia.org/wiki/Mars", "text_content": "Mars is the fourth planet from the Sun. The surface of Mars is orange-red because it is covered in iron(III) oxide dust, giving it the nickname \"the Red Planet\". Mars hosts many enormous extinct volcanos (such as Olympus Mons, 21.9 km or 13.6 mi tall) and one of the largest canyons in the Solar System (Valles Marineris, 4,000 km or 2,500 mi long). For comparison, Mars's diameter is 6,779 km (4,212 mi). It is classified as a terrestrial planet and is the second smallest of the Solar System's planets.\\nWhen viewed closely, the relatively flat plains in northern parts of Mars strongly contrast with the cratered terrain in southern highlands \u2013 this terrain observation is known as the Martian dichotomy. Geologically, the planet is fairly active with marsquakes trembling underneath the ground, dust devils sweeping across the landscape, and cirrus clouds. Carbon dioxide are substantially present in Mars's polar ice caps and thin atmosphere.\\nIn terms of orbital motion, a Martian solar day (sol) is equal to 24.5 hours and a Martian solar year is equal to 1.88 Earth years (687 Earth days). During a year, there are large surface temperature swings on the surface between \u221278.5 \u00b0C (\u2212109.3 \u00b0F) to 5.7 \u00b0C (42.3 \u00b0F) similar to Earth's seasons, as both planets have significant orbital eccentricity and axial tilt. Mars has two natural satellites that are small and irregular in shape: Phobos and Deimos.\\nMars was formed approximately 4.5 billion years ago. During the Noachian period (4.5 to 3.5 billion years ago), Mars's surface was marked by meteor impacts, valley formation, erosion, and the possible presence of water oceans. The Hesperian period (3.5 to 3.3\u20132.9 billion years ago) was dominated by widespread volcanic activity and flooding that carved immense outflow channels. The Amazonian period, which continues to the present, was marked by the wind as a dominant influence on geological processes. It is unknown whether life has ever existed on Mars.\\nMars is among the brightest objects in Earth's sky and its high-contrast albedo features have make it a common subject for telescope viewing. Since the late 20th century, Mars has been explored by uncrewed spacecraft and rovers, with the first flyby by the Mariner 4 probe in 1965, the first Mars orbiter by the Mars 2 probe in 1971, and the first landing by the Viking 1 probe in 1976. As of 2023, there are at least 11 active probes orbiting Mars or at the Martian surface. Mars is an attractive target for future human exploration missions, though in the 2020s no such mission is planned.\\n\\nNatural history\\nScientists have theorized that during the Solar System's formation, Mars was created as the result of a random process of run-away accretion of material from the protoplanetary disk that orbited the Sun. Mars has many distinctive chemical features caused by its position in the Solar System. Elements with comparatively low boiling points, such as chlorine, phosphorus, and sulfur, are much more common on Mars than on Earth; these elements were probably pushed outward by the young Sun's energetic solar wind.After the formation of the planets, all were subjected to the so-called \"Late Heavy Bombardment\". About 60% of the surface of Mars shows a record of impacts from that era, whereas much of the remaining surface is probably underlain by immense impact basins caused by those events. There is evidence of an enormous impact basin in the Northern Hemisphere of Mars, spanning 10,600 by 8,500 kilometres (6,600 by 5,300 mi), or roughly four times the size of the Moon's South Pole \u2013 Aitken basin, the largest impact basin yet discovered. This theory suggests that Mars was struck by a Pluto-sized body about four billion years ago. The event, thought to be the cause of the Martian hemispheric dichotomy, created the smooth Borealis basin that covers 40% of the planet.A 2023 study shows evidence, based on the orbital inclination of Deimos (a small moon of Mars), that Mars may once had a ring system 3.5 billion years to 4 billion years ago. This ring system may have been formed from a moon, 20 times more massive than Phobos, orbiting Mars billions of years ago; and Phobos would be a remnant of that ring.The geological history of Mars can be split into many periods, but the following are the three primary periods:\\nNoachian period: Formation of the oldest extant surfaces of Mars, 4.5 to 3.5 billion years ago. Noachian age surfaces are scarred by many large impact craters. The Tharsis bulge, a volcanic upland, is thought to have formed during this period, with extensive flooding by liquid water late in the period. Named after Noachis Terra.\\nHesperian period: 3.5 to between 3.3 and 2.9 billion years ago. The Hesperian period is marked by the formation of extensive lava plains. Named after Hesperia Planum.\\nAmazonian period: between 3.3 and 2.9 billion years ago to the present. Amazonian regions have few meteorite impact craters but are otherwise quite varied. Olympus Mons formed during this period, with lava flows elsewhere on Mars. Named after Amazonis Planitia.Geological activity is still taking place on Mars. The Athabasca Valles is home to sheet-like lava flows created about 200 mya. Water flows in the grabens called the Cerberus Fossae occurred less than 20 Mya, indicating equally recent volcanic intrusions. The Mars Reconnaissance Orbiter has captured images of avalanches.\\n\\nPhysical characteristics\\nMars is approximately half the diameter of Earth, with a surface area only slightly less than the total area of Earth's dry land. Mars is less dense than Earth, having about 15% of Earth's volume and 11% of Earth's mass, resulting in about 38% of Earth's surface gravity. Mars is the only presently known example of a desert planet, a rocky planet with a surface akin to that of Earth's hot deserts. The red-orange appearance of the Martian surface is caused by ferric oxide, or rust. It can look like butterscotch; other common surface colors include golden, brown, tan, and greenish, depending on the minerals present.\\n\\nInternal structure\\nLike Earth, Mars has differentiated into a dense metallic core overlaid by less dense materials. Current models of its interior imply a core consisting primarily of iron and nickel with about 16\u201317% sulfur. This iron(II) sulfide core is thought to be twice as rich in lighter elements as Earth's. The core is surrounded by a silicate mantle that formed many of the tectonic and volcanic features on the planet, but it appears to be dormant. Besides silicon and oxygen, the most abundant elements in the Martian crust are iron, magnesium, aluminium, calcium, and potassium. The average thickness of the planet's crust is about 50 kilometres (31 mi), with a maximum thickness of 125 kilometres (78 mi). By comparison, Earth's crust averages 40 kilometres (25 mi) in thickness.Mars is confirmed to be seismically active. In 2019, it was reported that InSight, now offline, had detected and recorded over 450 marsquakes and related events. In 2021 it was reported that, based on eleven low-frequency marsquakes detected by the InSight lander, the core of Mars was determined to be liquid. From this the Martian core was also found to have a radius of about 1830\u00b140 km and a temperature around 1900\u20132000 K. The Martian core radius is abnormally large, accounting for more than half the radius of Mars. The core radius of Mars is about half the size of Earth's core radius. To this, it has been suggested that the core contains some amount of lighter elements like oxygen and hydrogen in addition to the iron\u2013nickel alloy and about 15% of sulfur.The core of Mars is overlaid by the rocky mantle, which does not seem to have a thermally insulating layer analogous to Earth's lower mantle. The Martian mantle appears to be solid down to the depth of about 500 km, where the low-velocity zone (partially melted asthenosphere) begins. Below the asthenosphere, the velocity of seismic waves starts to grow again; and at the depth of about 1050 km lies the boundary of the transition zone extending down to the core.Further analysis of data from the InSight lander has suggested that Mars has a liquid core. Additionally, on 25 October 2023, it was reported by scientists using data from InSight that Mars has a radioactive magma ocean under its crust.\\n\\nSurface geology\\nMars is a terrestrial planet with a surface that consists of minerals containing silicon and oxygen, metals, and other elements that typically make up rock. The Martian surface is primarily composed of tholeiitic basalt, although parts are more silica-rich than typical basalt and may be similar to andesitic rocks on Earth, or silica glass. Regions of low albedo suggest concentrations of plagioclase feldspar, with northern low albedo regions displaying higher than normal concentrations of sheet silicates and high-silicon glass. Parts of the southern highlands include detectable amounts of high-calcium pyroxenes. Localized concentrations of hematite and olivine have been found. Much of the surface is deeply covered by finely grained iron(III) oxide dust.Although Mars has no evidence of a structured global magnetic field, observations show that parts of the planet's crust have been magnetized, suggesting that alternating polarity reversals of its dipole field have occurred in the past. This paleomagnetism of magnetically susceptible minerals is similar to the alternating bands found on Earth's ocean floors. One theory, published in 1999 and re-examined in October 2005 (with the help of the Mars Global Surveyor), is that these bands suggest plate tectonic activity on Mars four billion years ago, before the planetary dynamo ceased to function and the planet's magnetic field faded.The Phoenix lander returned data showing Martian soil to be slightly alkaline and containing elements such as magnesium, sodium, potassium and chlorine. These nutrients are found in soils on Earth. They are necessary for growth of plants. Experiments performed by the lander showed that the Martian soil has a basic pH of 7.7, and contains 0.6% of the salt perchlorate, concentrations that are toxic to humans.Streaks are common across Mars and new ones appear frequently on steep slopes of craters, troughs, and valleys. The streaks are dark at first and get lighter with age. The streaks can start in a tiny area, then spread out for hundreds of metres. They have been seen to follow the edges of boulders and other obstacles in their path. The commonly accepted theories include that they are dark underlying layers of soil revealed after avalanches of bright dust or dust devils. Several other explanations have been put forward, including those that involve water or even the growth of organisms.Radiation levels on the surface are on average 0.64 millisieverts of radiation per day, and significantly less than the radiation of 1.84 millisieverts per day or 22 millirads per day during the flight to and from Mars. For comparison the radiation levels in low Earth orbit, where Earth's space stations orbit, are around 0.5 millisieverts of radiation per day. Hellas Planitia has the lowest surface radiation at about 0.342 millisieverts per day, featuring lava tubes southwest of Hadriacus Mons with potentially levels as low as 0.064 millisieverts per day.\\n\\nGeography and features\\nAlthough better remembered for mapping the Moon, Johann Heinrich M\u00e4dler and Wilhelm Beer were the first areographers. They began by establishing that most of Mars's surface features were permanent and by more precisely determining the planet's rotation period. In 1840, M\u00e4dler combined ten years of observations and drew the first map of Mars.Features on Mars are named from a variety of sources. Albedo features are named for classical mythology. Craters larger than roughly 50 km are named for deceased scientists and writers and others who have contributed to the study of Mars. Smaller craters are named for towns and villages of the world with populations of less than 100,000. Large valleys are named for the word \"Mars\" or \"star\" in various languages; smaller valleys are named for rivers.Large albedo features retain many of the older names but are often updated to reflect new knowledge of the nature of the features. For example, Nix Olympica (the snows of Olympus) has become Olympus Mons (Mount Olympus). The surface of Mars as seen from Earth is divided into two kinds of areas, with differing albedo. The paler plains covered with dust and sand rich in reddish iron oxides were once thought of as Martian \"continents\" and given names like Arabia Terra (land of Arabia) or Amazonis Planitia (Amazonian plain). The dark features were thought to be seas, hence their names Mare Erythraeum, Mare Sirenum and Aurorae Sinus. The largest dark feature seen from Earth is Syrtis Major Planum. The permanent northern polar ice cap is named Planum Boreum. The southern cap is called Planum Australe.\\nMars's equator is defined by its rotation, but the location of its Prime Meridian was specified, as was Earth's (at Greenwich), by choice of an arbitrary point; M\u00e4dler and Beer selected a line for their first maps of Mars in 1830. After the spacecraft Mariner 9 provided extensive imagery of Mars in 1972, a small crater (later called Airy-0), located in the Sinus Meridiani (\"Middle Bay\" or \"Meridian Bay\"), was chosen by Merton Davies, Harold Masursky, and G\u00e9rard de Vaucouleurs for the definition of 0.0\u00b0 longitude to coincide with the original selection.Because Mars has no oceans and hence no \"sea level\", a zero-elevation surface had to be selected as a reference level; this is called the areoid of Mars, analogous to the terrestrial geoid. Zero altitude was defined by the height at which there is 610.5 Pa (6.105 mbar) of atmospheric pressure. This pressure corresponds to the triple point of water, and it is about 0.6% of the sea level surface pressure on Earth (0.006 atm).For mapping purposes, the United States Geological Survey divides the surface of Mars into thirty cartographic quadrangles, each named for a classical albedo feature it contains. In April 2023, The New York Times reported an updated global map of Mars based on images from the Hope spacecraft. A related, but much more detailed, global Mars map was released by NASA on 16 April 2023.\\n\\nVolcanoes\\nThe vast upland region Tharsis contain several extinct volcanoes, which include the shield volcano Olympus Mons (Mount Olympus). The edifice is over 600 km (370 mi) wide. Because the mountain is so large, with complex structure at its edges, giving a definite height to it is difficult. Its local relief, from the foot of the cliffs which form its northwest margin to its peak, is over 21 km (13 mi), a little over twice the height of Mauna Kea as measured from its base on the ocean floor. The total elevation change from the plains of Amazonis Planitia, over 1,000 km (620 mi) to the northwest, to the summit approaches 26 km (16 mi), roughly three times the height of Mount Everest, which in comparison stands at just over 8.8 kilometres (5.5 mi). Consequently, Olympus Mons is either the tallest or second-tallest mountain in the Solar System; the only known mountain which might be taller is the Rheasilvia peak on the asteroid Vesta, at 20\u201325 km (12\u201316 mi).\\n\\nImpact topography\\nThe dichotomy of Martian topography is striking: northern plains flattened by lava flows contrast with the southern highlands, pitted and cratered by ancient impacts. It is possible that, four billion years ago, the Northern Hemisphere of Mars was struck by an object one-tenth to two-thirds the size of Earth's Moon. If this is the case, the Northern Hemisphere of Mars would be the site of an impact crater 10,600 by 8,500 kilometres (6,600 by 5,300 mi) in size, or roughly the area of Europe, Asia, and Australia combined, surpassing Utopia Planitia and the Moon's South Pole\u2013Aitken basin as the largest impact crater in the Solar System.Mars is scarred by a number of impact craters: a total of 43,000 craters with a diameter of 5 kilometres (3.1 mi) or greater have been found. The largest exposed crater is Hellas, which is 2,300 kilometres (1,400 mi) wide and 7,000 metres (23,000 ft) deep, and is a light albedo feature clearly visible from Earth. There are other notable impact features, such as Argyre, which is around 1,800 kilometres (1,100 mi) in diameter, and Isidis, which is around 1,500 kilometres (930 mi) in diameter. Due to the smaller mass and size of Mars, the probability of an object colliding with the planet is about half that of Earth. Mars is located closer to the asteroid belt, so it has an increased chance of being struck by materials from that source. Mars is more likely to be struck by short-period comets, i.e., those that lie within the orbit of Jupiter.Martian craters can have a morphology that suggests the ground became wet after the meteor impacted.\\n\\nTectonic sites\\nThe large canyon, Valles Marineris (Latin for \"Mariner Valleys\", also known as Agathodaemon in the old canal maps), has a length of 4,000 kilometres (2,500 mi) and a depth of up to 7 kilometres (4.3 mi). The length of Valles Marineris is equivalent to the length of Europe and extends across one-fifth the circumference of Mars. By comparison, the Grand Canyon on Earth is only 446 kilometres (277 mi) long and nearly 2 kilometres (1.2 mi) deep. Valles Marineris was formed due to the swelling of the Tharsis area, which caused the crust in the area of Valles Marineris to collapse. In 2012, it was proposed that Valles Marineris is not just a graben, but a plate boundary where 150 kilometres (93 mi) of transverse motion has occurred, making Mars a planet with possibly a two-tectonic plate arrangement.\\n\\nHoles and caves\\nImages from the Thermal Emission Imaging System (THEMIS) aboard NASA's Mars Odyssey orbiter have revealed seven possible cave entrances on the flanks of the volcano Arsia Mons. The caves, named after loved ones of their discoverers, are collectively known as the \"seven sisters\". Cave entrances measure from 100 to 252 metres (328 to 827 ft) wide and they are estimated to be at least 73 to 96 metres (240 to 315 ft) deep. Because light does not reach the floor of most of the caves, they may extend much deeper than these lower estimates and widen below the surface. \"Dena\" is the only exception; its floor is visible and was measured to be 130 metres (430 ft) deep. The interiors of these caverns may be protected from micrometeoroids, UV radiation, solar flares and high energy particles that bombard the planet's surface.\\n\\nAtmosphere\\nMars lost its magnetosphere 4 billion years ago, possibly because of numerous asteroid strikes, so the solar wind interacts directly with the Martian ionosphere, lowering the atmospheric density by stripping away atoms from the outer layer. Both Mars Global Surveyor and Mars Express have detected ionised atmospheric particles trailing off into space behind Mars, and this atmospheric loss is being studied by the MAVEN orbiter. Compared to Earth, the atmosphere of Mars is quite rarefied. Atmospheric pressure on the surface today ranges from a low of 30 Pa (0.0044 psi) on Olympus Mons to over 1,155 Pa (0.1675 psi) in Hellas Planitia, with a mean pressure at the surface level of 600 Pa (0.087 psi). The highest atmospheric density on Mars is equal to that found 35 kilometres (22 mi) above Earth's surface. The resulting mean surface pressure is only 0.6% of Earth's 101.3 kPa (14.69 psi). The scale height of the atmosphere is about 10.8 kilometres (6.7 mi), which is higher than Earth's 6 kilometres (3.7 mi), because the surface gravity of Mars is only about 38% of Earth's.\\nThe atmosphere of Mars consists of about 96% carbon dioxide, 1.93% argon and 1.89% nitrogen along with traces of oxygen and water. The atmosphere is quite dusty, containing particulates about 1.5 \u03bcm in diameter which give the Martian sky a tawny color when seen from the surface. It may take on a pink hue due to iron oxide particles suspended in it. The concentration of methane in the Martian atmosphere fluctuates from about 0.24 ppb during the northern winter to about 0.65 ppb during the summer. Estimates of its lifetime range from 0.6 to 4 years, so its presence indicates that an active source of the gas must be present. Methane could be produced by non-biological process such as serpentinization involving water, carbon dioxide, and the mineral olivine, which is known to be common on Mars, or by Martian life.Compared to Earth, its higher concentration of atmospheric CO2 and lower surface pressure may be why sound is attenuated more on Mars, where natural sources are rare apart from the wind. Using acoustic recordings collected by the Perseverance rover, researchers concluded that the speed of sound there is approximately 240 m/s for frequencies below 240 Hz, and 250 m/s for those above.Auroras have been detected on Mars. Because Mars lacks a global magnetic field, the types and distribution of auroras there differ from those on Earth; rather than being mostly restricted to polar regions as is the case on Earth, a Martian aurora can encompass the planet. In September 2017, NASA reported radiation levels on the surface of the planet Mars were temporarily doubled, and were associated with an aurora 25 times brighter than any observed earlier, due to a massive, and unexpected, solar storm in the middle of the month.\\n\\nClimate\\nOf all the planets in the Solar System, the seasons of Mars are the most Earth-like, due to the similar tilts of the two planets' rotational axes. The lengths of the Martian seasons are about twice those of Earth's because Mars's greater distance from the Sun leads to the Martian year being about two Earth years long. Martian surface temperatures vary from lows of about \u2212110 \u00b0C (\u2212166 \u00b0F) to highs of up to 35 \u00b0C (95 \u00b0F) in equatorial summer. The wide range in temperatures is due to the thin atmosphere which cannot store much solar heat, the low atmospheric pressure (about 1% that of the atmosphere of Earth), and the low thermal inertia of Martian soil. The planet is 1.52 times as far from the Sun as Earth, resulting in just 43% of the amount of sunlight.If Mars had an Earth-like orbit, its seasons would be similar to Earth's because its axial tilt is similar to Earth's. The comparatively large eccentricity of the Martian orbit has a significant effect. Mars is near perihelion when it is summer in the Southern Hemisphere and winter in the north, and near aphelion when it is winter in the Southern Hemisphere and summer in the north. As a result, the seasons in the Southern Hemisphere are more extreme and the seasons in the northern are milder than would otherwise be the case. The summer temperatures in the south can be warmer than the equivalent summer temperatures in the north by up to 30 \u00b0C (54 \u00b0F).Mars has the largest dust storms in the Solar System, reaching speeds of over 160 km/h (100 mph). These can vary from a storm over a small area, to gigantic storms that cover the entire planet. They tend to occur when Mars is closest to the Sun, and have been shown to increase global temperature.\\n\\nHydrology\\nWater in its liquid form cannot exist on the surface of Mars due to low atmospheric pressure, which is less than 1% that of Earth, except at the lowest of elevations for short periods. The two polar ice caps appear to be made largely of water. The volume of water ice in the south polar ice cap, if melted, would be enough to cover the entire surface of the planet with a depth of 11 metres (36 ft). Large quantities of ice are thought to be trapped within the thick cryosphere of Mars. Radar data from Mars Express and the Mars Reconnaissance Orbiter (MRO) show large quantities of ice at both poles, and at middle latitudes. The Phoenix lander directly sampled water ice in shallow Martian soil on 31 July 2008.Landforms visible on Mars strongly suggest that liquid water has existed on the planet's surface. Huge linear swathes of scoured ground, known as outflow channels, cut across the surface in about 25 places. These are thought to be a record of erosion caused by the catastrophic release of water from subsurface aquifers, though some of these structures have been hypothesized to result from the action of glaciers or lava. One of the larger examples, Ma'adim Vallis, is 700 kilometres (430 mi) long, much greater than the Grand Canyon, with a width of 20 kilometres (12 mi) and a depth of 2 kilometres (1.2 mi) in places. It is thought to have been carved by flowing water early in Mars's history. The youngest of these channels is thought to have formed only a few million years ago.Elsewhere, particularly on the oldest areas of the Martian surface, finer-scale, dendritic networks of valleys are spread across significant proportions of the landscape. Features of these valleys and their distribution strongly imply that they were carved by runoff resulting from precipitation in early Mars history. Subsurface water flow and groundwater sapping may play important subsidiary roles in some networks, but precipitation was probably the root cause of the incision in almost all cases.Along craters and canyon walls, there are thousands of features that appear similar to terrestrial gullies. The gullies tend to be in the highlands of the Southern Hemisphere and face the Equator; all are poleward of 30\u00b0 latitude. A number of authors have suggested that their formation process involves liquid water, probably from melting ice, although others have argued for formation mechanisms involving carbon dioxide frost or the movement of dry dust. No partially degraded gullies have formed by weathering and no superimposed impact craters have been observed, indicating that these are young features, possibly still active. Other geological features, such as deltas and alluvial fans preserved in craters, are further evidence for warmer, wetter conditions at an interval or intervals in earlier Mars history. Such conditions necessarily require the widespread presence of crater lakes across a large proportion of the surface, for which there is independent mineralogical, sedimentological and geomorphological evidence. Further evidence that liquid water once existed on the surface of Mars comes from the detection of specific minerals such as hematite and goethite, both of which sometimes form in the presence of water.\\n\\nPolar caps\\nMars has two permanent polar ice caps. During a pole's winter, it lies in continuous darkness, chilling the surface and causing the deposition of 25\u201330% of the atmosphere into slabs of CO2 ice (dry ice). When the poles are again exposed to sunlight, the frozen CO2 sublimes. These seasonal actions transport large amounts of dust and water vapor, giving rise to Earth-like frost and large cirrus clouds. Clouds of water-ice were photographed by the Opportunity rover in 2004.The caps at both poles consist primarily of water ice. Frozen carbon dioxide accumulates as a comparatively thin layer about one metre thick on the north cap in the northern winter only, whereas the south cap has a permanent dry ice cover about eight metres thick. This permanent dry ice cover at the south pole is peppered by flat floored, shallow, roughly circular pits, which repeat imaging shows are expanding in some places and retreating in others. The northern polar cap has a diameter of about 1,000 kilometres (620 mi), and contains about 1.6 million cubic kilometres (5.7\u00d71016 cu ft) of ice, which, if spread evenly on the cap, would be 2 kilometres (1.2 mi) thick. (This compares to a volume of 2.85 million cubic kilometres (1.01\u00d71017 cu ft) for the Greenland ice sheet.) The southern polar cap has a diameter of 350 kilometres (220 mi) and a thickness of 3 kilometres (1.9 mi). The total volume of ice in the south polar cap plus the adjacent layered deposits has been estimated at 1.6 million cubic km. Both polar caps show spiral troughs, which a recent analysis of SHARAD ice penetrating radar has shown are a result of katabatic winds that spiral due to the Coriolis effect.The seasonal frosting of areas near the southern ice cap results in the formation of transparent 1-metre-thick slabs of dry ice above the ground. With the arrival of spring, sunlight warms the subsurface and pressure from subliming CO2 builds up under a slab, elevating and ultimately rupturing it. This leads to geyser-like eruptions of CO2 gas mixed with dark basaltic sand or dust. This process is rapid, observed happening in the space of a few days, weeks or months, a rate of change rather unusual in geology \u2013 especially for Mars. The gas rushing underneath a slab to the site of a geyser carves a spiderweb-like pattern of radial channels under the ice, the process being the inverted equivalent of an erosion network formed by water draining through a single plughole.\\n\\nObservations and findings of water evidence\\nIn 2004, Opportunity detected the mineral jarosite. This forms only in the presence of acidic water, showing that water once existed on Mars. The Spirit rover found concentrated deposits of silica in 2007 that indicated wet conditions in the past, and in December 2011, the mineral gypsum, which also forms in the presence of water, was found on the surface by NASA's Mars rover Opportunity. It is estimated that the amount of water in the upper mantle of Mars, represented by hydroxyl ions contained within Martian minerals, is equal to or greater than that of Earth at 50\u2013300 parts per million of water, which is enough to cover the entire planet to a depth of 200\u20131,000 metres (660\u20133,280 ft).On 18 March 2013, NASA reported evidence from instruments on the Curiosity rover of mineral hydration, likely hydrated calcium sulfate, in several rock samples including the broken fragments of \"Tintina\" rock and \"Sutton Inlier\" rock as well as in veins and nodules in other rocks like \"Knorr\" rock and \"Wernicke\" rock. Analysis using the rover's DAN instrument provided evidence of subsurface water, amounting to as much as 4% water content, down to a depth of 60 centimetres (24 in), during the rover's traverse from the Bradbury Landing site to the Yellowknife Bay area in the Glenelg terrain. In September 2015, NASA announced that they had found strong evidence of hydrated brine flows in recurring slope lineae, based on spectrometer readings of the darkened areas of slopes. These streaks flow downhill in Martian summer, when the temperature is above \u221223 \u00b0C, and freeze at lower temperatures. These observations supported earlier hypotheses, based on timing of formation and their rate of growth, that these dark streaks resulted from water flowing just below the surface. However, later work suggested that the lineae may be dry, granular flows instead, with at most a limited role for water in initiating the process. A definitive conclusion about the presence, extent, and role of liquid water on the Martian surface remains elusive.Researchers suspect much of the low northern plains of the planet were covered with an ocean hundreds of meters deep, though this theory remains controversial. In March 2015, scientists stated that such an ocean might have been the size of Earth's Arctic Ocean. This finding was derived from the ratio of protium to deuterium in the modern Martian atmosphere compared to that ratio on Earth. The amount of Martian deuterium (D/H = 9.3 \u00b1 1.7 10-4) is five to seven times the amount on Earth (D/H = 1.56 10-4), suggesting that ancient Mars had significantly higher levels of water. Results from the Curiosity rover had previously found a high ratio of deuterium in Gale Crater, though not significantly high enough to suggest the former presence of an ocean. Other scientists caution that these results have not been confirmed, and point out that Martian climate models have not yet shown that the planet was warm enough in the past to support bodies of liquid water. Near the northern polar cap is the 81.4 kilometres (50.6 mi) wide Korolev Crater, which the Mars Express orbiter found to be filled with approximately 2,200 cubic kilometres (530 cu mi) of water ice.In November 2016, NASA reported finding a large amount of underground ice in the Utopia Planitia region. The volume of water detected has been estimated to be equivalent to the volume of water in Lake Superior (which is 12,100 cubic kilometres). During observations from 2018 through 2021, the ExoMars Trace Gas Orbiter spotted indications of water, probably subsurface ice, in the Valles Marineris canyon system.\\n\\nOrbital motion\\nMars's average distance from the Sun is roughly 230 million km (143 million mi), and its orbital period is 687 (Earth) days. The solar day (or sol) on Mars is only slightly longer than an Earth day: 24 hours, 39 minutes, and 35.244 seconds. A Martian year is equal to 1.8809 Earth years, or 1 year, 320 days, and 18.2 hours. The gravitational potential difference and thus the delta-v needed to transfer between Mars and Earth is the second lowest for Earth.The axial tilt of Mars is 25.19\u00b0 relative to its orbital plane, which is similar to the axial tilt of Earth. As a result, Mars has seasons like Earth, though on Mars they are nearly twice as long because its orbital period is that much longer. In the present day epoch, the orientation of the north pole of Mars is close to the star Deneb.Mars has a relatively pronounced orbital eccentricity of about 0.09; of the seven other planets in the Solar System, only Mercury has a larger orbital eccentricity. It is known that in the past, Mars has had a much more circular orbit. At one point, 1.35 million Earth years ago, Mars had an eccentricity of roughly 0.002, much less than that of Earth today. Mars's cycle of eccentricity is 96,000 Earth years compared to Earth's cycle of 100,000 years.\\nMars has its closest approach to Earth (opposition) in a synodic period of 779.94 days. It should not be confused with Mars conjunction, where the Earth and Mars are at opposite sides of the Solar System and form a straight line crossing the Sun. The average time between the successive oppositions of Mars, its synodic period, is 780 days; but the number of days between successive oppositions can range from 764 to 812. The distance at close approach varies between about 54 and 103 million km (34 and 64 million mi) due to the planets' elliptical orbits, which causes comparable variation in angular size. Mars comes into opposition from Earth every 2.1 years. The planets come into opposition near Mars's perihelion in 2003, 2018 and 2035, with the 2020 and 2033 events being particularly close to perihelic opposition.The mean apparent magnitude of Mars is +0.71 with a standard deviation of 1.05. Because the orbit of Mars is eccentric, the magnitude at opposition from the Sun can range from about \u22123.0 to \u22121.4. The minimum brightness is magnitude +1.86 when the planet is near aphelion and in conjunction with the Sun. At its brightest, Mars (along with Jupiter) is second only to Venus in apparent brightness. Mars usually appears distinctly yellow, orange, or red. When farthest away from Earth, it is more than seven times farther away than when it is closest. Mars is usually close enough for particularly good viewing once or twice at 15-year or 17-year intervals. Optical ground-based telescopes are typically limited to resolving features about 300 kilometres (190 mi) across when Earth and Mars are closest because of Earth's atmosphere.As Mars approaches opposition, it begins a period of retrograde motion, which means it will appear to move backwards in a looping curve with respect to the background stars. This retrograde motion lasts for about 72 days, and Mars reaches its peak apparent brightness in the middle of this interval.\\n\\nMoons\\nMars has two relatively small (compared to Earth's) natural moons, Phobos (about 22 kilometres (14 mi) in diameter) and Deimos (about 12 kilometres (7.5 mi) in diameter), which orbit close to the planet. The origin of both moons is unclear, although a popular theory states that they were asteroids captured into Martian orbit.Both satellites were discovered in 1877 by Asaph Hall and were named after the characters Phobos (the deity of panic and fear) and Deimos (the deity of terror and dread), twins from Greek mythology who accompanied their father Ares, god of war, into battle. Mars was the Roman equivalent to Ares. In modern Greek, the planet retains its ancient name Ares (Aris: \u0386\u03c1\u03b7\u03c2).From the surface of Mars, the motions of Phobos and Deimos appear different from that of the Earth's satellite, the Moon. Phobos rises in the west, sets in the east, and rises again in just 11 hours. Deimos, being only just outside synchronous orbit \u2013 where the orbital period would match the planet's period of rotation \u2013 rises as expected in the east, but slowly. Because the orbit of Phobos is below a synchronous altitude, tidal forces from Mars are gradually lowering its orbit. In about 50 million years, it could either crash into Mars's surface or break up into a ring structure around the planet.The origin of the two satellites is not well understood. Their low albedo and carbonaceous chondrite composition have been regarded as similar to asteroids, supporting a capture theory. The unstable orbit of Phobos would seem to point toward a relatively recent capture. But both have circular orbits near the equator, which is unusual for captured objects, and the required capture dynamics are complex. Accretion early in the history of Mars is plausible, but would not account for a composition resembling asteroids rather than Mars itself, if that is confirmed. Mars may have yet-undiscovered moons, smaller than 50 to 100 metres (160 to 330 ft) in diameter, and a dust ring is predicted to exist between Phobos and Deimos.A third possibility for their origin as satellites of Mars is the involvement of a third body or a type of impact disruption. More-recent lines of evidence for Phobos having a highly porous interior, and suggesting a composition containing mainly phyllosilicates and other minerals known from Mars, point toward an origin of Phobos from material ejected by an impact on Mars that reaccreted in Martian orbit, similar to the prevailing theory for the origin of Earth's satellite. Although the visible and near-infrared (VNIR) spectra of the moons of Mars resemble those of outer-belt asteroids, the thermal infrared spectra of Phobos are reported to be inconsistent with chondrites of any class. It is also possible that Phobos and Deimos were fragments of an older moon, formed by debris from a large impact on Mars, and then destroyed by a more recent impact upon the satellite.\\n\\nHuman observations and exploration\\nThe history of observations of Mars is marked by oppositions of Mars when the planet is closest to Earth and hence is most easily visible, which occur every couple of years. Even more notable are the perihelic oppositions of Mars, which are distinguished because Mars is close to perihelion, making it even closer to Earth.\\n\\nAncient and medieval observations\\nThe ancient Sumerians named Mars Nergal, the god of war and plague. During Sumerian times, Nergal was a minor deity of little significance, but, during later times, his main cult center was the city of Nineveh. In Mesopotamian texts, Mars is referred to as the \"star of judgement of the fate of the dead\". The existence of Mars as a wandering object in the night sky was also recorded by the ancient Egyptian astronomers and, by 1534 BCE, they were familiar with the retrograde motion of the planet. By the period of the Neo-Babylonian Empire, the Babylonian astronomers were making regular records of the positions of the planets and systematic observations of their behavior. For Mars, they knew that the planet made 37 synodic periods, or 42 circuits of the zodiac, every 79 years. They invented arithmetic methods for making minor corrections to the predicted positions of the planets. In Ancient Greece, the planet was known as \u03a0\u03c5\u03c1\u03cc\u03b5\u03b9\u03c2. Commonly, the Greek name for the planet now referred to as Mars, was Ares. It was the Romans who named the planet Mars, for their god of war, often represented by the sword and shield of the planet's namesake.In the fourth century BCE, Aristotle noted that Mars disappeared behind the Moon during an occultation, indicating that the planet was farther away. Ptolemy, a Greek living in Alexandria, attempted to address the problem of the orbital motion of Mars. Ptolemy's model and his collective work on astronomy was presented in the multi-volume collection later called the Almagest (from the Arabic for \"greatest\"), which became the authoritative treatise on Western astronomy for the next fourteen centuries. Literature from ancient China confirms that Mars was known by Chinese astronomers by no later than the fourth century BCE. In the East Asian cultures, Mars is traditionally referred to as the \"fire star\" based on the Wuxing system.During the seventeenth century A.D., Tycho Brahe measured the diurnal parallax of Mars that Johannes Kepler used to make a preliminary calculation of the relative distance to the planet. From Brahe's observations of Mars, Kepler deduced that the planet orbited the Sun not in a circle, but in an ellipse. Moreover, Kepler showed that Mars sped up as it approached the Sun and slowed down as it moved farther away, in a manner that later physicists would explain as a consequence of the conservation of angular momentum.:\u200a433\u2013437\u200a When the telescope became available, the diurnal parallax of Mars was again measured in an effort to determine the Sun-Earth distance. This was first performed by Giovanni Domenico Cassini in 1672. The early parallax measurements were hampered by the quality of the instruments. The only occultation of Mars by Venus observed was that of 13 October 1590, seen by Michael Maestlin at Heidelberg. In 1610, Mars was viewed by Italian astronomer Galileo Galilei, who was first to see it via telescope. The first person to draw a map of Mars that displayed any terrain features was the Dutch astronomer Christiaan Huygens.\\n\\nMartian \"canals\"\\nBy the 19th century, the resolution of telescopes reached a level sufficient for surface features to be identified. On 5 September 1877, a perihelic opposition to Mars occurred. The Italian astronomer Giovanni Schiaparelli used a 22-centimetre (8.7 in) telescope in Milan to help produce the first detailed map of Mars. These maps notably contained features he called canali, which were later shown to be an optical illusion. These canali were supposedly long, straight lines on the surface of Mars, to which he gave names of famous rivers on Earth. His term, which means \"channels\" or \"grooves\", was popularly mistranslated in English as \"canals\".Influenced by the observations, the orientalist Percival Lowell founded an observatory which had 30- and 45-centimetre (12- and 18-in) telescopes. The observatory was used for the exploration of Mars during the last good opportunity in 1894, and the following less favorable oppositions. He published several books on Mars and life on the planet, which had a great influence on the public. The canali were independently observed by other astronomers, like Henri Joseph Perrotin and Louis Thollon in Nice, using one of the largest telescopes of that time.The seasonal changes (consisting of the diminishing of the polar caps and the dark areas formed during Martian summers) in combination with the canals led to speculation about life on Mars, and it was a long-held belief that Mars contained vast seas and vegetation. As bigger telescopes were used, fewer long, straight canali were observed. During observations in 1909 by Antoniadi with an 84-centimetre (33 in) telescope, irregular patterns were observed, but no canali were seen.\\n\\nRobotic exploration\\nDozens of crewless spacecraft, including orbiters, landers, and rovers, have been sent to Mars by the Soviet Union, the United States, Europe, India, the United Arab Emirates, and China to study the planet's surface, climate, and geology. NASA's Mariner 4 was the first spacecraft to visit Mars; launched on 28 November 1964, it made its closest approach to the planet on 15 July 1965. Mariner 4 detected the weak Martian radiation belt, measured at about 0.1% that of Earth, and captured the first images of another planet from deep space.Once spacecraft visited the planet during NASA's Mariner missions in the 1960s and 1970s, many previous concepts of Mars were radically broken. After the results of the Viking life-detection experiments, the hypothesis of a dead planet was generally accepted. The data from Mariner 9 and Viking allowed better maps of Mars to be made, and the Mars Global Surveyor mission, which launched in 1996 and operated until late 2006, produced complete, extremely detailed maps of the Martian topography, magnetic field and surface minerals. These maps are available online at websites including Google Mars. Both the Mars Reconnaissance Orbiter and Mars Express continued exploring with new instruments and supporting lander missions. NASA provides two online tools: Mars Trek, which provides visualizations of the planet using data from 50 years of exploration, and Experience Curiosity, which simulates traveling on Mars in 3-D with Curiosity.As of 2023, Mars is host to thirteen functioning spacecraft. Eight are in orbit: 2001 Mars Odyssey, Mars Express, Mars Reconnaissance Orbiter, MAVEN, ExoMars Trace Gas Orbiter, the Hope orbiter, and the Tianwen-1 orbiter. Another five are on the surface: the Mars Science Laboratory Curiosity rover, the Perseverance rover, the Ingenuity helicopter, the Tianwen-1 lander, and the Zhurong rover.Planned missions to Mars include the Rosalind Franklin rover mission, designed to search for evidence of past life, which was intended to be launched in 2018 but has been repeatedly delayed, with a launch date pushed to 2024 at the earliest, with a more likely one sometime in 2028. A current concept for a joint NASA-ESA mission to return samples from Mars would launch in 2026.\\n\\nHabitability and the search for life\\nDuring the late 19th century, it was widely accepted in the astronomical community that Mars had life-supporting qualities, including the presence of oxygen and water. However, in 1894 W. W. Campbell at Lick Observatory observed the planet and found that \"if water vapor or oxygen occur in the atmosphere of Mars it is in quantities too small to be detected by spectroscopes then available\". That observation contradicted many of the measurements of the time and was not widely accepted. Campbell and V. M. Slipher repeated the study in 1909 using better instruments, but with the same results. It was not until the findings were confirmed by W. S. Adams in 1925 that the myth of the Earth-like habitability of Mars was finally broken. However, even in the 1960s, articles were published on Martian biology, putting aside explanations other than life for the seasonal changes on Mars.The current understanding of planetary habitability \u2013 the ability of a world to develop environmental conditions favorable to the emergence of life \u2013 favors planets that have liquid water on their surface. Most often this requires the orbit of a planet to lie within the habitable zone, which for the Sun is estimated to extend from within the orbit of Earth to about that of Mars. During perihelion, Mars dips inside this region, but Mars's thin (low-pressure) atmosphere prevents liquid water from existing over large regions for extended periods. The past flow of liquid water demonstrates the planet's potential for habitability. Recent evidence has suggested that any water on the Martian surface may have been too salty and acidic to support regular terrestrial life.The environmental conditions on Mars are a challenge to sustaining organic life: the planet has little heat transfer across its surface, it has poor insulation against bombardment by the solar wind due to the absence of a magnetosphere and has insufficient atmospheric pressure to retain water in a liquid form (water instead sublimes to a gaseous state). Mars is nearly, or perhaps totally, geologically dead; the end of volcanic activity has apparently stopped the recycling of chemicals and minerals between the surface and interior of the planet.Evidence suggests that the planet was once significantly more habitable than it is today, but whether living organisms ever existed there remains unknown. The Viking probes of the mid-1970s carried experiments designed to detect microorganisms in Martian soil at their respective landing sites and had positive results, including a temporary increase in CO2 production on exposure to water and nutrients. This sign of life was later disputed by scientists, resulting in a continuing debate, with NASA scientist Gilbert Levin asserting that Viking may have found life. A 2014 analysis of Martian meteorite EETA79001 found chlorate, perchlorate, and nitrate ions in sufficiently high concentrations to suggest that they are widespread on Mars. UV and X-ray radiation would turn chlorate and perchlorate ions into other, highly reactive oxychlorines, indicating that any organic molecules would have to be buried under the surface to survive.Small quantities of methane and formaldehyde detected by Mars orbiters are both claimed to be possible evidence for life, as these chemical compounds would quickly break down in the Martian atmosphere. Alternatively, these compounds may instead be replenished by volcanic or other geological means, such as serpentinite. Impact glass, formed by the impact of meteors, which on Earth can preserve signs of life, has also been found on the surface of the impact craters on Mars. Likewise, the glass in impact craters on Mars could have preserved signs of life, if life existed at the site.\\n\\nHuman mission proposals\\nSeveral plans for a human mission to Mars have been proposed throughout the 20th and 21st centuries, but none have come to fruition. The NASA Authorization Act of 2017 directed NASA to study the feasibility of a crewed Mars mission in the early 2030s; the resulting report eventually concluded that this would be unfeasible. In addition, in 2021, China was planning to send a crewed Mars mission in 2033. Privately held companies such as SpaceX have also proposed plans to send humans to Mars, with the eventual goal to settle on the planet. The moon Phobos has been proposed as an anchor point for a space elevator.\\n\\nIn culture\\nMars is named after the Roman god of war. This association between Mars and war dates back at least to Babylonian astronomy, in which the planet was named for the god Nergal, deity of war and destruction. It persisted into modern times, as exemplified by Gustav Holst's orchestral suite The Planets, whose famous first movement labels Mars \"the bringer of war\". The planet's symbol, a circle with a spear pointing out to the upper right, is also used as a symbol for the male gender. The symbol dates from at least the 11th century, though a possible predecessor has been found in the Greek Oxyrhynchus Papyri.The idea that Mars was populated by intelligent Martians became widespread in the late 19th century. Schiaparelli's \"canali\" observations combined with Percival Lowell's books on the subject put forward the standard notion of a planet that was a drying, cooling, dying world with ancient civilizations constructing irrigation works. Many other observations and proclamations by notable personalities added to what has been termed \"Mars Fever\". High-resolution mapping of the surface of Mars revealed no artifacts of habitation, but pseudoscientific speculation about intelligent life on Mars still continues. Reminiscent of the canali observations, these speculations are based on small scale features perceived in the spacecraft images, such as \"pyramids\" and the \"Face on Mars\". In his book Cosmos, planetary astronomer Carl Sagan wrote: \"Mars has become a kind of mythic arena onto which we have projected our Earthly hopes and fears.\"The depiction of Mars in fiction has been stimulated by its dramatic red color and by nineteenth-century scientific speculations that its surface conditions might support not just life but intelligent life. This gave way to many science fiction stories involving these concepts, such as H. G. Wells's The War of the Worlds, in which Martians seek to escape their dying planet by invading Earth; Ray Bradbury's The Martian Chronicles, in which human explorers accidentally destroy a Martian civilization; as well as Edgar Rice Burroughs's series Barsoom, C. S. Lewiss novel Out of the Silent Planet (1938), and a number of Robert A. Heinlein stories before the mid-sixties. Since then, depictions of Martians have also extended to animation. A comic figure of an intelligent Martian, Marvin the Martian, appeared in Haredevil Hare (1948) as a character in the Looney Tunes animated cartoons of Warner Brothers, and has continued as part of popular culture to the present. After the Mariner and Viking spacecraft had returned pictures of Mars as a lifeless and canal-less world, these ideas about Mars were abandoned; for many science-fiction authors, the new discoveries initially seemed like a constraint, but eventually the post-Viking knowledge of Mars became itself a source of inspiration for works like Kim Stanley Robinson's Mars trilogy.\\n\\nSee also\\nAstronomy on Mars\\nOutline of Mars \u2013 Overview of and topical guide to Mars\\nList of missions to Mars\\nMagnetic field of Mars \u2013 Past magnetic field of the planet Mars\\nMineralogy of Mars \u2013 Overview of the mineralogy of Mars\\n\\nNotes\\nReferences\\nFurther reading\\nWeinersmith, Kelly; Weinersmith, Zach (2023). A City on Mars: Can we settle space, should we settle space, and have we really thought this through?. Penguin Press. ISBN 978-1-9848-8172-4.\\nShindell, Matthew (2023). For the Love of Mars: A Human History of the Red Planet. University of Chicago Press. ISBN 978-0226821894.\\n\\nExternal links\\nMars Trek \u2013 An integrated map browser of maps and datasets for Mars\\nGoogle Mars and Google Mars 3D, interactive maps of the planet\\nFirst TV image of Mars (15 July 1965), CNN News; 15 July 2023"}
{"article_name": "Leonardo_da_Vinci", "link": "https://en.wikipedia.org/wiki/Leonardo_da_Vinci", "text_content": "Leonardo di ser Piero da Vinci (15 April 1452 \u2013 2 May 1519) was an Italian polymath of the High Renaissance who was active as a painter, draughtsman, engineer, scientist, theorist, sculptor, and architect. While his fame initially rested on his achievements as a painter, he has also become known for his notebooks, in which he made drawings and notes on a variety of subjects, including anatomy, astronomy, botany, cartography, painting, and paleontology. Leonardo is widely regarded to have been a genius who epitomized the Renaissance humanist ideal, and his collective works comprise a contribution to later generations of artists matched only by that of his younger contemporary Michelangelo.Born out of wedlock to a successful notary and a lower-class woman in, or near, Vinci, he was educated in Florence by the Italian painter and sculptor Andrea del Verrocchio. He began his career in the city, but then spent much time in the service of Ludovico Sforza in Milan. Later, he worked in Florence and Milan again, as well as briefly in Rome, all while attracting a large following of imitators and students. Upon the invitation of Francis I, he spent his last three years in France, where he died in 1519. Since his death, there has not been a time where his achievements, diverse interests, personal life, and empirical thinking have failed to incite interest and admiration, making him a frequent namesake and subject in culture.\\nLeonardo is identified as one of the greatest painters in the history of art and is often credited as the founder of the High Renaissance. Despite having many lost works and fewer than 25 attributed major works \u2013  including numerous unfinished works \u2013  he created some of the most influential paintings in Western art. His magnum opus, the Mona Lisa, is his best known work and often regarded as the world's most famous painting. The Last Supper is the most reproduced religious painting of all time and his Vitruvian Man drawing is also regarded as a cultural icon. In 2017, Salvator Mundi, attributed in whole or part to Leonardo, was sold at auction for US$450.3 million, setting a new record for the most expensive painting ever sold at public auction.\\nRevered for his technological ingenuity, he conceptualized flying machines, a type of armored fighting vehicle, concentrated solar power, a ratio machine that could be used in an adding machine, and the double hull. Relatively few of his designs were constructed or were even feasible during his lifetime, as the modern scientific approaches to metallurgy and engineering were only in their infancy during the Renaissance. Some of his smaller inventions, however, entered the world of manufacturing unheralded, such as an automated bobbin winder and a machine for testing the tensile strength of wire. He made substantial discoveries in anatomy, civil engineering, hydrodynamics, geology, optics, and tribology, but he did not publish his findings and they had little to no direct influence on subsequent science.\\n\\nBiography\\nEarly life (1452\u20131472)\\nBirth and background\\nLeonardo da Vinci, properly named Leonardo di ser Piero da Vinci (\"Leonardo, son of ser Piero from Vinci\"), was born on 15 April 1452 in, or close to, the Tuscan hill town of Vinci, 20 miles from Florence. He was born out of wedlock to Piero da Vinci (Ser Piero da Vinci d'Antonio di ser Piero di ser Guido; 1426\u20131504), a Florentine legal notary, and Caterina di Meo Lippi (c.\u20091434\u20131494), from the lower class. It remains uncertain where Leonardo was born; the traditional account, from a local oral tradition recorded by the historian Emanuele Repetti, is that he was born in Anchiano, a country hamlet that would have offered sufficient privacy for the illegitimate birth, though it is still possible he was born in a house in Florence that Ser Piero almost certainly had. Leonardo's parents both married separately the year after his birth. Caterina \u2013  who later appears in Leonardo's notes as only \"Caterina\" or \"Catelina\" \u2013  is usually identified as the Caterina Buti del Vacca, who married the local artisan Antonio di Piero Buti del Vacca, nicknamed L'Accattabriga, 'the quarrelsome one'. Ser Piero married Albiera Amadori \u2013   having been betrothed to her the previous year \u2013   and after her death in 1464, went on to have three subsequent marriages. From all the marriages, Leonardo eventually had 16 half-siblings (of whom 11 survived infancy) who were much younger than he (the last was born when Leonardo was 46 years old) and with whom he had very little contact.\\nVery little is known about Leonardo's childhood and much is shrouded in myth, partially because of his biography in the frequently apocryphal Lives of the Most Excellent Painters, Sculptors, and Architects (1550) by 16th-century art historian Giorgio Vasari. Tax records indicate that by at least 1457 he lived in the household of his paternal grandfather, Antonio da Vinci, but it is possible that he spent the years before then in the care of his mother in Vinci, either Anchiano or Campo Zeppi in the parish of San Pantaleone. He is thought to have been close to his uncle, Francesco da Vinci, but his father was probably in Florence most of the time. Ser Piero, who was the descendant of a long line of notaries, established an official residence in Florence by at least 1469 and had a successful career. Despite his family history, Leonardo only received a basic and informal education in (vernacular) writing, reading, and mathematics; possibly because his artistic talents were recognised early, so his family decided to focus their attention there.Later in life, Leonardo recorded his earliest memory, now in the Codex Atlanticus. While writing on the flight of birds, he recalled as an infant when a kite came to his cradle and opened his mouth with its tail; commentators still debate whether the anecdote was an actual memory or a fantasy.\\n\\nVerrocchio's workshop\\nIn the mid-1460s, Leonardo's family moved to Florence, which at the time was the centre of Christian Humanist thought and culture. Around the age of 14, he became a garzone (studio boy) in the workshop of Andrea del Verrocchio, who was the leading Florentine painter and sculptor of his time. This was about the time of the death of Verrocchio's master, the great sculptor Donatello. Leonardo became an apprentice by the age of 17 and remained in training for seven years. Other famous painters apprenticed in the workshop or associated with it include Ghirlandaio, Perugino, Botticelli, and Lorenzo di Credi. Leonardo was exposed to both theoretical training and a wide range of technical skills, including drafting, chemistry, metallurgy, metal working, plaster casting, leather working, mechanics, and woodwork, as well as the artistic skills of drawing, painting, sculpting, and modelling.Leonardo was a contemporary of Botticelli, Ghirlandaio and Perugino, who were all slightly older than he was. He would have met them at the workshop of Verrocchio or at the Platonic Academy of the Medici. Florence was ornamented by the works of artists such as Donatello's contemporaries Masaccio, whose figurative frescoes were imbued with realism and emotion, and Ghiberti, whose Gates of Paradise, gleaming with gold leaf, displayed the art of combining complex figure compositions with detailed architectural backgrounds. Piero della Francesca had made a detailed study of perspective, and was the first painter to make a scientific study of light. These studies and Leon Battista Alberti's treatise De pictura were to have a profound effect on younger artists and in particular on Leonardo's own observations and artworks.Much of the painting in Verrocchio's workshop was done by his assistants. According to Vasari, Leonardo collaborated with Verrocchio on his The Baptism of Christ (c.\u20091472\u20131475), painting the young angel holding Jesus's robe with skill so far superior to his master's that Verrocchio purportedly put down his brush and never painted again (the latter claim probably being apocryphal). The new technique of oil paint was applied to areas of the mostly tempera work, including the landscape, the rocks seen through the brown mountain stream, and much of Jesus's figure, indicating Leonardo's hand. Additionally, Leonardo may have been a model for two works by Verrocchio: the bronze statue of David in the Bargello and the archangel Raphael in Tobias and the Angel.Vasari tells a story of Leonardo as a very young man: a local peasant made himself a round buckler shield and requested that Ser Piero have it painted for him. Leonardo, inspired by the story of Medusa, responded with a painting of a monster spitting fire that was so terrifying that his father bought a different shield to give to the peasant and sold Leonardo's to a Florentine art dealer for 100 ducats, who in turn sold it to the Duke of Milan.\\n\\nFirst Florentine period (1472\u2013c. 1482)\\nBy 1472, at the age of 20, Leonardo qualified as a master in the Guild of Saint Luke, the guild of artists and doctors of medicine, but even after his father set him up in his own workshop, his attachment to Verrocchio was such that he continued to collaborate and live with him. Leonardo's earliest known dated work is a 1473 pen-and-ink drawing of the Arno valley (see below). According to Vasari, the young Leonardo was the first to suggest making the Arno river a navigable channel between Florence and Pisa.In January 1478, Leonardo received an independent commission to paint an altarpiece for the Chapel of Saint Bernard in the Palazzo Vecchio, an indication of his independence from Verrocchio's studio. An anonymous early biographer, known as Anonimo Gaddiano, claims that in 1480 Leonardo was living with the Medici and often worked in the garden of the Piazza San Marco, Florence, where a Neoplatonic academy of artists, poets and philosophers organized by the Medici met. In March 1481, he received a commission from the monks of San Donato in Scopeto for The Adoration of the Magi. Neither of these initial commissions were completed, being abandoned when Leonardo went to offer his services to Duke of Milan Ludovico Sforza. Leonardo wrote Sforza a letter which described the diverse things that he could achieve in the fields of engineering and weapon design, and mentioned that he could paint. He brought with him a silver string instrument \u2013  either a lute or lyre \u2013  in the form of a horse's head.With Alberti, Leonardo visited the home of the Medici and through them came to know the older Humanist philosophers of whom Marsiglio Ficino, proponent of Neoplatonism; Cristoforo Landino, writer of commentaries on Classical writings, and John Argyropoulos, teacher of Greek and translator of Aristotle were the foremost. Also associated with the Platonic Academy of the Medici was Leonardo's contemporary, the brilliant young poet and philosopher Pico della Mirandola. In 1482, Leonardo was sent as an ambassador by Lorenzo de' Medici to Ludovico il Moro, who ruled Milan between 1479 and 1499.\\n\\nFirst Milanese period (c. 1482\u20131499)\\nLeonardo worked in Milan from 1482 until 1499. He was commissioned to paint the Virgin of the Rocks for the Confraternity of the Immaculate Conception and The Last Supper for the monastery of Santa Maria delle Grazie. In the spring of 1485, Leonardo travelled to Hungary (on behalf of Sforza) to meet king Matthias Corvinus, and was commissioned by him to paint a Madonna. In 1490 he was called as a consultant, together with Francesco di Giorgio Martini, for the building site of the cathedral of Pavia and was struck by the equestrian statue of Regisole, of which he left a sketch. Leonardo was employed on many other projects for Sforza, such as preparation of floats and pageants for special occasions; a drawing of, and wooden model for, a competition to design the cupola for Milan Cathedral; and a model for a huge equestrian monument to Ludovico's predecessor Francesco Sforza. This would have surpassed in size the only two large equestrian statues of the Renaissance, Donatello's Gattamelata in Padua and Verrocchio's Bartolomeo Colleoni in Venice, and became known as the Gran Cavallo. Leonardo completed a model for the horse and made detailed plans for its casting, but in November 1494, Ludovico gave the metal to his brother-in-law to be used for a cannon to defend the city from Charles VIII of France.\\nContemporary correspondence records that Leonardo and his assistants were commissioned by the Duke of Milan to paint the Sala delle Asse in the Sforza Castle, c. 1498. The project became a trompe-l'\u0153il decoration that made the great hall appear to be a pergola created by the interwoven limbs of sixteen mulberry trees, whose canopy included an intricate labyrinth of leaves and knots on the ceiling.\\n\\nSecond Florentine period (1500\u20131508)\\nWhen Ludovico Sforza was overthrown by France in 1500, Leonardo fled Milan for Venice, accompanied by his assistant Sala\u00ec and friend, the mathematician Luca Pacioli. In Venice, Leonardo was employed as a military architect and engineer, devising methods to defend the city from naval attack. On his return to Florence in 1500, he and his household were guests of the Servite monks at the monastery of Santissima Annunziata and were provided with a workshop where, according to Vasari, Leonardo created the cartoon of The Virgin and Child with Saint Anne and Saint John the Baptist, a work that won such admiration that \"men [and] women, young and old\" flocked to see it \"as if they were going to a solemn festival.\"In Cesena in 1502, Leonardo entered the service of Cesare Borgia, the son of Pope Alexander VI, acting as a military architect and engineer and travelling throughout Italy with his patron. Leonardo created a map of Cesare Borgia's stronghold, a town plan of Imola in order to win his patronage. Upon seeing it, Cesare hired Leonardo as his chief military engineer and architect. Later in the year, Leonardo produced another map for his patron, one of Chiana Valley, Tuscany, so as to give his patron a better overlay of the land and greater strategic position. He created this map in conjunction with his other project of constructing a dam from the sea to Florence, in order to allow a supply of water to sustain the canal during all seasons.\\nLeonardo had left Borgia's service and returned to Florence by early 1503, where he rejoined the Guild of Saint Luke on 18 October of that year. By this same month, Leonardo had begun working on a portrait of Lisa del Giocondo, the model for the Mona Lisa, which he would continue working on until his twilight years. In January 1504, he was part of a committee formed to recommend where Michelangelo's statue of David should be placed. He then spent two years in Florence designing and painting a mural of The Battle of Anghiari for the Signoria, with Michelangelo designing its companion piece, The Battle of Cascina.In 1506, Leonardo was summoned to Milan by Charles II d'Amboise, the acting French governor of the city. There, Leonardo took on another pupil, Count Francesco Melzi, the son of a Lombard aristocrat, who is considered to have been his favourite student. The Council of Florence wished Leonardo to return promptly to finish The Battle of Anghiari, but he was given leave at the behest of Louis XII, who considered commissioning the artist to make some portraits. Leonardo may have commenced a project for an equestrian figure of d'Amboise; a wax model survives and, if genuine, is the only extant example of Leonardo's sculpture. Leonardo was otherwise free to pursue his scientific interests. Many of Leonardo's most prominent pupils either knew or worked with him in Milan, including Bernardino Luini, Giovanni Antonio Boltraffio, and Marco d'Oggiono. In 1507, Leonardo was in Florence sorting out a dispute with his brothers over the estate of his father, who had died in 1504.\\n\\nSecond Milanese period (1508\u20131513)\\nBy 1508, Leonardo was back in Milan, living in his own house in Porta Orientale in the parish of Santa Babila.In 1512, Leonardo was working on plans for an equestrian monument for Gian Giacomo Trivulzio, but this was prevented by an invasion of a confederation of Swiss, Spanish and Venetian forces, which drove the French from Milan. Leonardo stayed in the city, spending several months in 1513 at the Medici's Vaprio d'Adda villa.\\n\\nRome and France (1513\u20131519)\\nIn March 1513, Lorenzo de' Medici's son Giovanni assumed the papacy (as Leo X); Leonardo went to Rome that September, where he was received by the pope's brother Giuliano. From September 1513 to 1516, Leonardo spent much of his time living in the Belvedere Courtyard in the Apostolic Palace, where Michelangelo and Raphael were both active. Leonardo was given an allowance of 33 ducats a month, and according to Vasari, decorated a lizard with scales dipped in quicksilver. The pope gave him a painting commission of unknown subject matter, but cancelled it when the artist set about developing a new kind of varnish. Leonardo became ill, in what may have been the first of multiple strokes leading to his death. He practiced botany in the Gardens of Vatican City, and was commissioned to make plans for the pope's proposed draining of the Pontine Marshes. He also dissected cadavers, making notes for a treatise on vocal cords; these he gave to an official in hopes of regaining the pope's favor, but was unsuccessful.In October 1515, King Francis I of France recaptured Milan. Leonardo was present at the 19 December meeting of Francis I and Leo X, which took place in Bologna. In 1516, Leonardo entered Francis' service, being given the use of the manor house Clos Luc\u00e9, near the king's residence at the royal Ch\u00e2teau d'Amboise. Being frequently visited by Francis, he drew plans for an immense castle town the king intended to erect at Romorantin, and made a mechanical lion, which during a pageant walked toward the king and \u2013  upon being struck by a wand \u2013  opened its chest to reveal a cluster of lilies. Leonardo was accompanied during this time by his friend and apprentice Francesco Melzi, and supported by a pension totalling 10,000 scudi. At some point, Melzi drew a portrait of Leonardo; the only others known from his lifetime were a sketch by an unknown assistant on the back of one of Leonardo's studies (c.\u20091517) and a drawing by Giovanni Ambrogio Figino depicting an elderly Leonardo with his right arm wrapped in clothing. The latter, in addition to the record of an October 1517 visit by Louis d'Aragon, confirms an account of Leonardo's right hand being paralytic when he was 65, which may indicate why he left works such as the Mona Lisa unfinished. He continued to work at some capacity until eventually becoming ill and bedridden for several months.\\n\\nDeath\\nLeonardo died at Clos Luc\u00e9 on 2 May 1519 at the age of 67, possibly of a stroke. Francis I had become a close friend. Vasari describes Leonardo as lamenting on his deathbed, full of repentance, that \"he had offended against God and men by failing to practice his art as he should have done.\" Vasari states that in his last days, Leonardo sent for a priest to make his confession and to receive the Holy Sacrament. Vasari also records that the king held Leonardo's head in his arms as he died, although this story may be legend rather than fact. In accordance with his will, sixty beggars carrying tapers followed Leonardo's casket. Melzi was the principal heir and executor, receiving, as well as money, Leonardo's paintings, tools, library and personal effects. Leonardo's other long-time pupil and companion, Sala\u00ec, and his servant Baptista de Vilanis, each received half of Leonardo's vineyards. His brothers received land, and his serving woman received a fur-lined cloak. On 12 August 1519, Leonardo's remains were interred in the Collegiate Church of Saint Florentin at the Ch\u00e2teau d'Amboise.Some 20 years after Leonardo's death, Francis was reported by the goldsmith and sculptor Benvenuto Cellini as saying: \"There had never been another man born in the world who knew as much as Leonardo, not so much about painting, sculpture and architecture, as that he was a very great philosopher.\"\\nSala\u00ec, or Il Salaino (\"The Little Unclean One\", i.e., the devil), entered Leonardo's household in 1490 as an assistant. After only a year, Leonardo made a list of his misdemeanours, calling him \"a thief, a liar, stubborn, and a glutton,\" after he had made off with money and valuables on at least five occasions and spent a fortune on clothes. Nevertheless, Leonardo treated him with great indulgence, and he remained in Leonardo's household for the next thirty years. Sala\u00ec executed a number of paintings under the name of Andrea Sala\u00ec, but although Vasari claims that Leonardo \"taught him many things about painting,\" his work is generally considered to be of less artistic merit than others among Leonardo's pupils, such as Marco d'Oggiono and Boltraffio.\\nAt the time of his death in 1524, Sala\u00ec owned a painting referred to as Joconda in a posthumous inventory of his belongings; it was assessed at 505 lire, an exceptionally high valuation for a small panel portrait.\\n\\nPersonal life\\nDespite the thousands of pages Leonardo left in notebooks and manuscripts, he scarcely made reference to his personal life.Within Leonardo's lifetime, his extraordinary powers of invention, his \"great physical beauty\" and \"infinite grace,\" as described by Vasari, as well as all other aspects of his life, attracted the curiosity of others. One such aspect was his love for animals, likely including vegetarianism and according to Vasari, a habit of purchasing caged birds and releasing them.Leonardo had many friends who are now notable either in their fields or for their historical significance, including mathematician Luca Pacioli, with whom he collaborated on the book Divina proportione in the 1490s. Leonardo appears to have had no close relationships with women except for his friendship with Cecilia Gallerani and the two Este sisters, Beatrice and Isabella. While on a journey that took him through Mantua, he drew a portrait of Isabella that appears to have been used to create a painted portrait, now lost.Beyond friendship, Leonardo kept his private life secret. His sexuality has been the subject of satire, analysis, and speculation. This trend began in the mid-16th century and was revived in the 19th and 20th centuries, most notably by Sigmund Freud in his Leonardo da Vinci, A Memory of His Childhood. Leonardo's most intimate relationships were perhaps with his pupils Sala\u00ec and Melzi. Melzi, writing to inform Leonardo's brothers of his death, described Leonardo's feelings for his pupils as both loving and passionate. It has been claimed since the 16th century that these relationships were of a sexual or erotic nature. Walter Isaacson in his biography of Leonardo makes explicit his opinion that the relations with Sala\u00ec were intimate and homosexual.\\nEarlier in Leonardo's life, court records of 1476, when he was aged twenty-four, show that Leonardo and three other young men were charged with sodomy in an incident involving a known male prostitute. The charges were dismissed for lack of evidence, and there is speculation that since one of the accused, Lionardo de Tornabuoni, was related to Lorenzo de' Medici, the family exerted its influence to secure the dismissal. Since that date much has been written about his presumed homosexuality and its role in his art, particularly in the androgyny and eroticism manifested in Saint John the Baptist and Bacchus and more explicitly in a number of erotic drawings.\\n\\nPaintings\\nDespite the recent awareness and admiration of Leonardo as a scientist and inventor, for the better part of four hundred years his fame rested on his achievements as a painter. A handful of works that are either authenticated or attributed to him have been regarded as among the great masterpieces. These paintings are famous for a variety of qualities that have been much imitated by students and discussed at great length by connoisseurs and critics. By the 1490s Leonardo had already been described as a \"Divine\" painter.Among the qualities that make Leonardo's work unique are his innovative techniques for laying on the paint; his detailed knowledge of anatomy, light, botany and geology; his interest in physiognomy and the way humans register emotion in expression and gesture; his innovative use of the human form in figurative composition; and his use of subtle gradation of tone. All these qualities come together in his most famous painted works, the Mona Lisa, the Last Supper, and the Virgin of the Rocks.\\n\\nEarly works\\nLeonardo first gained attention for his work on the Baptism of Christ, painted in conjunction with Verrocchio. Two other paintings appear to date from his time at Verrocchio's workshop, both of which are Annunciations. One is small, 59 centimetres (23 in) long and 14 cm (5.5 in) high. It is a \"predella\" to go at the base of a larger composition, a painting by Lorenzo di Credi from which it has become separated. The other is a much larger work, 217 cm (85 in) long. In both Annunciations, Leonardo used a formal arrangement, like two well-known pictures by Fra Angelico of the same subject, of the Virgin Mary sitting or kneeling to the right of the picture, approached from the left by an angel in profile, with a rich flowing garment, raised wings and bearing a lily. Although previously attributed to Ghirlandaio, the larger work is now generally attributed to Leonardo.In the smaller painting, Mary averts her eyes and folds her hands in a gesture that symbolised submission to God's will. Mary is not submissive, however, in the larger piece. The girl, interrupted in her reading by this unexpected messenger, puts a finger in her bible to mark the place and raises her hand in a formal gesture of greeting or surprise. This calm young woman appears to accept her role as the Mother of God, not with resignation but with confidence. In this painting, the young Leonardo presents the humanist face of the Virgin Mary, recognising humanity's role in God's incarnation.\\n\\nPaintings of the 1480s\\nIn the 1480s, Leonardo received two very important commissions and commenced another work that was of ground-breaking importance in terms of composition. Two of the three were never finished, and the third took so long that it was subject to lengthy negotiations over completion and payment.\\nOne of these paintings was Saint Jerome in the Wilderness, which Bortolon associates with a difficult period of Leonardo's life, as evidenced in his diary: \"I thought I was learning to live; I was only learning to die.\" Although the painting is barely begun, the composition can be seen and is very unusual. Jerome, as a penitent, occupies the middle of the picture, set on a slight diagonal and viewed somewhat from above. His kneeling form takes on a trapezoid shape, with one arm stretched to the outer edge of the painting and his gaze looking in the opposite direction. J. Wasserman points out the link between this painting and Leonardo's anatomical studies. Across the foreground sprawls his symbol, a great lion whose body and tail make a double spiral across the base of the picture space. The other remarkable feature is the sketchy landscape of craggy rocks against which the figure is silhouetted.\\nThe daring display of figure composition, the landscape elements and personal drama also appear in the great unfinished masterpiece, the Adoration of the Magi, a commission from the Monks of San Donato a Scopeto. It is a complex composition, of about 250 x 250 centimetres. Leonardo did numerous drawings and preparatory studies, including a detailed one in linear perspective of the ruined classical architecture that forms part of the background. In 1482 Leonardo went to Milan at the behest of Lorenzo de' Medici in order to win favour with Ludovico il Moro, and the painting was abandoned.\\nThe third important work of this period is the Virgin of the Rocks, commissioned in Milan for the Confraternity of the Immaculate Conception. The painting, to be done with the assistance of the de Predis brothers, was to fill a large complex altarpiece. Leonardo chose to paint an apocryphal moment of the infancy of Christ when the infant John the Baptist, in protection of an angel, met the Holy Family on the road to Egypt. The painting demonstrates an eerie beauty as the graceful figures kneel in adoration around the infant Christ in a wild landscape of tumbling rock and whirling water. While the painting is quite large, about 200\u00d7120 centimetres, it is not nearly as complex as the painting ordered by the monks of San Donato, having only four figures rather than about fifty and a rocky landscape rather than architectural details. The painting was eventually finished; in fact, two versions of the painting were finished: one remained at the chapel of the Confraternity, while Leonardo took the other to France. The Brothers did not get their painting, however, nor the de Predis their payment, until the next century.Leonardo's most remarkable portrait of this period is the Lady with an Ermine, presumed to be Cecilia Gallerani (c.\u20091483\u20131490), lover of Ludovico Sforza. The painting is characterised by the pose of the figure with the head turned at a very different angle to the torso, unusual at a date when many portraits were still rigidly in profile. The ermine plainly carries symbolic meaning, relating either to the sitter, or to Ludovico who belonged to the prestigious Order of the Ermine.\\n\\nPaintings of the 1490s\\nLeonardo's most famous painting of the 1490s is The Last Supper, commissioned for the refectory of the Convent of Santa Maria della Grazie in Milan. It represents the last meal shared by Jesus with his disciples before his capture and death, and shows the moment when Jesus has just said \"one of you will betray me\", and the consternation that this statement caused.The writer Matteo Bandello observed Leonardo at work and wrote that some days he would paint from dawn till dusk without stopping to eat and then not paint for three or four days at a time. This was beyond the comprehension of the prior of the convent, who hounded him until Leonardo asked Ludovico to intervene. Vasari describes how Leonardo, troubled over his ability to adequately depict the faces of Christ and the traitor Judas, told the duke that he might be obliged to use the prior as his model.The painting was acclaimed as a masterpiece of design and characterization, but it deteriorated rapidly, so that within a hundred years it was described by one viewer as \"completely ruined.\" Leonardo, instead of using the reliable technique of fresco, had used tempera over a ground that was mainly gesso, resulting in a surface subject to mould and to flaking. Despite this, the painting remains one of the most reproduced works of art; countless copies have been made in various mediums.\\nToward the end of this period, in 1498 Leonardo's trompe-l'\u0153il decoration of the Sala delle Asse was painted for the Duke of Milan in the Castello Sforzesco.\\n\\nPaintings of the 1500s\\nIn 1505, Leonardo was commissioned to paint The Battle of Anghiari in the Salone dei Cinquecento (Hall of the Five Hundred) in the Palazzo Vecchio, Florence. Leonardo devised a dynamic composition depicting four men riding raging war horses engaged in a battle for possession of a standard, at the Battle of Anghiari in 1440. Michelangelo was assigned the opposite wall to depict the Battle of Cascina. Leonardo's painting deteriorated rapidly and is now known from a copy by Rubens.\\nAmong the works created by Leonardo in the 16th century is the small portrait known as the Mona Lisa or La Gioconda, the laughing one. In the present era, it is arguably the most famous painting in the world. Its fame rests, in particular, on the elusive smile on the woman's face, its mysterious quality perhaps due to the subtly shadowed corners of the mouth and eyes such that the exact nature of the smile cannot be determined. The shadowy quality for which the work is renowned came to be called \"sfumato\", or Leonardo's smoke. Vasari wrote that the smile was \"so pleasing that it seems more divine than human, and it was considered a wondrous thing that it was as lively as the smile of the living original.\"Other characteristics of the painting are the unadorned dress, in which the eyes and hands have no competition from other details; the dramatic landscape background, in which the world seems to be in a state of flux; the subdued colouring; and the extremely smooth nature of the painterly technique, employing oils laid on much like tempera, and blended on the surface so that the brushstrokes are indistinguishable. Vasari expressed that the painting's quality would make even \"the most confident master ... despair and lose heart.\" The perfect state of preservation and the fact that there is no sign of repair or overpainting is rare in a panel painting of this date.In the painting Virgin and Child with Saint Anne, the composition again picks up the theme of figures in a landscape, which Wasserman describes as \"breathtakingly beautiful\" and harkens back to the Saint Jerome with the figure set at an oblique angle. What makes this painting unusual is that there are two obliquely set figures superimposed. Mary is seated on the knee of her mother, Saint Anne. She leans forward to restrain the Christ Child as he plays roughly with a lamb, the sign of his own impending sacrifice. This painting, which was copied many times, influenced Michelangelo, Raphael, and Andrea del Sarto, and through them Pontormo and Correggio. The trends in composition were adopted in particular by the Venetian painters Tintoretto and Veronese.\\n\\nDrawings\\nLeonardo was a prolific draughtsman, keeping journals full of small sketches and detailed drawings recording all manner of things that took his attention. As well as the journals there exist many studies for paintings, some of which can be identified as preparatory to particular works such as The Adoration of the Magi, The Virgin of the Rocks and The Last Supper. His earliest dated drawing is a Landscape of the Arno Valley, 1473, which shows the river, the mountains, Montelupo Castle and the farmlands beyond it in great detail.Among his famous drawings are the Vitruvian Man, a study of the proportions of the human body; the Head of an Angel, for The Virgin of the Rocks in the Louvre; a botanical study of Star of Bethlehem; and a large drawing (160\u00d7100 cm) in black chalk on coloured paper of The Virgin and Child with Saint Anne and Saint John the Baptist in the National Gallery, London. This drawing employs the subtle sfumato technique of shading, in the manner of the Mona Lisa. It is thought that Leonardo never made a painting from it, the closest similarity being to The Virgin and Child with Saint Anne in the Louvre.\\nOther drawings of interest include numerous studies generally referred to as \"caricatures\" because, although exaggerated, they appear to be based upon observation of live models. Vasari relates that Leonardo would look for interesting faces in public to use as models for some of his work. There are numerous studies of beautiful young men, often associated with Sala\u00ec, with the rare and much admired facial feature, the so-called \"Grecian profile\". These faces are often contrasted with that of a warrior. Sala\u00ec is often depicted in fancy-dress costume. Leonardo is known to have designed sets for pageants with which these may be associated. Other, often meticulous, drawings show studies of drapery. A marked development in Leonardo's ability to draw drapery occurred in his early works. Another often-reproduced drawing is a macabre sketch that was done by Leonardo in Florence in 1479 showing the body of Bernardo Baroncelli, hanged in connection with the murder of Giuliano, brother of Lorenzo de' Medici, in the Pazzi conspiracy. In his notes, Leonardo recorded the colours of the robes that Baroncelli was wearing when he died.\\nLike the two contemporary architects Donato Bramante (who designed the Belvedere Courtyard) and Antonio da Sangallo the Elder, Leonardo experimented with designs for centrally planned churches, a number of which appear in his journals, as both plans and views, although none was ever realised.\\n\\nJournals and notes\\nRenaissance humanism recognised no mutually exclusive polarities between the sciences and the arts, and Leonardo's studies in science and engineering are sometimes considered as impressive and innovative as his artistic work. These studies were recorded in 13,000 pages of notes and drawings, which fuse art and natural philosophy (the forerunner of modern science). They were made and maintained daily throughout Leonardo's life and travels, as he made continual observations of the world around him. Leonardo's notes and drawings display an enormous range of interests and preoccupations, some as mundane as lists of groceries and people who owed him money and some as intriguing as designs for wings and shoes for walking on water. There are compositions for paintings, studies of details and drapery, studies of faces and emotions, of animals, babies, dissections, plant studies, rock formations, whirlpools, war machines, flying machines and architecture.\\nThese notebooks \u2013  originally loose papers of different types and sizes \u2013  were largely entrusted to Leonardo's pupil and heir Francesco Melzi after the master's death. These were to be published, a task of overwhelming difficulty because of its scope and Leonardo's idiosyncratic writing. Some of Leonardo's drawings were copied by an anonymous Milanese artist for a planned treatise on art c.\u20091570. After Melzi's death in 1570, the collection passed to his son, the lawyer Orazio, who initially took little interest in the journals. In 1587, a Melzi household tutor named Lelio Gavardi took 13 of the manuscripts to Pisa; there, the architect Giovanni Magenta reproached Gavardi for having taken the manuscripts illicitly and returned them to Orazio. Having many more such works in his possession, Orazio gifted the volumes to Magenta. News spread of these lost works of Leonardo's, and Orazio retrieved seven of the 13 manuscripts, which he then gave to Pompeo Leoni for publication in two volumes; one of these was the Codex Atlanticus. The other six works had been distributed to a few others. After Orazio's death, his heirs sold the rest of Leonardo's possessions, and thus began their dispersal.Some works have found their way into major collections such as the Royal Library at Windsor Castle, the Louvre, the Biblioteca Nacional de Espa\u00f1a, the Victoria and Albert Museum, the Biblioteca Ambrosiana in Milan, which holds the 12-volume Codex Atlanticus, and the British Library in London, which has put a selection from the Codex Arundel (BL Arundel MS 263) online. Works have also been at Holkham Hall, the Metropolitan Museum of Art, and in the private hands of John Nicholas Brown I and Robert Lehman. The Codex Leicester is the only privately owned major scientific work of Leonardo; it is owned by Bill Gates and displayed once a year in different cities around the world.\\n\\nMost of Leonardo's writings are in mirror-image cursive. Since Leonardo wrote with his left hand, it was probably easier for him to write from right to left. Leonardo used a variety of shorthand and symbols, and states in his notes that he intended to prepare them for publication. In many cases a single topic is covered in detail in both words and pictures on a single sheet, together conveying information that would not be lost if the pages were published out of order. Why they were not published during Leonardo's lifetime is unknown.\\n\\nScience and inventions\\nLeonardo's approach to science was observational: he tried to understand a phenomenon by describing and depicting it in utmost detail and did not emphasise experiments or theoretical explanation. Since he lacked formal education in Latin and mathematics, contemporary scholars mostly ignored Leonardo the scientist, although he did teach himself Latin. His keen observations in many areas were noted, such as when he wrote \"Il sole non si move.\" (\"The Sun does not move.\")In the 1490s he studied mathematics under Luca Pacioli and prepared a series of drawings of regular solids in a skeletal form to be engraved as plates for Pacioli's book Divina proportione, published in 1509. While living in Milan, he studied light from the summit of Monte Rosa. Scientific writings in his notebook on fossils have been considered as influential on early palaeontology.The content of his journals suggest that he was planning a series of treatises on a variety of subjects. A coherent treatise on anatomy is said to have been observed during a visit by Cardinal Louis d'Aragon's secretary in 1517. Aspects of his work on the studies of anatomy, light and the landscape were assembled for publication by Melzi and eventually published as A Treatise on Painting in France and Italy in 1651 and Germany in 1724, with engravings based upon drawings by the Classical painter Nicolas Poussin. According to Arasse, the treatise, which in France went into 62 editions in fifty years, caused Leonardo to be seen as \"the precursor of French academic thought on art.\"While Leonardo's experimentation followed scientific methods, a recent and exhaustive analysis of Leonardo as a scientist by Fritjof Capra argues that Leonardo was a fundamentally different kind of scientist from Galileo, Newton and other scientists who followed him in that, as a \"Renaissance Man\", his theorising and hypothesising integrated the arts and particularly painting.\\n\\nAnatomy and physiology\\nLeonardo started his study in the anatomy of the human body under the apprenticeship of Verrocchio, who demanded that his students develop a deep knowledge of the subject. As an artist, he quickly became master of topographic anatomy, drawing many studies of muscles, tendons and other visible anatomical features.As a successful artist, Leonardo was given permission to dissect human corpses at the Hospital of Santa Maria Nuova in Florence and later at hospitals in Milan and Rome. From 1510 to 1511 he collaborated in his studies with the doctor Marcantonio della Torre, professor of Anatomy at the University of Pavia. Leonardo made over 240 detailed drawings and wrote about 13,000 words toward a treatise on anatomy. Only a small amount of the material on anatomy was published in Leonardo's Treatise on painting. During the time that Melzi was ordering the material into chapters for publication, they were examined by a number of anatomists and artists, including Vasari, Cellini and Albrecht D\u00fcrer, who made a number of drawings from them.Leonardo's anatomical drawings include many studies of the human skeleton and its parts, and of muscles and sinews. He studied the mechanical functions of the skeleton and the muscular forces that are applied to it in a manner that prefigured the modern science of biomechanics. He drew the heart and vascular system, the sex organs and other internal organs, making one of the first scientific drawings of a fetus in utero. The drawings and notation are far ahead of their time, and if published would undoubtedly have made a major contribution to medical science.Leonardo also closely observed and recorded the effects of age and of human emotion on the physiology, studying in particular the effects of rage. He drew many figures who had significant facial deformities or signs of illness. Leonardo also studied and drew the anatomy of many animals, dissecting cows, birds, monkeys, bears, and frogs, and comparing in his drawings their anatomical structure with that of humans. He also made a number of studies of horses.Leonardo's dissections and documentation of muscles, nerves, and vessels helped to describe the physiology and mechanics of movement. He attempted to identify the source of 'emotions' and their expression. He found it difficult to incorporate the prevailing system and theories of bodily humours, but eventually he abandoned these physiological explanations of bodily functions. He made the observations that humours were not located in cerebral spaces or ventricles. He documented that the humours were not contained in the heart or the liver, and that it was the heart that defined the circulatory system. He was the first to define atherosclerosis and liver cirrhosis. He created models of the cerebral ventricles with the use of melted wax and constructed a glass aorta to observe the circulation of blood through the aortic valve by using water and grass seed to watch flow patterns.\\n\\nEngineering and inventions\\nDuring his lifetime, Leonardo was also valued as an engineer. With the same rational and analytical approach that moved him to represent the human body and to investigate anatomy, Leonardo studied and designed many machines and devices. He drew their \"anatomy\" with unparalleled mastery, producing the first form of the modern technical drawing, including a perfected \"exploded view\" technique, to represent internal components. Those studies and projects collected in his codices fill more than 5,000 pages. In a letter of 1482 to the lord of Milan Ludovico il Moro, he wrote that he could create all sorts of machines both for the protection of a city and for siege. When he fled from Milan to Venice in 1499, he found employment as an engineer and devised a system of moveable barricades to protect the city from attack. In 1502, he created a scheme for diverting the flow of the Arno river, a project on which Niccol\u00f2 Machiavelli also worked. He continued to contemplate the canalization of Lombardy's plains while in Louis XII's company and of the Loire and its tributaries in the company of Francis I. Leonardo's journals include a vast number of inventions, both practical and impractical. They include musical instruments, a mechanical knight, hydraulic pumps, reversible crank mechanisms, finned mortar shells, and a steam cannon.\\nLeonardo was fascinated by the phenomenon of flight for much of his life, producing many studies, including Codex on the Flight of Birds (c.\u20091505), as well as plans for several flying machines, such as a flapping ornithopter and a machine with a helical rotor. In a 2003 documentary by British television station Channel Four, titled Leonardo's Dream Machines, various designs by Leonardo, such as a parachute and a giant crossbow, were interpreted and constructed. Some of those designs proved successful, whilst others fared less well when tested. Similarly, a team of engineers built ten machines designed by Leonardo in the 2009 American television series Doing DaVinci, including a fighting vehicle and a self-propelled cart.\\nResearch performed by Marc van den Broek revealed older prototypes for more than 100 inventions that are ascribed to Leonardo. Similarities between Leonardo's illustrations and drawings from the Middle Ages and from Ancient Greece and Rome, the Chinese and Persian Empires, and Egypt suggest that a large portion of Leonardo's inventions had been conceived before his lifetime. Leonardo's innovation was to combine different functions from existing drafts and set them into scenes that illustrated their utility. By reconstituting technical inventions he created something new.In his notebooks, Leonardo first stated the 'laws' of sliding friction in 1493. His inspiration for investigating friction came about in part from his study of perpetual motion, which he correctly concluded was not possible. His results were never published and the friction laws were not rediscovered until 1699 by Guillaume Amontons, with whose name they are now usually associated. For this contribution, Leonardo was named as the first of the 23 \"Men of Tribology\" by Duncan Dowson.\\n\\nLegacy\\nAlthough he had no formal academic training, many historians and scholars regard Leonardo as the prime exemplar of the \"Universal Genius\" or \"Renaissance Man\", an individual of \"unquenchable curiosity\" and \"feverishly inventive imagination.\" He is widely considered one of the most diversely talented individuals ever to have lived. According to art historian Helen Gardner, the scope and depth of his interests were without precedent in recorded history, and \"his mind and personality seem to us superhuman, while the man himself mysterious and remote.\" Scholars interpret his view of the world as being based in logic, though the empirical methods he used were unorthodox for his time.Leonardo's fame within his own lifetime was such that the King of France carried him away like a trophy, and was claimed to have supported him in his old age and held him in his arms as he died. Interest in Leonardo and his work has never diminished. Crowds still queue to see his best-known artworks, T-shirts still bear his most famous drawing, and writers continue to hail him as a genius while speculating about his private life, as well as about what one so intelligent actually believed in.The continued admiration that Leonardo commanded from painters, critics and historians is reflected in many other written tributes. Baldassare Castiglione, author of Il Cortegiano (The Courtier), wrote in 1528: \"...Another of the greatest painters in this world looks down on this art in which he is unequalled...\" while the biographer known as \"Anonimo Gaddiano\" wrote, c.\u20091540: \"His genius was so rare and universal that it can be said that nature worked a miracle on his behalf...\" Vasari, in his Lives of the Artists (1568), opens his chapter on Leonardo:\\nIn the normal course of events many men and women are born with remarkable talents; but occasionally, in a way that transcends nature, a single person is marvellously endowed by Heaven with beauty, grace and talent in such abundance that he leaves other men far behind, all his actions seem inspired and indeed everything he does clearly comes from God rather than from human skill. Everyone acknowledged that this was true of Leonardo da Vinci, an artist of outstanding physical beauty, who displayed infinite grace in everything that he did and who cultivated his genius so brilliantly that all problems he studied he solved with ease.\\nThe 19th century brought a particular admiration for Leonardo's genius, causing Henry Fuseli to write in 1801: \"Such was the dawn of modern art, when Leonardo da Vinci broke forth with a splendour that distanced former excellence: made up of all the elements that constitute the essence of genius...\" This is echoed by A.E. Rio who wrote in 1861: \"He towered above all other artists through the strength and the nobility of his talents.\"By the 19th century, the scope of Leonardo's notebooks was known, as well as his paintings. Hippolyte Taine wrote in 1866: \"There may not be in the world an example of another genius so universal, so incapable of fulfilment, so full of yearning for the infinite, so naturally refined, so far ahead of his own century and the following centuries.\"\\nArt historian Bernard Berenson wrote in 1896: Leonardo is the one artist of whom it may be said with perfect literalness: Nothing that he touched but turned into a thing of eternal beauty. Whether it be the cross section of a skull, the structure of a weed, or a study of muscles, he, with his feeling for line and for light and shade, forever transmuted it into life-communicating values.\\nThe interest in Leonardo's genius has continued unabated; experts study and translate his writings, analyse his paintings using scientific techniques, argue over attributions and search for works which have been recorded but never found. Liana Bortolon, writing in 1967, said: Because of the multiplicity of interests that spurred him to pursue every field of knowledge...Leonardo can be considered, quite rightly, to have been the universal genius par excellence, and with all the disquieting overtones inherent in that term. Man is as uncomfortable today, faced with a genius, as he was in the 16th century. Five centuries have passed, yet we still view Leonardo with awe. The Elmer Belt Library of Vinciana is a special collection at the University of California, Los Angeles.Twenty-first-century author Walter Isaacson based much of his biography of Leonardo on thousands of notebook entries, studying the personal notes, sketches, budget notations, and musings of the man whom he considers the greatest of innovators. Isaacson was surprised to discover a \"fun, joyous\" side of Leonardo in addition to his limitless curiosity and creative genius.On the 500th anniversary of Leonardo's death, the Louvre in Paris arranged for the largest ever single exhibit of his work, called Leonardo, between November 2019 and February 2020. The exhibit includes over 100 paintings, drawings and notebooks. Eleven of the paintings that Leonardo completed in his lifetime were included. Five of these are owned by the Louvre, but the Mona Lisa was not included because it is in such great demand among general visitors to the Louvre; it remains on display in its gallery. Vitruvian Man, however, is on display following a legal battle with its owner, the Gallerie dell'Accademia in Venice. Salvator Mundi was also not included because its Saudi owner did not agree to lease the work.The Mona Lisa, considered Leonardo's magnum opus, is often regarded as the most famous portrait ever made. The Last Supper is the most reproduced religious painting of all time, and Leonardo's Vitruvian Man drawing is also considered a cultural icon.More than a decade of analysis of Leonardo's genetic genealogy, conducted by Alessandro Vezzosi and Agnese Sabato, came to a conclusion in mid-2021. It was determined that the artist has 14 living male relatives. The work could also help determine the authenticity of remains thought to belong to Leonardo.\\n\\nLocation of remains\\nWhile Leonardo was certainly buried in the collegiate church of Saint Florentin at the Ch\u00e2teau d'Amboise in 12 August 1519, the current location of his remains is unclear. Much of Ch\u00e2teau d'Amboise was damaged during the French Revolution, leading to the church's demolition in 1802. Some of the graves were destroyed in the process, scattering the bones interred there and thereby leaving the whereabouts of Leonardo's remains subject to dispute; a gardener may have even buried some in the corner of the courtyard.In 1863, fine-arts inspector general Ars\u00e8ne Houssaye received an imperial commission to excavate the site and discovered a partially complete skeleton with a bronze ring on one finger, white hair, and stone fragments bearing the inscriptions \"EO\", \"AR\", \"DUS\", and \"VINC\" \u2013  interpreted as forming \"Leonardus Vinci\". The skull's eight teeth corresponds to someone with approximately the same age and a silver shield found near the bones depicts a beardless Francis I, corresponding to the king's appearance during Leonardo's time in France.Houssaye postulated that the unusually large skull was an indicator of Leonardo's intelligence; author Charles Nicholl describes this as a \"dubious phrenological deduction\". At the same time, Houssaye noted some issues with his observations, including that the feet were turned toward the high altar, a practice generally reserved for laymen, and that the skeleton of 1.73 metres (5.7 ft) seemed too short. Art historian Mary Margaret Heaton wrote in 1874 that the height would be appropriate for Leonardo. The skull was allegedly presented to Napoleon III before being returned to the Ch\u00e2teau d'Amboise, where they were re-interred in the chapel of Saint Hubert in 1874. A plaque above the tomb states that its contents are only presumed to be those of Leonardo.It has since been theorized that the folding of the skeleton's right arm over the head may correspond to the paralysis of Leonardo's right hand. In 2016, it was announced that DNA tests would be conducted to determine whether the attribution is correct. The DNA of the remains will be compared to that of samples collected from Leonardo's work and his half-brother Domenico's descendants; it may also be sequenced.In 2019, documents were published revealing that Houssaye had kept the ring and a lock of hair. In 1925, his great-grandson sold these to an American collector. Sixty years later, another American acquired them, leading to their being displayed at the Leonardo Museum in Vinci beginning on 2 May 2019, the 500th anniversary of the artist's death.\\n\\nNotes\\nGeneral\\n\\nDates of works\\n\\nReferences\\nCitations\\nEarly\\n\\nModern\\n\\nWorks cited\\nEarly\\nModern\\nBooks\\n\\nJournals and encyclopedia articles\\n\\nFurther reading\\nSee Kemp (2003) and Bambach (2019, pp. 442\u2013579) for extensive bibliographies\\n\\nExternal links\\nGeneral\\n\\nUniversal Leonardo, a database of Leonardo's life and works maintained by Martin Kemp and Marina Wallace\\nLeonardo da Vinci on the National Gallery websiteWorks\\n\\nBiblioteca Leonardiana, online bibliography (in Italian)\\ne-Leo: Archivio digitale di storia della tecnica e della scienza, archive of drawings, notes and manuscripts\\nWorks by Leonardo da Vinci at Project Gutenberg\\nWorks by Leonardo da Vinci at LibriVox (public domain audiobooks) \\nComplete text and images of Richter's translation of the Notebooks\\nThe Notebooks of Leonardo da Vinci"}
{"article_name": "Quantum_mechanics", "link": "https://en.wikipedia.org/wiki/Quantum_mechanics", "text_content": "Quantum mechanics is a fundamental theory in physics that describes the behavior of nature at and below the scale of atoms.:\u200a1.1\u200a It is the foundation of all quantum physics including quantum chemistry, quantum field theory, quantum technology, and quantum information science.\\nClassical physics, the collection of theories that existed before the advent of quantum mechanics, describes many aspects of nature at an ordinary (macroscopic) scale, but is not sufficient for describing them at small (atomic and subatomic) scales. Most theories in classical physics can be derived from quantum mechanics as an approximation valid at large (macroscopic) scale.Unlike classical systems, quantum systems have bound states quantized to discrete values of energy, momentum, angular momentum, and other quantities; measurements of systems show characteristics of both particles and waves (wave\u2013particle duality); and there are limits to how accurately the value of a physical quantity can be predicted prior to its measurement, given a complete set of initial conditions (the uncertainty principle).\\nQuantum mechanics arose gradually from theories to explain observations that could not be reconciled with classical physics, such as Max Planck's solution in 1900 to the black-body radiation problem, and the correspondence between energy and frequency in Albert Einstein's 1905 paper, which explained the photoelectric effect. These early attempts to understand microscopic phenomena, now known as the \"old quantum theory\", led to the full development of quantum mechanics in the mid-1920s by Niels Bohr, Erwin Schr\u00f6dinger, Werner Heisenberg, Max Born, Paul Dirac and others. The modern theory is formulated in various specially developed mathematical formalisms. In one of them, a mathematical entity called the wave function provides information, in the form of probability amplitudes, about what measurements of a particle's energy, momentum, and other physical properties may yield.\\n\\nOverview and fundamental concepts\\nQuantum mechanics allows the calculation of properties and behaviour of physical systems. It is typically applied to microscopic systems: molecules, atoms and sub-atomic particles. It has been demonstrated to hold for complex molecules with thousands of atoms, but its application to human beings raises philosophical problems, such as Wigner's friend, and its application to the universe as a whole remains speculative. Predictions of quantum mechanics have been verified experimentally to an extremely high degree of accuracy. For example, the refinement of quantum mechanics for the interaction of light and matter, known as quantum electrodynamics (QED), has been  shown to agree with experiment to within 1 part in 108 for some atomic properties.\\nA fundamental feature of the theory is that it usually cannot predict with certainty what will happen, but only give probabilities. Mathematically, a probability is found by taking the square of the absolute value of a complex number, known as a probability amplitude. This is known as the Born rule, named after physicist Max Born. For example, a quantum particle like an electron can be described by a wave function, which associates to each point in space a probability amplitude. Applying the Born rule to these amplitudes gives a probability density function for the position that the electron will be found to have when an experiment is performed to measure it. This is the best the theory can do; it cannot say for certain where the electron will be found. The Schr\u00f6dinger equation relates the collection of probability amplitudes that pertain to one moment of time to the collection of probability amplitudes that pertain to another.\\nOne consequence of the mathematical rules of quantum mechanics is a tradeoff in predictability between different measurable quantities. The most famous form of this uncertainty principle says that no matter how a quantum particle is prepared or how carefully experiments upon it are arranged, it is impossible to have a precise prediction for a measurement of its position and also at the same time for a measurement of its momentum.\\nAnother consequence of the mathematical rules of quantum mechanics is the phenomenon of quantum interference, which is often illustrated with the double-slit experiment. In the basic version of this experiment, a coherent light source, such as a laser beam, illuminates a plate pierced by two parallel slits, and the light passing through the slits is observed on a screen behind the plate.:\u200a102\u2013111\u200a:\u200a1.1\u20131.8\u200a The wave nature of light causes the light waves passing through the two slits to interfere, producing bright and dark bands on the screen \u2013 a result that would not be expected if light consisted of classical particles. However, the light is always found to be absorbed at the screen at discrete points, as individual particles rather than waves; the interference pattern appears via the varying density of these particle hits on the screen. Furthermore, versions of the experiment that include detectors at the slits find that each detected photon passes through one slit (as would a classical particle), and not through both slits (as would a wave).:\u200a109\u200a However, such experiments demonstrate that particles do not form the interference pattern if one detects which slit they pass through.  This behavior is known as wave\u2013particle duality. In addition to light, electrons, atoms, and molecules are all found to exhibit the same dual behavior when fired towards a double slit.Another non-classical phenomenon predicted by quantum mechanics is quantum tunnelling: a particle that goes up against a potential barrier can cross it, even if its kinetic energy is smaller than the maximum of the potential. In classical mechanics this particle would be trapped. Quantum tunnelling has several important consequences, enabling radioactive decay, nuclear fusion in stars, and applications such as scanning tunnelling microscopy and the tunnel diode.When quantum systems interact, the result can be the creation of quantum entanglement: their properties become so intertwined that a description of the whole solely in terms of the individual parts is no longer possible. Erwin Schr\u00f6dinger called entanglement \"...the characteristic trait of quantum mechanics, the one that enforces its entire departure from classical lines of thought\". Quantum entanglement enables quantum computing and is part of quantum communication protocols, such as quantum key distribution and superdense coding. Contrary to popular misconception, entanglement does not allow sending signals faster than light, as demonstrated by the no-communication theorem.Another possibility opened by entanglement is testing for \"hidden variables\", hypothetical properties more fundamental than the quantities addressed in quantum theory itself, knowledge of which would allow more exact predictions than quantum theory can provide. A collection of results, most significantly Bell's theorem, have demonstrated that broad classes of such hidden-variable theories are in fact incompatible with quantum physics. According to Bell's theorem, if nature actually operates in accord with any theory of local hidden variables, then the results of a Bell test will be constrained in a particular, quantifiable way. Many Bell tests have been performed and they have shown results incompatible with the constraints imposed by local hidden variables.It is not possible to present these concepts in more than a superficial way without introducing the actual mathematics involved; understanding quantum mechanics requires not only manipulating complex numbers, but also linear algebra, differential equations, group theory, and other more advanced subjects. Accordingly, this article will present a mathematical formulation of quantum mechanics and survey its application to some useful and oft-studied examples.\\n\\nMathematical formulation\\nIn the mathematically rigorous formulation of quantum mechanics, the state of a quantum mechanical system is a vector \\n  \\n    \\n      \\n        \u03c8\\n      \\n    \\n    {\\displaystyle \\psi }\\n   belonging to a (separable) complex Hilbert space \\n  \\n    \\n      \\n        \\n          \\n            H\\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\mathcal {H}}}\\n  . This vector is postulated to be normalized under the Hilbert space inner product, that is, it obeys \\n  \\n    \\n      \\n        \u27e8\\n        \u03c8\\n        ,\\n        \u03c8\\n        \u27e9\\n        =\\n        1\\n      \\n    \\n    {\\displaystyle \\langle \\psi ,\\psi \\rangle =1}\\n  , and it is well-defined up to a complex number of modulus 1 (the global phase), that is, \\n  \\n    \\n      \\n        \u03c8\\n      \\n    \\n    {\\displaystyle \\psi }\\n   and \\n  \\n    \\n      \\n        \\n          e\\n          \\n            i\\n            \u03b1\\n          \\n        \\n        \u03c8\\n      \\n    \\n    {\\displaystyle e^{i\\alpha }\\psi }\\n   represent the same physical system. In other words, the possible states are points in the projective space of a Hilbert space, usually called the complex projective space. The exact nature of this Hilbert space is dependent on the system \u2013 for example, for describing position and momentum the Hilbert space is the space of complex square-integrable functions \\n  \\n    \\n      \\n        \\n          L\\n          \\n            2\\n          \\n        \\n        (\\n        \\n          C\\n        \\n        )\\n      \\n    \\n    {\\displaystyle L^{2}(\\mathbb {C} )}\\n  , while the Hilbert space for the spin of a single proton is simply the space of two-dimensional complex vectors \\n  \\n    \\n      \\n        \\n          \\n            C\\n          \\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\mathbb {C} ^{2}}\\n   with the usual inner product.\\nPhysical quantities of interest \u2013 position, momentum, energy, spin \u2013 are represented by observables, which are Hermitian (more precisely, self-adjoint) linear operators acting on the Hilbert space. A quantum state can be an eigenvector of an observable, in which case it is called an eigenstate, and the associated eigenvalue corresponds to the value of the observable in that eigenstate. More generally, a quantum state will be a linear combination of the eigenstates, known as a quantum superposition. When an observable is measured, the result will be one of its eigenvalues with probability given by the Born rule: in the simplest case the eigenvalue \\n  \\n    \\n      \\n        \u03bb\\n      \\n    \\n    {\\displaystyle \\lambda }\\n   is non-degenerate and the probability is given by \\n  \\n    \\n      \\n        \\n          |\\n        \\n        \u27e8\\n        \\n          \\n            \\n              \u03bb\\n              \u2192\\n            \\n          \\n        \\n        ,\\n        \u03c8\\n        \u27e9\\n        \\n          \\n            |\\n          \\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\displaystyle |\\langle {\\vec {\\lambda }},\\psi \\rangle |^{2}}\\n  , where \\n  \\n    \\n      \\n        \\n          \\n            \\n              \u03bb\\n              \u2192\\n            \\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\vec {\\lambda }}}\\n   is its associated eigenvector. More generally, the eigenvalue is degenerate and the probability is given by \\n  \\n    \\n      \\n        \u27e8\\n        \u03c8\\n        ,\\n        \\n          P\\n          \\n            \u03bb\\n          \\n        \\n        \u03c8\\n        \u27e9\\n      \\n    \\n    {\\displaystyle \\langle \\psi ,P_{\\lambda }\\psi \\rangle }\\n  , where \\n  \\n    \\n      \\n        \\n          P\\n          \\n            \u03bb\\n          \\n        \\n      \\n    \\n    {\\displaystyle P_{\\lambda }}\\n   is the projector onto its associated eigenspace. In the continuous case, these formulas give instead the probability density.\\nAfter the measurement, if result \\n  \\n    \\n      \\n        \u03bb\\n      \\n    \\n    {\\displaystyle \\lambda }\\n   was obtained, the quantum state is postulated to collapse to \\n  \\n    \\n      \\n        \\n          \\n            \\n              \u03bb\\n              \u2192\\n            \\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\vec {\\lambda }}}\\n  , in the non-degenerate case, or to \\n  \\n    \\n      \\n        \\n          P\\n          \\n            \u03bb\\n          \\n        \\n        \u03c8\\n        \\n          \\n            /\\n          \\n        \\n        \\n        \\n          \\n            \u27e8\\n            \u03c8\\n            ,\\n            \\n              P\\n              \\n                \u03bb\\n              \\n            \\n            \u03c8\\n            \u27e9\\n          \\n        \\n      \\n    \\n    {\\textstyle P_{\\lambda }\\psi {\\big /}\\!{\\sqrt {\\langle \\psi ,P_{\\lambda }\\psi \\rangle }}}\\n  , in the general case. The probabilistic nature of quantum mechanics thus stems from the act of measurement. This is one of the most difficult aspects of quantum systems to understand. It was the central topic in the famous Bohr\u2013Einstein debates, in which the two scientists attempted to clarify these fundamental principles by way of thought experiments. In the decades after the formulation of quantum mechanics, the question of what constitutes a \"measurement\" has been extensively studied. Newer interpretations of quantum mechanics have been formulated that do away with the concept of \"wave function collapse\" (see, for example, the many-worlds interpretation). The basic idea is that when a quantum system interacts with a measuring apparatus, their respective wave functions become entangled so that the original quantum system ceases to exist as an independent entity. For details, see the article on measurement in quantum mechanics.The time evolution of a quantum state is described by the Schr\u00f6dinger equation:\\n\\n  \\n    \\n      \\n        i\\n        \u210f\\n        \\n          \\n            d\\n            \\n              d\\n              t\\n            \\n          \\n        \\n        \u03c8\\n        (\\n        t\\n        )\\n        =\\n        H\\n        \u03c8\\n        (\\n        t\\n        )\\n        .\\n      \\n    \\n    {\\displaystyle i\\hbar {\\frac {d}{dt}}\\psi (t)=H\\psi (t).}\\n  Here \\n  \\n    \\n      \\n        H\\n      \\n    \\n    {\\displaystyle H}\\n   denotes the Hamiltonian, the observable corresponding to the total energy of the system, and \\n  \\n    \\n      \\n        \u210f\\n      \\n    \\n    {\\displaystyle \\hbar }\\n   is the reduced Planck constant. The constant \\n  \\n    \\n      \\n        i\\n        \u210f\\n      \\n    \\n    {\\displaystyle i\\hbar }\\n   is introduced so that the Hamiltonian is reduced to the classical Hamiltonian in cases where the quantum system can be approximated by a classical system; the ability to make such an approximation in certain limits is called the correspondence principle.\\nThe solution of this differential equation is given by\\n\\n  \\n    \\n      \\n        \u03c8\\n        (\\n        t\\n        )\\n        =\\n        \\n          e\\n          \\n            \u2212\\n            i\\n            H\\n            t\\n            \\n              /\\n            \\n            \u210f\\n          \\n        \\n        \u03c8\\n        (\\n        0\\n        )\\n        .\\n      \\n    \\n    {\\displaystyle \\psi (t)=e^{-iHt/\\hbar }\\psi (0).}\\n  The operator \\n  \\n    \\n      \\n        U\\n        (\\n        t\\n        )\\n        =\\n        \\n          e\\n          \\n            \u2212\\n            i\\n            H\\n            t\\n            \\n              /\\n            \\n            \u210f\\n          \\n        \\n      \\n    \\n    {\\displaystyle U(t)=e^{-iHt/\\hbar }}\\n   is known as the time-evolution operator, and has the crucial property that it is unitary. This time evolution is deterministic in the sense that \u2013 given an initial quantum state \\n  \\n    \\n      \\n        \u03c8\\n        (\\n        0\\n        )\\n      \\n    \\n    {\\displaystyle \\psi (0)}\\n    \u2013 it makes a definite prediction of what the quantum state \\n  \\n    \\n      \\n        \u03c8\\n        (\\n        t\\n        )\\n      \\n    \\n    {\\displaystyle \\psi (t)}\\n   will be at any later time.\\nSome wave functions produce probability distributions that are independent of time, such as eigenstates of the Hamiltonian. Many systems that are treated dynamically in classical mechanics are described by such \"static\" wave functions. For example, a single electron in an unexcited atom is pictured classically as a particle moving in a circular trajectory around the atomic nucleus, whereas in quantum mechanics, it is described by a static wave function surrounding the nucleus. For example, the electron wave function for an unexcited hydrogen atom is a spherically symmetric function known as an s orbital (Fig. 1).\\nAnalytic solutions of the Schr\u00f6dinger equation are known for very few relatively simple model Hamiltonians including the quantum harmonic oscillator, the particle in a box, the dihydrogen cation, and the hydrogen atom. Even the helium atom \u2013 which contains just two electrons \u2013 has defied all attempts at a fully analytic treatment.\\nHowever, there are techniques for finding approximate solutions. One method, called perturbation theory, uses the analytic result for a simple quantum mechanical model to create a result for a related but more complicated model by (for example) the addition of a weak potential energy. Another method is called \"semi-classical equation of motion\", which applies to systems for which quantum mechanics produces only small deviations from classical behavior. These deviations can then be computed based on the classical motion. This approach is particularly important in the field of quantum chaos.\\n\\nUncertainty principle\\nOne consequence of the basic quantum formalism is the uncertainty principle. In its most familiar form, this states that no preparation of a quantum particle can imply simultaneously precise predictions both for a measurement of its position and for a measurement of its momentum. Both position and momentum are observables, meaning that they are represented by Hermitian operators. The position operator \\n  \\n    \\n      \\n        \\n          \\n            \\n              X\\n              ^\\n            \\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\hat {X}}}\\n   and momentum operator \\n  \\n    \\n      \\n        \\n          \\n            \\n              P\\n              ^\\n            \\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\hat {P}}}\\n   do not commute, but rather satisfy the canonical commutation relation:\\n\\n  \\n    \\n      \\n        [\\n        \\n          \\n            \\n              X\\n              ^\\n            \\n          \\n        \\n        ,\\n        \\n          \\n            \\n              P\\n              ^\\n            \\n          \\n        \\n        ]\\n        =\\n        i\\n        \u210f\\n        .\\n      \\n    \\n    {\\displaystyle [{\\hat {X}},{\\hat {P}}]=i\\hbar .}\\n  Given a quantum state, the Born rule lets us compute expectation values for both \\n  \\n    \\n      \\n        X\\n      \\n    \\n    {\\displaystyle X}\\n   and \\n  \\n    \\n      \\n        P\\n      \\n    \\n    {\\displaystyle P}\\n  , and moreover for powers of them. Defining \\nthe uncertainty for an observable by a standard deviation, we have\\n\\n  \\n    \\n      \\n        \\n          \u03c3\\n          \\n            X\\n          \\n        \\n        =\\n        \\n          \\n            \\n              \\n                \\n                  \u27e8\\n                  \\n                    X\\n                    \\n                      2\\n                    \\n                  \\n                  \u27e9\\n                \\n                \u2212\\n                \\n                  \\n                    \u27e8\\n                    X\\n                    \u27e9\\n                  \\n                  \\n                    2\\n                  \\n                \\n              \\n            \\n          \\n        \\n        ,\\n      \\n    \\n    {\\displaystyle \\sigma _{X}={\\textstyle {\\sqrt {\\left\\langle X^{2}\\right\\rangle -\\left\\langle X\\right\\rangle ^{2}}}},}\\n  and likewise for the momentum:\\n\\n  \\n    \\n      \\n        \\n          \u03c3\\n          \\n            P\\n          \\n        \\n        =\\n        \\n          \\n            \\n              \u27e8\\n              \\n                P\\n                \\n                  2\\n                \\n              \\n              \u27e9\\n            \\n            \u2212\\n            \\n              \\n                \u27e8\\n                P\\n                \u27e9\\n              \\n              \\n                2\\n              \\n            \\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle \\sigma _{P}={\\sqrt {\\left\\langle P^{2}\\right\\rangle -\\left\\langle P\\right\\rangle ^{2}}}.}\\n  The uncertainty principle states that\\n\\n  \\n    \\n      \\n        \\n          \u03c3\\n          \\n            X\\n          \\n        \\n        \\n          \u03c3\\n          \\n            P\\n          \\n        \\n        \u2265\\n        \\n          \\n            \u210f\\n            2\\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle \\sigma _{X}\\sigma _{P}\\geq {\\frac {\\hbar }{2}}.}\\n  Either standard deviation can in principle be made arbitrarily small, but not both simultaneously. This inequality generalizes to arbitrary pairs of self-adjoint operators \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\displaystyle A}\\n   and \\n  \\n    \\n      \\n        B\\n      \\n    \\n    {\\displaystyle B}\\n  . The commutator of these two operators is\\n\\n  \\n    \\n      \\n        [\\n        A\\n        ,\\n        B\\n        ]\\n        =\\n        A\\n        B\\n        \u2212\\n        B\\n        A\\n        ,\\n      \\n    \\n    {\\displaystyle [A,B]=AB-BA,}\\n  and this provides the lower bound on the product of standard deviations:\\n\\n  \\n    \\n      \\n        \\n          \u03c3\\n          \\n            A\\n          \\n        \\n        \\n          \u03c3\\n          \\n            B\\n          \\n        \\n        \u2265\\n        \\n          \\n            \\n              1\\n              2\\n            \\n          \\n        \\n        \\n          |\\n          \\n            \\n              \\n                \u27e8\\n              \\n            \\n            [\\n            A\\n            ,\\n            B\\n            ]\\n            \\n              \\n                \u27e9\\n              \\n            \\n          \\n          |\\n        \\n        .\\n      \\n    \\n    {\\displaystyle \\sigma _{A}\\sigma _{B}\\geq {\\tfrac {1}{2}}\\left|{\\bigl \\langle }[A,B]{\\bigr \\rangle }\\right|.}\\n  Another consequence of the canonical commutation relation is that the position and momentum operators are Fourier transforms of each other, so that a description of an object according to its momentum is the Fourier transform of its description according to its position. The fact that dependence in momentum is the Fourier transform of the dependence in position means that the momentum operator is equivalent (up to an \\n  \\n    \\n      \\n        i\\n        \\n          /\\n        \\n        \u210f\\n      \\n    \\n    {\\displaystyle i/\\hbar }\\n   factor) to taking the derivative according to the position, since in Fourier analysis differentiation corresponds to multiplication in the dual space. This is why in quantum equations in position space, the momentum \\n  \\n    \\n      \\n        \\n          p\\n          \\n            i\\n          \\n        \\n      \\n    \\n    {\\displaystyle p_{i}}\\n   is replaced by \\n  \\n    \\n      \\n        \u2212\\n        i\\n        \u210f\\n        \\n          \\n            \u2202\\n            \\n              \u2202\\n              x\\n            \\n          \\n        \\n      \\n    \\n    {\\displaystyle -i\\hbar {\\frac {\\partial }{\\partial x}}}\\n  , and in particular in the non-relativistic Schr\u00f6dinger equation in position space the momentum-squared term is replaced with a Laplacian times \\n  \\n    \\n      \\n        \u2212\\n        \\n          \u210f\\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\displaystyle -\\hbar ^{2}}\\n  .\\n\\nComposite systems and entanglement\\nWhen two different quantum systems are considered together, the Hilbert space of the combined system is the tensor product of the Hilbert spaces of the two components. For example, let A and B be two quantum systems, with Hilbert spaces \\n  \\n    \\n      \\n        \\n          \\n            \\n              H\\n            \\n          \\n          \\n            A\\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\mathcal {H}}_{A}}\\n   and \\n  \\n    \\n      \\n        \\n          \\n            \\n              H\\n            \\n          \\n          \\n            B\\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\mathcal {H}}_{B}}\\n  , respectively. The Hilbert space of the composite system is then\\n\\n  \\n    \\n      \\n        \\n          \\n            \\n              H\\n            \\n          \\n          \\n            A\\n            B\\n          \\n        \\n        =\\n        \\n          \\n            \\n              H\\n            \\n          \\n          \\n            A\\n          \\n        \\n        \u2297\\n        \\n          \\n            \\n              H\\n            \\n          \\n          \\n            B\\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle {\\mathcal {H}}_{AB}={\\mathcal {H}}_{A}\\otimes {\\mathcal {H}}_{B}.}\\n  If the state for the first system is the vector \\n  \\n    \\n      \\n        \\n          \u03c8\\n          \\n            A\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi _{A}}\\n   and the state for the second system is \\n  \\n    \\n      \\n        \\n          \u03c8\\n          \\n            B\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi _{B}}\\n  , then the state of the composite system is\\n\\n  \\n    \\n      \\n        \\n          \u03c8\\n          \\n            A\\n          \\n        \\n        \u2297\\n        \\n          \u03c8\\n          \\n            B\\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle \\psi _{A}\\otimes \\psi _{B}.}\\n  Not all states in the joint Hilbert space \\n  \\n    \\n      \\n        \\n          \\n            \\n              H\\n            \\n          \\n          \\n            A\\n            B\\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\mathcal {H}}_{AB}}\\n   can be written in this form, however, because the superposition principle implies that linear combinations of these \"separable\" or \"product states\" are also valid. For example, if \\n  \\n    \\n      \\n        \\n          \u03c8\\n          \\n            A\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi _{A}}\\n   and \\n  \\n    \\n      \\n        \\n          \u03d5\\n          \\n            A\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\phi _{A}}\\n   are both possible states for system \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\displaystyle A}\\n  , and likewise \\n  \\n    \\n      \\n        \\n          \u03c8\\n          \\n            B\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi _{B}}\\n   and \\n  \\n    \\n      \\n        \\n          \u03d5\\n          \\n            B\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\phi _{B}}\\n   are both possible states for system \\n  \\n    \\n      \\n        B\\n      \\n    \\n    {\\displaystyle B}\\n  , then\\n\\n  \\n    \\n      \\n        \\n          \\n            \\n              1\\n              \\n                2\\n              \\n            \\n          \\n        \\n        \\n          (\\n          \\n            \\n              \u03c8\\n              \\n                A\\n              \\n            \\n            \u2297\\n            \\n              \u03c8\\n              \\n                B\\n              \\n            \\n            +\\n            \\n              \u03d5\\n              \\n                A\\n              \\n            \\n            \u2297\\n            \\n              \u03d5\\n              \\n                B\\n              \\n            \\n          \\n          )\\n        \\n      \\n    \\n    {\\displaystyle {\\tfrac {1}{\\sqrt {2}}}\\left(\\psi _{A}\\otimes \\psi _{B}+\\phi _{A}\\otimes \\phi _{B}\\right)}\\n  is a valid joint state that is not separable. States that are not separable are called entangled.If the state for a composite system is entangled, it is impossible to describe either component system A or system B by a state vector. One can instead define reduced density matrices that describe the statistics that can be obtained by making measurements on either component system alone. This necessarily causes a loss of information, though: knowing the reduced density matrices of the individual systems is not enough to reconstruct the state of the composite system. Just as density matrices specify the state of a subsystem of a larger system, analogously, positive operator-valued measures (POVMs) describe the effect on a subsystem of a measurement performed on a larger system. POVMs are extensively used in quantum information theory.As described above, entanglement is a key feature of models of measurement processes in which an apparatus becomes entangled with the system being measured. Systems interacting with the environment in which they reside generally become entangled with that environment, a phenomenon known as quantum decoherence. This can explain why, in practice, quantum effects are difficult to observe in systems larger than microscopic.\\n\\nEquivalence between formulations\\nThere are many mathematically equivalent formulations of quantum mechanics. One of the oldest and most common is the \"transformation theory\" proposed by Paul Dirac, which unifies and generalizes the two earliest formulations of quantum mechanics \u2013 matrix mechanics (invented by Werner Heisenberg) and wave mechanics (invented by Erwin Schr\u00f6dinger). An alternative formulation of quantum mechanics is Feynman's path integral formulation, in which a quantum-mechanical amplitude is considered as a sum over all possible classical and non-classical paths between the initial and final states. This is the quantum-mechanical counterpart of the action principle in classical mechanics.\\n\\nSymmetries and conservation laws\\nThe Hamiltonian \\n  \\n    \\n      \\n        H\\n      \\n    \\n    {\\displaystyle H}\\n   is known as the generator of time evolution, since it defines a unitary time-evolution operator \\n  \\n    \\n      \\n        U\\n        (\\n        t\\n        )\\n        =\\n        \\n          e\\n          \\n            \u2212\\n            i\\n            H\\n            t\\n            \\n              /\\n            \\n            \u210f\\n          \\n        \\n      \\n    \\n    {\\displaystyle U(t)=e^{-iHt/\\hbar }}\\n   for each value of \\n  \\n    \\n      \\n        t\\n      \\n    \\n    {\\displaystyle t}\\n  . From this relation between \\n  \\n    \\n      \\n        U\\n        (\\n        t\\n        )\\n      \\n    \\n    {\\displaystyle U(t)}\\n   and \\n  \\n    \\n      \\n        H\\n      \\n    \\n    {\\displaystyle H}\\n  , it follows that any observable \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\displaystyle A}\\n   that commutes with \\n  \\n    \\n      \\n        H\\n      \\n    \\n    {\\displaystyle H}\\n   will be conserved: its expectation value will not change over time. This statement generalizes, as mathematically, any Hermitian operator \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\displaystyle A}\\n   can generate a family of unitary operators parameterized by a variable \\n  \\n    \\n      \\n        t\\n      \\n    \\n    {\\displaystyle t}\\n  . Under the evolution generated by \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\displaystyle A}\\n  , any observable \\n  \\n    \\n      \\n        B\\n      \\n    \\n    {\\displaystyle B}\\n   that commutes with \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\displaystyle A}\\n   will be conserved. Moreover, if \\n  \\n    \\n      \\n        B\\n      \\n    \\n    {\\displaystyle B}\\n   is conserved by evolution under \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\displaystyle A}\\n  , then \\n  \\n    \\n      \\n        A\\n      \\n    \\n    {\\displaystyle A}\\n   is conserved under the evolution generated by \\n  \\n    \\n      \\n        B\\n      \\n    \\n    {\\displaystyle B}\\n  . This implies a quantum version of the result proven by Emmy Noether in classical (Lagrangian) mechanics: for every differentiable symmetry of a Hamiltonian, there exists a corresponding conservation law.\\n\\nExamples\\nFree particle\\nThe simplest example of a quantum system with a position degree of freedom is a free particle in a single spatial dimension. A free particle is one which is not subject to external influences, so that its Hamiltonian consists only of its kinetic energy:\\n\\n  \\n    \\n      \\n        H\\n        =\\n        \\n          \\n            1\\n            \\n              2\\n              m\\n            \\n          \\n        \\n        \\n          P\\n          \\n            2\\n          \\n        \\n        =\\n        \u2212\\n        \\n          \\n            \\n              \u210f\\n              \\n                2\\n              \\n            \\n            \\n              2\\n              m\\n            \\n          \\n        \\n        \\n          \\n            \\n              d\\n              \\n                2\\n              \\n            \\n            \\n              d\\n              \\n                x\\n                \\n                  2\\n                \\n              \\n            \\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle H={\\frac {1}{2m}}P^{2}=-{\\frac {\\hbar ^{2}}{2m}}{\\frac {d^{2}}{dx^{2}}}.}\\n  The general solution of the Schr\u00f6dinger equation is given by\\n\\n  \\n    \\n      \\n        \u03c8\\n        (\\n        x\\n        ,\\n        t\\n        )\\n        =\\n        \\n          \\n            1\\n            \\n              2\\n              \u03c0\\n            \\n          \\n        \\n        \\n          \u222b\\n          \\n            \u2212\\n            \u221e\\n          \\n          \\n            \u221e\\n          \\n        \\n        \\n          \\n            \\n              \u03c8\\n              ^\\n            \\n          \\n        \\n        (\\n        k\\n        ,\\n        0\\n        )\\n        \\n          e\\n          \\n            i\\n            (\\n            k\\n            x\\n            \u2212\\n            \\n              \\n                \\n                  \u210f\\n                  \\n                    k\\n                    \\n                      2\\n                    \\n                  \\n                \\n                \\n                  2\\n                  m\\n                \\n              \\n            \\n            t\\n            )\\n          \\n        \\n        \\n          d\\n        \\n        k\\n        ,\\n      \\n    \\n    {\\displaystyle \\psi (x,t)={\\frac {1}{\\sqrt {2\\pi }}}\\int _{-\\infty }^{\\infty }{\\hat {\\psi }}(k,0)e^{i(kx-{\\frac {\\hbar k^{2}}{2m}}t)}\\mathrm {d} k,}\\n  which is a superposition of all possible plane waves \\n  \\n    \\n      \\n        \\n          e\\n          \\n            i\\n            (\\n            k\\n            x\\n            \u2212\\n            \\n              \\n                \\n                  \u210f\\n                  \\n                    k\\n                    \\n                      2\\n                    \\n                  \\n                \\n                \\n                  2\\n                  m\\n                \\n              \\n            \\n            t\\n            )\\n          \\n        \\n      \\n    \\n    {\\displaystyle e^{i(kx-{\\frac {\\hbar k^{2}}{2m}}t)}}\\n  , which are eigenstates of the momentum operator with momentum \\n  \\n    \\n      \\n        p\\n        =\\n        \u210f\\n        k\\n      \\n    \\n    {\\displaystyle p=\\hbar k}\\n  . The coefficients of the superposition are \\n  \\n    \\n      \\n        \\n          \\n            \\n              \u03c8\\n              ^\\n            \\n          \\n        \\n        (\\n        k\\n        ,\\n        0\\n        )\\n      \\n    \\n    {\\displaystyle {\\hat {\\psi }}(k,0)}\\n  , which is the Fourier transform of the initial quantum state \\n  \\n    \\n      \\n        \u03c8\\n        (\\n        x\\n        ,\\n        0\\n        )\\n      \\n    \\n    {\\displaystyle \\psi (x,0)}\\n  .\\nIt is not possible for the solution to be a single momentum eigenstate, or a single position eigenstate, as these are not normalizable quantum states. Instead, we can consider a Gaussian wave packet:\\n\\n  \\n    \\n      \\n        \u03c8\\n        (\\n        x\\n        ,\\n        0\\n        )\\n        =\\n        \\n          \\n            1\\n            \\n              \\n                \u03c0\\n                a\\n              \\n              \\n                4\\n              \\n            \\n          \\n        \\n        \\n          e\\n          \\n            \u2212\\n            \\n              \\n                \\n                  x\\n                  \\n                    2\\n                  \\n                \\n                \\n                  2\\n                  a\\n                \\n              \\n            \\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi (x,0)={\\frac {1}{\\sqrt[{4}]{\\pi a}}}e^{-{\\frac {x^{2}}{2a}}}}\\n  which has Fourier transform, and therefore momentum distribution\\n\\n  \\n    \\n      \\n        \\n          \\n            \\n              \u03c8\\n              ^\\n            \\n          \\n        \\n        (\\n        k\\n        ,\\n        0\\n        )\\n        =\\n        \\n          \\n            \\n              a\\n              \u03c0\\n            \\n            \\n              4\\n            \\n          \\n        \\n        \\n          e\\n          \\n            \u2212\\n            \\n              \\n                \\n                  a\\n                  \\n                    k\\n                    \\n                      2\\n                    \\n                  \\n                \\n                2\\n              \\n            \\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle {\\hat {\\psi }}(k,0)={\\sqrt[{4}]{\\frac {a}{\\pi }}}e^{-{\\frac {ak^{2}}{2}}}.}\\n  We see that as we make \\n  \\n    \\n      \\n        a\\n      \\n    \\n    {\\displaystyle a}\\n   smaller the spread in position gets smaller, but the spread in momentum gets larger. Conversely, by making \\n  \\n    \\n      \\n        a\\n      \\n    \\n    {\\displaystyle a}\\n   larger we make the spread in momentum smaller, but the spread in position gets larger. This illustrates the uncertainty principle.\\nAs we let the Gaussian wave packet evolve in time, we see that its center moves through space at a constant velocity (like a classical particle with no forces acting on it). However, the wave packet will also spread out as time progresses, which means that the position becomes more and more uncertain. The uncertainty in momentum, however, stays constant.\\n\\nParticle in a box\\nThe particle in a one-dimensional potential energy box is the most mathematically simple example where restraints lead to the quantization of energy levels. The box is defined as having zero potential energy everywhere inside a certain region, and therefore infinite potential energy everywhere outside that region.:\u200a77\u201378\u200a For the one-dimensional case in the \\n  \\n    \\n      \\n        x\\n      \\n    \\n    {\\displaystyle x}\\n   direction, the time-independent Schr\u00f6dinger equation may be written\\n\\n  \\n    \\n      \\n        \u2212\\n        \\n          \\n            \\n              \u210f\\n              \\n                2\\n              \\n            \\n            \\n              2\\n              m\\n            \\n          \\n        \\n        \\n          \\n            \\n              \\n                d\\n                \\n                  2\\n                \\n              \\n              \u03c8\\n            \\n            \\n              d\\n              \\n                x\\n                \\n                  2\\n                \\n              \\n            \\n          \\n        \\n        =\\n        E\\n        \u03c8\\n        .\\n      \\n    \\n    {\\displaystyle -{\\frac {\\hbar ^{2}}{2m}}{\\frac {d^{2}\\psi }{dx^{2}}}=E\\psi .}\\n  With the differential operator defined by\\n\\n  \\n    \\n      \\n        \\n          \\n            \\n              \\n                p\\n                ^\\n              \\n            \\n          \\n          \\n            x\\n          \\n        \\n        =\\n        \u2212\\n        i\\n        \u210f\\n        \\n          \\n            d\\n            \\n              d\\n              x\\n            \\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\hat {p}}_{x}=-i\\hbar {\\frac {d}{dx}}}\\n  the previous equation is evocative of the classic kinetic energy analogue,\\n\\n  \\n    \\n      \\n        \\n          \\n            1\\n            \\n              2\\n              m\\n            \\n          \\n        \\n        \\n          \\n            \\n              \\n                p\\n                ^\\n              \\n            \\n          \\n          \\n            x\\n          \\n          \\n            2\\n          \\n        \\n        =\\n        E\\n        ,\\n      \\n    \\n    {\\displaystyle {\\frac {1}{2m}}{\\hat {p}}_{x}^{2}=E,}\\n  with state \\n  \\n    \\n      \\n        \u03c8\\n      \\n    \\n    {\\displaystyle \\psi }\\n   in this case having energy \\n  \\n    \\n      \\n        E\\n      \\n    \\n    {\\displaystyle E}\\n   coincident with the kinetic energy of the particle.\\nThe general solutions of the Schr\u00f6dinger equation for the particle in a box are\\n\\n  \\n    \\n      \\n        \u03c8\\n        (\\n        x\\n        )\\n        =\\n        A\\n        \\n          e\\n          \\n            i\\n            k\\n            x\\n          \\n        \\n        +\\n        B\\n        \\n          e\\n          \\n            \u2212\\n            i\\n            k\\n            x\\n          \\n        \\n        \\n        \\n        E\\n        =\\n        \\n          \\n            \\n              \\n                \u210f\\n                \\n                  2\\n                \\n              \\n              \\n                k\\n                \\n                  2\\n                \\n              \\n            \\n            \\n              2\\n              m\\n            \\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi (x)=Ae^{ikx}+Be^{-ikx}\\qquad \\qquad E={\\frac {\\hbar ^{2}k^{2}}{2m}}}\\n  or, from Euler's formula,\\n\\n  \\n    \\n      \\n        \u03c8\\n        (\\n        x\\n        )\\n        =\\n        C\\n        sin\\n        \u2061\\n        (\\n        k\\n        x\\n        )\\n        +\\n        D\\n        cos\\n        \u2061\\n        (\\n        k\\n        x\\n        )\\n        .\\n        \\n      \\n    \\n    {\\displaystyle \\psi (x)=C\\sin(kx)+D\\cos(kx).\\!}\\n  The infinite potential walls of the box determine the values of \\n  \\n    \\n      \\n        C\\n        ,\\n        D\\n        ,\\n      \\n    \\n    {\\displaystyle C,D,}\\n   and \\n  \\n    \\n      \\n        k\\n      \\n    \\n    {\\displaystyle k}\\n   at \\n  \\n    \\n      \\n        x\\n        =\\n        0\\n      \\n    \\n    {\\displaystyle x=0}\\n   and \\n  \\n    \\n      \\n        x\\n        =\\n        L\\n      \\n    \\n    {\\displaystyle x=L}\\n   where \\n  \\n    \\n      \\n        \u03c8\\n      \\n    \\n    {\\displaystyle \\psi }\\n   must be zero. Thus, at \\n  \\n    \\n      \\n        x\\n        =\\n        0\\n      \\n    \\n    {\\displaystyle x=0}\\n  ,\\n\\n  \\n    \\n      \\n        \u03c8\\n        (\\n        0\\n        )\\n        =\\n        0\\n        =\\n        C\\n        sin\\n        \u2061\\n        (\\n        0\\n        )\\n        +\\n        D\\n        cos\\n        \u2061\\n        (\\n        0\\n        )\\n        =\\n        D\\n      \\n    \\n    {\\displaystyle \\psi (0)=0=C\\sin(0)+D\\cos(0)=D}\\n  and \\n  \\n    \\n      \\n        D\\n        =\\n        0\\n      \\n    \\n    {\\displaystyle D=0}\\n  . At \\n  \\n    \\n      \\n        x\\n        =\\n        L\\n      \\n    \\n    {\\displaystyle x=L}\\n  ,\\n\\n  \\n    \\n      \\n        \u03c8\\n        (\\n        L\\n        )\\n        =\\n        0\\n        =\\n        C\\n        sin\\n        \u2061\\n        (\\n        k\\n        L\\n        )\\n        ,\\n      \\n    \\n    {\\displaystyle \\psi (L)=0=C\\sin(kL),}\\n  in which \\n  \\n    \\n      \\n        C\\n      \\n    \\n    {\\displaystyle C}\\n   cannot be zero as this would conflict with the postulate that \\n  \\n    \\n      \\n        \u03c8\\n      \\n    \\n    {\\displaystyle \\psi }\\n   has norm 1. Therefore, since \\n  \\n    \\n      \\n        sin\\n        \u2061\\n        (\\n        k\\n        L\\n        )\\n        =\\n        0\\n      \\n    \\n    {\\displaystyle \\sin(kL)=0}\\n  , \\n  \\n    \\n      \\n        k\\n        L\\n      \\n    \\n    {\\displaystyle kL}\\n   must be an integer multiple of \\n  \\n    \\n      \\n        \u03c0\\n      \\n    \\n    {\\displaystyle \\pi }\\n  ,\\n\\n  \\n    \\n      \\n        k\\n        =\\n        \\n          \\n            \\n              n\\n              \u03c0\\n            \\n            L\\n          \\n        \\n        \\n        \\n        n\\n        =\\n        1\\n        ,\\n        2\\n        ,\\n        3\\n        ,\\n        \u2026\\n        .\\n      \\n    \\n    {\\displaystyle k={\\frac {n\\pi }{L}}\\qquad \\qquad n=1,2,3,\\ldots .}\\n  This constraint on \\n  \\n    \\n      \\n        k\\n      \\n    \\n    {\\displaystyle k}\\n   implies a constraint on the energy levels, yielding\\n\\n  \\n    \\n      \\n        \\n          E\\n          \\n            n\\n          \\n        \\n        =\\n        \\n          \\n            \\n              \\n                \u210f\\n                \\n                  2\\n                \\n              \\n              \\n                \u03c0\\n                \\n                  2\\n                \\n              \\n              \\n                n\\n                \\n                  2\\n                \\n              \\n            \\n            \\n              2\\n              m\\n              \\n                L\\n                \\n                  2\\n                \\n              \\n            \\n          \\n        \\n        =\\n        \\n          \\n            \\n              \\n                n\\n                \\n                  2\\n                \\n              \\n              \\n                h\\n                \\n                  2\\n                \\n              \\n            \\n            \\n              8\\n              m\\n              \\n                L\\n                \\n                  2\\n                \\n              \\n            \\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle E_{n}={\\frac {\\hbar ^{2}\\pi ^{2}n^{2}}{2mL^{2}}}={\\frac {n^{2}h^{2}}{8mL^{2}}}.}\\n  \\nA finite potential well is the generalization of the infinite potential well problem to potential wells having finite depth. The finite potential well problem is mathematically more complicated than the infinite particle-in-a-box problem as the wave function is not pinned to zero at the walls of the well. Instead, the wave function must satisfy more complicated mathematical boundary conditions as it is nonzero in regions outside the well. Another related problem is that of the rectangular potential barrier, which furnishes a model for the quantum tunneling effect that plays an important role in the performance of modern technologies such as flash memory and scanning tunneling microscopy.\\n\\nHarmonic oscillator\\nAs in the classical case, the potential for the quantum harmonic oscillator is given by\\n\\n  \\n    \\n      \\n        V\\n        (\\n        x\\n        )\\n        =\\n        \\n          \\n            1\\n            2\\n          \\n        \\n        m\\n        \\n          \u03c9\\n          \\n            2\\n          \\n        \\n        \\n          x\\n          \\n            2\\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle V(x)={\\frac {1}{2}}m\\omega ^{2}x^{2}.}\\n  This problem can either be treated by directly solving the Schr\u00f6dinger equation, which is not trivial, or by using the more elegant \"ladder method\" first proposed by Paul Dirac. The eigenstates are given by\\n\\n  \\n    \\n      \\n        \\n          \u03c8\\n          \\n            n\\n          \\n        \\n        (\\n        x\\n        )\\n        =\\n        \\n          \\n            \\n              1\\n              \\n                \\n                  2\\n                  \\n                    n\\n                  \\n                \\n                \\n                n\\n                !\\n              \\n            \\n          \\n        \\n        \u22c5\\n        \\n          \\n            (\\n            \\n              \\n                \\n                  m\\n                  \u03c9\\n                \\n                \\n                  \u03c0\\n                  \u210f\\n                \\n              \\n            \\n            )\\n          \\n          \\n            1\\n            \\n              /\\n            \\n            4\\n          \\n        \\n        \u22c5\\n        \\n          e\\n          \\n            \u2212\\n            \\n              \\n                \\n                  m\\n                  \u03c9\\n                  \\n                    x\\n                    \\n                      2\\n                    \\n                  \\n                \\n                \\n                  2\\n                  \u210f\\n                \\n              \\n            \\n          \\n        \\n        \u22c5\\n        \\n          H\\n          \\n            n\\n          \\n        \\n        \\n          (\\n          \\n            \\n              \\n                \\n                  \\n                    m\\n                    \u03c9\\n                  \\n                  \u210f\\n                \\n              \\n            \\n            x\\n          \\n          )\\n        \\n        ,\\n        \\n      \\n    \\n    {\\displaystyle \\psi _{n}(x)={\\sqrt {\\frac {1}{2^{n}\\,n!}}}\\cdot \\left({\\frac {m\\omega }{\\pi \\hbar }}\\right)^{1/4}\\cdot e^{-{\\frac {m\\omega x^{2}}{2\\hbar }}}\\cdot H_{n}\\left({\\sqrt {\\frac {m\\omega }{\\hbar }}}x\\right),\\qquad }\\n  \\n  \\n    \\n      \\n        n\\n        =\\n        0\\n        ,\\n        1\\n        ,\\n        2\\n        ,\\n        \u2026\\n        .\\n      \\n    \\n    {\\displaystyle n=0,1,2,\\ldots .}\\n  where Hn are the Hermite polynomials\\n\\n  \\n    \\n      \\n        \\n          H\\n          \\n            n\\n          \\n        \\n        (\\n        x\\n        )\\n        =\\n        (\\n        \u2212\\n        1\\n        \\n          )\\n          \\n            n\\n          \\n        \\n        \\n          e\\n          \\n            \\n              x\\n              \\n                2\\n              \\n            \\n          \\n        \\n        \\n          \\n            \\n              d\\n              \\n                n\\n              \\n            \\n            \\n              d\\n              \\n                x\\n                \\n                  n\\n                \\n              \\n            \\n          \\n        \\n        \\n          (\\n          \\n            e\\n            \\n              \u2212\\n              \\n                x\\n                \\n                  2\\n                \\n              \\n            \\n          \\n          )\\n        \\n        ,\\n      \\n    \\n    {\\displaystyle H_{n}(x)=(-1)^{n}e^{x^{2}}{\\frac {d^{n}}{dx^{n}}}\\left(e^{-x^{2}}\\right),}\\n  and the corresponding energy levels are\\n\\n  \\n    \\n      \\n        \\n          E\\n          \\n            n\\n          \\n        \\n        =\\n        \u210f\\n        \u03c9\\n        \\n          (\\n          \\n            n\\n            +\\n            \\n              \\n                1\\n                2\\n              \\n            \\n          \\n          )\\n        \\n        .\\n      \\n    \\n    {\\displaystyle E_{n}=\\hbar \\omega \\left(n+{1 \\over 2}\\right).}\\n  This is another example illustrating the discretization of energy for bound states.\\n\\nMach\u2013Zehnder interferometer\\nThe Mach\u2013Zehnder interferometer (MZI) illustrates the concepts of superposition and interference with linear algebra in dimension 2, rather than differential equations. It can be seen as a simplified version of the double-slit experiment, but it is of interest in its own right, for example in the delayed choice quantum eraser, the Elitzur\u2013Vaidman bomb tester, and in studies of quantum entanglement.We can model a photon going through the interferometer by considering that at each point it can be in a superposition of only two paths: the \"lower\" path which starts from the left, goes straight through both beam splitters, and ends at the top, and the \"upper\" path which starts from the bottom, goes straight through both beam splitters, and ends at the right. The quantum state of the photon is therefore a vector \\n  \\n    \\n      \\n        \u03c8\\n        \u2208\\n        \\n          \\n            C\\n          \\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi \\in \\mathbb {C} ^{2}}\\n   that is a superposition of the \"lower\" path \\n  \\n    \\n      \\n        \\n          \u03c8\\n          \\n            l\\n          \\n        \\n        =\\n        \\n          \\n            (\\n            \\n              \\n                \\n                  1\\n                \\n              \\n              \\n                \\n                  0\\n                \\n              \\n            \\n            )\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi _{l}={\\begin{pmatrix}1\\\\0\\end{pmatrix}}}\\n   and the \"upper\" path \\n  \\n    \\n      \\n        \\n          \u03c8\\n          \\n            u\\n          \\n        \\n        =\\n        \\n          \\n            (\\n            \\n              \\n                \\n                  0\\n                \\n              \\n              \\n                \\n                  1\\n                \\n              \\n            \\n            )\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi _{u}={\\begin{pmatrix}0\\\\1\\end{pmatrix}}}\\n  , that is, \\n  \\n    \\n      \\n        \u03c8\\n        =\\n        \u03b1\\n        \\n          \u03c8\\n          \\n            l\\n          \\n        \\n        +\\n        \u03b2\\n        \\n          \u03c8\\n          \\n            u\\n          \\n        \\n      \\n    \\n    {\\displaystyle \\psi =\\alpha \\psi _{l}+\\beta \\psi _{u}}\\n   for complex \\n  \\n    \\n      \\n        \u03b1\\n        ,\\n        \u03b2\\n      \\n    \\n    {\\displaystyle \\alpha ,\\beta }\\n  . In order to respect the postulate that \\n  \\n    \\n      \\n        \u27e8\\n        \u03c8\\n        ,\\n        \u03c8\\n        \u27e9\\n        =\\n        1\\n      \\n    \\n    {\\displaystyle \\langle \\psi ,\\psi \\rangle =1}\\n   we require that \\n  \\n    \\n      \\n        \\n          |\\n        \\n        \u03b1\\n        \\n          \\n            |\\n          \\n          \\n            2\\n          \\n        \\n        +\\n        \\n          |\\n        \\n        \u03b2\\n        \\n          \\n            |\\n          \\n          \\n            2\\n          \\n        \\n        =\\n        1\\n      \\n    \\n    {\\displaystyle |\\alpha |^{2}+|\\beta |^{2}=1}\\n  .\\nBoth beam splitters are modelled as the unitary matrix \\n  \\n    \\n      \\n        B\\n        =\\n        \\n          \\n            1\\n            \\n              2\\n            \\n          \\n        \\n        \\n          \\n            (\\n            \\n              \\n                \\n                  1\\n                \\n                \\n                  i\\n                \\n              \\n              \\n                \\n                  i\\n                \\n                \\n                  1\\n                \\n              \\n            \\n            )\\n          \\n        \\n      \\n    \\n    {\\displaystyle B={\\frac {1}{\\sqrt {2}}}{\\begin{pmatrix}1&i\\\\i&1\\end{pmatrix}}}\\n  , which means that when a photon meets the beam splitter it will either stay on the same path with a probability amplitude of \\n  \\n    \\n      \\n        1\\n        \\n          /\\n        \\n        \\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\displaystyle 1/{\\sqrt {2}}}\\n  , or be reflected to the other path with a probability amplitude of \\n  \\n    \\n      \\n        i\\n        \\n          /\\n        \\n        \\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\displaystyle i/{\\sqrt {2}}}\\n  . The phase shifter on the upper arm is modelled as the unitary matrix \\n  \\n    \\n      \\n        P\\n        =\\n        \\n          \\n            (\\n            \\n              \\n                \\n                  1\\n                \\n                \\n                  0\\n                \\n              \\n              \\n                \\n                  0\\n                \\n                \\n                  \\n                    e\\n                    \\n                      i\\n                      \u0394\\n                      \u03a6\\n                    \\n                  \\n                \\n              \\n            \\n            )\\n          \\n        \\n      \\n    \\n    {\\displaystyle P={\\begin{pmatrix}1&0\\\\0&e^{i\\Delta \\Phi }\\end{pmatrix}}}\\n  , which means that if the photon is on the \"upper\" path it will gain a relative phase of \\n  \\n    \\n      \\n        \u0394\\n        \u03a6\\n      \\n    \\n    {\\displaystyle \\Delta \\Phi }\\n  , and it will stay unchanged if it is in the lower path.\\nA photon that enters the interferometer from the left will then be acted upon with a beam splitter \\n  \\n    \\n      \\n        B\\n      \\n    \\n    {\\displaystyle B}\\n  , a phase shifter \\n  \\n    \\n      \\n        P\\n      \\n    \\n    {\\displaystyle P}\\n  , and another beam splitter \\n  \\n    \\n      \\n        B\\n      \\n    \\n    {\\displaystyle B}\\n  , and so end up in the state \\n\\n  \\n    \\n      \\n        B\\n        P\\n        B\\n        \\n          \u03c8\\n          \\n            l\\n          \\n        \\n        =\\n        i\\n        \\n          e\\n          \\n            i\\n            \u0394\\n            \u03a6\\n            \\n              /\\n            \\n            2\\n          \\n        \\n        \\n          \\n            (\\n            \\n              \\n                \\n                  \u2212\\n                  sin\\n                  \u2061\\n                  (\\n                  \u0394\\n                  \u03a6\\n                  \\n                    /\\n                  \\n                  2\\n                  )\\n                \\n              \\n              \\n                \\n                  cos\\n                  \u2061\\n                  (\\n                  \u0394\\n                  \u03a6\\n                  \\n                    /\\n                  \\n                  2\\n                  )\\n                \\n              \\n            \\n            )\\n          \\n        \\n        ,\\n      \\n    \\n    {\\displaystyle BPB\\psi _{l}=ie^{i\\Delta \\Phi /2}{\\begin{pmatrix}-\\sin(\\Delta \\Phi /2)\\\\\\cos(\\Delta \\Phi /2)\\end{pmatrix}},}\\n  and the probabilities that it will be detected at the right or at the top are given respectively by\\n\\n  \\n    \\n      \\n        p\\n        (\\n        u\\n        )\\n        =\\n        \\n          |\\n        \\n        \u27e8\\n        \\n          \u03c8\\n          \\n            u\\n          \\n        \\n        ,\\n        B\\n        P\\n        B\\n        \\n          \u03c8\\n          \\n            l\\n          \\n        \\n        \u27e9\\n        \\n          \\n            |\\n          \\n          \\n            2\\n          \\n        \\n        =\\n        \\n          cos\\n          \\n            2\\n          \\n        \\n        \u2061\\n        \\n          \\n            \\n              \u0394\\n              \u03a6\\n            \\n            2\\n          \\n        \\n        ,\\n      \\n    \\n    {\\displaystyle p(u)=|\\langle \\psi _{u},BPB\\psi _{l}\\rangle |^{2}=\\cos ^{2}{\\frac {\\Delta \\Phi }{2}},}\\n  \\n\\n  \\n    \\n      \\n        p\\n        (\\n        l\\n        )\\n        =\\n        \\n          |\\n        \\n        \u27e8\\n        \\n          \u03c8\\n          \\n            l\\n          \\n        \\n        ,\\n        B\\n        P\\n        B\\n        \\n          \u03c8\\n          \\n            l\\n          \\n        \\n        \u27e9\\n        \\n          \\n            |\\n          \\n          \\n            2\\n          \\n        \\n        =\\n        \\n          sin\\n          \\n            2\\n          \\n        \\n        \u2061\\n        \\n          \\n            \\n              \u0394\\n              \u03a6\\n            \\n            2\\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle p(l)=|\\langle \\psi _{l},BPB\\psi _{l}\\rangle |^{2}=\\sin ^{2}{\\frac {\\Delta \\Phi }{2}}.}\\n  One can therefore use the Mach\u2013Zehnder interferometer to estimate the phase shift by estimating these probabilities.\\nIt is interesting to consider what would happen if the photon were definitely in either the \"lower\" or \"upper\" paths between the beam splitters. This can be accomplished by blocking one of the paths, or equivalently by removing the first beam splitter (and feeding the photon from the left or the bottom, as desired). In both cases, there will be no interference between the paths anymore, and the probabilities are given by \\n  \\n    \\n      \\n        p\\n        (\\n        u\\n        )\\n        =\\n        p\\n        (\\n        l\\n        )\\n        =\\n        1\\n        \\n          /\\n        \\n        2\\n      \\n    \\n    {\\displaystyle p(u)=p(l)=1/2}\\n  , independently of the phase \\n  \\n    \\n      \\n        \u0394\\n        \u03a6\\n      \\n    \\n    {\\displaystyle \\Delta \\Phi }\\n  . From this we can conclude that the photon does not take one path or another after the first beam splitter, but rather that it is in a genuine quantum superposition of the two paths.\\n\\nApplications\\nQuantum mechanics has had enormous success in explaining many of the features of our universe, with regard to small-scale and discrete quantities and interactions which cannot be explained by classical methods. Quantum mechanics is often the only theory that can reveal the individual behaviors of the subatomic particles that make up all forms of matter (electrons, protons, neutrons, photons, and others). Solid-state physics and materials science are dependent upon quantum mechanics.In many aspects, modern technology operates at a scale where quantum effects are significant. Important applications of quantum theory include quantum chemistry, quantum optics, quantum computing, superconducting magnets, light-emitting diodes, the optical amplifier and the laser, the transistor and semiconductors such as the microprocessor, medical and research imaging such as magnetic resonance imaging and electron microscopy. Explanations for many biological and physical phenomena are rooted in the nature of the chemical bond, most notably the macro-molecule DNA.\\n\\nRelation to other scientific theories\\nClassical mechanics\\nThe rules of quantum mechanics assert that the state space of a system is a Hilbert space and that observables of the system are Hermitian operators acting on vectors in that space \u2013 although they do not tell us which Hilbert space or which operators. These can be chosen appropriately in order to obtain a quantitative description of a quantum system, a necessary step in making physical predictions. An important guide for making these choices is the correspondence principle, a heuristic which states that the predictions of quantum mechanics reduce to those of classical mechanics in the regime of large quantum numbers. One can also start from an established classical model of a particular system, and then try to guess the underlying quantum model that would give rise to the classical model in the correspondence limit. This approach is known as quantization.\\nWhen quantum mechanics was originally formulated, it was applied to models whose correspondence limit was non-relativistic classical mechanics. For instance, the well-known model of the quantum harmonic oscillator uses an explicitly non-relativistic expression for the kinetic energy of the oscillator, and is thus a quantum version of the classical harmonic oscillator.\\nComplications arise with chaotic systems, which do not have good quantum numbers, and quantum chaos studies the relationship between classical and quantum descriptions in these systems.\\nQuantum decoherence is a mechanism through which quantum systems lose coherence, and thus become incapable of displaying many typically quantum effects: quantum superpositions become simply probabilistic mixtures, and quantum entanglement becomes simply classical correlations. Quantum coherence is not typically evident at macroscopic scales, except maybe at temperatures approaching absolute zero at which quantum behavior may manifest macroscopically.Many macroscopic properties of a classical system are a direct consequence of the quantum behavior of its parts. For example, the stability of bulk matter (consisting of atoms and molecules which would quickly collapse under electric forces alone), the rigidity of solids, and the mechanical, thermal, chemical, optical and magnetic properties of matter are all results of the interaction of electric charges under the rules of quantum mechanics.\\n\\nSpecial relativity and electrodynamics\\nEarly attempts to merge quantum mechanics with special relativity involved the replacement of the Schr\u00f6dinger equation with a covariant equation such as the Klein\u2013Gordon equation or the Dirac equation. While these theories were successful in explaining many experimental results, they had certain unsatisfactory qualities stemming from their neglect of the relativistic creation and annihilation of particles. A fully relativistic quantum theory required the development of quantum field theory, which applies quantization to a field (rather than a fixed set of particles). The first complete quantum field theory, quantum electrodynamics, provides a fully quantum description of the electromagnetic interaction. Quantum electrodynamics is, along with general relativity, one of the most accurate physical theories ever devised.The full apparatus of quantum field theory is often unnecessary for describing electrodynamic systems. A simpler approach, one that has been used since the inception of quantum mechanics, is to treat charged particles as quantum mechanical objects being acted on by a classical electromagnetic field. For example, the elementary quantum model of the hydrogen atom describes the electric field of the hydrogen atom using a classical \\n  \\n    \\n      \\n        \\n          \u2212\\n          \\n            e\\n            \\n              2\\n            \\n          \\n          \\n            /\\n          \\n          (\\n          4\\n          \u03c0\\n          \\n            \u03f5\\n            \\n              \\n                \\n                \\n                  0\\n                \\n              \\n            \\n          \\n          r\\n          )\\n        \\n      \\n    \\n    {\\displaystyle \\textstyle -e^{2}/(4\\pi \\epsilon _{_{0}}r)}\\n   Coulomb potential. This \"semi-classical\" approach fails if quantum fluctuations in the electromagnetic field play an important role, such as in the emission of photons by charged particles.\\nQuantum field theories for the strong nuclear force and the weak nuclear force have also been developed. The quantum field theory of the strong nuclear force is called quantum chromodynamics, and describes the interactions of subnuclear particles such as quarks and gluons. The weak nuclear force and the electromagnetic force were unified, in their quantized forms, into a single quantum field theory (known as electroweak theory), by the physicists Abdus Salam, Sheldon Glashow and Steven Weinberg.\\n\\nRelation to general relativity\\nEven though the predictions of both quantum theory and general relativity have been supported by rigorous and repeated empirical evidence, their abstract formalisms contradict each other and they have proven extremely difficult to incorporate into one consistent, cohesive model. Gravity is negligible in many areas of particle physics, so that unification between general relativity and quantum mechanics is not an urgent issue in those particular applications. However, the lack of a correct theory of quantum gravity is an important issue in physical cosmology and the search by physicists for an elegant \"Theory of Everything\" (TOE). Consequently, resolving the inconsistencies between both theories has been a major goal of 20th- and 21st-century physics. This TOE would combine not only the models of subatomic physics but also derive the four fundamental forces of nature from a single force or phenomenon.One proposal for doing so is string theory, which posits that the point-like particles of particle physics are replaced by one-dimensional objects called strings. String theory describes how these strings propagate through space and interact with each other. On distance scales larger than the string scale, a string looks just like an ordinary particle, with its mass, charge, and other properties determined by the vibrational state of the string. In string theory, one of the many vibrational states of the string corresponds to the graviton, a quantum mechanical particle that carries gravitational force.Another popular theory is loop quantum gravity (LQG), which describes quantum properties of gravity and is thus a theory of quantum spacetime. LQG is an attempt to merge and adapt standard quantum mechanics and standard general relativity. This theory describes space as an extremely fine fabric \"woven\" of finite loops called spin networks. The evolution of a spin network over time is called a spin foam. The characteristic length scale of a spin foam is the Planck length, approximately 1.616\u00d710\u221235 m, and so lengths shorter than the Planck length are not physically meaningful in LQG.\\n\\nPhilosophical implications\\nSince its inception, the many counter-intuitive aspects and results of quantum mechanics have provoked strong philosophical debates and many interpretations. The arguments centre on the probabilistic nature of quantum mechanics, the difficulties with wavefunction collapse and the related measurement problem, and quantum nonlocality. Perhaps the only consensus that exists about these issues is that there is no consensus. Richard Feynman once said, \"I think I can safely say that nobody understands quantum mechanics.\" According to Steven Weinberg, \"There is now in my opinion no entirely satisfactory interpretation of quantum mechanics.\"The views of Niels Bohr, Werner Heisenberg and other physicists are often grouped together as the \"Copenhagen interpretation\". According to these views, the probabilistic nature of quantum mechanics is not a temporary feature which will eventually be replaced by a deterministic theory, but is instead a final renunciation of the classical idea of \"causality\". Bohr in particular emphasized that any well-defined application of the quantum mechanical formalism must always make reference to the experimental arrangement, due to the complementary nature of evidence obtained under different experimental situations. Copenhagen-type interpretations were adopted by Nobel laureates in quantum physics, including Bohr, Heisenberg, Schr\u00f6dinger, Feynman, and Zeilinger as well as 21st century researchers in quantum foundations.Albert Einstein, himself one of the founders of quantum theory, was troubled by its apparent failure to respect some cherished metaphysical principles, such as determinism and locality. Einstein's long-running exchanges with Bohr about the meaning and status of quantum mechanics are now known as the Bohr\u2013Einstein debates. Einstein believed that underlying quantum mechanics must be a theory that explicitly forbids action at a distance. He argued that quantum mechanics was incomplete, a theory that was valid but not fundamental, analogous to how thermodynamics is valid, but the fundamental theory behind it is statistical mechanics. In 1935, Einstein and his collaborators Boris Podolsky and Nathan Rosen published an argument that the principle of locality implies the incompleteness of quantum mechanics, a thought experiment later termed the Einstein\u2013Podolsky\u2013Rosen paradox. In 1964, John Bell showed that EPR's principle of locality, together with determinism, was actually incompatible with quantum mechanics: they implied constraints on the correlations produced by distance systems, now known as Bell inequalities, that can be violated by entangled particles. Since then several experiments have been performed to obtain these correlations, with the result that they do in fact violate Bell inequalities, and thus falsify the conjunction of locality with determinism.Bohmian mechanics shows that it is possible to reformulate quantum mechanics to make it deterministic, at the price of making it explicitly nonlocal. It attributes not only a wave function to a physical system, but in addition a real position, that evolves deterministically under a nonlocal guiding equation. The evolution of a physical system is given at all times by the Schr\u00f6dinger equation together with the guiding equation; there is never a collapse of the wave function. This solves the measurement problem.Everett's many-worlds interpretation, formulated in 1956, holds that all the possibilities described by quantum theory simultaneously occur in a multiverse composed of mostly independent parallel universes. This is a consequence of removing the axiom of the collapse of the wave packet. All possible states of the measured system and the measuring apparatus, together with the observer, are present in a real physical quantum superposition. While the multiverse is deterministic, we perceive non-deterministic behavior governed by probabilities, because we do not observe the multiverse as a whole, but only one parallel universe at a time. Exactly how this is supposed to work has been the subject of much debate. Several attempts have been made to make sense of this and derive the Born rule, with no consensus on whether they have been successful.Relational quantum mechanics appeared in the late 1990s as a modern derivative of Copenhagen-type ideas, and QBism was developed some years later.\\n\\nHistory\\nQuantum mechanics was developed in the early decades of the 20th century, driven by the need to explain phenomena that, in some cases, had been observed in earlier times. Scientific inquiry into the wave nature of light began in the 17th and 18th centuries, when scientists such as Robert Hooke, Christiaan Huygens and Leonhard Euler proposed a wave theory of light based on experimental observations. In 1803 English polymath Thomas Young described the famous double-slit experiment. This experiment played a major role in the general acceptance of the wave theory of light.\\nDuring the early 19th century, chemical research by John Dalton and Amedeo Avogadro lent weight to the atomic theory of matter, an idea that James Clerk Maxwell, Ludwig Boltzmann and others built upon to establish the kinetic theory of gases. The successes of kinetic theory gave further credence to the idea that matter is composed of atoms, yet the theory also had shortcomings that would only be resolved by the development of quantum mechanics. While the early conception of atoms from Greek philosophy had been that they were indivisible units \u2013  the word \"atom\" deriving from the Greek for \"uncuttable\" \u2013  the 19th century saw the formulation of hypotheses about subatomic structure. One important discovery in that regard was Michael Faraday's 1838 observation of a glow caused by an electrical discharge inside a glass tube containing gas at low pressure. Julius Pl\u00fccker, Johann Wilhelm Hittorf and Eugen Goldstein carried on and improved upon Faraday's work, leading to the identification of cathode rays, which J. J. Thomson found to consist of subatomic particles that would be called electrons.The black-body radiation problem was discovered by Gustav Kirchhoff in 1859. In 1900, Max Planck proposed the hypothesis that energy is radiated and absorbed in discrete \"quanta\" (or energy packets), yielding a calculation that precisely matched the observed patterns of black-body radiation. The word quantum derives from the Latin, meaning \"how great\" or \"how much\". According to Planck, quantities of energy could be thought of as divided into \"elements\" whose size (E) would be proportional to their frequency (\u03bd):\\n\\n  \\n    \\n      \\n        E\\n        =\\n        h\\n        \u03bd\\n         \\n      \\n    \\n    {\\displaystyle E=h\\nu \\ }\\n  ,where h is Planck's constant. Planck cautiously insisted that this was only an aspect of the processes of absorption and emission of radiation and was not the physical reality of the radiation. In fact, he considered his quantum hypothesis a mathematical trick to get the right answer rather than a sizable discovery. However, in 1905 Albert Einstein interpreted Planck's quantum hypothesis realistically and used it to explain the photoelectric effect, in which shining light on certain materials can eject electrons from the material. Niels Bohr then developed Planck's ideas about radiation into a model of the hydrogen atom that successfully predicted the spectral lines of hydrogen. Einstein further developed this idea to show that an electromagnetic wave such as light could also be described as a particle (later called the photon), with a discrete amount of energy that depends on its frequency. In his paper \"On the Quantum Theory of Radiation\", Einstein expanded on the interaction between energy and matter to explain the absorption and emission of energy by atoms. Although overshadowed at the time by his general theory of relativity, this paper articulated the mechanism underlying the stimulated emission of radiation, which became the basis of the laser.\\n\\nThis phase is known as the old quantum theory. Never complete or self-consistent, the old quantum theory was rather a set of heuristic corrections to classical mechanics. The theory is now understood as a semi-classical approximation to modern quantum mechanics. Notable results from this period include, in addition to the work of Planck, Einstein and Bohr mentioned above, Einstein and Peter Debye's work on the specific heat of solids, Bohr and Hendrika Johanna van Leeuwen's proof that classical physics cannot account for diamagnetism, and Arnold Sommerfeld's extension of the Bohr model to include special-relativistic effects.\\nIn the mid-1920s quantum mechanics was developed to become the standard formulation for atomic physics. In 1923, the French physicist Louis de Broglie put forward his theory of matter waves by stating that particles can exhibit wave characteristics and vice versa. Building on de Broglie's approach, modern quantum mechanics was born in 1925, when the German physicists Werner Heisenberg, Max Born, and Pascual Jordan developed matrix mechanics and the Austrian physicist Erwin Schr\u00f6dinger invented wave mechanics. Born introduced the probabilistic interpretation of Schr\u00f6dinger's wave function in July 1926. Thus, the entire field of quantum physics emerged, leading to its wider acceptance at the Fifth Solvay Conference in 1927.By 1930 quantum mechanics had been further unified and formalized by David Hilbert, Paul Dirac and John von Neumann with greater emphasis on measurement, the statistical nature of our knowledge of reality, and philosophical speculation about the 'observer'. It has since permeated many disciplines, including quantum chemistry, quantum electronics, quantum optics, and quantum information science. It also provides a useful framework for many features of the modern periodic table of elements, and describes the behaviors of atoms during chemical bonding and the flow of electrons in computer semiconductors, and therefore plays a crucial role in many modern technologies. While quantum mechanics was constructed to describe the world of the very small, it is also needed to explain some macroscopic phenomena such as superconductors and superfluids.\\n\\nSee also\\nExplanatory notes\\nReferences\\nFurther reading\\nExternal links\\n\\nJ. O'Connor and E. F. Robertson: A history of quantum mechanics.\\nIntroduction to Quantum Theory at Quantiki.\\nQuantum Physics Made Relatively Simple: three video lectures by Hans BetheCourse materialQuantum Cook Book and PHYS 201: Fundamentals of Physics II by Ramamurti Shankar, Yale OpenCourseware\\nModern Physics: With waves, thermodynamics, and optics \u2013 an online textbook.\\nMIT OpenCourseWare: Chemistry and Physics. See 8.04, 8.05 and 8.06\\n5\u00bd Examples in Quantum Mechanics\\nImperial College Quantum Mechanics Course.PhilosophyIsmael, Jenann. \"Quantum Mechanics\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\\nKrips, Henry. \"Measurement in Quantum Theory\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy."}
{"article_name": "Global_warming", "link": "https://en.wikipedia.org/wiki/Global_warming", "text_content": "In common usage, climate change describes global warming\u2014the ongoing increase in global average temperature\u2014and its effects on Earth's climate system. Climate change in a broader sense also includes previous long-term changes to Earth's climate. The current rise in global average temperature is more rapid than previous changes, and is primarily caused by humans burning fossil fuels. Fossil fuel use, deforestation, and some agricultural and industrial practices add to greenhouse gases, notably carbon dioxide and methane. Greenhouse gases absorb some of the heat that the Earth radiates after it warms from sunlight. Larger amounts of these gases trap more heat in Earth's lower atmosphere, causing global warming.\\nClimate change has an increasing impact on the environment. Deserts are expanding, while heat waves and wildfires are becoming more common. Amplified warming in the Arctic has contributed to melting permafrost, glacial retreat and sea ice loss. Higher temperatures are also causing more intense storms, droughts, and other weather extremes. Rapid environmental change in mountains, coral reefs, and the Arctic is forcing many species to relocate or become extinct. Even if efforts to minimise future warming are successful, some effects will continue for centuries. These include ocean heating, ocean acidification and sea level rise.Climate change threatens people with increased flooding, extreme heat, increased food and water scarcity, more disease, and economic loss. Human migration and conflict can also be a result. The World Health Organization (WHO) calls climate change the greatest threat to global health in the 21st century. Societies and ecosystems will experience more severe risks without action to limit warming. Adapting to climate change through efforts like flood control measures or drought-resistant crops partially reduces climate change risks, although some limits to adaptation have already been reached. Poorer communities are responsible for a small share of global emissions, yet have the least ability to adapt and are most vulnerable to climate change.\\n\\nMany climate change impacts have been felt in recent years, with 2023 the warmest on record at +1.48 \u00b0C (2.66 \u00b0F). Additional warming will increase these impacts and can trigger tipping points, such as the melting of the Greenland ice sheet. Under the 2015 Paris Agreement, nations collectively agreed to keep warming \"well under 2 \u00b0C\". However, with pledges made under the Agreement, global warming would still reach about 2.7 \u00b0C (4.9 \u00b0F) by the end of the century. Limiting warming to 1.5 \u00b0C will require halving emissions by 2030 and achieving net-zero emissions by 2050.Strategies to phase out fossil fuels involve conserving energy, generating electricity cleanly, and using electricity to power transportation, heat buildings, and operate industrial facilities. The electricity supply can be made cleaner and more plentiful by vastly increasing deployment of wind, and solar power, alongside other forms of renewable energy and nuclear power. Carbon can also be removed from the atmosphere, for instance by increasing forest cover and farming with methods that capture carbon in soil.\\n\\nTerminology\\nBefore the 1980s, when it was unclear whether the warming effect of increased greenhouse gases was stronger than the cooling effect of airborne particulates in air pollution, scientists used the term inadvertent climate modification to refer to human impacts on the climate.In the 1980s, the terms global warming and climate change became more common. Though the two terms are sometimes used interchangeably, scientifically, global warming refers only to increased surface warming, while climate change describes the totality of changes to Earth's climate system. Global warming\u2014used as early as 1975\u2014became the more popular term after NASA climate scientist James Hansen used it in his 1988 testimony in the U.S. Senate. Since the 2000s, climate change has increased in usage. Climate change can also refer more broadly to both human-caused changes or natural changes throughout Earth's history.Various scientists, politicians and media now use the terms climate crisis or climate emergency to talk about climate change, and global heating instead of global warming.\\n\\nGlobal temperature rise\\nTemperature records prior to global warming\\nHuman beings evolved over the last few million years in a climate that cycled through ice ages, with global average temperature ranging between current levels and 5\u20136 \u00b0C colder than today. The temperature record prior to human evolution includes hotter temperatures and occasional abrupt changes, such as the Paleocene\u2013Eocene Thermal Maximum 55.5 million years ago.Historical patterns of warming and cooling, like the Medieval Warm Period and the Little Ice Age, did not occur at the same time across different regions. Temperatures may have reached as high as those of the late 20th century in a limited set of regions. Climate information for that period comes from climate proxies, such as trees and ice cores.\\n\\nWarming since the Industrial Revolution\\nThermometer records began to provide global coverage around 1850. There was little net warming between the 18th century and 1970, as aerosols offset the warming impact of greenhouse gas emissions. Increasing accumulation of greenhouse gases coupled with aerosol polution controls caused temperatures to then begin markedly increasing.Multiple independent instrumental datasets show that the climate system is warming in recent years. A so-called \"global warming hiatus\" from 1998 to 2013 when warming was relatively slow was likely caused by negative phases of the Pacific Decadal Oscillation (PDO) and Atlantic Multidecadal Oscillation (AMO). The 2013-2022 decade warmed to an average 1.15 \u00b0C [1.00\u20131.25 \u00b0C] compared to the pre-industrial baseline (1850\u20131900). Surface temperatures are rising by about 0.2 \u00b0C per decade.Evidence of warming from air temperature measurements is reinforced by a wide range of other observations. For example, changes to the natural water cycle have been predicted and observed, such as an increase in the frequency and intensity of heavy precipitation, melting of snow and land ice, and increased atmospheric humidity. Flora and fauna are also behaving in a manner consistent with warming; for instance, plants are flowering earlier in spring. Another key indicator is the cooling of the upper atmosphere, which demonstrates that greenhouse gases are trapping heat near the Earth's surface and preventing it from radiating into space.\\n\\nDifferences by region\\nDifferent regions of the world warm at different rates. The pattern is independent of where greenhouse gases are emitted, because the gases persist long enough to diffuse across the planet. Since the pre-industrial period, the average surface temperature over land regions has increased almost twice as fast as the global-average surface temperature. This is because of the larger heat capacity of oceans, and because oceans lose more heat by evaporation. The thermal energy in the global climate system has grown with only brief pauses since at least 1970, and over 90% of this extra energy has been stored in the ocean. The rest has heated the atmosphere, melted ice, and warmed the continents.The Northern Hemisphere and the North Pole have warmed much faster than the South Pole and Southern Hemisphere. The Northern Hemisphere not only has much more land, but also more seasonal snow cover and sea ice. As these surfaces flip from reflecting a lot of light to being dark after the ice has melted, they start absorbing more heat. Local black carbon deposits on snow and ice also contribute to Arctic warming. Arctic temperatures are increasing at over twice the rate of the rest of the world. Melting of glaciers and ice sheets in the Arctic disrupts ocean circulation, including a weakened Gulf Stream, further changing the climate.\\n\\nFuture global temperatures\\nThe IPCC Sixth Assessment Report uses a 20 year temperature average to define global warming temperature rise, and it expects that 1.5 \u00b0C limit to be exceeded in the early 2030s. As annual temperatures fluctuate, the World Meteorological Organization estimates that there is a 66% chance that global temperature will exceed a rise of 1.5 \u00b0C for at least one year between 2023 and 2027. By the end of the 21st century, the IPCC projects that global warming is very likely to reach 1.0 \u00b0C to 1.8 \u00b0C under a very low GHG emissions scenario, 2.1 \u00b0C to 3.5 \u00b0C under an intermediate emissions scenario, or 3.3 \u00b0C to 5.7 \u00b0C under a very high GHG emissions scenario.The remaining carbon budget for staying beneath certain temperature increases is determined by modelling the carbon cycle and climate sensitivity to greenhouse gases. According to the IPCC, global warming can be kept below 1.5 \u00b0C with a two-thirds chance if emissions after 2018 do not exceed 420 or 570 gigatonnes of CO2. This corresponds to 10 to 13 years of current emissions. There are high uncertainties about the budget. For instance, it may be 100 gigatonnes of CO2 smaller due to methane release from permafrost and wetlands. However, it is clear that fossil fuel resources are too abundant for shortages to be relied on to limit carbon emissions in the 21st century.\\n\\nCauses of recent global temperature rise\\nThe climate system experiences various cycles on its own which can last for years, decades or even centuries. For example, El Ni\u00f1o events cause short-term spikes in surface temperature while La Ni\u00f1a events cause short term cooling. Their relative frequency can affect global temperature trends on a decadal timescale. Other changes are caused by an imbalance of energy from external forcings. Examples of these include changes in the concentrations of greenhouse gases, solar luminosity, volcanic eruptions, and variations in the Earth's orbit around the Sun.To determine the human contribution to climate change, unique \"fingerprints\" for all potential causes are developed and compared with both observed patterns and known internal climate variability. For example, solar forcing\u2014whose fingerprint involves warming the entire atmosphere\u2014is ruled out because only the lower atmosphere has warmed. Atmospheric aerosols produce a smaller, cooling effect. Other drivers, such as changes in albedo, are less impactful.\\n\\nGreenhouse gases\\nGreenhouse gases are transparent to sunlight, and thus allow it to pass through the atmosphere to heat the Earth's surface. The Earth radiates it as heat, and greenhouse gases absorb a portion of it. This absorption slows the rate at which heat escapes into space, trapping heat near the Earth's surface and warming it over time.While water vapour (\u224850%) and clouds (\u224825%) are the biggest contributors to the greenhouse effect, they primarily change as a function of temperature and are therefore mostly considered to be feedbacks that change climate sensitivity. On the other hand, concentrations of gases such as CO2 (\u224820%), tropospheric ozone, CFCs and nitrous oxide are added or removed independently from temperature, and are therefore considered to be external forcings that change global temperatures.Before the Industrial Revolution, naturally-occurring amounts of greenhouse gases caused the air near the surface to be about 33 \u00b0C warmer than it would have been in their absence. Human activity since the Industrial Revolution, mainly extracting and burning fossil fuels (coal, oil, and natural gas), has increased the amount of greenhouse gases in the atmosphere, resulting in a radiative imbalance. In 2019, the concentrations of CO2 and methane had increased by about 48% and 160%, respectively, since 1750. These CO2 levels are higher than they have been at any time during the last 2 million years. Concentrations of methane are far higher than they were over the last 800,000 years.\\nGlobal anthropogenic greenhouse gas emissions in 2019 were equivalent to 59 billion tonnes of CO2. Of these emissions, 75% was CO2, 18% was methane, 4% was nitrous oxide, and 2% was fluorinated gases. CO2 emissions primarily come from burning fossil fuels to provide energy for transport, manufacturing, heating, and electricity. Additional CO2 emissions come from deforestation and industrial processes, which include the CO2 released by the chemical reactions for making cement, steel, aluminum, and fertiliser. Methane emissions come from livestock, manure, rice cultivation, landfills, wastewater, and coal mining, as well as oil and gas extraction. Nitrous oxide emissions largely come from the microbial decomposition of fertiliser.The Earth's surface absorbs CO2 as part of the carbon cycle. Despite the contribution of deforestation to greenhouse gas emissions, the Earth's land surface, particularly its forests, remain a significant carbon sink for CO2. Land-surface sink processes, such as carbon fixation in the soil and photosynthesis, remove about 29% of annual global CO2 emissions. The ocean also serves as a significant carbon sink via a two-step process. First, CO2 dissolves in the surface water. Afterwards, the ocean's overturning circulation distributes it deep into the ocean's interior, where it accumulates over time as part of the carbon cycle. Over the last two decades, the world's oceans have absorbed 20 to 30% of emitted CO2.\\n\\nAerosols and clouds\\nAir pollution, in the form of aerosols, affects the climate on a large scale. Aerosols scatter and absorb solar radiation. From 1961 to 1990, a gradual reduction in the amount of sunlight reaching the Earth's surface was observed. This phenomenon is popularly known as global dimming, and is primarily attributed to sulfate aerosols produced by the combustion of fossil fuels with heavy sulfur concentrations like coal and bunker fuel. Smaller contributions come from black carbon, organic carbon from combustion of fossil fuels and biofuels, and from anthropogenic dust. Globally, aerosols have been declining since 1990 due to pollution controls, meaning that they no longer mask greenhouse gas warming as much.Aerosols also have indirect effects on the Earth's energy budget. Sulfate aerosols act as cloud condensation nuclei and lead to clouds that have more and smaller cloud droplets. These clouds reflect solar radiation more efficiently than clouds with fewer and larger droplets. They also reduce the growth of raindrops, which makes clouds more reflective to incoming sunlight. Indirect effects of aerosols are the largest uncertainty in radiative forcing.While aerosols typically limit global warming by reflecting sunlight, black carbon in soot that falls on snow or ice can contribute to global warming. Not only does this increase the absorption of sunlight, it also increases melting and sea-level rise. Limiting new black carbon deposits in the Arctic could reduce global warming by 0.2 \u00b0C by 2050.\\n\\nLand surface changes\\nHumans change the Earth's surface mainly to create more agricultural land. Today, agriculture takes up 34% of Earth's land area, while 26% is forests, and 30% is uninhabitable (glaciers, deserts, etc.). The amount of forested land continues to decrease, which is the main land use change that causes global warming. Deforestation releases CO2 contained in trees when they are destroyed, plus it prevents those trees from absorbing more CO2. The main causes of deforestation are: permanent land-use change from forest to agricultural land producing products such as beef and palm oil (27%), logging to produce forestry/forest products (26%), short term shifting cultivation (24%), and wildfires (23%).The type of vegetation in a region affects the local temperature. It impacts how much of the sunlight gets reflected back into space (albedo), and how much heat is lost by evaporation. For instance, the change from a dark forest to grassland makes the surface lighter, causing it to reflect more sunlight. Deforestation can also affect temperatures by modifying the release of chemical compounds that influence clouds, and by changing wind patterns. In tropic and temperate areas the net effect is to produce significant warming, while at latitudes closer to the poles a gain of albedo (as forest is replaced by snow cover) leads to a cooling effect. Globally, these effects are estimated to have led to a slight cooling, dominated by an increase in surface albedo. According to FAO, forest degradation aggravates the impacts of climate change as it reduces the carbon sequestration abilities of forests. Indeed, among their many benefits, forests also have the potential to reduce the impact of high temperatures.\\n\\nSolar and volcanic activity\\nAs the Sun is the Earth's primary energy source, changes in incoming sunlight directly affect the climate system. Solar irradiance has been measured directly by satellites, and indirect measurements are available from the early 1600s onwards. Since 1880, there has been no upward trend in the amount of the Sun's energy reaching the Earth.Explosive volcanic eruptions represent the largest natural forcing over the industrial era. Eruptions can produce gases, dust and ash that partially block sunlight and reduce temperatures, or they can produce water vapor, which adds to greenhouse gases and increases temperatures. Gases in the stratosphere can cause atmospheric changes that last a couple years, with the temperature signal lasting about twice as long. In the industrial era, volcanic activity has had negligible impacts on global temperature trends. Present-day volcanic CO2 emissions are equivalent to less than 1% of current anthropogenic CO2 emissions.Physical climate models are unable to reproduce the rapid warming observed in recent decades when taking into account only variations in solar output and volcanic activity. Further evidence for greenhouse gases causing global warming comes from measurements that show a warming of the lower atmosphere (the troposphere), coupled with a cooling of the upper atmosphere (the stratosphere). If solar variations were responsible for the observed warming, the troposphere and stratosphere would both warm.\\n\\nClimate change feedback\\nThe response of the climate system to an initial forcing is modified by feedbacks: increased by \"self-reinforcing\" or \"positive\" feedbacks and reduced by \"balancing\" or \"negative\" feedbacks. The main reinforcing feedbacks are the water-vapour feedback, the ice\u2013albedo feedback, and the net effect of clouds. The primary balancing mechanism is radiative cooling, as Earth's surface gives off more heat to space in response to rising temperature. In addition to temperature feedbacks, there are feedbacks in the carbon cycle, such as the fertilizing effect of CO2 on plant growth.Uncertainty over feedbacks, particularly cloud cover, is the major reason why different climate models project different magnitudes of warming for a given amount of emissions. As air warms, it can hold more moisture. Water vapour, as a potent greenhouse gas, holds heat in the atmosphere. If cloud cover increases, more sunlight will be reflected back into space, cooling the planet. If clouds become higher and thinner, they act as an insulator, reflecting heat from below back downwards and warming the planet.Another major feedback is the reduction of snow cover and sea ice in the Arctic, which reduces the reflectivity of the Earth's surface.\\nMore of the Sun's energy is now absorbed in these regions, contributing to amplification of Arctic temperature changes. Arctic amplification is also melting permafrost, which releases methane and CO2 into the atmosphere. Climate change can also cause methane releases from wetlands, marine systems, and freshwater systems. Overall, climate feedbacks are expected to become increasingly positive.Around half of human-caused CO2 emissions have been absorbed by land plants and by the oceans. Climate change increases droughts and heat waves that inhibit plant growth, which makes it uncertain whether this carbon sink will continue to grow. Soils contain large quantities of carbon and may release some when they heat up. As more CO2 and heat are absorbed by the ocean, it acidifies, its circulation changes and phytoplankton takes up less carbon, decreasing the rate at which the ocean absorbs atmospheric carbon. Overall, at higher CO2 concentrations the Earth will absorb a reduced fraction of our emissions.\\n\\nModelling\\nA climate model is a representation of the physical, chemical and biological processes that affect the climate system. Models include natural processes like changes in the Earth's orbit, historical changes in the Sun's activity, and volcanic forcing. Models are used to estimate the degree of warming future emissions will cause when accounting for the strength of climate feedbacks,. Models also predict the circulation of the oceans, the annual cycle of the seasons, and the flows of carbon between the land surface and the atmosphere.The physical realism of models is tested by examining their ability to simulate contemporary or past climates. Past models have underestimated the rate of Arctic shrinkage and underestimated the rate of precipitation increase. Sea level rise since 1990 was underestimated in older models, but more recent models agree well with observations. The 2017 United States-published National Climate Assessment notes that \"climate models may still be underestimating or missing relevant feedback processes\". Additionally, climate models may be unable to adequately predict short-term regional climatic shifts.A subset of climate models add societal factors to a physical climate model. These models simulate how population, economic growth, and energy use affect\u2014and interact with\u2014the physical climate. With this information, these models can produce scenarios of future greenhouse gas emissions. This is then used as input for physical climate models and carbon cycle models to predict how atmospheric concentrations of greenhouse gases might change. Depending on the socioeconomic scenario and the mitigation scenario, models produce atmospheric CO2 concentrations that range widely between 380 and 1400 ppm.\\n\\nImpacts\\nEnvironmental effects\\nThe environmental effects of climate change are broad and far-reaching, affecting oceans, ice, and weather. Changes may occur gradually or rapidly. Evidence for these effects comes from studying climate change in the past, from modelling, and from modern observations. Since the 1950s, droughts and heat waves have appeared simultaneously with increasing frequency. Extremely wet or dry events within the monsoon period have increased in India and East Asia. Monsoonal precipitation over the Northern Hemisphere has increased since 1980. The rainfall rate and intensity of hurricanes and typhoons is likely increasing, and the geographic range likely expanding poleward in response to climate warming. Frequency of tropical cyclones has not increased as a result of climate change.\\nGlobal sea level is rising as a consequence of glacial melt, melt of the Greenland ice sheets and Antarctica, and thermal expansion. Between 1993 and 2020, the rise increased over time, averaging 3.3 \u00b1 0.3 mm per year. Over the 21st century, the IPCC projects that in a very high emissions scenario the sea level could rise by 61\u2013110 cm. Increased ocean warmth is undermining and threatening to unplug Antarctic glacier outlets, risking a large melt of the ice sheet and the possibility of a 2-meter sea level rise by 2100 under high emissions.Climate change has led to decades of shrinking and thinning of the Arctic sea ice. While ice-free summers are expected to be rare at 1.5 \u00b0C degrees of warming, they are set to occur once every three to ten years at a warming level of 2 \u00b0C. Higher atmospheric CO2 concentrations have led to changes in ocean chemistry. An increase in dissolved CO2 is causing oceans to acidify. In addition, oxygen levels are decreasing as oxygen is less soluble in warmer water. Dead zones in the ocean, regions with very little oxygen, are expanding too.\\n\\nTipping points and long-term impacts\\nGreater degrees of global warming increase the risk of passing through 'tipping points'\u2014thresholds beyond which certain impacts can no longer be avoided even if temperatures are reduced. An example is the collapse of West Antarctic and Greenland ice sheets, where a temperature rise of 1.5 to 2 \u00b0C may commit the ice sheets to melt, although the time scale of melt is uncertain and depends on future warming. Some large-scale changes could occur over a short time period, such as a shutdown of certain ocean currents like the Atlantic meridional overturning circulation (AMOC). Tipping points can also include irreversible damage to ecosystems like the Amazon rainforest and coral reefs.The long-term effects of climate change on oceans include further ice melt, ocean warming, sea level rise, and ocean acidification. The timescale of long term impacts are centuries to millennia due to CO2's long atmospheric lifetime. When net emissions stabilize surface air temperatures will also stabilize, but oceans and ice caps will continue to absorb excess heat from the atmosphere. The result is an estimated total sea level rise of 2.3 metres per degree Celsius (4.2 ft/\u00b0F) after 2000 years. Oceanic CO2 uptake is slow enough that ocean acidification will also continue for hundreds to thousands of years.\\n\\nNature and wildlife\\nRecent warming has driven many terrestrial and freshwater species poleward and towards higher altitudes. Higher atmospheric CO2 levels and an extended growing season have resulted in global greening. However, heatwaves and drought have reduced ecosystem productivity in some regions. The future balance of these opposing effects is unclear. Climate change has contributed to the expansion of drier climate zones, such as the expansion of deserts in the subtropics. The size and speed of global warming is making abrupt changes in ecosystems more likely. Overall, it is expected that climate change will result in the extinction of many species.The oceans have heated more slowly than the land, but plants and animals in the ocean have migrated towards the colder poles faster than species on land. Just as on land, heat waves in the ocean occur more frequently due to climate change, harming a wide range of organisms such as corals, kelp, and seabirds. Ocean acidification makes it harder for marine calcifying organisms such as mussels, barnacles and corals to produce shells and skeletons; and heatwaves have bleached coral reefs. Harmful algal blooms enhanced by climate change and eutrophication lower oxygen levels, disrupt food webs and cause great loss of marine life. Coastal ecosystems are under particular stress. Almost half of global wetlands have disappeared due to climate change and other human impacts.\\n\\nHumans\\nThe effects of climate change are impacting humans everywhere in the world. Impacts can be observed on all continents and ocean regions, with low-latitude, less developed areas facing the greatest risk. Continued warming has potentially \"severe, pervasive and irreversible impacts\" for people and ecosystems. The risks are unevenly distributed, but are generally greater for disadvantaged people in developing and developed countries.\\n\\nFood and health\\nThe WHO calls climate change the greatest threat to global health in the 21st century. Extreme weather leads to injury and loss of life, and crop failures to malnutrition. Various infectious diseases are more easily transmitted in a warmer climate, such as dengue fever and malaria. Young children are the most vulnerable to food shortages. Both children and older people are vulnerable to extreme heat. The World Health Organization (WHO) has estimated that between 2030 and 2050, climate change would cause around 250,000 additional deaths per year. They assessed deaths from heat exposure in elderly people, increases in diarrhea, malaria, dengue, coastal flooding, and childhood malnutrition. Over 500,000 more adult deaths are projected yearly by 2050 due to reductions in food availability and quality. By 2100, 50% to 75% of the global population may face climate conditions that are life-threatening due to combined effects of extreme heat and humidity.Climate change is affecting food security. It has caused reduction in global yields of maize, wheat, and soybeans between 1981 and 2010. Future warming could further reduce global yields of major crops. Crop production will probably be negatively affected in low-latitude countries, while effects at northern latitudes may be positive or negative. Up to an additional 183 million people worldwide, particularly those with lower incomes, are at risk of hunger as a consequence of these impacts. Climate change also impacts fish populations. Globally, less will be available to be fished. Regions dependent on glacier water, regions that are already dry, and small islands have a higher risk of water stress due to climate change.\\n\\nInequality\\nEconomic damages due to climate change may be severe and there is a chance of disastrous consequences. Climate change has likely already increased global economic inequality, and this trend is projected to continue. Severe impacts are expected in South-East Asia and sub-Saharan Africa, where most of the local inhabitants are dependent upon natural and agricultural resources. The World Bank estimates that climate change could drive over 120 million people into poverty by 2030.Inequalities based on wealth and social status have worsened due to climate change. Major difficulties in mitigating, adapting, and recovering to climate shocks are faced by marginalized people who have less control over resources. Indigenous people, who are subsistent on their land and ecosystems, will face endangerment to their wellness and lifestyles due to climate change. An expert elicitation concluded that the role of climate change in armed conflict has been small compared to factors such as socio-economic inequality and state capabilities.While women are not inherently more at risk from climate change and shocks, limits on women's resources and discriminatory gender norms constrain their adaptive capacity and resilience. For example, women's work burdens, including hours worked in agriculture, tend to decline less than men's during climate shocks such as heat stress.\\n\\nClimate migration\\nLow-lying islands and coastal communities are threatened by sea level rise, which makes urban flooding more common. Sometimes, land is permanently lost to the sea. This could lead to statelessness for people in island nations, such as the Maldives and Tuvalu. In some regions, the rise in temperature and humidity may be too severe for humans to adapt to. With worst-case climate change, models project that almost one-third of humanity might live in extremely hot and uninhabitable climates.These factors can drive climate or environmental migration, within and between countries. More people are expected to be displaced because of sea level rise, extreme weather and conflict from increased competition over natural resources. Climate change may also increase vulnerability, leading to \"trapped populations\" who are not able to move due to a lack of resources.\\n\\nReducing and recapturing emissions\\nClimate change can be mitigated by reducing the rate at which greenhouse gases are emitted into the atmosphere, and by increasing the rate at which carbon dioxide is removed from the atmosphere. In order to limit global warming to less than 1.5 \u00b0C global greenhouse gas emissions needs to be net-zero by 2050, or by 2070 with a 2 \u00b0C target. This requires far-reaching, systemic changes on an unprecedented scale in energy, land, cities, transport, buildings, and industry.The United Nations Environment Programme estimates that countries need to triple their pledges under the Paris Agreement within the next decade to limit global warming to 2 \u00b0C. An even greater level of reduction is required to meet the 1.5 \u00b0C goal. With pledges made under the Paris Agreement as of October 2021, global warming would still have a 66% chance of reaching about 2.7 \u00b0C (range: 2.2\u20133.2 \u00b0C) by the end of the century. Globally, limiting warming to 2 \u00b0C may result in higher economic benefits than economic costs.Although there is no single pathway to limit global warming to 1.5 or 2 \u00b0C, most scenarios and strategies see a major increase in the use of renewable energy in combination with increased energy efficiency measures to generate the needed greenhouse gas reductions. To reduce pressures on ecosystems and enhance their carbon sequestration capabilities, changes would also be necessary in agriculture and forestry, such as preventing deforestation and restoring natural ecosystems by reforestation.Other approaches to mitigating climate change have a higher level of risk. Scenarios that limit global warming to 1.5 \u00b0C typically project the large-scale use of carbon dioxide removal methods over the 21st century. There are concerns, though, about over-reliance on these technologies, and environmental impacts. Solar radiation modification (SRM) is also a possible supplement to deep reductions in emissions. However, SRM raises significant ethical and legal concerns, and the risks are imperfectly understood.\\n\\nClean energy\\nRenewable energy is key to limiting climate change. For decades, fossil fuels have accounted for roughly 80% of the world's energy use. The remaining share has been split between nuclear power and renewables (including hydropower, bioenergy, wind and solar power and geothermal energy). Fossil fuel use is expected to peak in absolute terms prior to 2030 and then to decline, with coal use experiencing the sharpest reductions. Renewables represented 75% of all new electricity generation installed in 2019, nearly all solar and wind. Other forms of clean energy, such as nuclear and hydropower, currently have a larger share of the energy supply. However, their future growth forecasts appear limited in comparison.While solar panels and onshore wind are now among the cheapest forms of adding new power generation capacity in many locations, green energy policies are needed to achieve a rapid transition from fossil fuels to renewables. To achieve carbon neutrality by 2050, renewable energy would become the dominant form of electricity generation, rising to 85% or more by 2050 in some scenarios. Investment in coal would be eliminated and coal use nearly phased out by 2050.Electricity generated from renewable sources would also need to become the main energy source for heating and transport. Transport can switch away from internal combustion engine vehicles and towards electric vehicles, public transit, and active transport (cycling and walking). For shipping and flying, low-carbon fuels would reduce emissions. Heating could be increasingly decarbonised with technologies like heat pumps.There are obstacles to the continued rapid growth of clean energy, including renewables. For wind and solar, there are environmental and land use concerns for new projects. Wind and solar also produce energy intermittently and with seasonal variability. Traditionally, hydro dams with reservoirs and conventional power plants have been used when variable energy production is low. Going forward, battery storage can be expanded, energy demand and supply can be matched, and long-distance transmission can smooth variability of renewable outputs. Bioenergy is often not carbon-neutral and may have negative consequences for food security. The growth of nuclear power is constrained by controversy around radioactive waste, nuclear weapon proliferation, and accidents. Hydropower growth is limited by the fact that the best sites have been developed, and new projects are confronting increased social and environmental concerns.Low-carbon energy improves human health by minimising climate change as well as reducing air pollution deaths, which were estimated at 7 million annually in 2016. Meeting the Paris Agreement goals that limit warming to a 2 \u00b0C increase could save about a million of those lives per year by 2050, whereas limiting global warming to 1.5 \u00b0C could save millions and simultaneously increase energy security and reduce poverty. Improving air quality also has economic benefits which may be larger than mitigation costs.\\n\\nEnergy conservation\\nReducing energy demand is another major aspect of reducing emissions. If less energy is needed, there is more flexibility for clean energy development. It also makes it easier to manage the electricity grid, and minimises carbon-intensive infrastructure development. Major increases in energy efficiency investment will be required to achieve climate goals, comparable to the level of investment in renewable energy. Several COVID-19 related changes in energy use patterns, energy efficiency investments, and funding have made forecasts for this decade more difficult and uncertain.Strategies to reduce energy demand vary by sector. In the transport sector, passengers and freight can switch to more efficient travel modes, such as buses and trains, or use electric vehicles. Industrial strategies to reduce energy demand include improving heating systems and motors, designing less energy-intensive products, and increasing product lifetimes. In the building sector the focus is on better design of new buildings, and higher levels of energy efficiency in retrofitting. The use of technologies like heat pumps can also increase building energy efficiency.\\n\\nAgriculture and industry\\nAgriculture and forestry face a triple challenge of limiting greenhouse gas emissions, preventing the further conversion of forests to agricultural land, and meeting increases in world food demand. A set of actions could reduce agriculture and forestry-based emissions by two thirds from 2010 levels. These include reducing growth in demand for food and other agricultural products, increasing land productivity, protecting and restoring forests, and reducing greenhouse gas emissions from agricultural production.On the demand side, a key component of reducing emissions is shifting people towards plant-based diets. Eliminating the production of livestock for meat and dairy would eliminate about 3/4ths of all emissions from agriculture and other land use. Livestock also occupy 37% of ice-free land area on Earth and consume feed from the 12% of land area used for crops, driving deforestation and land degradation.Steel and cement production are responsible for about 13% of industrial CO2 emissions. In these industries, carbon-intensive materials such as coke and lime play an integral role in the production, so that reducing CO2 emissions requires research into alternative chemistries.\\n\\nCarbon sequestration\\nNatural carbon sinks can be enhanced to sequester significantly larger amounts of CO2 beyond naturally occurring levels. Reforestation and afforestation (planting forests where there were none before) are among the most mature sequestration techniques, although the latter raises food security concerns. Farmers can promote sequestration of carbon in soils through practices such as use of winter cover crops, reducing the intensity and frequency of tillage, and using compost and manure as soil amendments. Forest and landscape restoration yields many benefits for the climate, including greenhouse gas emissions sequestration and reduction. Restoration/recreation of coastal wetlands, prairie plots and seagrass meadows increases the uptake of carbon into organic matter. When carbon is sequestered in soils and in organic matter such as trees, there is a risk of the carbon being re-released into the atmosphere later through changes in land use, fire, or other changes in ecosystems.Where energy production or CO2-intensive heavy industries continue to produce waste CO2, the gas can be captured and stored instead of released to the atmosphere. Although its current use is limited in scale and expensive, carbon capture and storage (CCS) may be able to play a significant role in limiting CO2 emissions by mid-century. This technique, in combination with bioenergy (BECCS) can result in net negative emissions as CO2 is drawn from the atmosphere. It remains highly uncertain whether carbon dioxide removal techniques will be able to play a large role in limiting warming to 1.5 \u00b0C. Policy decisions that rely on carbon dioxide removal increase the risk of global warming rising beyond international goals.\\n\\nAdaptation\\nAdaptation is \"the process of adjustment to current or expected changes in climate and its effects\".:\u200a5\u200a Without additional mitigation, adaptation cannot avert the risk of \"severe, widespread and irreversible\" impacts. More severe climate change requires more transformative adaptation, which can be prohibitively expensive. The capacity and potential for humans to adapt is unevenly distributed across different regions and populations, and developing countries generally have less. The first two decades of the 21st century saw an increase in adaptive capacity in most low- and middle-income countries with improved access to basic sanitation and electricity, but progress is slow. Many countries have implemented adaptation policies. However, there is a considerable gap between necessary and available finance.Adaptation to sea level rise consists of avoiding at-risk areas, learning to live with increased flooding, and building flood controls. If that fails, managed retreat may be needed. There are economic barriers for tackling dangerous heat impact. Avoiding strenuous work or having air conditioning is not possible for everybody. In agriculture, adaptation options include a switch to more sustainable diets, diversification, erosion control, and genetic improvements for increased tolerance to a changing climate. Insurance allows for risk-sharing, but is often difficult to get for people on lower incomes. Education, migration and early warning systems can reduce climate vulnerability. Planting mangroves or encouraging other coastal vegetation can buffer storms.Ecosystems adapt to climate change, a process that can be supported by human intervention. By increasing connectivity between ecosystems, species can migrate to more favourable climate conditions. Species can also be introduced to areas acquiring a favorable climate. Protection and restoration of natural and semi-natural areas helps build resilience, making it easier for ecosystems to adapt. Many of the actions that promote adaptation in ecosystems, also help humans adapt via ecosystem-based adaptation. For instance, restoration of natural fire regimes makes catastrophic fires less likely, and reduces human exposure. Giving rivers more space allows for more water storage in the natural system, reducing flood risk. Restored forest acts as a carbon sink, but planting trees in unsuitable regions can exacerbate climate impacts.There are synergies but also trade-offs between adaptation and mitigation. An example for synergy is increased food productivity, which has large benefits for both adaptation and mitigation. An example of a trade-off is that increased use of air conditioning allows people to better cope with heat, but increases energy demand. Another trade-off example is that more compact urban development may reduce emissions from transport and construction, but may also increase the urban heat island effect, exposing people to heat-related health risks.\\n\\nPolicies and politics\\nCountries that are most vulnerable to climate change have typically been responsible for a small share of global emissions. This raises questions about justice and fairness. Limiting global warming makes it much easier to achieve the UN's Sustainable Development Goals, such as eradicating poverty and reducing inequalities. The connection is recognised in Sustainable Development Goal 13 which is to \"take urgent action to combat climate change and its impacts\". The goals on food, clean water and ecosystem protection have synergies with climate mitigation.The geopolitics of climate change is complex. It has often been framed as a free-rider problem, in which all countries benefit from mitigation done by other countries, but individual countries would lose from switching to a low-carbon economy themselves. Sometimes mitigation also has localized benefits though. For instance, the benefits of a coal phase-out to public health and local environments exceed the costs in almost all regions. Furthermore, net importers of fossil fuels win economically from switching to clean energy, causing net exporters to face stranded assets: fossil fuels they cannot sell.\\n\\nPolicy options\\nA wide range of policies, regulations, and laws are being used to reduce emissions. As of 2019, carbon pricing covers about 20% of global greenhouse gas emissions. Carbon can be priced with carbon taxes and emissions trading systems. Direct global fossil fuel subsidies reached $319 billion in 2017, and $5.2 trillion when indirect costs such as air pollution are priced in. Ending these can cause a 28% reduction in global carbon emissions and a 46% reduction in air pollution deaths. Money saved on fossil subsidies could be used to support the transition to clean energy instead. More direct methods to reduce greenhouse gases include vehicle efficiency standards, renewable fuel standards, and air pollution regulations on heavy industry. Several countries require utilities to increase the share of renewables in power production.\\n\\nClimate justice\\nPolicy designed through the lens of climate justice tries to address human rights issues and social inequality. According to proponents of climate justice, the costs of climate adaptation should be paid by those most responsible for climate change, while the beneficiaries of payments should be those suffering impacts. One way this can be addressed in practice is to have wealthy nations pay poorer countries to adapt.Oxfam found that in 2023 the wealthiest 10% of people were responsible for 50% of global emissions, while the bottom 50% were responsible for just 8%. Production is another way to look at responsibility, with a 2023 study published in One Earth estimating that the top 21 fossil fuel companies would owe cumulative climate reparations of $5.4 trillion over the period 2025\u20132050. To achieve a just transition, people working in the fossil fuel sector would also need other jobs, and their communities would need investments.\\n\\nInternational climate agreements\\nNearly all countries in the world are parties to the 1994 United Nations Framework Convention on Climate Change (UNFCCC). The goal of the UNFCCC is to prevent dangerous human interference with the climate system. As stated in the convention, this requires that greenhouse gas concentrations are stabilised in the atmosphere at a level where ecosystems can adapt naturally to climate change, food production is not threatened, and economic development can be sustained. The UNFCCC does not itself restrict emissions but rather provides a framework for protocols that do. Global emissions have risen since the UNFCCC was signed. Its yearly conferences are the stage of global negotiations.The 1997 Kyoto Protocol extended the UNFCCC and included legally binding commitments for most developed countries to limit their emissions. During the negotiations, the G77 (representing developing countries) pushed for a mandate requiring developed countries to \"[take] the lead\" in reducing their emissions, since developed countries contributed most to the accumulation of greenhouse gases in the atmosphere. Per-capita emissions were also still relatively low in developing countries and developing countries would need to emit more to meet their development needs.The 2009 Copenhagen Accord has been widely portrayed as disappointing because of its low goals, and was rejected by poorer nations including the G77. Associated parties aimed to limit the global temperature rise to below 2 \u00b0C. The Accord set the goal of sending $100 billion per year to developing countries for mitigation and adaptation by 2020, and proposed the founding of the Green Climate Fund. As of 2020, only 83.3 billion were delivered. Only in 2023 the target is expected to be achieved.In 2015 all UN countries negotiated the Paris Agreement, which aims to keep global warming well below 2.0 \u00b0C and contains an aspirational goal of keeping warming under 1.5 \u00b0C. The agreement replaced the Kyoto Protocol. Unlike Kyoto, no binding emission targets were set in the Paris Agreement. Instead, a set of procedures was made binding. Countries have to regularly set ever more ambitious goals and reevaluate these goals every five years. The Paris Agreement restated that developing countries must be financially supported. As of October 2021, 194 states and the European Union have signed the treaty and 191 states and the EU have ratified or acceded to the agreement.The 1987 Montreal Protocol, an international agreement to stop emitting ozone-depleting gases, may have been more effective at curbing greenhouse gas emissions than the Kyoto Protocol specifically designed to do so. The 2016 Kigali Amendment to the Montreal Protocol aims to reduce the emissions of hydrofluorocarbons, a group of powerful greenhouse gases which served as a replacement for banned ozone-depleting gases. This made the Montreal Protocol a stronger agreement against climate change.\\n\\nNational responses\\nIn 2019, the United Kingdom parliament became the first national government to declare a climate emergency. Other countries and jurisdictions followed suit. That same year, the European Parliament declared a \"climate and environmental emergency\". The European Commission presented its European Green Deal with the goal of making the EU carbon-neutral by 2050. In 2021, the European Commission released its \"Fit for 55\" legislation package, which contains guidelines for the car industry; all new cars on the European market must be zero-emission vehicles from 2035.Major countries in Asia have made similar pledges: South Korea and Japan have committed to become carbon-neutral by 2050, and China by 2060. While India has strong incentives for renewables, it also plans a significant expansion of coal in the country. Vietnam is among very few coal-dependent fast developing countries that pledged to phase out unabated coal power by the 2040s or as soon as possible thereafter.As of 2021, based on information from 48 national climate plans, which represent 40% of the parties to the Paris Agreement, estimated total greenhouse gas emissions will be 0.5% lower compared to 2010 levels, below the 45% or 25% reduction goals to limit global warming to 1.5 \u00b0C or 2 \u00b0C, respectively.\\n\\nSociety\\nDenial and misinformation\\nPublic debate about climate change has been strongly affected by climate change denial and misinformation, which originated in the United States and has since spread to other countries, particularly Canada and Australia. Climate change denial has originated from fossil fuel companies, industry groups, conservative think tanks, and contrarian scientists. Like the tobacco industry, the main strategy of these groups has been to manufacture doubt about scientific data and results. People who hold unwarranted doubt about climate change are called climate change \"skeptics\", although \"contrarians\" or \"deniers\" are more appropriate terms.There are different variants of climate denial: some deny that warming takes place at all, some acknowledge warming but attribute it to natural influences, and some minimise the negative impacts of climate change. Manufacturing uncertainty about the science later developed into a manufactured controversy: creating the belief that there is significant uncertainty about climate change within the scientific community in order to delay policy changes. Strategies to promote these ideas include criticism of scientific institutions, and questioning the motives of individual scientists. An echo chamber of climate-denying blogs and media has further fomented misunderstanding of climate change.\\n\\nPublic awareness and opinion\\nClimate change came to international public attention in the late 1980s. Due to media coverage in the early 1990s, people often confused climate change with other environmental issues like ozone depletion. In popular culture, the climate fiction movie The Day After Tomorrow (2004) and the Al Gore documentary An Inconvenient Truth (2006) focused on climate change.Significant regional, gender, age and political differences exist in both public concern for, and understanding of, climate change. More highly educated people, and in some countries, women and younger people, were more likely to see climate change as a serious threat. Partisan gaps also exist in many countries, and countries with high CO2 emissions tend to be less concerned. Views on causes of climate change vary widely between countries. Concern has increased over time, to the point where in 2021 a majority of citizens in many countries express a high level of worry about climate change, or view it as a global emergency. Higher levels of worry are associated with stronger public support for policies that address climate change.\\n\\nClimate movement\\nClimate protests demand that political leaders take action to prevent climate change. They can take the form of public demonstrations, fossil fuel divestment, lawsuits and other activities. Prominent demonstrations include the School Strike for Climate. In this initiative, young people across the globe have been protesting since 2018 by skipping school on Fridays, inspired by Swedish teenager Greta Thunberg. Mass civil disobedience actions by groups like Extinction Rebellion have protested by disrupting roads and public transport.Litigation is increasingly used as a tool to strengthen climate action from public institutions and companies. Activists also initiate lawsuits which target governments and demand that they take ambitious action or enforce existing laws on climate change. Lawsuits against fossil-fuel companies generally seek compensation for loss and damage.\\n\\nHistory\\nEarly discoveries\\nScientists in the 19th century such as Alexander von Humboldt began to foresee the effects of climate change. In the 1820s, Joseph Fourier proposed the greenhouse effect to explain why Earth's temperature was higher than the sun's energy alone could explain. Earth's atmosphere is transparent to sunlight, so sunlight reaches the surface where it is converted to heat. However, the atmosphere is not transparent to heat radiating from the surface, and captures some of that heat, which in turn warms the planet.In 1856 Eunice Newton Foote demonstrated that the warming effect of the sun is greater for air with water vapour than for dry air, and that the effect is even greater with carbon dioxide (CO2). She concluded that \"An atmosphere of that gas would give to our earth a high temperature...\"\\nStarting in 1859, John Tyndall established that nitrogen and oxygen\u2014together totaling 99% of dry air\u2014are transparent to radiated heat. However, water vapour and gases such as methane and carbon dioxide absorb radiated heat and re-radiate that heat into the atmosphere. Tyndall proposed that changes in the concentrations of these gases may have caused climatic changes in the past, including ice ages.Svante Arrhenius noted that water vapour in air continuously varied, but the CO2 concentration in air was influenced by long-term geological processes. Warming from increased CO2 levels would increase the amount of water vapour, amplifying warming in a positive feedback loop. In 1896, he published the first climate model of its kind, projecting that halving CO2 levels could have produced a drop in temperature initiating an ice age. Arrhenius calculated the temperature increase expected from doubling CO2 to be around 5\u20136 \u00b0C. Other scientists were initially skeptical and believed that the greenhouse effect was saturated so that adding more CO2 would make no difference, and that the climate would be self-regulating. Beginning in 1938, Guy Stewart Callendar published evidence that climate was warming and CO2 levels were rising, but his calculations met the same objections.\\n\\nDevelopment of a scientific consensus\\nIn the 1950s, Gilbert Plass created a detailed computer model that included different atmospheric layers and the infrared spectrum. This model predicted that increasing CO2 levels would cause warming. Around the same time, Hans Suess found evidence that CO2 levels had been rising, and Roger Revelle showed that the oceans would not absorb the increase. The two scientists subsequently helped Charles Keeling to begin a record of continued increase, which has been termed the \"Keeling Curve\". Scientists alerted the public, and the dangers were highlighted at James Hansen's 1988 Congressional testimony. The Intergovernmental Panel on Climate Change (IPCC), set up in 1988 to provide formal advice to the world's governments, spurred interdisciplinary research. As part of the IPCC reports, scientists assess the scientific discussion that takes place in peer-reviewed journal articles.There is a near-complete scientific consensus that the climate is warming and that this is caused by human activities. As of 2019, agreement in recent literature reached over 99%. No scientific body of national or international standing disagrees with this view. Consensus has further developed that some form of action should be taken to protect people against the impacts of climate change. National science academies have called on world leaders to cut global emissions. The 2021 IPCC Assessment Report stated that it is \"unequivocal\" that climate change is caused by humans.\\n\\nSee also\\nAnthropocene \u2013 proposed new geological time interval in which humans are having significant geological impact\\nList of climate scientists\\n\\nReferences\\nSources\\nThis article incorporates text from a free content work.  Licensed under CC BY-SA 3.0 (license statement/permission). Text taken from The status of women in agrifood systems \u2013 Overview\u200b,  FAO, FAO.\\n\\nIPCC reports\\nOther peer-reviewed sources\\nBooks, reports and legal documents\\nNon-technical sources\\nExternal links\\n\\nIntergovernmental Panel on Climate Change\\nUK Met Office: Climate Guide\\nNOAA Climate website \u2013 National Oceanic and Atmospheric Administration in the United States"}
{"article_name": "Nelson_Mandela", "link": "https://en.wikipedia.org/wiki/Nelson_Mandela", "text_content": "Nelson Rolihlahla Mandela ( man-DEH-l\u0259; Xhosa: [xol\u00ed\u026ca\u026ca mand\u025b\u0302\u02d0la]; born Rolihlahla Mandela; 18 July 1918 \u2013 5 December 2013) was a South African anti-apartheid activist and politician who served as the first president of South Africa from 1994 to 1999. He was the country's first black head of state and the first elected in a fully representative democratic election. His government focused on dismantling the legacy of apartheid by fostering racial reconciliation. Ideologically an African nationalist and socialist, he served as the president of the African National Congress (ANC) party from 1991 to 1997.\\nA Xhosa, Mandela was born into the Thembu royal family in Mvezo, South Africa. He studied law at the University of Fort Hare and the University of Witwatersrand before working as a lawyer in Johannesburg. There he became involved in anti-colonial and African nationalist politics, joining the ANC in 1943 and co-founding its Youth League in 1944. After the National Party's white-only government established apartheid, a system of racial segregation that privileged whites, Mandela and the ANC committed themselves to its overthrow. He was appointed president of the ANC's Transvaal branch, rising to prominence for his involvement in the 1952 Defiance Campaign and the 1955 Congress of the People. He was repeatedly arrested for seditious activities and was unsuccessfully prosecuted in the 1956 Treason Trial. Influenced by Marxism, he secretly joined the banned South African Communist Party (SACP). Although initially committed to non-violent protest, in association with the SACP he co-founded the militant uMkhonto we Sizwe in 1961 and led a sabotage campaign against the government. He was arrested and imprisoned in 1962, and, following the Rivonia Trial, was sentenced to life imprisonment for conspiring to overthrow the state.\\nMandela served 27 years in prison, split between Robben Island, Pollsmoor Prison and Victor Verster Prison. Amid growing domestic and international pressure and fears of racial civil war, President F. W. de Klerk released him in 1990. Mandela and de Klerk led efforts to negotiate an end to apartheid, which resulted in the 1994 multiracial general election in which Mandela led the ANC to victory and became president. Leading a broad coalition government which promulgated a new constitution, Mandela emphasised reconciliation between the country's racial groups and created the Truth and Reconciliation Commission to investigate past human rights abuses. Economically, his administration retained its predecessor's liberal framework despite his own socialist beliefs, also introducing measures to encourage land reform, combat poverty and expand healthcare services. Internationally, Mandela acted as mediator in the Pan Am Flight 103 bombing trial and served as secretary-general of the Non-Aligned Movement from 1998 to 1999. He declined a second presidential term and was succeeded by his deputy, Thabo Mbeki. Mandela became an elder statesman and focused on combating poverty and HIV/AIDS through the charitable Nelson Mandela Foundation.\\nMandela was a controversial figure for much of his life. Although critics on the right denounced him as a communist terrorist and those on the far left deemed him too eager to negotiate and reconcile with apartheid's supporters, he gained international acclaim for his activism. Globally regarded as an icon of democracy and social justice, he received more than 250 honours, including the Nobel Peace Prize. He is held in deep respect within South Africa, where he is often referred to by his Thembu clan name, Madiba, and described as the \"Father of the Nation\".\\n\\nEarly life\\nChildhood: 1918\u20131934\\nMandela was born on 18 July 1918 in the village of Mvezo in Umtata, then part of South Africa's Cape Province. Given the forename Rolihlahla, a Xhosa term colloquially meaning \"troublemaker\", in later years he became known by his clan name, Madiba. His patrilineal great-grandfather, Ngubengcuka, was ruler of the Thembu Kingdom in the Transkeian Territories of South Africa's modern Eastern Cape province. One of Ngubengcuka's sons, named Mandela, was Nelson's grandfather and the source of his surname. Because Mandela was the king's child by a wife of the Ixhiba clan, a so-called \"Left-Hand House\", the descendants of his cadet branch of the royal family were morganatic, ineligible to inherit the throne but recognised as hereditary royal councillors.Nelson Mandela's father, Gadla Henry Mphakanyiswa Mandela (1880\u20131928), was a local chief and councillor to the monarch; he was appointed to the position in 1915, after his predecessor was accused of corruption by a governing white magistrate. In 1926, Gadla was also sacked for corruption, but Nelson was told that his father had lost his job for standing up to the magistrate's unreasonable demands. A devotee of the god Qamata, Gadla was a polygamist with four wives, four sons and nine daughters, who lived in different villages. Nelson's mother was Gadla's third wife, Nosekeni Fanny, daughter of Nkedama of the Right Hand House and a member of the amaMpemvu clan of the Xhosa.\\n\\nMandela later stated that his early life was dominated by traditional Xhosa custom and taboo. He grew up with two sisters in his mother's kraal in the village of Qunu, where he tended herds as a cattle-boy and spent much time outside with other boys. Both his parents were illiterate, but his mother, being a devout Christian, sent him to a local Methodist school when he was about seven. Baptised a Methodist, Mandela was given the English forename of \"Nelson\" by his teacher. When Mandela was about nine, his father came to stay at Qunu, where he died of an undiagnosed ailment that Mandela believed to be lung disease. Feeling \"cut adrift\", he later said that he inherited his father's \"proud rebelliousness\" and \"stubborn sense of fairness\".Mandela's mother took him to the \"Great Place\" palace at Mqhekezweni, where he was entrusted to the guardianship of the Thembu regent, Chief Jongintaba Dalindyebo. Although he did not see his mother again for many years, Mandela felt that Jongintaba and his wife Noengland treated him as their own child, raising him alongside their son, Justice, and daughter, Nomafu. As Mandela attended church services every Sunday with his guardians, Christianity became a significant part of his life. He attended a Methodist mission school located next to the palace, where he studied English, Xhosa, history and geography. He developed a love of African history, listening to the tales told by elderly visitors to the palace, and was influenced by the anti-imperialist rhetoric of a visiting chief, Joyi. Nevertheless, at the time he considered the European colonizers not as oppressors but as benefactors who had brought education and other benefits to southern Africa. Aged 16, he, Justice and several other boys travelled to Tyhalarha to undergo the ulwaluko circumcision ritual that symbolically marked their transition from boys to men; afterwards he was given the name Dalibunga.\\n\\nClarkebury, Healdtown, and Fort Hare: 1934\u20131940\\nIntending to gain skills needed to become a privy councillor for the Thembu royal house, Mandela began his secondary education in 1933 at Clarkebury Methodist High School in Engcobo, a Western-style institution that was the largest school for black Africans in Thembuland. Made to socialise with other students on an equal basis, he claimed that he lost his \"stuck up\" attitude, becoming best friends with a girl for the first time; he began playing sports and developed his lifelong love of gardening. He completed his Junior Certificate in two years, and in 1937 he moved to Healdtown, the Methodist college in Fort Beaufort attended by most Thembu royalty, including Justice. The headmaster emphasised the superiority of European culture and government, but Mandela became increasingly interested in native African culture, making his first non-Xhosa friend, a speaker of Sotho, and coming under the influence of one of his favourite teachers, a Xhosa who broke taboo by marrying a Sotho. Mandela spent much of his spare time at Healdtown as a long-distance runner and boxer, and in his second year he became a prefect.In 1939, with Jongintaba's backing, Mandela began work on a BA degree at the University of Fort Hare, an elite black institution of approximately 150 students in Alice, Eastern Cape. He studied English, anthropology, politics, \"native administration\", and Roman Dutch law in his first year, desiring to become an interpreter or clerk in the Native Affairs Department. Mandela stayed in the Wesley House dormitory, befriending his own kinsman, K. D. Matanzima, as well as Oliver Tambo, who became a close friend and comrade for decades to come. He took up ballroom dancing, performed in a drama society play about Abraham Lincoln, and gave Bible classes in the local community as part of the Student Christian Association. Although he had friends who held connections to the African National Congress (ANC) who wanted South Africa to be independent of the British Empire, Mandela avoided any involvement with the nascent movement, and became a vocal supporter of the British war effort when the Second World War broke out. He helped establish a first-year students' house committee which challenged the dominance of the second-years, and at the end of his first year became involved in a students' representative council (SRC) boycott against the quality of food, for which he was suspended from the university; he never returned to complete his degree.\\n\\nArriving in Johannesburg: 1941\u20131943\\nReturning to Mqhekezweni in December 1940, Mandela found that Jongintaba had arranged marriages for him and Justice; dismayed, they fled to Johannesburg via Queenstown, arriving in April 1941. Mandela found work as a night watchman at Crown Mines, his \"first sight of South African capitalism in action\", but was fired when the induna (headman) discovered that he was a runaway. He stayed with a cousin in George Goch Township, who introduced Mandela to realtor and ANC activist Walter Sisulu. The latter secured Mandela a job as an articled clerk at the law firm of Witkin, Sidelsky and Eidelman, a company run by Lazar Sidelsky, a liberal Jew sympathetic to the ANC's cause. At the firm, Mandela befriended Gaur Radebe\u2014a Hlubi member of the ANC and Communist Party\u2014and Nat Bregman, a Jewish communist who became his first white friend. Mandela attended Communist Party gatherings, where he was impressed that Europeans, Africans, Indians, and Coloureds mixed as equals. He later stated that he did not join the party because its atheism conflicted with his Christian faith, and because he saw the South African struggle as being racially based rather than as class warfare. To continue his higher education, Mandela signed up to a University of South Africa correspondence course, working on his bachelor's degree at night.Earning a small wage, Mandela rented a room in the house of the Xhoma family in the Alexandra township; despite being rife with poverty, crime and pollution, Alexandra always remained a special place for him. Although embarrassed by his poverty, he briefly dated a Swazi woman before unsuccessfully courting his landlord's daughter. To save money and be closer to downtown Johannesburg, Mandela moved into the compound of the Witwatersrand Native Labour Association, living among miners of various tribes; as the compound was visited by various chiefs, he once met the Queen Regent of Basutoland. In late 1941, Jongintaba visited Johannesburg\u2014there forgiving Mandela for running away\u2014before returning to Thembuland, where he died in the winter of 1942. Mandela and Justice arrived a day late for the funeral. After he passed his BA exams in early 1943, Mandela returned to Johannesburg to follow a political path as a lawyer rather than become a privy councillor in Thembuland. He later stated that he experienced no epiphany, but that he \"simply found [himself] doing so, and could not do otherwise.\"\\n\\nRevolutionary activity and imprisonment\\nLaw studies and the ANC Youth League: 1943\u20131949\\nMandela began studying law at the University of the Witwatersrand, where he was the only black African student and faced racism. There, he befriended liberal and communist European, Jewish and Indian students, among them Joe Slovo and Ruth First. Becoming increasingly politicised, Mandela marched in August 1943 in support of a successful bus boycott to reverse fare rises. Joining the ANC, he was increasingly influenced by Sisulu, spending time with other activists at Sisulu's Orlando house, including his old friend Oliver Tambo. In 1943, Mandela met Anton Lembede, an ANC member affiliated with the \"Africanist\" branch of African nationalism, which was virulently opposed to a racially united front against colonialism and imperialism or to an alliance with the communists. Despite his friendships with non-blacks and communists, Mandela embraced Lembede's views, believing that black Africans should be entirely independent in their struggle for political self-determination. Deciding on the need for a youth wing to mass-mobilise Africans in opposition to their subjugation, Mandela was among a delegation that approached ANC president Alfred Bitini Xuma on the subject at his home in Sophiatown; the African National Congress Youth League (ANCYL) was founded on Easter Sunday 1944 in the Bantu Men's Social Centre, with Lembede as president and Mandela as a member of its executive committee.\\nAt Sisulu's house, Mandela met Evelyn Mase, a trainee nurse and ANC activist from Engcobo, Transkei. Entering a relationship and marrying in October 1944, they initially lived with her relatives until moving into a rented house in the township of Orlando in early 1946. Their first child, Madiba \"Thembi\" Thembekile, was born in February 1945; a daughter, Makaziwe, was born in 1947 but died of meningitis nine months later. Mandela enjoyed home life, welcoming his mother and his sister, Leabie, to stay with him. In early 1947, his three years of articles ended at Witkin, Sidelsky and Eidelman, and he decided to become a full-time student, subsisting on loans from the Bantu Welfare Trust.In July 1947, Mandela rushed Lembede, who was ill, to hospital, where he died; he was succeeded as ANCYL president by the more moderate Peter Mda, who agreed to co-operate with communists and non-blacks, appointing Mandela ANCYL secretary. Mandela disagreed with Mda's approach, and in December 1947 supported an unsuccessful measure to expel communists from the ANCYL, considering their ideology un-African. In 1947, Mandela was elected to the executive committee of the ANC's Transvaal Province branch, serving under regional president C. S. Ramohanoe. When Ramohanoe acted against the wishes of the committee by co-operating with Indians and communists, Mandela was one of those who forced his resignation.In the South African general election in 1948, in which only whites were permitted to vote, the Afrikaner-dominated Herenigde Nasionale Party under Daniel Fran\u00e7ois Malan took power, soon uniting with the Afrikaner Party to form the National Party. Openly racialist, the party codified and expanded racial segregation with new apartheid legislation. Gaining increasing influence in the ANC, Mandela and his party cadre allies began advocating direct action against apartheid, such as boycotts and strikes, influenced by the tactics already employed by South Africa's Indian community. Xuma did not support these measures and was removed from the presidency in a vote of no confidence, replaced by James Moroka and a more militant executive committee containing Sisulu, Mda, Tambo and Godfrey Pitje. Mandela later related that he and his colleagues had \"guided the ANC to a more radical and revolutionary path.\" Having devoted his time to politics, Mandela failed his final year at Witwatersrand three times; he was ultimately denied his degree in December 1949.\\n\\nDefiance Campaign and Transvaal ANC Presidency: 1950\u20131954\\nMandela took Xuma's place on the ANC national executive in March 1950, and that same year was elected national president of the ANCYL. In March, the Defend Free Speech Convention was held in Johannesburg, bringing together African, Indian and communist activists to call a May Day general strike in protest against apartheid and white minority rule. Mandela opposed the strike because it was multi-racial and not ANC-led, but a majority of black workers took part, resulting in increased police repression and the introduction of the Suppression of Communism Act, 1950, affecting the actions of all protest groups. At the ANC national conference of December 1951, he continued arguing against a racially united front, but was outvoted.Thereafter, Mandela rejected Lembede's Africanism and embraced the idea of a multi-racial front against apartheid. Influenced by friends like Moses Kotane and by the Soviet Union's support for wars of national liberation, his mistrust of communism broke down and he began reading literature by Karl Marx, Vladimir Lenin, and Mao Zedong, eventually embracing the Marxist philosophy of dialectical materialism. Commenting on communism, he later stated that he \"found [himself] strongly drawn to the idea of a classless society which, to [his] mind, was similar to traditional African culture where life was shared and communal.\" In April 1952, Mandela began work at the H.M. Basner law firm, which was owned by a communist, although his increasing commitment to work and activism meant he spent less time with his family.In 1952, the ANC began preparation for a joint Defiance Campaign against apartheid with Indian and communist groups, founding a National Voluntary Board to recruit volunteers. The campaign was designed to follow the path of nonviolent resistance influenced by Mahatma Gandhi; some supported this for ethical reasons, but Mandela instead considered it pragmatic. At a Durban rally on 22 June, Mandela addressed an assembled crowd of 10,000 people, initiating the campaign protests for which he was arrested and briefly interned in Marshall Square prison. These events established Mandela as one of the best-known black political figures in South Africa. With further protests, the ANC's membership grew from 20,000 to 100,000 members; the government responded with mass arrests and introduced the Public Safety Act, 1953 to permit martial law. In May, authorities banned Transvaal ANC president J. B. Marks from making public appearances; unable to maintain his position, he recommended Mandela as his successor. Although Africanists opposed his candidacy, Mandela was elected to be regional president in October.\\nIn July 1952, Mandela was arrested under the Suppression of Communism Act and stood trial as one of the 21 accused\u2014among them Moroka, Sisulu and Yusuf Dadoo\u2014in Johannesburg. Found guilty of \"statutory communism\", a term that the government used to describe most opposition to apartheid, their sentence of nine months' hard labour was suspended for two years. In December, Mandela was given a six-month ban from attending meetings or talking to more than one individual at a time, making his Transvaal ANC presidency impractical, and during this period the Defiance Campaign petered out. In September 1953, Andrew Kunene read out Mandela's \"No Easy Walk to Freedom\" speech at a Transvaal ANC meeting; the title was taken from a quote by Indian independence leader Jawaharlal Nehru, a seminal influence on Mandela's thought. The speech laid out a contingency plan for a scenario in which the ANC was banned. This Mandela Plan, or M-Plan, involved dividing the organisation into a cell structure with a more centralised leadership.Mandela obtained work as an attorney for the firm Terblanche and Briggish, before moving to the liberal-run Helman and Michel, passing qualification exams to become a full-fledged attorney. In August 1953, Mandela and Tambo opened their own law firm, Mandela and Tambo, operating in downtown Johannesburg. The only African-run law firm in the country, it was popular with aggrieved black people, often dealing with cases of police brutality. Disliked by the authorities, the firm was forced to relocate to a remote location after their office permit was removed under the Group Areas Act; as a result, their clientele dwindled. As a lawyer of aristocratic heritage, Mandela was part of Johannesburg's elite black middle-class, and accorded much respect from the black community. Although a second daughter, Makaziwe Phumia, was born in May 1954, Mandela's relationship with Evelyn became strained, and she accused him of adultery. He may have had affairs with ANC member Lillian Ngoyi and secretary Ruth Mompati; various individuals close to Mandela in this period have stated that the latter bore him a child. Disgusted by her son's behaviour, Nosekeni returned to Transkei, while Evelyn embraced the Jehovah's Witnesses and rejected Mandela's preoccupation with politics.\\n\\nCongress of the People and the Treason Trial: 1955\u20131961\\nAfter taking part in the unsuccessful protest to prevent the forced relocation of all black people from the Sophiatown suburb of Johannesburg in February 1955, Mandela concluded that violent action would prove necessary to end apartheid and white minority rule. On his advice, Sisulu requested weaponry from the People's Republic of China, which was denied. Although the Chinese government supported the anti-apartheid struggle, they believed the movement insufficiently prepared for guerrilla warfare. With the involvement of the South African Indian Congress, the Coloured People's Congress, the South African Congress of Trade Unions and the Congress of Democrats, the ANC planned a Congress of the People, calling on all South Africans to send in proposals for a post-apartheid era. Based on the responses, a Freedom Charter was drafted by Rusty Bernstein, calling for the creation of a democratic, non-racialist state with the nationalisation of major industry. The charter was adopted at a June 1955 conference in Kliptown; 3,000 delegates attended the event, which was forcibly closed down by police. The tenets of the Freedom Charter remained important for Mandela, and in 1956 he described it as \"an inspiration to the people of South Africa\".Following the end of a second ban in September 1955, Mandela went on a working holiday to Transkei to discuss the implications of the Bantu Authorities Act, 1951 with local Xhosa chiefs, also visiting his mother and Noengland before proceeding to Cape Town. In March 1956, he received his third ban on public appearances, restricting him to Johannesburg for five years, but he often defied it. Mandela's marriage broke down and Evelyn left him, taking their children to live with her brother. Initiating divorce proceedings in May 1956, she claimed that Mandela had physically abused her; he denied the allegations and fought for custody of their children. She withdrew her petition of separation in November, but Mandela filed for divorce in January 1958; the divorce was finalised in March, with the children placed in Evelyn's care. During the divorce proceedings, he began courting a social worker, Winnie Madikizela, whom he married in Bizana in June 1958. She later became involved in ANC activities, spending several weeks in prison. Together they had two children: Zenani, born in February 1959, and Zindziswa (1960\u20132020).\\nIn December 1956, Mandela was arrested alongside most of the ANC national executive and accused of \"high treason\" against the state. Held in Johannesburg Prison amid mass protests, they underwent a preparatory examination before being granted bail. The defence's refutation began in January 1957, overseen by defence lawyer Vernon Berrang\u00e9, and continued until the case was adjourned in September. In January 1958, Oswald Pirow was appointed to prosecute the case, and in February the judge ruled that there was \"sufficient reason\" for the defendants to go on trial in the Transvaal Supreme Court. The formal Treason Trial began in Pretoria in August 1958, with the defendants successfully applying to have the three judges\u2014all linked to the governing National Party\u2014replaced. In August, one charge was dropped, and in October the prosecution withdrew its indictment, submitting a reformulated version in November which argued that the ANC leadership committed high treason by advocating violent revolution, a charge the defendants denied.In April 1959, Africanists dissatisfied with the ANC's united front approach founded the Pan-Africanist Congress (PAC); Mandela disagreed with the PAC's racially exclusionary views, describing them as \"immature\" and \"na\u00efve\". Both parties took part in an anti-pass campaign in early 1960, in which Africans burned the passes that they were legally obliged to carry. One of the PAC-organised demonstrations was fired upon by police, resulting in the deaths of 69 protesters in the Sharpeville massacre. The incident brought international condemnation of the government and resulted in rioting throughout South Africa, with Mandela publicly burning his pass in solidarity.Responding to the unrest, the government implemented state of emergency measures, declaring martial law and banning the ANC and PAC; in March, they arrested Mandela and other activists, imprisoning them for five months without charge in the unsanitary conditions of the Pretoria Local prison. Imprisonment caused problems for Mandela and his co-defendants in the Treason Trial; their lawyers could not reach them, and so it was decided that the lawyers would withdraw in protest until the accused were freed from prison when the state of emergency was lifted in late August 1960. Over the following months, Mandela used his free time to organise an All-In African Conference near Pietermaritzburg, Natal, in March 1961, at which 1,400 anti-apartheid delegates met, agreeing on a stay-at-home strike to mark 31 May, the day South Africa became a republic. On 29 March 1961, six years after the Treason Trial began, the judges produced a verdict of not guilty, ruling that there was insufficient evidence to convict the accused of \"high treason\", since they had advocated neither communism nor violent revolution; the outcome embarrassed the government.\\n\\nMK, the SACP, and African tour: 1961\u201362\\nDisguised as a chauffeur, Mandela travelled around the country incognito, organising the ANC's new cell structure and the planned mass stay-at-home strike. Referred to as the \"Black Pimpernel\" in the press\u2014a reference to Emma Orczy's 1905 novel The Scarlet Pimpernel\u2014a warrant for his arrest was put out by the police. Mandela held secret meetings with reporters, and after the government failed to prevent the strike, he warned them that many anti-apartheid activists would soon resort to violence through groups like the PAC's Poqo. He believed that the ANC should form an armed group to channel some of this violence in a controlled direction, convincing both ANC leader Albert Luthuli\u2014who was morally opposed to violence\u2014and allied activist groups of its necessity.Inspired by the actions of Fidel Castro's 26th of July Movement in the Cuban Revolution, in 1961 Mandela, Sisulu and Slovo co-founded Umkhonto we Sizwe (\"Spear of the Nation\", abbreviated MK). Becoming chairman of the militant group, Mandela gained ideas from literature on guerrilla warfare by Marxist militants Mao and Che Guevara as well as from the military theorist Carl von Clausewitz. Although initially declared officially separate from the ANC so as not to taint the latter's reputation, MK was later widely recognised as the party's armed wing. Most early MK members were white communists who were able to conceal Mandela in their homes; after hiding in communist Wolfie Kodesh's flat in Berea, Mandela moved to the communist-owned Liliesleaf Farm in Rivonia, there joined by Raymond Mhlaba, Slovo and Bernstein, who put together the MK constitution. Although in later life Mandela denied, for political reasons, ever being a member of the Communist Party, historical research published in 2011 strongly suggested that he had joined in the late 1950s or early 1960s. This was confirmed by both the SACP and the ANC after Mandela's death. According to the SACP, he was not only a member of the party, but also served on its Central Committee.\\n\\nOperating through a cell structure, MK planned to carry out acts of sabotage that would exert maximum pressure on the government with minimum casualties; they sought to bomb military installations, power plants, telephone lines, and transport links at night, when civilians were not present. Mandela stated that they chose sabotage because it was the least harmful action, did not involve killing, and offered the best hope for racial reconciliation afterwards; he nevertheless acknowledged that should this have failed then guerrilla warfare might have been necessary. Soon after ANC leader Luthuli was awarded the Nobel Peace Prize, MK publicly announced its existence with 57 bombings on Dingane's Day (16 December) 1961, followed by further attacks on New Year's Eve.The ANC decided to send Mandela as a delegate to the February 1962 meeting of the Pan-African Freedom Movement for East, Central and Southern Africa (PAFMECSA) in Addis Ababa, Ethiopia. Leaving South Africa in secret via Bechuanaland, on his way Mandela visited Tanganyika and met with its president, Julius Nyerere. Arriving in Ethiopia, Mandela met with Emperor Haile Selassie I, and gave his speech after Selassie's at the conference. After the symposium, he travelled to Cairo, Egypt, admiring the political reforms of President Gamal Abdel Nasser, and in April 1962 he went to Morocco where asked El Khatib to meet the king to ask him to give him \u00a35,000. The next day he got the \u00a35,000 along with some weapons and training to Mandela's soldier, and then went to Tunis, Tunisia, where President Habib Bourguiba gave him \u00a35,000 for weaponry. He proceeded to Morocco, Mali, Guinea, Sierra Leone, Liberia and Senegal, receiving funds from Liberian president William Tubman and Guinean president Ahmed S\u00e9kou Tour\u00e9. He left Africa for London, England, where he met anti-apartheid activists, reporters and prominent politicians. Upon returning to Ethiopia, he began a six-month course in guerrilla warfare, but completed only two months before being recalled to South Africa by the ANC's leadership.\\n\\nImprisonment\\nArrest and Rivonia trial: 1962\u20131964\\nOn 5 August 1962, police captured Mandela along with fellow activist Cecil Williams near Howick. Many MK members suspected that the authorities had been tipped off with regard to Mandela's whereabouts, although Mandela himself gave these ideas little credence. In later years, Donald Rickard, a former American diplomat, revealed that the Central Intelligence Agency, which feared Mandela's associations with communists, had informed the South African police of his location. Jailed in Johannesburg's Marshall Square prison, Mandela was charged with inciting workers' strikes and leaving the country without permission. Representing himself with Slovo as legal advisor, Mandela intended to use the trial to showcase \"the ANC's moral opposition to racism\" while supporters demonstrated outside the court. Moved to Pretoria, where Winnie could visit him, he began correspondence studies for a Bachelor of Laws (LLB) degree from the University of London International Programmes. His hearing began in October, but he disrupted proceedings by wearing a traditional kaross, refusing to call any witnesses, and turning his plea of mitigation into a political speech. Found guilty, he was sentenced to five years' imprisonment; as he left the courtroom, supporters sang \"Nkosi Sikelel iAfrika\".\\n\\nOn 11 July 1963, police raided Liliesleaf Farm, arresting those that they found there and uncovering paperwork documenting MK's activities, some of which mentioned Mandela. The Rivonia Trial began at Pretoria Supreme Court in October, with Mandela and his comrades charged with four counts of sabotage and conspiracy to violently overthrow the government; their chief prosecutor was Percy Yutar. Judge Quartus de Wet soon threw out the prosecution's case for insufficient evidence, but Yutar reformulated the charges, presenting his new case from December 1963 until February 1964, calling 173 witnesses and bringing thousands of documents and photographs to the trial.Although four of the accused denied involvement with MK, Mandela and the other five accused admitted sabotage but denied that they had ever agreed to initiate guerrilla war against the government. They used the trial to highlight their political cause; at the opening of the defence's proceedings, Mandela gave his three-hour \"I Am Prepared to Die\" speech. That speech\u2014which was inspired by Castro's \"History Will Absolve Me\"\u2014was widely reported in the press despite official censorship. The trial gained international attention; there were global calls for the release of the accused from the United Nations and World Peace Council, while the University of London Union voted Mandela to its presidency. On 12 June 1964, justice De Wet found Mandela and two of his co-accused guilty on all four charges; although the prosecution had called for the death sentence to be applied, the judge instead condemned them to life imprisonment.\\n\\nRobben Island: 1964\u20131982\\nIn 1964, Mandela and his co-accused were transferred from Pretoria to the prison on Robben Island, remaining there for the next 18 years. Isolated from non-political prisoners in Section B, Mandela was imprisoned in a damp concrete cell measuring 8 feet (2.4 m) by 7 feet (2.1 m), with a straw mat on which to sleep. Verbally and physically harassed by several white prison wardens, the Rivonia Trial prisoners spent their days breaking rocks into gravel, until being reassigned in January 1965 to work in a lime quarry. Mandela was initially forbidden to wear sunglasses, and the glare from the lime permanently damaged his eyesight. At night, he worked on his LLB degree, which he was obtaining from the University of London through a correspondence course with Wolsey Hall, Oxford, but newspapers were forbidden, and he was locked in solitary confinement on several occasions for the possession of smuggled news clippings. He was initially classified as the lowest grade of prisoner, Class D, meaning that he was permitted one visit and one letter every six months, although all mail was heavily censored.\\nThe political prisoners took part in work and hunger strikes\u2014the latter considered largely ineffective by Mandela\u2014to improve prison conditions, viewing this as a microcosm of the anti-apartheid struggle. ANC prisoners elected him to their four-man \"High Organ\" along with Sisulu, Govan Mbeki and Raymond Mhlaba, and he involved himself in a group, named Ulundi, that represented all political prisoners (including Eddie Daniels) on the island, through which he forged links with PAC and Yu Chi Chan Club members. Initiating the \"University of Robben Island\", whereby prisoners lectured on their own areas of expertise, he debated socio-political topics with his comrades.Though attending Christian Sunday services, Mandela studied Islam. He also studied Afrikaans, hoping to build a mutual respect with the warders and convert them to his cause. Various official visitors met with Mandela, most significantly the liberal parliamentary representative Helen Suzman of the Progressive Party, who championed Mandela's cause outside of prison. In September 1970, he met British Labour Party politician Denis Healey. South African Minister of Justice Jimmy Kruger visited in December 1974, but he and Mandela did not get along with each other. His mother visited in 1968, dying shortly after, and his firstborn son Thembi died in a car accident the following year; Mandela was forbidden from attending either funeral. His wife was rarely able to see him, being regularly imprisoned for political activity, and his daughters first visited in December 1975. Winnie was released from prison in 1977 but was forcibly settled in Brandfort and remained unable to see him.From 1967 onwards, prison conditions improved. Black prisoners were given trousers rather than shorts, games were permitted, and the standard of their food was raised. In 1969, an escape plan for Mandela was developed by Gordon Bruce, but it was abandoned after the conspiracy was infiltrated by an agent of the South African Bureau of State Security (BOSS), who hoped to see Mandela shot during the escape. In 1970, Commander Piet Badenhorst became commanding officer. Mandela, seeing an increase in the physical and mental abuse of prisoners, complained to visiting judges, who had Badenhorst reassigned. He was replaced by Commander Willie Willemse, who developed a co-operative relationship with Mandela and was keen to improve prison standards.\\n\\nBy 1975, Mandela had become a Class A prisoner, which allowed him greater numbers of visits and letters. He corresponded with anti-apartheid activists like Mangosuthu Buthelezi and Desmond Tutu. That year, he began his autobiography, which was smuggled to London, but remained unpublished at the time; prison authorities discovered several pages, and his LLB study privileges were revoked for four years. Instead, he devoted his spare time to gardening and reading until the authorities permitted him to resume his LLB degree studies in 1980.By the late 1960s, Mandela's fame had been eclipsed by Steve Biko and the Black Consciousness Movement (BCM). Seeing the ANC as ineffectual, the BCM called for militant action, but, following the Soweto uprising of 1976, many BCM activists were imprisoned on Robben Island. Mandela tried to build a relationship with these young radicals, although he was critical of their racialism and contempt for white anti-apartheid activists. Renewed international interest in his plight came in July 1978, when he celebrated his 60th birthday. He was awarded an honorary doctorate in Lesotho, the Jawaharlal Nehru Award for International Understanding in India in 1979, and the Freedom of the City of Glasgow, Scotland in 1981. In March 1980, the slogan \"Free Mandela!\" was developed by journalist Percy Qoboza, sparking an international campaign that led the UN Security Council to call for his release. Despite increasing foreign pressure, the government refused, relying on its Cold War allies US president Ronald Reagan and British prime minister Margaret Thatcher; both considered Mandela's ANC a terrorist organisation sympathetic to communism and supported its suppression.\\n\\nPollsmoor Prison: 1982\u20131988\\nIn April 1982, Mandela was transferred to Pollsmoor Prison in Tokai, Cape Town, along with senior ANC leaders Walter Sisulu, Andrew Mlangeni, Ahmed Kathrada and Raymond Mhlaba; they believed that they were being isolated to remove their influence on younger activists at Robben Island. Conditions at Pollsmoor were better than at Robben Island, although Mandela missed the camaraderie and scenery of the island. Getting on well with Pollsmoor's commanding officer, Brigadier Munro, Mandela was permitted to create a roof garden; he also read voraciously and corresponded widely, now being permitted 52 letters a year. He was appointed patron of the multi-racial United Democratic Front (UDF), founded to combat reforms implemented by South African president P. W. Botha. Botha's National Party government had permitted Coloured and Indian citizens to vote for their own parliaments, which had control over education, health and housing, but black Africans were excluded from the system. Like Mandela, the UDF saw this as an attempt to divide the anti-apartheid movement on racial lines.\\nThe early 1980s witnessed an escalation of violence across the country, and many predicted civil war. This was accompanied by economic stagnation as various multinational banks\u2014under pressure from an international lobby\u2014had stopped investing in South Africa. Numerous banks and Thatcher asked Botha to release Mandela\u2014then at the height of his international fame\u2014to defuse the volatile situation. Although considering Mandela a dangerous \"arch-Marxist\", Botha offered him, in February 1985, a release from prison if he \"unconditionally rejected violence as a political weapon\". Mandela spurned the offer, releasing a statement through his daughter Zindzi stating, \"What freedom am I being offered while the organisation of the people [ANC] remains banned? Only free men can negotiate. A prisoner cannot enter into contracts.\"In 1985, Mandela underwent surgery on an enlarged prostate gland before being given new solitary quarters on the ground floor. He was met by \"seven eminent persons\", an international delegation sent to negotiate a settlement, but Botha's government refused to co-operate, calling a state of emergency in June and initiating a police crackdown on unrest. The anti-apartheid resistance fought back, with the ANC committing 231 attacks in 1986 and 235 in 1987. The violence escalated as the government used the army and police to combat the resistance and provided covert support for vigilante groups and the Zulu nationalist movement Inkatha, which was involved in an increasingly violent struggle with the ANC. Mandela requested talks with Botha but was denied, instead secretly meeting with Minister of Justice Kobie Coetsee in 1987, and having a further 11 meetings over the next three years. Coetsee organised negotiations between Mandela and a team of four government figures starting in May 1988; the team agreed to the release of political prisoners and the legalisation of the ANC on the condition that they permanently renounce violence, break links with the Communist Party, and not insist on majority rule. Mandela rejected these conditions, insisting that the ANC would end its armed activities only when the government renounced violence.Mandela's 70th birthday in July 1988 attracted international attention, including a tribute concert at London's Wembley Stadium that was televised and watched by an estimated 200 million viewers. Although presented globally as a heroic figure, he faced personal problems when ANC leaders informed him that Winnie had set herself up as head of a gang, the \"Mandela United Football Club\", which had been responsible for torturing and killing opponents\u2014including children\u2014in Soweto. Though some encouraged him to divorce her, he decided to remain loyal until she was found guilty by trial.\\n\\nVictor Verster Prison and release: 1988\u20131990\\nRecovering from tuberculosis exacerbated by the damp conditions in his cell, Mandela was moved to Victor Verster Prison, near Paarl, in December 1988. He was housed in the relative comfort of a warder's house with a personal cook, and he used the time to complete his LLB degree. While there, he was permitted many visitors and organised secret communications with exiled ANC leader Oliver Tambo.In 1989, Botha suffered a stroke; although he retained the state presidency, he stepped down as leader of the National Party, to be replaced by F. W. de Klerk. In a surprise move, Botha invited Mandela to a meeting over tea in July 1989, an invitation Mandela considered genial. Botha was replaced as state president by de Klerk six weeks later; the new president believed that apartheid was unsustainable and released a number of ANC prisoners. Following the fall of the Berlin Wall in November 1989, de Klerk called his cabinet together to debate legalising the ANC and freeing Mandela. Although some were deeply opposed to his plans, de Klerk met with Mandela in December to discuss the situation, a meeting both men considered friendly, before legalising all formerly banned political parties in February 1990 and announcing Mandela's unconditional release. Shortly thereafter, for the first time in 20 years, photographs of Mandela were allowed to be published in South Africa.Leaving Victor Verster Prison on 11 February, Mandela held Winnie's hand in front of amassed crowds and the press; the event was broadcast live across the world. Driven to Cape Town's City Hall through crowds, he gave a speech declaring his commitment to peace and reconciliation with the white minority, but he made it clear that the ANC's armed struggle was not over and would continue as \"a purely defensive action against the violence of apartheid\". He expressed hope that the government would agree to negotiations, so that \"there may no longer be the need for the armed struggle\", and insisted that his main focus was to bring peace to the black majority and give them the right to vote in national and local elections. Staying at Tutu's home, in the following days Mandela met with friends, activists, and press, giving a speech to an estimated 100,000 people at Johannesburg's FNB Stadium.\\n\\nEnd of apartheid\\nEarly negotiations: 1990\u201391\\nMandela proceeded on an African tour, meeting supporters and politicians in Zambia, Zimbabwe, Namibia, Libya and Algeria, and continuing to Sweden, where he was reunited with Tambo, and London, where he appeared at the Nelson Mandela: An International Tribute for a Free South Africa concert at Wembley Stadium. Encouraging foreign countries to support sanctions against the apartheid government, he met President Fran\u00e7ois Mitterrand in France, Pope John Paul II in the Vatican, and Thatcher in the United Kingdom. In the United States, he met President George H. W. Bush, addressed both Houses of Congress and visited eight cities, being particularly popular among the African American community. In Cuba, he became friends with President Castro, whom he had long admired. He met President R. Venkataraman in India, President Suharto in Indonesia, Prime Minister Mahathir Mohamad in Malaysia, and Prime Minister Bob Hawke in Australia. He visited Japan, but not the Soviet Union, a longtime ANC supporter.In May 1990, Mandela led a multiracial ANC delegation into preliminary negotiations with a government delegation of 11 Afrikaner men. Mandela impressed them with his discussions of Afrikaner history, and the negotiations led to the Groot Schuur Minute, in which the government lifted the state of emergency. In August, Mandela\u2014recognising the ANC's severe military disadvantage\u2014offered a ceasefire, the Pretoria Minute, for which he was widely criticised by MK activists. He spent much time trying to unify and build the ANC, appearing at a Johannesburg conference in December attended by 1,600 delegates, many of whom found him more moderate than expected. At the ANC's July 1991 national conference in Durban, Mandela admitted that the party had faults and announced his aim to build a \"strong and well-oiled task force\" for securing majority rule. At the conference, he was elected ANC President, replacing the ailing Tambo, and a 50-strong multiracial, mixed gendered national executive was elected.Mandela was given an office in the newly purchased ANC headquarters at Shell House, Johannesburg, and moved into Winnie's large Soweto home. Their marriage was increasingly strained as he learned of her affair with Dali Mpofu, but he supported her during her trial for kidnapping and assault. He gained funding for her defence from the International Defence and Aid Fund for Southern Africa and from Libyan leader Muammar Gaddafi, but, in June 1991, she was found guilty and sentenced to six years in prison, reduced to two on appeal. On 13 April 1992, Mandela publicly announced his separation from Winnie. The ANC forced her to step down from the national executive for misappropriating ANC funds; Mandela moved into the mostly white Johannesburg suburb of Houghton. Mandela's prospects for a peaceful transition were further damaged by an increase in \"black-on-black\" violence, particularly between ANC and Inkatha supporters in KwaZulu-Natal, which resulted in thousands of deaths. Mandela met with Inkatha leader Buthelezi, but the ANC prevented further negotiations on the issue. Mandela argued that there was a \"third force\" within the state intelligence services fuelling the \"slaughter of the people\" and openly blamed de Klerk\u2014whom he increasingly distrusted\u2014for the Sebokeng massacre. In September 1991, a national peace conference was held in Johannesburg at which Mandela, Buthelezi and de Klerk signed a peace accord, though the violence continued.\\n\\nCODESA talks: 1991\u201392\\nThe Convention for a Democratic South Africa (CODESA) began in December 1991 at the Johannesburg World Trade Centre, attended by 228 delegates from 19 political parties. Although Cyril Ramaphosa led the ANC's delegation, Mandela remained a key figure. After de Klerk used the closing speech to condemn the ANC's violence, Mandela took to the stage to denounce de Klerk as the \"head of an illegitimate, discredited minority regime\". Dominated by the National Party and ANC, little negotiation was achieved. CODESA 2 was held in May 1992, at which de Klerk insisted that post-apartheid South Africa must use a federal system with a rotating presidency to ensure the protection of ethnic minorities; Mandela opposed this, demanding a unitary system governed by majority rule. Following the Boipatong massacre of ANC activists by government-aided Inkatha militants, Mandela called off the negotiations, before attending a meeting of the Organisation of African Unity in Senegal, at which he called for a special session of the UN Security Council and proposed that a UN peacekeeping force be stationed in South Africa to prevent \"state terrorism\". Calling for domestic mass action, in August the ANC organised the largest-ever strike in South African history, and supporters marched on Pretoria.\\nFollowing the Bisho massacre, in which 28 ANC supporters and one soldier were shot dead by the Ciskei Defence Force during a protest march, Mandela realised that mass action was leading to further violence and resumed negotiations in September. He agreed to do so on the conditions that all political prisoners be released, that Zulu traditional weapons be banned, and that Zulu hostels would be fenced off, the latter two measures intended to prevent further Inkatha attacks; de Klerk reluctantly agreed. The negotiations agreed that a multiracial general election would be held, resulting in a five-year coalition government of national unity and a constitutional assembly that gave the National Party continuing influence. The ANC also conceded to safeguarding the jobs of white civil servants; such concessions brought fierce internal criticism. The duo agreed on an interim constitution based on a liberal democratic model, guaranteeing separation of powers, creating a constitutional court, and including a US-style bill of rights; it also divided the country into nine provinces, each with its own premier and civil service, a concession between de Klerk's desire for federalism and Mandela's for unitary government.The democratic process was threatened by the Concerned South Africans Group (COSAG), an alliance of black ethnic-secessionist groups like Inkatha and far-right Afrikaner parties; in June 1993, one of the latter\u2014the Afrikaner Weerstandsbeweging (AWB)\u2014attacked the Kempton Park World Trade Centre. Following the murder of ANC activist Chris Hani, Mandela made a publicised speech to calm rioting, soon after appearing at a mass funeral in Soweto for Tambo, who had died of a stroke. In July 1993, both Mandela and de Klerk visited the United States, independently meeting President Bill Clinton, and each receiving the Liberty Medal. Soon after, Mandela and de Klerk were jointly awarded the Nobel Peace Prize in Norway. Influenced by Thabo Mbeki, Mandela began meeting with big business figures, and he played down his support for nationalisation, fearing that he would scare away much-needed foreign investment. Although criticised by socialist ANC members, he had been encouraged to embrace private enterprise by members of the Chinese and Vietnamese Communist parties at the January 1992 World Economic Forum in Switzerland.\\n\\nGeneral election: 1994\\nWith the election set for 27 April 1994, the ANC began campaigning, opening 100 election offices and orchestrating People's Forums across the country at which Mandela could appear, as a popular figure with great status among black South Africans. The ANC campaigned on a Reconstruction and Development Programme (RDP) to build a million houses in five years, introduce universal free education and extend access to water and electricity. The party's slogan was \"a better life for all\", although it was not explained how this development would be funded. With the exception of the Weekly Mail and the New Nation, South Africa's press opposed Mandela's election, fearing continued ethnic strife, instead supporting the National or Democratic Party. Mandela devoted much time to fundraising for the ANC, touring North America, Europe and Asia to meet wealthy donors, including former supporters of the apartheid regime. He also urged a reduction in the voting age from 18 to 14; rejected by the ANC, this policy became the subject of ridicule.Concerned that COSAG would undermine the election, particularly in the wake of the conflict in Bophuthatswana and the Shell House massacre\u2014incidents of violence involving the AWB and Inkatha, respectively\u2014Mandela met with Afrikaner politicians and generals, including P. W. Botha, Pik Botha and Constand Viljoen, persuading many to work within the democratic system. With de Klerk, he also convinced Inkatha's Buthelezi to enter the elections rather than launch a war of secession. As leaders of the two major parties, de Klerk and Mandela appeared on a televised debate; although de Klerk was widely considered the better speaker at the event, Mandela's offer to shake his hand surprised him, leading some commentators to deem it a victory for Mandela. The election went ahead with little violence, although an AWB cell killed 20 with car bombs. As widely expected, the ANC won a sweeping victory, taking 63% of the vote, just short of the two-thirds majority needed to unilaterally change the constitution. The ANC was also victorious in seven provinces, with Inkatha and the National Party each taking one. Mandela voted at the Ohlange High School in Durban, and though the ANC's victory assured his election as president, he publicly accepted that the election had been marred by instances of fraud and sabotage.\\n\\nPresidency of South Africa: 1994\u20131999\\nThe newly elected National Assembly's first act was to formally elect Mandela as South Africa's first black chief executive. His inauguration took place in Pretoria on 10 May 1994, televised to a billion viewers globally. The event was attended by four thousand guests, including world leaders from a wide range of geographic and ideological backgrounds. Mandela headed a Government of National Unity dominated by the ANC\u2014which had no experience of governing by itself\u2014but containing representatives from the National Party and Inkatha. Under the Interim Constitution, Inkatha and the National Party were entitled to seats in the government by virtue of winning at least 20 seats. In keeping with earlier agreements, both de Klerk and Thabo Mbeki were given the position of Deputy President. Although Mbeki had not been his first choice for the job, Mandela grew to rely heavily on him throughout his presidency, allowing him to shape policy details. Moving into the presidential office at Tuynhuys in Cape Town, Mandela allowed de Klerk to retain the presidential residence in the Groote Schuur estate, instead settling into the nearby Westbrooke manor, which he renamed \"Genadendal\", meaning \"Valley of Mercy\" in Afrikaans. Retaining his Houghton home, he also had a house built in his home village of Qunu, which he visited regularly, walking around the area, meeting with locals, and judging tribal disputes.Aged 76, he faced various ailments, and although exhibiting continued energy, he felt isolated and lonely. He often entertained celebrities, such as Michael Jackson, Whoopi Goldberg and the Spice Girls, and befriended ultra-rich businessmen, like Harry Oppenheimer of Anglo American. He also met with Queen Elizabeth II on her March 1995 state visit to South Africa, which earned him strong criticism from ANC anti-capitalists. Despite his opulent surroundings, Mandela lived simply, donating a third of his R 552,000 annual income to the Nelson Mandela Children's Fund, which he had founded in 1995. Although dismantling press censorship, speaking out in favour of freedom of the press and befriending many journalists, Mandela was critical of much of the country's media, noting that it was overwhelmingly owned and run by middle-class whites and believing that it focused too heavily on scaremongering about crime.In December 1994, Mandela published Long Walk to Freedom, an autobiography based around a manuscript he had written in prison, augmented by interviews conducted with American journalist Richard Stengel. In late 1994, he attended the 49th conference of the ANC in Bloemfontein, at which a more militant national executive was elected, among them Winnie Mandela; although she expressed an interest in reconciling, Nelson initiated divorce proceedings in August 1995. By 1995, he had entered into a relationship with Gra\u00e7a Machel, a Mozambican political activist 27 years his junior who was the widow of former president Samora Machel. They had first met in July 1990 when she was still in mourning, but their friendship grew into a partnership, with Machel accompanying him on many of his foreign visits. She turned down Mandela's first marriage proposal, wanting to retain some independence and dividing her time between Mozambique and Johannesburg.\\n\\nNational reconciliation\\nPresiding over the transition from apartheid minority rule to a multicultural democracy, Mandela saw national reconciliation as the primary task of his presidency. Having seen other post-colonial African economies damaged by the departure of white elites, Mandela worked to reassure South Africa's white population that they were protected and represented in \"the Rainbow Nation\". Although his Government of National Unity would be dominated by the ANC, he attempted to create a broad coalition by appointing de Klerk as Deputy President and appointing other National Party officials as ministers for Agriculture, Environment, and Minerals and Energy, as well as naming Buthelezi as Minister for Home Affairs. The other cabinet positions were taken by ANC members, many of whom\u2014like Joe Modise, Alfred Nzo, Joe Slovo, Mac Maharaj and Dullah Omar\u2014had long been comrades of Mandela, although others, such as Tito Mboweni and Jeff Radebe, were far younger. Mandela's relationship with de Klerk was strained; Mandela thought that de Klerk was intentionally provocative, and de Klerk felt that he was being intentionally humiliated by the president. In January 1995, Mandela heavily chastised de Klerk for awarding amnesty to 3,500 police officers just before the election, and later criticised him for defending former Minister of Defence Magnus Malan when the latter was charged with murder.Mandela personally met with senior figures of the apartheid regime, including lawyer Percy Yutar and Hendrik Verwoerd's widow, Betsie Schoombie, also laying a wreath by the statue of Afrikaner hero Daniel Theron. Emphasising personal forgiveness and reconciliation, he announced that \"courageous people do not fear forgiving, for the sake of peace.\" He encouraged black South Africans to get behind the previously hated national rugby team, the Springboks, as South Africa hosted the 1995 Rugby World Cup. Mandela wore a Springbok shirt at the final against New Zealand, and after the Springboks won the match, Mandela presented the trophy to captain Francois Pienaar, an Afrikaner. This was widely seen as a major step in the reconciliation of white and black South Africans; as de Klerk later put it, \"Mandela won the hearts of millions of white rugby fans.\" Mandela's efforts at reconciliation assuaged the fears of white people, but also drew criticism from more militant black people. Among the latter was his estranged wife, Winnie, who accused the ANC of being more interested in appeasing the white community than in helping the black majority.Mandela oversaw the formation of a Truth and Reconciliation Commission to investigate crimes committed under apartheid by both the government and the ANC, appointing Tutu as its chair. To prevent the creation of martyrs, the commission granted individual amnesties in exchange for testimony of crimes committed during the apartheid era. Dedicated in February 1996, it held two years of hearings detailing rapes, torture, bombings and assassinations before issuing its final report in October 1998. Both de Klerk and Mbeki appealed to have parts of the report suppressed, though only de Klerk's appeal was successful. Mandela praised the commission's work, stating that it \"had helped us move away from the past to concentrate on the present and the future\".\\n\\nDomestic programmes\\nMandela's administration inherited a country with a huge disparity in wealth and services between white and black communities. Of a population of 40 million, around 23 million lacked electricity or adequate sanitation, and 12 million lacked clean water supplies, with 2 million children not in school and a third of the population illiterate. There was 33% unemployment, and just under half of the population lived below the poverty line. Government financial reserves were nearly depleted, with a fifth of the national budget being spent on debt repayment, meaning that the extent of the promised Reconstruction and Development Programme (RDP) was scaled back, with none of the proposed nationalisation or job creation. In 1996, the RDP was replaced with a new policy, Growth, Employment and Redistribution (GEAR), which maintained South Africa's mixed economy but placed an emphasis on economic growth through a framework of market economics and the encouragement of foreign investment; many in the ANC derided it as a neo-liberal policy that did not address social inequality, no matter how Mandela defended it. In adopting this approach, Mandela's government adhered to the \"Washington consensus\" advocated by the World Bank and International Monetary Fund.Under Mandela's presidency, welfare spending increased by 13% in 1996/97, 13% in 1997/98, and 7% in 1998/99. The government introduced parity in grants for communities, including disability grants, child maintenance grants and old-age pensions, which had previously been set at different levels for South Africa's different racial groups. In 1994, free healthcare was introduced for children under six and pregnant women, a provision extended to all those using primary level public sector health care services in 1996. By the 1999 election, the ANC could boast that due to their policies, 3 million people were connected to telephone lines, 1.5 million children were brought into the education system, 500 clinics were upgraded or constructed, 2 million people were connected to the electricity grid, water access was extended to 3 million people, and 750,000 houses were constructed, housing nearly 3 million people.\\nThe Land Reform Act 3 of 1996 safeguarded the rights of labour tenants living on farms where they grew crops or grazed livestock. This legislation ensured that such tenants could not be evicted without a court order or if they were over the age of 65. Recognising that arms manufacturing was a key industry for the South African economy, Mandela endorsed the trade in weapons but brought in tighter regulations surrounding Armscor to ensure that South African weaponry was not sold to authoritarian regimes. Under Mandela's administration, tourism was increasingly promoted, becoming a major sector of the South African economy.Critics like Edwin Cameron accused Mandela's government of doing little to stem the HIV/AIDS pandemic in the country; by 1999, 10% of South Africa's population were HIV positive. Mandela later admitted that he had personally neglected the issue, in part due to public reticence in discussing issues surrounding sex in South Africa, and that he had instead left the issue for Mbeki to deal with. Mandela also received criticism for failing to sufficiently combat crime; South Africa had one of the world's highest crime rates, and the activities of international crime syndicates in the country grew significantly throughout the decade. Mandela's administration was also perceived as having failed to deal with the problem of corruption.Further problems were caused by the exodus of thousands of skilled white South Africans from the country, who were escaping the increasing crime rates, higher taxes and the impact of positive discrimination toward black people in employment. This exodus resulted in a brain drain, and Mandela criticised those who left. At the same time, South Africa experienced an influx of millions of illegal migrants from poorer parts of Africa; although public opinion toward these illegal immigrants was generally unfavourable, characterising them as disease-spreading criminals who were a drain on resources, Mandela called on South Africans to embrace them as \"brothers and sisters\".\\n\\nForeign affairs\\nMandela expressed the view that \"South Africa's future foreign relations [should] be based on our belief that human rights should be the core of international relations\". Following the South African example, Mandela encouraged other nations to resolve conflicts through diplomacy and reconciliation. In September 1998, Mandela was appointed secretary-general of the Non-Aligned Movement, who held their annual conference in Durban. He used the event to criticise the \"narrow, chauvinistic interests\" of the Israeli government in stalling negotiations to end the Israeli\u2013Palestinian conflict and urged India and Pakistan to negotiate to end the Kashmir conflict, for which he was criticised by both Israel and India. Inspired by the region's economic boom, Mandela sought greater economic relations with East Asia, in particular with Malaysia, although this was prevented by the 1997 Asian financial crisis. He extended diplomatic recognition to the People's Republic of China (PRC), who were growing as an economic force, and initially also to Taiwan, who were already longstanding investors in the South African economy. However, under pressure from the PRC, he cut recognition of Taiwan in November 1996, and he paid an official visit to Beijing in May 1999.\\nMandela attracted controversy for his close relationship with Indonesian president Suharto, whose regime was responsible for mass human rights abuses, although on a July 1997 visit to Indonesia he privately urged Suharto to withdraw from the occupation of East Timor. He also faced similar criticism from the West for his government's trade links to Syria, Cuba and Libya and for his personal friendships with Castro and Gaddafi. Castro visited South Africa in 1998 to widespread popular acclaim, and Mandela met Gaddafi in Libya to award him the Order of Good Hope. When Western governments and media criticised these visits, Mandela lambasted such criticism as having racist undertones, and stated that \"the enemies of countries in the West are not our enemies.\" Mandela hoped to resolve the long-running dispute between Libya and the United States and Britain over bringing to trial the two Libyans, Abdelbaset al-Megrahi and Lamin Khalifah Fhimah, who were indicted in November 1991 and accused of sabotaging Pan Am Flight 103. Mandela proposed that they be tried in a third country, which was agreed to by all parties; governed by Scots law, the trial was held at Camp Zeist in the Netherlands in April 1999, and found one of the two men guilty.Mandela echoed Mbeki's calls for an \"African Renaissance\", and he was greatly concerned with issues on the continent. He took a soft diplomatic approach to removing Sani Abacha's military junta in Nigeria but later became a leading figure in calling for sanctions when Abacha's regime increased human rights violations. In 1996, he was appointed chairman of the Southern African Development Community (SADC) and initiated unsuccessful negotiations to end the First Congo War in Zaire. He also played a key role as a mediator in the ethnic conflict between Tutsi and Hutu political groups in the Burundian Civil War, helping to initiate a settlement which brought increased stability to the country but did not end the ethnic violence. In South Africa's first post-apartheid military operation, troops were ordered into Lesotho in September 1998 to protect the government of Prime Minister Pakalitha Mosisili after a disputed election had prompted opposition uprisings. The action was not authorised by Mandela himself, who was out of the country at the time, but by Buthelezi, who was serving as acting president during Mandela's absence, with the approval of Mandela and Mbeki.\\n\\nWithdrawing from politics\\nThe new Constitution of South Africa was agreed upon by parliament in May 1996, enshrining a series of institutions to place checks on political and administrative authority within a constitutional democracy. De Klerk opposed the implementation of this constitution, and that month he and the National Party withdrew from the coalition government in protest, claiming that the ANC were not treating them as equals. The ANC took over the cabinet positions formerly held by the Nationals, with Mbeki becoming sole Deputy President. Inkatha remained part of the coalition, and when both Mandela and Mbeki were out of the country in September 1998, Buthelezi was appointed \"Acting President\", marking an improvement in his relationship with Mandela. Although Mandela had often governed decisively in his first two years as president, he had subsequently increasingly delegated duties to Mbeki, retaining only a close personal supervision of intelligence and security measures. During a 1997 visit to London, he said that \"the ruler of South Africa, the de facto ruler, is Thabo Mbeki\" and that he was \"shifting everything to him\".Mandela stepped down as ANC President at the party's December 1997 conference. He hoped that Ramaphosa would succeed him, believing Mbeki to be too inflexible and intolerant of criticism, but the ANC elected Mbeki regardless. Mandela and the Executive supported Jacob Zuma, a Zulu who had been imprisoned on Robben Island, as Mbeki's replacement for Deputy President. Zuma's candidacy was challenged by Winnie, whose populist rhetoric had gained her a strong following within the party, although Zuma defeated her in a landslide victory vote at the election.Mandela's relationship with Machel had intensified; in February 1998, he publicly stated that he was \"in love with a remarkable lady\", and under pressure from Tutu, who urged him to set an example for young people, he organised a wedding for his 80th birthday, in July that year. The following day, he held a grand party with many foreign dignitaries. Although the 1996 constitution allowed the president to serve two consecutive five-year terms, Mandela had never planned to stand for a second term in office. He gave his farewell speech to Parliament on 29 March 1999 when it adjourned prior to the 1999 general elections, after which he retired. Although opinion polls in South Africa showed wavering support for both the ANC and the government, Mandela himself remained highly popular, with 80% of South Africans polled in 1999 expressing satisfaction with his performance as president.\\n\\nPost-presidency and final years\\nContinued activism and philanthropy: 1999\u20132004\\nRetiring in June 1999, Mandela aimed to lead a quiet family life, divided between Johannesburg and Qunu. Although he set about authoring a sequel to his first autobiography, to be titled The Presidential Years, it remained unfinished and was only published posthumously in 2017. Mandela found such seclusion difficult and reverted to a busy public life involving a daily programme of tasks, meetings with world leaders and celebrities, and\u2014when in Johannesburg\u2014working with the Nelson Mandela Foundation, founded in 1999 to focus on rural development, school construction, and combating HIV/AIDS. Although he had been heavily criticised for failing to do enough to fight the HIV/AIDS pandemic during his presidency, he devoted much of his time to the issue following his retirement, describing it as \"a war\" that had killed more than \"all previous wars\"; affiliating himself with the Treatment Action Campaign, he urged Mbeki's government to ensure that HIV-positive South Africans had access to anti-retrovirals. Meanwhile, Mandela was successfully treated for prostate cancer in July 2001.In 2002, Mandela inaugurated the Nelson Mandela Annual Lecture, and in 2003 the Mandela Rhodes Foundation was created at Rhodes House, University of Oxford, to provide postgraduate scholarships to African students. These projects were followed by the Nelson Mandela Centre of Memory and the 46664 campaign against HIV/AIDS. He gave the closing address at the XIII International AIDS Conference in Durban in 2000, and in 2004, spoke at the XV International AIDS Conference in Bangkok, Thailand, calling for greater measures to tackle tuberculosis as well as HIV/AIDS. Mandela publicised AIDS as the cause of his son Makgatho's death in January 2005, to defy the stigma about discussing the disease.Publicly, Mandela became more vocal in criticising Western powers. He strongly opposed the 1999 NATO intervention in Kosovo and called it an attempt by the world's powerful nations to police the entire world. In 2003, he spoke out against the plans for the United States to launch a war in Iraq, describing it as \"a tragedy\" and lambasting US president George W. Bush and British prime minister Tony Blair (whom he referred to as an \"American foreign minister\") for undermining the UN, saying, \"All that (Mr. Bush) wants is Iraqi oil\". He attacked the United States more generally, asserting that \"If there is a country that has committed unspeakable atrocities in the world, it is the United States of America\", citing the atomic bombing of Japan; this attracted international controversy, although he later improved his relationship with Bush. Retaining an interest in the Lockerbie suspect, he visited Megrahi in Barlinnie prison and spoke out against the conditions of his treatment, referring to them as \"psychological persecution\".\\n\\n\"Retiring from retirement\": 2004\u20132013\\nIn June 2004, aged 85 and amid failing health, Mandela announced that he was \"retiring from retirement\" and retreating from public life, remarking, \"Don't call me, I will call you.\" Although continuing to meet with close friends and family, the foundation discouraged invitations for him to appear at public events and denied most interview requests.He retained some involvement in international affairs. In 2005, he founded the Nelson Mandela Legacy Trust, travelling to the United States to speak before the Brookings Institution and the NAACP on the need for economic assistance to Africa. He spoke with US senator Hillary Clinton and President George W. Bush and first met the then-senator Barack Obama. Mandela also encouraged Zimbabwean president Robert Mugabe to resign over growing human rights abuses in the country. When this proved ineffective, he spoke out publicly against Mugabe in 2007, asking him to step down \"with residual respect and a modicum of dignity.\" That year, Mandela, Machel and Desmond Tutu convened a group of world leaders in Johannesburg to contribute their wisdom and independent leadership to some of the world's toughest problems. Mandela announced the formation of this new group, The Elders, in a speech delivered on his 89th birthday.\\nMandela's 90th birthday was marked across the country on 18 July 2008, with the main celebrations held at Qunu, and a concert in his honour in Hyde Park, London. In a speech marking the event, Mandela called for the rich to help the poor across the world. Throughout Mbeki's presidency, Mandela continued to support the ANC, usually overshadowing Mbeki at any public events that the two attended. Mandela was more at ease with Mbeki's successor, Zuma, although the Nelson Mandela Foundation was upset when his grandson, Mandla Mandela, flew him out to the Eastern Cape to attend a pro-Zuma rally in the midst of a storm in 2009.In 2004, Mandela successfully campaigned for South Africa to host the 2010 FIFA World Cup, declaring that there would be \"few better gifts for us\" in the year marking a decade since the fall of apartheid. Despite maintaining a low profile during the event due to ill health, Mandela made his final public appearance during the World Cup closing ceremony, where he received much applause. Between 2005 and 2013, Mandela, and later his family, were embroiled in a series of legal disputes regarding money held in family trusts for the benefit of his descendants. In mid-2013, as Mandela was hospitalised for a lung infection in Pretoria, his descendants were involved in an intra-family legal dispute relating to the burial place of Mandela's children, and ultimately Mandela himself.\\n\\nIllness and death: 2011\u20132013\\nIn February 2011, Mandela was briefly hospitalised with a respiratory infection, attracting international attention, before being re-admitted for a lung infection and gallstone removal in December 2012. After a successful medical procedure in early March 2013, his lung infection recurred and he was briefly hospitalised in Pretoria. In June 2013, his lung infection worsened and he was readmitted to a Pretoria hospital in serious condition. The Archbishop of Cape Town Thabo Makgoba visited Mandela at the hospital and prayed with Machel, while Zuma cancelled a trip to Mozambique to visit him the following day. In September 2013, Mandela was discharged from hospital, although his condition remained unstable.After suffering from a prolonged respiratory infection, Mandela died on 5 December 2013 at the age of 95, at around 20:50 local time at his home in Houghton, surrounded by his family. Zuma publicly announced his death on television, proclaiming ten days of national mourning, a memorial service held at Johannesburg's FNB Stadium on 10 December 2013, and 8 December as a national day of prayer and reflection. Mandela's body lay in state from 11 to 13 December at the Union Buildings in Pretoria and a state funeral was held on 15 December in Qunu. Approximately 90 representatives of foreign states travelled to South Africa to attend memorial events. It was later revealed that 300 million rand (about 20 million dollars) originally earmarked for humanitarian development projects had been redirected to finance the funeral. The media was awash with tributes and reminiscences, while images of tributes to Mandela proliferated across social media. His US$4.1 million estate was left to his widow, other family members, staff, and educational institutions.\\n\\nPolitical ideology\\nMandela identified as both an African nationalist, an ideological position he held since joining the ANC, and as a socialist. He was a practical politician, rather than an intellectual scholar or political theorist. According to biographer Tom Lodge, \"for Mandela, politics has always been primarily about enacting stories, about making narratives, primarily about morally exemplary conduct, and only secondarily about ideological vision, more about means rather than ends.\"The historian Sabelo J. Ndlovu-Gatsheni described Mandela as a \"liberal African nationalist\u2013decolonial humanist\", while political analyst Raymond Suttner cautioned against labelling Mandela a liberal and stated that Mandela displayed a \"hybrid socio-political make-up\". Mandela adopted some of his political ideas from other thinkers\u2014among them Indian independence leaders like Gandhi and Nehru, African American civil rights activists, and African nationalists like Nkrumah\u2014and applied them to the South African situation. At the same time, he rejected other aspects of their thought, such as the anti-white sentiment of many African nationalists. In doing so he synthesised both counter-cultural and hegemonic views, for instance by drawing upon ideas from the then-dominant Afrikaner nationalism in promoting his anti-apartheid vision.His political development was strongly influenced by his legal training and practice, in particular his hope to achieve change not through violence but through \"legal revolution\". Over the course of his life, he began by advocating a path of non-violence, later embracing violence, and then adopting a non-violent approach to negotiation and reconciliation. When endorsing violence, he did so because he saw no alternative, and was always pragmatic about it, perceiving it as a means to get his opponent to the negotiating table. He sought to target symbols of white supremacy and racist oppression rather than white people as individuals and was anxious not to inaugurate a race war in South Africa. This willingness to use violence distinguishes Mandela from the ideology of Gandhism, with which some commentators have sought to associate him.\\n\\nDemocracy\\nAlthough he presented himself in an autocratic manner in several speeches, Mandela was a devout believer in democracy and abided by majority decisions even when deeply disagreeing with them. He had exhibited a commitment to the values of democracy and human rights since at least the 1960s. He held a conviction that \"inclusivity, accountability and freedom of speech\" were the fundamentals of democracy, and was driven by a belief in natural and human rights. Suttner argued that there were \"two modes of leadership\" that Mandela adopted. On one side he adhered to ideas about collective leadership, although on the other believed that there were scenarios in which a leader had to be decisive and act without consultation to achieve a particular objective.According to Lodge, Mandela's political thought reflected tensions between his support for liberal democracy and pre-colonial African forms of consensus decision making. He was an admirer of British-style parliamentary democracy, stating that \"I regard the British Parliament as the most democratic institution in the world, and the independence and impartiality of its judiciary never fail to arouse my admiration.\" In this he has been described as being committed to \"the Euro-North American modernist project of emancipation\", something which distinguishes him from other African nationalist and socialist leaders like Nyerere who were concerned about embracing styles of democratic governance that were Western, rather than African, in origin. Mandela nevertheless also expressed admiration for what he deemed to be indigenous forms of democracy, describing Xhosa traditional society's mode of governance as \"democracy in its purest form\". He also spoke of an influential African ethical tenet, Ubuntu, which is a Ngnuni term meaning \"A person is a person through other persons\" or \"I am because we are.\"\\n\\nSocialism and Marxism\\nMandela advocated the ultimate establishment of a classless society, with Sampson describing him as being \"openly opposed to capitalism, private land-ownership and the power of big money\". Mandela was influenced by Marxism, and during the revolution he advocated scientific socialism. He denied being a communist at the Treason Trial, and maintained this stance both when later talking to journalists, and in his autobiography, where he outlined that the cooperation with the SACP was pragmatic, asking rhetorically, \"who is to say that we were not using them?\" According to the sociologist Craig Soudien, \"sympathetic as Mandela was to socialism, a communist he was not.\" Conversely, the biographer David Jones Smith stated that Mandela \"embraced communism and communists\" in the late 1950s and early 1960s, while the historian Stephen Ellis commented that Mandela had assimilated much of the Marxist\u2013Leninist ideology by 1960.Ellis also found evidence that Mandela had been an active member of the South African Communist Party (SACP) during the late 1950s and early 1960s, something that was confirmed after his death by both the ANC and the SACP, the latter of which claimed that he was not only a member of the party, but also served on its Central Committee. His membership had been hidden by the ANC, aware that knowledge of Mandela's former SACP involvement might have been detrimental to his attempts to attract support from Western countries. Mandela's view of these Western governments differed from those of Marxist\u2013Leninists, for he did not believe that they were anti-democratic or reactionary and remained committed to democratic systems of governance.The 1955 Freedom Charter, which Mandela had helped create, called for the nationalisation of banks, gold mines and land, to ensure equal distribution of wealth. Despite these beliefs, Mandela initiated a programme of privatisation during his presidency in line with trends in other countries of the time. It has been repeatedly suggested that Mandela would have preferred to develop a social democratic economy in South Africa but that this was not feasible as a result of the international political and economic situation during the early 1990s. This decision was in part influenced by the fall of the socialist states in the Soviet Union and Eastern Bloc during the early 1990s.\\n\\nPersonality and personal life\\nMandela was widely considered a charismatic leader, described by biographer Mary Benson as \"a born mass leader who could not help magnetizing people\". He was highly image conscious and throughout his life always sought out fine quality clothes, with many commentators believing that he carried himself in a regal manner. His aristocratic heritage was repeatedly emphasised by supporters, thus contributing to his \"charismatic power\". While living in Johannesburg in the 1950s, he cultivated the image of the \"African gentleman\", having \"the pressed clothes, correct manners, and modulated public speech\" associated with such a position. In doing so, Lodge argued that Mandela became \"one of the first media politicians ... embodying a glamour and a style that projected visually a brave new African world of modernity and freedom\". Mandela was known to change his clothes several times a day, and he became so associated with highly coloured Batik shirts after assuming the presidency that they came to be known as \"Madiba shirts\".For political scientists Betty Glad and Robert Blanton, Mandela was an \"exceptionally intelligent, shrewd, and loyal leader\". His official biographer, Anthony Sampson, commented that he was a \"master of imagery and performance\", excelling at presenting himself well in press photographs and producing sound bites. His public speeches were presented in a formal, stiff manner, and often consisted of clich\u00e9d set phrases. He typically spoke slowly, and carefully chose his words. Although he was not considered a great orator, his speeches conveyed \"his personal commitment, charm and humour\".Mandela was a private person who often concealed his emotions and confided in very few people. Privately, he lived an austere life, refusing to drink alcohol or smoke, and even as president made his own bed. Renowned for his mischievous sense of humour, he was known for being both stubborn and loyal, and at times exhibited a quick temper. He was typically friendly and welcoming, and appeared relaxed in conversation with everyone, including his opponents. A self-described Anglophile, he claimed to have lived by the \"trappings of British style and manners\". Constantly polite and courteous, he was attentive to all, irrespective of their age or status, and often talked to children or servants. He was known for his ability to find common ground with very different communities. In later life, he always looked for the best in people, even defending political opponents to his allies, who sometimes thought him too trusting of others. He was fond of Indian cuisine, and had a lifelong interest in archaeology and boxing.\\n\\nHe was raised in the Methodist denomination of Christianity; the Methodist Church of Southern Africa claimed that he retained his allegiance to them throughout his life. On analysing Mandela's writings, the theologian Dion Forster described him as a Christian humanist, although added that his thought relied to a greater extent on the Southern African concept of Ubuntu than on Christian theology. According to Sampson, Mandela never had \"a strong religious faith\" however, while Elleke Boehmer stated that Mandela's religious belief was \"never robust\".Mandela was very self-conscious about being a man and regularly made references to manhood. He was heterosexual, and biographer Fatima Meer said that he was \"easily tempted\" by women. Another biographer, Martin Meredith, characterised him as being \"by nature a romantic\", highlighting that he had relationships with various women. Mandela was married three times, fathered six children, and had seventeen grandchildren and at least seventeen great-grandchildren. He could be stern and demanding of his children, although he was more affectionate with his grandchildren. His first marriage was to Evelyn Ntoko Mase in October 1944; they divorced in March 1958 under the multiple strains of his adultery and constant absences, devotion to revolutionary agitation, and the fact that she was a Jehovah's Witness, a religion requiring political neutrality. Mandela's second wife was the social worker Winnie Madikizela-Mandela, whom he married in June 1958. They divorced in March 1996. Mandela married his third wife, Gra\u00e7a Machel, on his 80th birthday in July 1998.\\n\\nReception and legacy\\nBy the time of his death, within South Africa Mandela was widely considered both \"the father of the nation\" and \"the founding father of democracy\". Outside of South Africa, he was a \"global icon\", with the scholar of South African studies Rita Barnard describing him as \"one of the most revered figures of our time\". One biographer considered him \"a modern democratic hero\". Some have portrayed Mandela in messianic terms, in contrast to his own statement that \"I was not a messiah, but an ordinary man who had become a leader because of extraordinary circumstances.\" He is often cited alongside Mahatma Gandhi and Martin Luther King Jr. as one of the 20th century's exemplary anti-racist and anti-colonial leaders. Boehmer described him as \"a totem of the totemic values of our age: toleration and liberal democracy\" and \"a universal symbol of social justice\".Mandela's international fame emerged during his incarceration in the 1980s, when he became the world's most famous political prisoner, a symbol of the anti-apartheid cause, and an icon for millions who embraced the ideal of human equality. In 1986, Mandela's biographer characterised him as \"the embodiment of the struggle for liberation\" in South Africa. Meredith stated that in becoming \"a potent symbol of resistance\" to apartheid during the 1980s, he had gained \"mythical status\" internationally. Sampson commented that even during his life, this myth had become \"so powerful that it blurs the realities\", converting Mandela into \"a secular saint\". Within a decade of the end of his presidency, Mandela's era was widely thought of as \"a golden age of hope and harmony\", with much nostalgia being expressed for it. His name was often invoked by those criticising his successors like Mbeki and Zuma. Across the world, Mandela earned international acclaim for his activism in overcoming apartheid and fostering racial reconciliation, coming to be viewed as \"a moral authority\" with a great \"concern for truth\". Mandela's iconic status has been blamed for concealing the complexities of his life.Mandela generated controversy throughout his career as an activist and politician, having detractors on both the right and the radical left. During the 1980s, Mandela was widely labelled a terrorist by prominent political figures in the Western world for his embrace of political violence. According to Thatcher, for instance, the ANC was \"a typical terrorist organisation\". The US government's State and Defense departments officially designated the ANC as a terrorist organisation, resulting in Mandela remaining on their terrorism watch-list until 2008. On the left, some voices in the ANC\u2014among them Frank B. Wilderson III\u2014accused him of selling out for agreeing to enter negotiations with the apartheid government and for not implementing the reforms of the Freedom Charter during his presidency. According to Barnard, \"there is also a sense in which his chiefly bearing and mode of conduct, the very respect and authority he accrued in representing his nation in his own person, went against the spirit of democracy\", and concerns were similarly expressed that he placed his own status and celebrity above the transformation of his country. His government would be criticised for its failure to deal with both the HIV/AIDS pandemic and the high levels of poverty in South Africa. Mandela was also criticised for his friendship with political leaders such as Fidel Castro and Muammar Gaddafi, who had supported the struggle against apartheid but were deemed dictators by critics.\\n\\nOrders, decorations, monuments, and honours\\nOver the course of his life, Mandela was given over 250 awards, accolades, prizes, honorary degrees and citizenships in recognition of his political achievements. Among his awards were the Nobel Peace Prize, the US Presidential Medal of Freedom, the Soviet Union's Lenin Peace Prize, and the Libyan Al-Gaddafi International Prize for Human Rights. In 1990, India awarded him the Bharat Ratna, and in 1992 Pakistan gave him their Nishan-e-Pakistan. The same year, he was awarded the Atat\u00fcrk Peace Award by Turkey; he at first refused the award, citing human rights violations committed by Turkey at the time, but later accepted the award in 1999. He was appointed to the Order of Isabella the Catholic and the Order of Canada, and was the first living person to be made an honorary Canadian citizen. Queen Elizabeth II appointed him as a Bailiff Grand Cross of the Order of St. John and granted him membership in the Order of Merit.In 2004, Johannesburg granted Mandela the Freedom of the City, and in 2008 a Mandela statue was unveiled at the spot where Mandela was released from prison. On the Day of Reconciliation 2013, a bronze statue of Mandela was unveiled at Pretoria's Union Buildings. In November 2009, the United Nations General Assembly proclaimed Mandela's birthday, 18 July, as \"Mandela Day\", marking his contribution to the anti-apartheid struggle. It called on individuals to donate 67 minutes to doing something for others, commemorating the 67 years that Mandela had been a part of the movement. In 2015 the UN General Assembly named the amended Standard Minimum Rules for the Treatment of Prisoners as \"the Mandela Rules\" to honour his legacy. Subsequently, the years 2019 to 2028 were also designated the United Nations Nelson Mandela Decade of Peace.\\n\\nBiographies and popular media\\nThe first biography of Mandela was based on brief interviews with him that the author, Mary Benson, had conducted in the 1960s. Two authorised biographies were later produced by friends of Mandela. The first was Fatima Meer's Higher Than Hope, which was heavily influenced by Winnie and thus placed great emphasis on Mandela's family. The second was Anthony Sampson's Mandela, published in 1999. Other biographies included Martin Meredith's Mandela, first published in 1997, and Tom Lodge's Mandela, brought out in 2006.Since the late 1980s, Mandela's image began to appear on a proliferation of items, among them \"photographs, paintings, drawings, statues, public murals, buttons, t-shirts, refrigerator magnets, and more\", items that have been characterised as \"Mandela kitsch\". In the 1980s he was the subject of several songs, such as The Specials' \"Free Nelson Mandela\", Hugh Masekela's \"Bring Him Back Home (Nelson Mandela)\", and Johnny Clegg's \"Asimbonanga (Mandela)\", which helped to bring awareness of his imprisonment to an international audience.Mandela has also been depicted in films on multiple occasions. Some of these, such as the 2013 feature film Mandela: Long Walk to Freedom, the 2017 miniseries Madiba and the 1996 documentary Mandela, have focused on covering his adult life in entirety or until his inaugural as president. Others, such as the 2009 feature film Invictus and the 2010 documentary The 16th Man, have focused on specific events in his life. Lukhele has argued that in Invictus and other films, \"the America film industry\" has played a significant part in \"the crafting of Mandela's global image\".\\n\\nSee also\\nList of peace activists\\nMandela effect\\n\\nReferences\\nFootnotes\\nBibliography\\nExternal links\\n\\nNelson Mandela Centre of Memory\\nNelson Mandela Children's Fund\\nNelson Mandela Foundation (archived)\\nMandela Rhodes Foundation\\nThe Elders\\nNelson Mandela Museum\\nNelson Mandela Day (archived)\\nNelson Mandela's family tree\\nNelson Mandela at Curlie\\nNelson Mandela at IMDb\\nAppearances on C-SPAN\\nNelson Mandela on Nobelprize.org"}
{"article_name": "Music", "link": "https://en.wikipedia.org/wiki/Music", "text_content": "In the most general of terms, Music is the arrangement of sound to create some combination of form, harmony, melody, rhythm, or otherwise expressive content. Definitions of music vary depending on culture, though it is an aspect of all human societies and a cultural universal. While scholars agree that music is defined by a few specific elements, there is no consensus on their precise definitions. The creation of music is commonly divided into musical composition, musical improvisation, and musical performance, though the topic itself extends into academic disciplines, criticism, philosophy, psychology, and therapeutic contexts. Music may be performed or improvised using a vast range of instruments, including the human voice, thus is often credited for it's extreme versatility, and opportunity for creativity.In some musical contexts, a performance or composition may be to some extent improvised. For instance, in Hindustani classical music, the performer plays spontaneously while following a partially defined structure and using characteristic motifs. In modal jazz, the performers may take turns leading and responding while sharing a changing set of notes. In a free jazz context, there may be no structure whatsoever, with each performer acting at their discretion. Music may be deliberately composed to be unperformable or agglomerated electronically from many performances. Music is played in public and private areas, highlighted at events such as festivals, rock concerts, and orchestra performances, and heard incidentally as part of a score or soundtrack to a film, TV show, opera, or video game. Musical playback is the primary function of an MP3 player or CD player, and a universal feature of radios and smartphones.\\nMusic often plays a key role in social activities, religious rituals, rite of passage ceremonies, celebrations, and cultural activities. The music industry includes songwriters, performers, sound engineers, producers, tour organizers, distributors of instruments, accessories, and sheet music. Compositions, performances, and recordings are assessed and evaluated by music critics, music journalists, and music scholars, as well as amateurs.\\n\\nEtymology and terminology\\nThe modern English word 'music' came into use in the 1630s. It is derived from a long line of successive precursors: the Old English 'musike' of the mid-13th century; the Old French musique of the 12th century; and the Latin m\u016bsica. The Latin word itself derives from the Ancient Greek mousik\u00e9 (techn\u0113)\u2014\u03bc\u03bf\u03c5\u03c3\u03b9\u03ba\u03ae (\u03c4\u03ad\u03c7\u03bd\u03b7)\u2014literally meaning \"(art) of the Muses\". The Muses were nine deities in Ancient Greek mythology who presided over the arts and sciences. They were included in tales by the earliest Western authors, Homer and Hesiod, and eventually came to be associated with music specifically. Over time, Polyhymnia would reside over music more prominently than the other muses. The Latin word musica was also the originator for both the Spanish m\u00fasica and French musique via spelling and linguistic adjustment, though other European terms were probably loanwords, including the Italian musica, German Musik, Dutch muziek, Norwegian musikk, Polish muzyka and Russian muz\u00efka.The modern Western world usually defines music as an all-encompassing term used to describe diverse genres, styles, and traditions. This is not the case worldwide, and languages such as modern Indonesian (musik) and Shona (musakazo) have recently adopted words to reflect this universal conception, as they did not have words that fit exactly the Western scope. Before Western contact in East Asia, neither Japan nor China had a single word that encompasses music in a broad sense, but culturally, they often regarded music in such a fashion. The closest word to mean music in Chinese, yue, shares a character with le, meaning joy, and originally referred to all the arts before narrowing in meaning. Africa is too diverse to make firm generalizations, but the musicologist J. H. Kwabena Nketia has emphasized African music's often inseparable connection to dance and speech in general. Some African cultures, such as the Songye people of the Democratic Republic of the Congo and the Tiv people of Nigeria, have a strong and broad conception of 'music' but no corresponding word in their native languages. Other words commonly translated as 'music' often have more specific meanings in their respective cultures: the Hindi word for music, sangita, properly refers to art music, while the many Indigenous languages of the Americas have words for music that refer specifically to song but describe instrumental music regardless. Though the Arabic musiqi can refer to all music, it is usually used for instrumental and metric music, while khandan identifies vocal and improvised music.\\n\\nHistory\\nOrigins and prehistory\\nIt is often debated to what extent the origins of music will ever be understood, and there are competing theories that aim to explain it. Many scholars highlight a relationship between the origin of music and the origin of language, and there is disagreement surrounding whether music developed before, after, or simultaneously with language. A similar source of contention surrounds whether music was the intentional result of natural selection or was a byproduct spandrel of evolution. The earliest influential theory was proposed by Charles Darwin in 1871, who stated that music arose as a form of sexual selection, perhaps via mating calls. Darwin's original perspective has been heavily criticized for its inconsistencies with other sexual selection methods, though many scholars in the 21st century have developed and promoted the theory. Other theories include that music arose to assist in organizing labor, improving long-distance communication, benefiting communication with the divine, assisting in community cohesion or as a defense to scare off predators.Prehistoric music can only be theorized based on findings from paleolithic archaeology sites. The Divje Babe flute, carved from a cave bear femur, is thought to be at least 40,000 years old, though there is considerable debate surrounding whether it is truly a musical instrument or an object formed by animals. The earliest objects whose designations as musical instruments are widely accepted are bone flutes from the Swabian Jura, Germany, namely from the Geissenkl\u00f6sterle, Hohle Fels and Vogelherd caves. Dated to the Aurignacian (of the Upper Paleolithic) and used by Early European modern humans, from all three caves there are eight examples, four made from the wing bones of birds and four from mammoth ivory; three of these are near complete. Three flutes from the Geissenkl\u00f6sterle are dated as the oldest, c.\u200943,150\u201339,370 BP.\\n\\nAntiquity\\nThe earliest material and representational evidence of Egyptian musical instruments dates to the Predynastic period, but the evidence is more securely attested in the Old Kingdom when harps, flutes and double clarinets were played. Percussion instruments, lyres, and lutes were added to orchestras by the Middle Kingdom. Cymbals frequently accompanied music and dance, much as they still do in Egypt today. Egyptian folk music, including the traditional Sufi dhikr rituals, are the closest contemporary music genre to ancient Egyptian music, having preserved many of its features, rhythms and instruments.The \"Hurrian Hymn to Nikkal\", found on clay tablets in the ancient Syrian city of Ugarit, is the oldest surviving notated work of music, dating back to approximately 1400 BCE.Music was an important part of social and cultural life in ancient Greece, in fact it was one of the main subjects taught to children. Musical education was considered to be important for the development of an individual's soul. Musicians and singers played a prominent role in Greek theater, and those who received a musical education were seen as nobles and in perfect harmony (as can be read in the Republic, Plato). Mixed gender choruses performed for entertainment, celebration, and spiritual ceremonies. Instruments included the double-reed aulos and a plucked string instrument, the lyre, principally a special kind called a kithara. Music was an important part of education, and boys were taught music starting at age six. Greek musical literacy created significant musical development. Greek music theory included the Greek musical modes, that eventually became the basis for Western religious and classical music. Later, influences from the Roman Empire, Eastern Europe, and the Byzantine Empire changed Greek music. The Seikilos epitaph is the oldest surviving example of a complete musical composition, including musical notation, from anywhere in the world. The oldest surviving work written on the subject of music theory is Harmonika Stoicheia by Aristoxenus.\\n\\nAsian cultures\\nAsian music covers a swath of music cultures surveyed in the articles on Arabia, Central Asia, East Asia, South Asia, and Southeast Asia. Several have traditions reaching into antiquity.\\n\\nIndian classical music is one of the oldest musical traditions in the world. Sculptures from the Indus Valley civilization show dance and old musical instruments, like the seven-holed flute. Stringed instruments and drums have been recovered from Harappa and Mohenjo Daro by excavations carried out by Mortimer Wheeler. The Rigveda, an ancient Hindu text, has elements of present Indian music, with musical notation to denote the meter and mode of chanting. Indian classical music (marga) is monophonic, and based on a single melody line or raga rhythmically organized through talas. The poem Cilappatikaram provides information about how new scales can be formed by modal shifting of the tonic from an existing scale. Present day Hindi music was influenced by Persian traditional music and Afghan Mughals. Carnatic music, popular in the southern states, is largely devotional; the majority of the songs are addressed to the Hindu deities. There are songs emphasizing love and other social issues.\\n\\nIndonesian music has been formed since the Bronze Age culture migrated to the Indonesian archipelago in the 2nd-3rd centuries BCE. Indonesian traditional music uses percussion instruments, especially kendang and gongs. Some of them developed elaborate and distinctive instruments, such as the sasando stringed instrument on the island of Rote, the Sundanese angklung, and the complex and sophisticated Javanese and Balinese gamelan orchestras. Indonesia is the home of gong chime, a general term for a set of small, high pitched pot gongs. Gongs are usually placed in order of note, with the boss up on a string held in a low wooden frame. The most popular form of Indonesian music is gamelan, an ensemble of tuned percussion instruments that include metallophones, drums, gongs and spike fiddles along with bamboo suling (like a flute).Chinese classical music, the traditional art or court music of China, has a history stretching over about 3,000 years. It has its own unique systems of musical notation, as well as musical tuning and pitch, musical instruments and styles or genres. Chinese music is pentatonic-diatonic, having a scale of twelve notes to an octave (5 + 7 = 12) as does European-influenced music.\\n\\nWestern classical\\nEarly music\\nThe medieval music era (500 to 1400), which took place during the Middle Ages, started with the introduction of monophonic (single melodic line) chanting into Catholic Church services. Musical notation was used since ancient times in Greek culture, but in the Middle Ages, notation was first introduced by the Catholic Church, so chant melodies could be written down, to facilitate the use of the same melodies for religious music across the Catholic empire. The only European Medieval repertory that has been found, in written form, from before 800 is the monophonic liturgical plainsong chant of the Catholic Church, the central tradition of which was called Gregorian chant. Alongside these traditions of sacred and church music there existed a vibrant tradition of secular song (non-religious songs). Examples of composers from this period are L\u00e9onin, P\u00e9rotin, Guillaume de Machaut, and Walther von der Vogelweide.Renaissance music (c.\u20091400 to 1600) was more focused on secular themes, such as courtly love. Around 1450, the printing press was invented, which made printed sheet music much less expensive and easier to mass-produce (prior to the invention of the press, all notated music was hand-copied). The increased availability of sheet music spread musical styles quicker and across a larger area. Musicians and singers often worked for the church, courts and towns. Church choirs grew in size, and the church remained an important patron of music. By the middle of the 15th century, composers wrote richly polyphonic sacred music, in which different melody lines were interwoven simultaneously. Prominent composers from this era include Guillaume Du Fay, Giovanni Pierluigi da Palestrina, Thomas Morley, Orlando di Lasso and Josquin des Prez. As musical activity shifted from the church to aristocratic courts, kings, queens and princes competed for the finest composers. Many leading composers came from the Netherlands, Belgium, and France; they are called the Franco-Flemish composers. They held important positions throughout Europe, especially in Italy. Other countries with vibrant musical activity included Germany, England, and Spain.\\n\\nCommon practice period\\nBaroque\\nThe Baroque era of music took place from 1600 to 1750, as the Baroque artistic style flourished across Europe; and during this time, music expanded in its range and complexity. Baroque music began when the first operas (dramatic solo vocal music accompanied by orchestra) were written. During the Baroque era, polyphonic contrapuntal music, in which multiple, simultaneous independent melody lines were used, remained important (counterpoint was important in the vocal music of the Medieval era). German Baroque composers wrote for small ensembles including strings, brass, and woodwinds, as well as for choirs and keyboard instruments such as pipe organ, harpsichord, and clavichord. During this period several major music forms were defined that lasted into later periods when they were expanded and evolved further, including the fugue, the invention, the sonata, and the concerto. The late Baroque style was polyphonically complex and richly ornamented. Important composers from the Baroque era include Johann Sebastian Bach (Cello suites), George Frideric Handel (Messiah), Georg Philipp Telemann and Antonio Vivaldi (The Four Seasons).\\n\\nClassicism\\nThe music of the Classical period (1730 to 1820) aimed to imitate what were seen as the key elements of the art and philosophy of Ancient Greece and Rome: the ideals of balance, proportion and disciplined expression. (Note: the music from the Classical period should not be confused with Classical music in general, a term which refers to Western art music from the 5th century to the 2000s, which includes the Classical period as one of a number of periods). Music from the Classical period has a lighter, clearer and considerably simpler texture than the Baroque music which preceded it. The main style was homophony, where a prominent melody and a subordinate chordal accompaniment part are clearly distinct. Classical instrumental melodies tended to be almost voicelike and singable. New genres were developed, and the fortepiano, the forerunner to the modern piano, replaced the Baroque era harpsichord and pipe organ as the main keyboard instrument (though pipe organ continued to be used in sacred music, such as Masses).\\nImportance was given to instrumental music. It was dominated by further development of musical forms initially defined in the Baroque period: the sonata, the concerto, and the symphony. Other main kinds were the trio, string quartet, serenade and divertimento. The sonata was the most important and developed form. Although Baroque composers also wrote sonatas, the Classical style of sonata is completely distinct. All of the main instrumental forms of the Classical era, from string quartets to symphonies and concertos, were based on the structure of the sonata. The instruments used chamber music and orchestra became more standardized. In place of the basso continuo group of the Baroque era, which consisted of harpsichord, organ or lute along with a number of bass instruments selected at the discretion of the group leader (e.g., viol, cello, theorbo, serpent), Classical chamber groups used specified, standardized instruments (e.g., a string quartet would be performed by two violins, a viola and a cello). The practice of improvised chord-playing by the continuo keyboardist or lute player, a hallmark of Baroque music, underwent a gradual decline between 1750-1800.One of the most important changes made in the Classical period was the development of public concerts. The aristocracy still played a significant role in the sponsorship of concerts and compositions, but it was now possible for composers to survive without being permanent employees of queens or princes. The increasing popularity of classical music led to a growth in the number and types of orchestras. The expansion of orchestral concerts necessitated the building of large public performance spaces. Symphonic music including symphonies, musical accompaniment to ballet and mixed vocal/instrumental genres, such as opera and oratorio, became more popular.The best known composers of Classicism are Carl Philipp Emanuel Bach, Christoph Willibald Gluck, Johann Christian Bach, Joseph Haydn, Wolfgang Amadeus Mozart, Ludwig van Beethoven and Franz Schubert. Beethoven and Schubert are also considered to be composers in the later part of the Classical era, as it began to move towards Romanticism.\\n\\nRomanticism\\nRomantic music (c.\u20091820 to 1900) from the 19th century had many elements in common with the Romantic styles in literature and painting of the era. Romanticism was an artistic, literary, and intellectual movement was characterized by its emphasis on emotion and individualism as well as glorification of all the past and nature. Romantic music expanded beyond the rigid styles and forms of the Classical era into more passionate, dramatic expressive pieces and songs. Romantic composers such as Wagner and Brahms attempted to increase emotional expression and power in their music to describe deeper truths or human feelings. With symphonic tone poems, composers tried to tell stories and evoke images or landscapes using instrumental music. Some composers promoted nationalistic pride with patriotic orchestral music inspired by folk music. The emotional and expressive qualities of music came to take precedence over tradition.Romantic composers grew in idiosyncrasy, and went further in the syncretism of exploring different art-forms in a musical context, (such as literature), history (historical figures and legends), or nature itself. Romantic love or longing was a prevalent theme in many works composed during this period. In some cases, the formal structures from the classical period continued to be used (e.g., the sonata form used in string quartets and symphonies), but these forms were expanded and altered. In many cases, new approaches were explored for existing genres, forms, and functions. Also, new forms were created that were deemed better suited to the new subject matter. Composers continued to develop opera and ballet music, exploring new styles and themes.In the years after 1800, the music developed by Ludwig van Beethoven and Franz Schubert introduced a more dramatic, expressive style. In Beethoven's case, short motifs, developed organically, came to replace melody as the most significant compositional unit (an example is the distinctive four note figure used in his Fifth Symphony). Later Romantic composers such as Pyotr Ilyich Tchaikovsky, Anton\u00edn Dvo\u0159\u00e1k, and Gustav Mahler used more unusual chords and more dissonance to create dramatic tension. They generated complex and often much longer musical works. During the late Romantic period, composers explored dramatic chromatic alterations of tonality, such as extended chords and altered chords, which created new sound \"colors.\" The late 19th century saw a dramatic expansion in the size of the orchestra, and the industrial revolution helped to create better instruments, creating a more powerful sound. Public concerts became an important part of well-to-do urban society. It also saw a new diversity in theatre music, including operetta, and musical comedy and other forms of musical theatre.\\n\\n20th and 21st century\\nIn the 19th century, a key way new compositions became known to the public, was by the sales of sheet music, which middle class amateur music lovers would perform at home, on their piano or other common instruments, such as the violin. With 20th-century music, the invention of new electric technologies such as radio broadcasting and mass market availability of gramophone records meant sound recordings heard by listeners (on the radio or record player), became the main way to learn about new songs and pieces. There was a vast increase in music listening as the radio gained popularity and phonographs were used to replay and distribute music, anyone with a radio or record player could hear operas, symphonies and big bands in their own living room. During the 19th century, the focus on sheet music had restricted access to new music to middle and upper-class people who could read music and who owned pianos and other instruments. Radios and record players allowed lower-income people, who could not afford an opera or symphony concert ticket to hear this music. It meant people could hear music from different parts of the country, or even different parts of the world, even if they could not afford to travel to these locations. This helped to spread musical styles.The focus of art music in the 20th century was characterized by exploration of new rhythms, styles, and sounds. The horrors of World War I influenced many of the arts, including music, and composers began exploring darker, harsher sounds. Traditional music styles such as jazz and folk music were used by composers as a source of ideas for classical music. Igor Stravinsky, Arnold Schoenberg, and John Cage were influential composers in 20th-century art music. The invention of sound recording and the ability to edit music gave rise to new subgenres of classical music, including the acousmatic and Musique concr\u00e8te schools of electronic composition. Sound recording was a major influence on the development of popular music genres, because it enabled recordings of songs and bands to be widely distributed. The introduction of the multitrack recording system had a major influence on rock music, because it could do more than record a band's performance. Using a multitrack system, a band and their music producer could overdub many layers of instrument tracks and vocals, creating new sounds that would not be possible in a live performance.Jazz evolved and became an important genre of music over the course of the 20th century, and during the second half, rock music did the same. Jazz is an American musical artform that originated in the beginning of the 20th century, in African American communities in the Southern United States from a confluence of African and European music traditions. The style's West African pedigree is evident in its use of blue notes, improvisation, polyrhythms, syncopation, and the swung note.\\nRock music is a genre of popular music that developed in the 1950s from rock and roll, rockabilly, blues, and country music. The sound of rock often revolves around the electric or acoustic guitar, and it uses a strong back beat laid down by a rhythm section. Along with the guitar or keyboards, saxophone and blues-style harmonica are used as soloing instruments. In its \"purest form\", it \"has three chords, a strong, insistent back beat, and a catchy melody.\" The traditional rhythm section for popular music is rhythm guitar, electric bass guitar, drums. Some bands have keyboard instruments such as organ, piano, or, since the 1970s, analog synthesizers. In the 1980s, pop musicians began using digital synthesizers, such as the DX-7 synthesizer, electronic drum machines such as the TR-808 and synth bass devices (such as the TB-303) or synth bass keyboards. In the 1990s, an increasingly large range of computerized hardware musical devices and instruments and software (e.g. digital audio workstations) were used. In the 2020s, soft synths and computer music apps make it possible for bedroom producers to create and record types of music, such as electronic dance music, in their home, adding sampled and digital instruments and editing the recording digitally. In the 1990s, bands in genres such as nu metal began including DJs in their bands. DJs create music by manipulating recorded music, using a DJ mixer.Innovation in music technology continued into the 21st century, including the development of isomorphic keyboards and Dynamic Tonality.\\n\\nCreation\\nComposition\\n\"Composition\" is the act or practice of creating a song, an instrumental music piece, a work with both singing and instruments, or another type of music. In many cultures, including Western classical music, the act of composing also includes the creation of music notation, such as a sheet music \"score\", which is then performed by the composer or by other singers or musicians. In popular music and traditional music, the act of composing, which is typically called songwriting, may involve the creation of a basic outline of the song, called the lead sheet, which sets out the melody, lyrics and chord progression. In classical music, the composer typically orchestrates his or her own compositions, but in musical theatre and in pop music, songwriters may hire an arranger to do the orchestration. In some cases, a songwriter may not use notation at all, and instead, compose the song in her mind and then play or record it from memory. In jazz and popular music, notable recordings by influential performers are given the weight that written scores play in classical music.Even when music is notated relatively precisely, as in classical music, there are many decisions that a performer has to make, because notation does not specify all of the elements of music precisely. The process of deciding how to perform music that has been previously composed and notated is termed \"interpretation\". Different performers' interpretations of the same work of music can vary widely, in terms of the tempos that are chosen and the playing or singing style or phrasing of the melodies. Composers and songwriters who present their own music are interpreting their songs, just as much as those who perform the music of others. The standard body of choices and techniques present at a given time and a given place is referred to as performance practice, whereas interpretation is generally used to mean the individual choices of a performer.Although a musical composition often uses musical notation and has a single author, this is not always the case. A work of music can have multiple composers, which often occurs in popular music when a band collaborates to write a song, or in musical theatre, when one person writes the melodies, a second person writes the lyrics, and a third person orchestrates the songs. In some styles of music, such as the blues, a composer/songwriter may create, perform and record new songs or pieces without ever writing them down in music notation. A piece of music can also be composed with words, images, or computer programs that explain or notate how the singer or musician should create musical sounds. Examples range from avant-garde music that uses graphic notation, to text compositions such as Aus den sieben Tagen, to computer programs that select sounds for musical pieces. Music that makes heavy use of randomness and chance is called aleatoric music, and is associated with contemporary composers active in the 20th century, such as John Cage, Morton Feldman, and Witold Lutos\u0142awski. A commonly known example of chance-based music is the sound of wind chimes jingling in a breeze.\\nThe study of composition has traditionally been dominated by examination of methods and practice of Western classical music, but the definition of composition is broad enough to include the creation of popular music and traditional music songs and instrumental pieces as well as spontaneously improvised works like those of free jazz performers and African percussionists such as Ewe drummers.\\n\\nPerformance\\nPerformance is the physical expression of music, which occurs when a song is sung or piano piece, guitar melody, symphony, drum beat or other musical part is played. In classical music, a work is written in music notation by a composer and then performed once the composer is satisfied with its structure and instrumentation. However, as it gets performed, the interpretation of a song or piece can evolve and change. In classical music, instrumental performers, singers or conductors may gradually make changes to the phrasing or tempo of a piece. In popular and traditional music, the performers have more freedom to make changes to the form of a song or piece. As such, in popular and traditional music styles, even when a band plays a cover song, they can make changes such as adding a guitar solo or inserting an introduction.A performance can either be planned out and rehearsed (practiced)\u2014which is the norm in classical music, jazz big bands, and many popular music styles\u2013or improvised over a chord progression (a sequence of chords), which is the norm in small jazz and blues groups. Rehearsals of orchestras, concert bands and choirs are led by a conductor. Rock, blues and jazz bands are usually led by the bandleader. A rehearsal is a structured repetition of a song or piece by the performers until it can be sung or played correctly and, if it is a song or piece for more than one musician, until the parts are together from a rhythmic and tuning perspective.\\nMany cultures have strong traditions of solo performance (in which one singer or instrumentalist performs), such as in Indian classical music, and in the Western art-music tradition. Other cultures, such as in Bali, include strong traditions of group performance. All cultures include a mixture of both, and performance may range from improvised solo playing to highly planned and organized performances such as the modern classical concert, religious processions, classical music festivals or music competitions. Chamber music, which is music for a small ensemble with only one or a few of each type of instrument, is often seen as more intimate than large symphonic works.\\n\\nImprovisation\\nMusical improvisation is the creation of spontaneous music, often within (or based on) a pre-existing harmonic framework, chord progression, or riffs. Improvisers use the notes of the chord, various scales that are associated with each chord, and chromatic ornaments and passing tones which may be neither chord tones nor from the typical scales associated with a chord. Musical improvisation can be done with or without preparation. Improvisation is a major part of some types of music, such as blues, jazz, and jazz fusion, in which instrumental performers improvise solos, melody lines, and accompaniment parts..In the Western art music tradition, improvisation was an important skill during the Baroque era and during the Classical era. In the Baroque era, performers improvised ornaments, and basso continuo keyboard players improvised chord voicings based on figured bass notation. As well, the top soloists were expected to be able to improvise pieces such as preludes. In the Classical era, solo performers and singers improvised virtuoso cadenzas during concerts.\\nHowever, in the 20th and early 21st century, as \"common practice\" Western art music performance became institutionalized in symphony orchestras, opera houses, and ballets, improvisation has played a smaller role, as more and more music was notated in scores and parts for musicians to play. At the same time, some 20th and 21st century art music composers have increasingly included improvisation in their creative work. In Indian classical music, improvisation is a core component and an essential criterion of performances.\\n\\nArt and entertainment\\nMusic is composed and performed for many purposes, ranging from aesthetic pleasure, religious or ceremonial purposes, or as an entertainment product for the marketplace. When music was only available through sheet music scores, such as during the Classical and Romantic eras, music lovers would buy the sheet music of their favourite pieces and songs so that they could perform them at home on the piano. With the advent of the phonograph, records of popular songs, rather than sheet music became the dominant way that music lovers would enjoy their favourite songs. With the advent of home tape recorders in the 1980s and digital music in the 1990s, music lovers could make tapes or playlists of favourite songs and take them with them on a portable cassette player or MP3 player. Some music lovers create mix tapes of favourite songs, which serve as a \"self-portrait, a gesture of friendship, prescription for an ideal party... [and] an environment consisting solely of what is most ardently loved\".Amateur musicians can compose or perform music for their own pleasure and derive income elsewhere. Professional musicians are employed by institutions and organisations, including armed forces (in marching bands, concert bands and popular music groups), religious institutions, symphony orchestras, broadcasting or film production companies, and music schools. Professional musicians sometimes work as freelancers or session musicians, seeking contracts and engagements in a variety of settings. There are often many links between amateur and professional musicians. Beginning amateur musicians take lessons with professional musicians. In community settings, advanced amateur musicians perform with professional musicians in a variety of ensembles such as community concert bands and community orchestras.\\nA distinction is often made between music performed for a live audience and music that is performed in a studio so that it can be recorded and distributed through the music retail system or the broadcasting system. However, there are also many cases where a live performance in front of an audience is also recorded and distributed. Live concert recordings are popular in both classical music and in popular music forms such as rock, where illegally taped live concerts are prized by music lovers. In the jam band scene, live, improvised jam sessions are preferred to studio recordings.\\n\\nNotation\\nMusic notation typically means the written expression of music notes and rhythms on paper using symbols. When music is written down, the pitches and rhythm of the music, such as the notes of a melody, are notated. Music notation often provides instructions on how to perform the music. For example, the sheet music for a song may state the song is a \"slow blues\" or a \"fast swing\", which indicates the tempo and the genre. To read notation, a person must have an understanding of music theory, harmony and the performance practice associated with a particular song or piece's genre.\\nWritten notation varies with the style and period of music. Nowadays, notated music is produced as sheet music or, for individuals with computer scorewriter programs, as an image on a computer screen. In ancient times, music notation was put onto stone or clay tablets. To perform music from notation, a singer or instrumentalist requires an understanding of the rhythmic and pitch elements embodied in the symbols and the performance practice that is associated with a piece of music or genre. In genres requiring musical improvisation, the performer often plays from music where only the chord changes and form of the song are written, requiring the performer to have a great understanding of the music's structure, harmony and the styles of a particular genre e.g., jazz or country music.\\nIn Western art music, the most common types of written notation are scores, which include all the music parts of an ensemble piece, and parts, which are the music notation for the individual performers or singers. In popular music, jazz, and blues, the standard musical notation is the lead sheet, which notates the melody, chords, lyrics (if it is a vocal piece), and structure of the music. Fake books are also used in jazz; they may consist of lead sheets or simply chord charts, which permit rhythm section members to improvise an accompaniment part to jazz songs. Scores and parts are also used in popular music and jazz, particularly in large ensembles such as jazz \"big bands.\" In popular music, guitarists and electric bass players often read music notated in tablature (often abbreviated as \"tab\"), which indicates the location of the notes to be played on the instrument using a diagram of the guitar or bass fingerboard. Tablature was used in the Baroque era to notate music for the lute, a stringed, fretted instrument.\\n\\nOral and aural tradition\\nMany types of music, such as traditional blues and folk music were not written down in sheet music; instead, they were originally preserved in the memory of performers, and the songs were handed down orally, from one musician or singer to another, or aurally, in which a performer learns a song \"by ear\". When the composer of a song or piece is no longer known, this music is often classified as \"traditional\" or as a \"folk song\". Different musical traditions have different attitudes towards how and where to make changes to the original source material, from quite strict, to those that demand improvisation or modification to the music. A culture's history and stories may also be passed on by ear through song.\\n\\nElements\\nMusic has many different fundamentals or elements. Depending on the definition of \"element\" being used, these can include pitch, beat or pulse, tempo, rhythm, melody, harmony, texture, style, allocation of voices, timbre or color, dynamics, expression, articulation, form, and structure. The elements of music feature prominently in the music curriculums of Australia, the UK, and the US. All three curriculums identify pitch, dynamics, timbre, and texture as elements, but the other identified elements of music are far from universally agreed upon. Below is a list of the three official versions of the \"elements of music\":\\n\\nAustralia: pitch, timbre, texture, dynamics and expression, rhythm, form and structure.\\nUK: pitch, timbre, texture, dynamics, duration, tempo, structure.\\nUSA: pitch, timbre, texture, dynamics, rhythm, form, harmony, style/articulation.In relation to the UK curriculum, in 2013 the term: \"appropriate musical notations\" was added to their list of elements and the title of the list was changed from the \"elements of music\" to the \"inter-related dimensions of music\". The inter-related dimensions of music are listed as: pitch, duration, dynamics, tempo, timbre, texture, structure, and appropriate musical notations.The phrase \"the elements of music\" is used in a number of different contexts. The two most common contexts can be differentiated by describing them as the \"rudimentary elements of music\" and the \"perceptual elements of music\".\\n\\nPitch\\nPitch is an aspect of a sound that we can hear, reflecting whether one musical sound, note, or tone is \"higher\" or \"lower\" than another musical sound, note, or tone. We can talk about the highness or lowness of pitch in the more general sense, such as the way a listener hears a piercingly high piccolo note or whistling tone as higher in pitch than a deep thump of a bass drum. We also talk about pitch in the precise sense associated with musical melodies, basslines and chords. Precise pitch can only be determined in sounds that have a frequency that is clear and stable enough to distinguish from noise. For example, it is much easier for listeners to discern the pitch of a single note played on a piano than to try to discern the pitch of a crash cymbal that is struck.\\n\\nMelody\\nA melody, also called a \"tune\", is a series of pitches (notes) sounding in succession (one after the other), often in a rising and falling pattern. The notes of a melody are typically created using pitch systems such as scales or modes. Melodies also often contain notes from the chords used in the song. The melodies in simple folk songs and traditional songs may use only the notes of a single scale, the scale associated with the tonic note or key of a given song. For example, a folk song in the key of C (also referred to as C major) may have a melody that uses only the notes of the C major scale (the individual notes C, D, E, F, G, A, B, and C; these are the \"white notes\" on a piano keyboard. On the other hand, Bebop-era jazz from the 1940s and contemporary music from the 20th and 21st centuries may use melodies with many chromatic notes (i.e., notes in addition to the notes of the major scale; on a piano, a chromatic scale would include all the notes on the keyboard, including the \"white notes\" and \"black notes\" and unusual scales, such as the whole tone scale (a whole tone scale in the key of C would contain the notes C, D, E, F\u266f, G\u266f and A\u266f). A low musical line played by bass instruments, such as double bass, electric bass, or tuba, is called a bassline.\\n\\nHarmony\\nHarmony refers to the \"vertical\" sounds of pitches in music, which means pitches that are played or sung together at the same time to create a chord. Usually, this means the notes are played at the same time, although harmony may also be implied by a melody that outlines a harmonic structure (i.e., by using melody notes that are played one after the other, outlining the notes of a chord). In music written using the system of major-minor tonality (\"keys\"), which includes most classical music written from 1600 to 1900 and most Western pop, rock, and traditional music, the key of a piece determines the \"home note\" or tonic to which the piece generally resolves, and the character (e.g. major or minor) of the scale in use. Simple classical pieces and many pop and traditional music songs are written so that all the music is in a single key. More complex Classical, pop, and traditional music songs and pieces may have two keys (and in some cases three or more keys). Classical music from the Romantic era (written from about 1820\u20131900) often contains multiple keys, as does jazz, especially Bebop jazz from the 1940s, in which the key or \"home note\" of a song may change every four bars or even every two bars.\\n\\nRhythm\\nRhythm is the arrangement of sounds and silences in time. Meter animates time in regular pulse groupings, called measures or bars, which in Western classical, popular, and traditional music often group notes in sets of two (e.g., 2/4 time), three (e.g., 3/4 time, also known as Waltz time, or 3/8 time), or four (e.g., 4/4 time). Meters are made easier to hear because songs and pieces often (but not always) place an emphasis on the first beat of each grouping. Notable exceptions exist, such as the backbeat used in much Western pop and rock, in which a song that uses a measure that consists of four beats (called 4/4 time or common time) will have accents on beats two and four, which are typically performed by the drummer on the snare drum, a loud and distinctive-sounding percussion instrument. In pop and rock, the rhythm parts of a song are played by the rhythm section, which includes chord-playing instruments (e.g., electric guitar, acoustic guitar, piano, or other keyboard instruments), a bass instrument (typically electric bass or for some styles such as jazz and bluegrass, double bass) and a drum kit player.\\n\\nTexture\\nMusical texture is the overall sound of a piece of music or song. The texture of a piece or song is determined by how the melodic, rhythmic, and harmonic materials are combined in a composition, thus determining the overall nature of the sound in a piece. Texture is often described in regard to the density, or thickness, and range, or width, between lowest and highest pitches, in relative terms as well as more specifically distinguished according to the number of voices, or parts, and the relationship between these voices (see common types below). For example, a thick texture contains many 'layers' of instruments. One layer can be a string section or another brass. The thickness is affected by the amount and the richness of the instruments. Texture is commonly described according to the number of and relationship between parts or lines of music:\\n\\nmonophony: a single melody (or \"tune\") with neither instrumental accompaniment nor a harmony part. A mother singing a lullaby to her baby would be an example.\\nheterophony: two or more instruments or singers playing/singing the same melody, but with each performer slightly varying the rhythm or speed of the melody or adding different ornaments to the melody. Two bluegrass fiddlers playing the same traditional fiddle tune together will typically each vary the melody by some degree and each add different ornaments.\\npolyphony: multiple independent melody lines that interweave together, which are sung or played at the same time. Choral music written in the Renaissance music era was typically written in this style. A round, which is a song such as \"Row, Row, Row Your Boat\", which different groups of singers all start to sing at a different time, is an example of polyphony.\\nhomophony: a clear melody supported by chordal accompaniment. Most Western popular music songs from the 19th century onward are written in this texture.Music that contains a large number of independent parts (e.g., a double concerto accompanied by 100 orchestral instruments with many interweaving melodic lines) is generally said to have a \"thicker\" or \"denser\" texture than a work with few parts (e.g., a solo flute melody accompanied by a single cello).\\n\\nTimbre\\nTimbre, sometimes called \"color\" or \"tone color\" is the quality or sound of a voice or instrument. Timbre is what makes a particular musical sound different from another, even when they have the same pitch and loudness. For example, a 440 Hz A note sounds different when it is played on oboe, piano, violin, or electric guitar. Even if different players of the same instrument play the same note, their notes might sound different due to differences in instrumental technique (e.g., different embouchures), different types of accessories (e.g., mouthpieces for brass players, reeds for oboe and bassoon players) or strings made out of different materials for string players (e.g., gut strings versus steel strings). Even two instrumentalists playing the same note on the same instrument (one after the other) may sound different due to different ways of playing the instrument (e.g., two string players might hold the bow differently).\\nThe physical characteristics of sound that determine the perception of timbre include the spectrum, envelope, and overtones of a note or musical sound. For electric instruments developed in the 20th century, such as electric guitar, electric bass and electric piano, the performer can also change the tone by adjusting equalizer controls, tone controls on the instrument, and by using electronic effects units such as distortion pedals. The tone of the electric Hammond organ is controlled by adjusting drawbars.\\n\\nExpression\\nExpressive qualities are those elements in music that create change in music without changing the main pitches or substantially changing the rhythms of the melody and its accompaniment. Performers, including singers and instrumentalists, can add musical expression to a song or piece by adding phrasing, by adding effects such as vibrato (with voice and some instruments, such as guitar, violin, brass instruments, and woodwinds), dynamics (the loudness or softness of piece or a section of it), tempo fluctuations (e.g., ritardando or accelerando, which are, respectively slowing down and speeding up the tempo), by adding pauses or fermatas on a cadence, and by changing the articulation of the notes (e.g., making notes more pronounced or accented, by making notes more legato, which means smoothly connected, or by making notes shorter).\\nExpression is achieved through the manipulation of pitch (such as inflection, vibrato, slides etc.), volume (dynamics, accent, tremolo etc.), duration (tempo fluctuations, rhythmic changes, changing note duration such as with legato and staccato, etc.), timbre (e.g. changing vocal timbre from a light to a resonant voice) and sometimes even texture (e.g. doubling the bass note for a richer effect in a piano piece). Expression therefore can be seen as a manipulation of all elements to convey \"an indication of mood, spirit, character etc.\" and as such cannot be included as a unique perceptual element of music, although it can be considered an important rudimentary element of music.\\n\\nForm\\nIn music, form describes the overall structure or plan of a song or piece of music, and it describes the layout of a composition as divided into sections. In the early 20th century, Tin Pan Alley songs and Broadway musical songs were often in AABA thirty-two-bar form, in which the A sections repeated the same eight bar melody (with variation) and the B section provided a contrasting melody or harmony for eight bars. From the 1960s onward, Western pop and rock songs are often in verse-chorus form, which comprises a sequence of verse and chorus (\"refrain\") sections, with new lyrics for most verses and repeating lyrics for the choruses. Popular music often makes use of strophic form, sometimes in conjunction with the twelve bar blues.In the tenth edition of The Oxford Companion to Music, Percy Scholes defines musical form as \"a series of strategies designed to find a successful mean between the opposite extremes of unrelieved repetition and unrelieved alteration.\" Examples of common forms of Western music include the fugue, the invention, sonata-allegro, canon, strophic, theme and variations, and rondo.\\nScholes states that European classical music had only six stand-alone forms: simple binary, simple ternary, compound binary, rondo, air with variations, and fugue (although musicologist Alfred Mann emphasized that the fugue is primarily a method of composition that has sometimes taken on certain structural conventions.)\\nWhere a piece cannot readily be broken into sectional units (though it might borrow some form from a poem, story or programme), it is said to be through-composed. Such is often the case with a fantasia, prelude, rhapsody, etude (or study), symphonic poem, Bagatelle, impromptu or similar compostion. Professor Charles Keil classified forms and formal detail as \"sectional, developmental, or variational.\"\\n\\nPhilosophy\\nThe philosophy of music is the study of fundamental questions regarding music and has connections with questions in metaphysics and aesthetics. Questions include:\\n\\nWhat is the definition of music? (What are the necessary and sufficient conditions for classifying something as music?)\\nWhat is the relationship between music and mind?\\nWhat does music history reveal to us about the world?\\nWhat is the connection between music and emotions?\\nWhat is meaning in relation to music?In ancient times, such as with the Ancient Greeks, the aesthetics of music explored the mathematical and cosmological dimensions of rhythmic and harmonic organization. In the 18th century, focus shifted to the experience of hearing music, and thus to questions about its beauty and human enjoyment (plaisir and jouissance) of music. The origin of this philosophic shift is sometimes attributed to Alexander Gottlieb Baumgarten in the 18th century, followed by Immanuel Kant. Through their writing, the ancient term 'aesthetics', meaning sensory perception, received its present-day connotation. In the 2000s, philosophers have tended to emphasize issues besides beauty and enjoyment. For example, music's capacity to express emotion has been foregrounded. In the 20th century, important contributions were made by Peter Kivy, Jerrold Levinson, Roger Scruton, and Stephen Davies. However, many musicians, music critics, and other non-philosophers have contributed to the aesthetics of music. In the 19th century, a significant debate arose between Eduard Hanslick, a music critic and musicologist, and composer Richard Wagner regarding whether music can express meaning. Harry Partch and some other musicologists, such as Kyle Gann, have studied and tried to popularize microtonal music and the usage of alternate musical scales. Modern composers like La Monte Young, Rhys Chatham and Glenn Branca paid much attention to a scale called just intonation.It is often thought that music has the ability to affect our emotions, intellect, and psychology; it can assuage our loneliness or incite our passions. The philosopher Plato suggests in The Republic that music has a direct effect on the soul. Therefore, he proposes that in the ideal regime music would be closely regulated by the state (Book VII). In Ancient China, the philosopher Confucius believed that music and rituals or rites are interconnected and harmonious with nature; he stated that music was the harmonization of heaven and earth, while the order was brought by the rites order, making them extremely crucial functions in society.\\n\\nPsychology\\nModern music psychology aims to explain and understand musical behavior and experience. Research in this field and its subfields are primarily empirical; their knowledge tends to advance on the basis of interpretations of data collected by systematic observation of and interaction with human participants. In addition to its focus on fundamental perceptions and cognitive processes, music psychology is a field of research with practical relevance for many areas, including music performance, composition, education, criticism, and therapy, as well as investigations of human aptitude, skill, intelligence, creativity, and social behavior.\\n\\nNeuroscience\\nCognitive neuroscience of music is the scientific study of brain-based mechanisms involved in the cognitive processes underlying music. These behaviours include music listening, performing, composing, reading, writing, and ancillary activities. It also is increasingly concerned with the brain basis for musical aesthetics and musical emotion. The field is distinguished by its reliance on direct observations of the brain, using such techniques as functional magnetic resonance imaging (fMRI), transcranial magnetic stimulation (TMS), magnetoencephalography (MEG), electroencephalography (EEG), and positron emission tomography (PET).\\n\\nCognitive musicology\\nCognitive musicology is a branch of cognitive science concerned with computationally modeling musical knowledge with the goal of understanding both music and cognition. The use of computer models provides an exacting, interactive medium in which to formulate and test theories and has roots in artificial intelligence and cognitive science.This interdisciplinary field investigates topics such as the parallels between language and music in the brain. Biologically inspired models of computation are often included in research, such as neural networks and evolutionary programs. This field seeks to model how musical knowledge is represented, stored, perceived, performed, and generated. By using a well-structured computer environment, the systematic structures of these cognitive phenomena can be investigated.\\n\\nPsychoacoustics\\nPsychoacoustics is the scientific study of sound perception. More specifically, it is the branch of science studying the psychological and physiological responses associated with sound (including speech and music). It can be further categorized as a branch of psychophysics.\\n\\nEvolutionary musicology\\nEvolutionary musicology concerns the \"origins of music, the question of animal song, selection pressures underlying music evolution\", and \"music evolution and human evolution\". It seeks to understand music perception and activity in the context of evolutionary theory. Charles Darwin speculated that music may have held an adaptive advantage and functioned as a protolanguage, a view which has spawned several competing theories of music evolution. An alternate view sees music as a by-product of linguistic evolution; a type of \"auditory cheesecake\" that pleases the senses without providing any adaptive function. This view has been directly countered by numerous music researchers.\\n\\nCultural effects\\nAn individual's culture or ethnicity plays a role in their music cognition, including their preferences, emotional reaction, and musical memory. Musical preferences are biased toward culturally familiar musical traditions beginning in infancy, and adults' classification of the emotion of a musical piece depends on both culturally specific and universal structural features. Additionally, individuals' musical memory abilities are greater for culturally familiar music than for culturally unfamiliar music.\\n\\nPerceptual\\nSince the emergence of the study of psychoacoustics in the 1930s, most lists of elements of music have related more to how we hear music than how we learn to play it or study it. C.E. Seashore, in his book Psychology of Music, identified four \"psychological attributes of sound\". These were: \"pitch, loudness, time, and timbre\" (p. 3). He did not call them the \"elements of music\" but referred to them as \"elemental components\" (p. 2). Nonetheless, these elemental components link precisely with four of the most common musical elements: \"Pitch\" and \"timbre\" match exactly, \"loudness\" links with dynamics, and \"time\" links with the time-based elements of rhythm, duration, and tempo. This usage of the phrase \"the elements of music\" links more closely with Webster's New 20th Century Dictionary definition of an element as: \"a substance which cannot be divided into a simpler form by known methods\" and educational institutions' lists of elements generally align with this definition as well.\\nAlthough writers of lists of \"rudimentary elements of music\" can vary their lists depending on their personal (or institutional) priorities, the perceptual elements of music should consist of an established (or proven) list of discrete elements which can be independently manipulated to achieve an intended musical effect. It seems at this stage that there is still research to be done in this area.\\nA slightly different way of approaching the identification of the elements of music, is to identify the \"elements of sound\" as: pitch, duration, loudness, timbre, sonic texture and spatial location, and then to define the \"elements of music\" as: sound, structure, and artistic intent.\\n\\nSociological aspects\\nEthnographic studies demonstrate that music is a participatory, community-based activity. Music is experienced by individuals in a range of social settings from being alone, to attending a large concert, forming a music community, which cannot be understood as a function of individual will or accident; it includes both commercial and non-commercial participants with a shared set of common values. Musical performances take different forms in different cultures and socioeconomic milieus.\\nIn Europe and North America, there was a divide between what types of music were viewed as \"high culture\" and \"low culture.\" \"High culture\" included Baroque, Classical, Romantic, and modern-era symphonies, concertos, and solo works, and are typically heard in formal concerts in concert halls and churches, with the audience sitting quietly. Other types of music\u2014including jazz, blues, soul, and country\u2014are often performed in bars, nightclubs, and theatres, where the audience may drink, dance and cheer. Until the 20th century, the division between \"high\" and \"low\" musical forms was accepted as a valid distinction that separated out \"art music\", from popular music heard in bars and dance halls. Musicologists, such as David Brackett, note a \"redrawing of high-low cultural-aesthetic boundaries\" in the 20th century. And, \"when industry and public discourses link categories of music with categories of people, they tend to conflate stereotypes with actual listening communities.\" Stereotypes can be based on socioeconomic standing, or social class, of the performers or audience of the different types of music.\\nWhen composers introduce styles of music that break with convention, there can be strong resistance from academics and others. Late-period Beethoven string quartets, Stravinsky ballet scores, serialism, bebop, hip hop, punk rock, and electronica were controversial and criticised, when they were first introduced. Such themes are examined in the sociology of music, sometimes called sociomusicology, which is pursued in departments of sociology, media studies, or music, and is closely related to ethnomusicology.\\n\\nRole of women\\nWomen have played a major role in music throughout history, as composers, songwriters, instrumental performers, singers, conductors, music scholars, music educators, music critics/music journalists and other musical professions. In the 2010s, while women comprise a significant proportion of popular music and classical music singers, and a significant proportion of songwriters (many of them being singer-songwriters), there are few women record producers, rock critics and rock instrumentalists. Although there have been a huge number of women composers in classical music, from the medieval period to the present day, women composers are significantly underrepresented in the commonly performed classical music repertoire, music history textbooks and music encyclopedias; for example, in the Concise Oxford History of Music, Clara Schumann is one of the few female composers who is mentioned.\\nWomen comprise a significant proportion of instrumental soloists in classical music and the percentage of women in orchestras is increasing. A 2015 article on concerto soloists in major Canadian orchestras, however, indicated that 84% of the soloists with the Orchestre Symphonique de Montreal were men. In 2012, women still made up just 6% of the top-ranked Vienna Philharmonic orchestra. Women are less common as instrumental players in popular music genres such as rock and heavy metal, although there have been a number of notable female instrumentalists and all-female bands. Women are particularly underrepresented in extreme metal genres. In the 1960s pop-music scene, \"[l]ike most aspects of the...music business, [in the 1960s,] songwriting was a male-dominated field. Though there were plenty of female singers on the radio, women ...were primarily seen as consumers:... Singing was sometimes an acceptable pastime for a girl, but playing an instrument, writing songs, or producing records simply wasn't done.\" Young women \"...were not socialized to see themselves as people who create [music].\"Women are also underrepresented in orchestral conducting, music criticism/music journalism, music producing, and sound engineering. While women were discouraged from composing in the 19th century, and there are few women musicologists, women became involved in music education \"...to such a degree that women dominated [this field] during the later half of the 19th century and well into the 20th century.\"According to Jessica Duchen, a music writer for London's The Independent, women musicians in classical music are \"...too often judged for their appearances, rather than their talent\" and they face pressure \"...to look sexy onstage and in photos.\" Duchen states that while \"[t]here are women musicians who refuse to play on their looks,...the ones who do tend to be more materially successful.\" According to the UK's Radio 3 editor, Edwina Wolstencroft, the music industry has long been open to having women in performance or entertainment roles, but women are much less likely to have positions of authority, such as being the conductor of an orchestra. In popular music, while there are many women singers recording songs, there are very few women behind the audio console acting as music producers, the individuals who direct and manage the recording process. One of the most recorded artists is Asha Bhosle, an Indian singer best known as a playback singer in Hindi cinema.\\n\\nMedia and technology\\nSince the 20th century, live music can be broadcast over the radio, television or the Internet, or recorded and listened to on a CD player or MP3 player.\\nIn the early 20th century (in the late 1920s), as talking pictures emerged in the early 20th century, with their prerecorded musical tracks, an increasing number of moviehouse orchestra musicians found themselves out of work. During the 1920s, live musical performances by orchestras, pianists, and theater organists were common at first-run theaters. With the coming of the talking motion pictures, those featured performances were largely eliminated. The American Federation of Musicians (AFM) took out newspaper advertisements protesting the replacement of live musicians with mechanical playing devices. One 1929 ad that appeared in the Pittsburgh Press features an image of a can labeled \"Canned Music / Big Noise Brand / Guaranteed to Produce No Intellectual or Emotional Reaction Whatever\"Sometimes, live performances incorporate prerecorded sounds. For example, a disc jockey uses disc records for scratching, and some 20th-century works have a solo for an instrument or voice that is performed along with music that is prerecorded onto a tape. Some pop bands use recorded backing tracks. Computers and many keyboards can be programmed to produce and play Musical Instrument Digital Interface (MIDI) music. Audiences can also become performers by participating in karaoke, an activity of Japanese origin centered on a device that plays voice-eliminated versions of well-known songs. Most karaoke machines also have video screens that show lyrics to songs being performed; performers can follow the lyrics as they sing over the instrumental tracks.\\n\\nThe advent of the Internet and widespread high-speed broadband access has transformed the experience of music, partly through the increased ease of access to recordings of music via streaming video and vastly increased choice of music for consumers. Another effect of the Internet arose with online communities and social media websites like YouTube and Facebook, a social networking service. These sites make it easier for aspiring singers and amateur bands to distribute videos of their songs, connect with other musicians, and gain audience interest. Professional musicians also use YouTube as a free publisher of promotional material. YouTube users, for example, no longer only download and listen to MP3s, but also actively create their own. According to Don Tapscott and Anthony D. Williams, in their book Wikinomics, there has been a shift from a traditional consumer role to what they call a \"prosumer\" role, a consumer who both creates content and consumes. Manifestations of this in music include the production of mashes, remixes, and music videos by fans.\\n\\nEducation\\nNon-institutional\\nThe incorporation of music into general education from preschool to post secondary education, is common in North America and Europe. Involvement in playing and singing music is thought to teach basic skills such as concentration, counting, listening, and cooperation while also promoting understanding of language, improving the ability to recall information, and creating an environment more conducive to learning in other areas. In elementary schools, children often learn to play instruments such as the recorder, sing in small choirs, and learn about the history of Western art music and traditional music. Some elementary school children also learn about popular music styles. In religious schools, children sing hymns and other religious music. In secondary schools (and less commonly in elementary schools), students may have the opportunity to perform in some types of musical ensembles, such as choirs (a group of singers), marching bands, concert bands, jazz bands, or orchestras. In some school systems, music lessons on how to play instruments may be provided. Some students also take private music lessons after school with a singing teacher or instrument teacher. Amateur musicians typically learn basic musical rudiments (e.g., learning about musical notation for musical scales and rhythms) and beginner- to intermediate-level singing or instrument-playing techniques.\\nAt the university level, students in most arts and humanities programs can receive credit for taking a few music courses, which typically take the form of an overview course on the history of music, or a music appreciation course that focuses on listening to music and learning about different musical styles. In addition, most North American and European universities have some types of musical ensembles that students in arts and humanities are able to participate in, such as choirs, marching bands, concert bands, or orchestras. The study of Western art music is increasingly common outside of North America and Europe, such as the Indonesian Institute of the Arts in Yogyakarta, Indonesia, or the classical music programs that are available in Asian countries such as South Korea, Japan, and China. At the same time, Western universities and colleges are widening their curriculum to include music of non-Western cultures, such as the music of Africa or Bali (e.g. Gamelan music).\\n\\nInstitutional\\nPeople aiming to become professional musicians, singers, composers, songwriters, music teachers and practitioners of other music-related professions such as music history professors, sound engineers, and so on study in specialized post-secondary programs offered by colleges, universities and music conservatories. Some institutions that train individuals for careers in music offer training in a wide range of professions, as is the case with many of the top U.S. universities, which offer degrees in music performance (including singing and playing instruments), music history, music theory, music composition, music education (for individuals aiming to become elementary or high school music teachers) and, in some cases, conducting. On the other hand, some small colleges may only offer training in a single profession (e.g., sound recording).\\nWhile most university and conservatory music programs focus on training students in classical music, there are universities and colleges that train musicians for careers as jazz or popular music musicians and composers, with notable U.S. examples including the Manhattan School of Music and the Berklee College of Music. Two schools in Canada which offer professional jazz training are McGill University and Humber College. Individuals aiming at careers in some types of music, such as heavy metal music, country music or blues are unlikely to become professionals by completing degrees or diplomas. Instead, they typically learn about their style of music by singing or playing in bands (often beginning in amateur bands, cover bands and tribute bands), studying recordings on DVD and the Internet, and working with already-established professionals in their style of music, either through informal mentoring or regular music lessons. Since the 2000s, the increasing popularity and availability of Internet forums and YouTube \"how-to\" videos have enabled singers and musicians from metal, blues and similar genres to improve their skills. Many pop, rock and country singers train informally with vocal coaches and voice teachers.\\n\\nAcademic study\\nMusicology\\nMusicology, the academic study of music, is studied in universities and music conservatories. The earliest definitions from the 19th century defined three sub-disciplines of musicology: systematic musicology, historical musicology, and comparative musicology or ethnomusicology. In 2010-era scholarship, one is more likely to encounter a division into music theory, music history, and ethnomusicology. Research in musicology has often been enriched by cross-disciplinary work, for example in the field of psychoacoustics. The study of music of non-Western cultures, and cultural study of music, is called ethnomusicology. Students can pursue study of musicology, ethnomusicology, music history, and music theory through different types of degrees, including bachelor's, master's and PhD.\\n\\nMusic theory\\nMusic theory is the study of music, generally in a highly technical manner outside of other disciplines. More broadly it refers to any study of music, usually related in some form with compositional concerns, and may include mathematics, physics, and anthropology. What is most commonly taught in beginning music theory classes are guidelines to write in the style of the common practice period, or tonal music. Theory, even of music of the common practice period, may take other forms. Musical set theory is the application of mathematical set theory to music, first applied to atonal music. Speculative music theory, contrasted with analytic music theory, is devoted to the analysis and synthesis of music materials, for example tuning systems, generally as preparation for composition.\\n\\nZoomusicology\\nZoomusicology is the study of the music of non-human animals, or the musical aspects of sounds produced by non-human animals. As George Herzog (1941) asked, \"do animals have music?\" Fran\u00e7ois-Bernard M\u00e2che's Musique, mythe, nature, ou les Dauphins d'Arion (1983), a study of \"ornitho-musicology\" using a technique of Nicolas Ruwet's Language, musique, po\u00e9sie (1972) paradigmatic segmentation analysis, shows that bird songs are organised according to a repetition-transformation principle. Jean-Jacques Nattiez (1990), argues that \"in the last analysis, it is a human being who decides what is and is not musical, even when the sound is not of human origin. If we acknowledge that sound is not organised and conceptualised (that is, made to form music) merely by its producer, but by the mind that perceives it, then music is uniquely human.\"\\n\\nEthnomusicology\\nIn the West, much of the history of music that is taught deals with the Western civilization's art music, known as classical music. The history of music in non-Western cultures (\"world music\" or the field of \"ethnomusicology\") is also taught in Western universities. This includes the documented classical traditions of Asian countries outside the influence of Western Europe, as well as the folk or indigenous music of various other cultures. Popular or folk styles of music in non-Western countries varied from culture to culture, and period to period. Different cultures emphasised different instruments, techniques, singing styles and uses for music. Music has been used for entertainment, ceremonies, rituals, religious purposes and for practical and artistic communication. Non-Western music has also been used for propaganda purposes, as was the case with Chinese opera during the Cultural Revolution.\\nThere is a host of music classifications for non-Western music, many of which are caught up in the argument over the definition of music. Among the largest of these is the division between classical music (or \"art\" music), and popular music (or commercial music \u2013 including non-Western styles of rock, country, and pop music-related styles). Some genres do not fit neatly into one of these \"big two\" classifications, (such as folk music, world music, or jazz-related music).\\nAs world cultures have come into greater global contact, their indigenous musical styles have often merged with other styles, which produces new styles. For example, the United States bluegrass style contains elements from Anglo-Irish, Scottish, Irish, German and African instrumental and vocal traditions, which were able to fuse in the United States' multi-ethnic \"melting pot\" society. Some types of world music contain a mixture of non-Western indigenous styles with Western pop music elements. Genres of music are determined as much by tradition and presentation as by the actual music. Some works, like George Gershwin's Rhapsody in Blue, are claimed by both jazz and classical music, while Gershwin's Porgy and Bess and Leonard Bernstein's West Side Story are claimed by both opera and the Broadway musical tradition. Many music festivals for non-Western music, include bands and singers from a particular musical genre, such as world music.Indian music, for example, is one of the oldest and longest living types of music, and is still widely heard and performed in South Asia, as well as internationally (especially since the 1960s). Indian music has mainly three forms of classical music, Hindustani, Carnatic, and Dhrupad styles. It has also a large repertoire of styles, which involve only percussion music such as the talavadya performances famous in South India.\\n\\nTherapy\\nMusic therapy is an interpersonal process in which a trained therapist uses music and all of its facets\u2014physical, emotional, mental, social, aesthetic, and spiritual\u2014to help clients to improve or maintain their health. In some instances, the client's needs are addressed directly through music; in others they are addressed through the relationships that develop between the client and therapist. Music therapy is used with individuals of all ages and with a variety of conditions, including: psychiatric disorders, medical problems, physical disabilities, sensory impairments, developmental disabilities, substance abuse issues, communication disorders, interpersonal problems, and aging. It is also used to improve learning, build self-esteem, reduce stress, support physical exercise, and facilitate a host of other health-related activities. Music therapists may encourage clients to sing, play instruments, create songs, or do other musical activities.\\nIn the 10th century, the philosopher Al-Farabi described how vocal music can stimulate the feelings and souls of listeners. Music has long been used to help people deal with their emotions. In the 17th century, the scholar Robert Burton's The Anatomy of Melancholy argued that music and dance were critical in treating mental illness, especially melancholia. He noted that music has an \"excellent power ...to expel many other diseases\" and he called it \"a sovereign remedy against despair and melancholy.\" He pointed out that in Antiquity, Canus, a Rhodian fiddler, used music to \"make a melancholy man merry, ...a lover more enamoured, a religious man more devout.\" In the Ottoman Empire, mental illnesses were treated with music. In November 2006, Michael J. Crawford and his colleagues also found that music therapy helped schizophrenic patients.\\n\\nSee also\\nGlossary of music terminology\\nLists of musicians\\nList of musicology topics\\nMusic and emotion\\nMusic archaeology\\nMusic history\\nMusic-specific disorders\\n\\nReferences\\nNotes\\nCitations\\nSources\\nFurther reading\\nExternal links\\n\\nGrove Music Online \u2014 online version of The New Grove Dictionary of Music and Musicians.\\nAll ten volumes of the Garland Encyclopedia of World Music (subscription required)\\nDolmetsch free online music dictionary, complete, with references to a list of specialised music dictionaries (by continent, by instrument, by genre, etc.)"}
{"article_name": "Ancient_Egypt", "link": "https://en.wikipedia.org/wiki/Ancient_Egypt", "text_content": "Ancient Egypt was a civilization of ancient Northeast Africa, concentrated along the lower reaches of the Nile River, situated in the place that is now the country Egypt. Ancient Egyptian civilization followed prehistoric Egypt and coalesced around 3100 BC (according to conventional Egyptian chronology) with the political unification of Upper and Lower Egypt under Menes (often identified with Narmer). The history of ancient Egypt occurred as a series of stable kingdoms, separated by periods of relative instability known as Intermediate Periods: the Old Kingdom of the Early Bronze Age, the Middle Kingdom of the Middle Bronze Age and the New Kingdom of the Late Bronze Age.\\nEgypt reached the pinnacle of its power during the New Kingdom, ruling much of Nubia and a sizable portion of the Levant, after which it entered a period of slow decline. During the course of its history, Egypt was invaded or conquered by a number of foreign powers, including the Hyksos, the Nubians, the Assyrians, the Achaemenid Persians, and the Macedonians under Alexander the Great. The Greek Ptolemaic Kingdom, formed in the aftermath of Alexander's death, ruled Egypt until 30 BC, when, under Cleopatra, it fell to the Roman Empire and became a Roman province. Egypt remained under Roman control until the 640s AD, when it was conquered by the Rashidun Caliphate.\\nThe success of ancient Egyptian civilization came partly from its ability to adapt to the conditions of the Nile River valley for agriculture. The predictable flooding and controlled irrigation of the fertile valley produced surplus crops, which supported a more dense population, and social development and culture. With resources to spare, the administration sponsored mineral exploitation of the valley and surrounding desert regions, the early development of an independent writing system, the organization of collective construction and agricultural projects, trade with surrounding regions, and a military intended to assert Egyptian dominance. Motivating and organizing these activities was a bureaucracy of elite scribes, religious leaders, and administrators under the control of a pharaoh, who ensured the cooperation and unity of the Egyptian people in the context of an elaborate system of religious beliefs.The many achievements of the ancient Egyptians include the quarrying, surveying, and construction techniques that supported the building of monumental pyramids, temples, and obelisks; a system of mathematics, a practical and effective system of medicine, irrigation systems, and agricultural production techniques, the first known planked boats, Egyptian faience and glass technology, new forms of literature, and the earliest known peace treaty, made with the Hittites. Ancient Egypt has left a lasting legacy. Its art and architecture were widely copied, and its antiquities were carried off to far corners of the world. Its monumental ruins have inspired the imaginations of travelers and writers for millennia. A newfound respect for antiquities and excavations in the early modern period by Europeans and Egyptians has led to the scientific investigation of Egyptian civilization and a greater appreciation of its cultural legacy.\\n\\nHistory\\nThe Nile has been the lifeline of its region for much of human history. The fertile floodplain of the Nile gave humans the opportunity to develop a settled agricultural economy and a more sophisticated, centralized society that became a cornerstone in the history of human civilization. Nomadic modern human hunter-gatherers began living in the Nile valley through the end of the Middle Pleistocene some 120,000 years ago. By the late Paleolithic period, the arid climate of Northern Africa had become increasingly hot and dry, forcing the populations of the area to concentrate along the river region.\\n\\nPredynastic period\\nIn Predynastic and Early Dynastic times, the Egyptian climate was much less arid than it is today. Large regions of Egypt were covered in treed savanna and traversed by herds of grazing ungulates. Foliage and fauna were far more prolific in all environs, and the Nile region supported large populations of waterfowl. Hunting would have been common for Egyptians, and this is also the period when many animals were first domesticated.By about 5500 BC, small tribes living in the Nile valley had developed into a series of cultures demonstrating firm control of agriculture and animal husbandry, and identifiable by their pottery and personal items, such as combs, bracelets, and beads. The largest of these early cultures in upper (Southern) Egypt was the Badarian culture, which probably originated in the Western Desert; it was known for its high-quality ceramics, stone tools, and its use of copper.The Badari was followed by the Naqada culture: the Naqada I (Amratian), the Naqada II (Gerzeh), and Naqada III (Semainean). These brought a number of technological improvements. As early as the Naqada I Period, predynastic Egyptians imported obsidian from Ethiopia, used to shape blades and other objects from flakes. Mutual trade with the Levant was established during Naqada II (c.\u20093600-3350 BC); this period was also the beginning of trade with Mesopotamia, which continued into the early dynastic period and beyond. Over a period of about 1,000 years, the Naqada culture developed from a few small farming communities into a powerful civilization whose leaders were in complete control of the people and resources of the Nile valley. Establishing a power center at Nekhen (in Greek, Hierakonpolis), and later at Abydos, Naqada III leaders expanded their control of Egypt northwards along the Nile. They also traded with Nubia to the south, the oases of the western desert to the west, and the cultures of the eastern Mediterranean and Near East to the east.The Naqada culture manufactured a diverse selection of material goods, reflective of the increasing power and wealth of the elite, as well as societal personal-use items, which included combs, small statuary, painted pottery, high quality decorative stone vases, cosmetic palettes, and jewelry made of gold, lapis, and ivory. They also developed a ceramic glaze known as faience, which was used well into the Roman Period to decorate cups, amulets, and figurines. During the last predynastic phase, the Naqada culture began using written symbols that eventually were developed into a full system of hieroglyphs for writing the ancient Egyptian language.\\n\\nEarly Dynastic Period (c. 3150\u20132686 BC)\\nThe Early Dynastic Period was approximately contemporary to the early Sumerian-Akkadian civilization of Mesopotamia and of ancient Elam. The third-century BC Egyptian priest Manetho grouped the long line of kings from Menes to his own time into 30 dynasties, a system still used today. He began his official history with the king named \"Meni\" (or Menes in Greek), who was believed to have united the two kingdoms of Upper and Lower Egypt.\\nThe transition to a unified state happened more gradually than ancient Egyptian writers represented, and there is no contemporary record of Menes. Some scholars now believe, however, that the mythical Menes may have been the king Narmer, who is depicted wearing royal regalia on the ceremonial Narmer Palette, in a symbolic act of unification. In the Early Dynastic Period, which began about 3000 BC, the first of the Dynastic kings solidified control over lower Egypt by establishing a capital at Memphis, from which he could control the labor force and agriculture of the fertile delta region, as well as the lucrative and critical trade routes to the Levant. The increasing power and wealth of the kings during the early dynastic period was reflected in their elaborate mastaba tombs and mortuary cult structures at Abydos, which were used to celebrate the deified king after his death. The strong institution of kingship developed by the kings served to legitimize state control over the land, labor, and resources that were essential to the survival and growth of ancient Egyptian civilization.\\n\\nOld Kingdom (2686\u20132181 BC)\\nMajor advances in architecture, art, and technology were made during the Old Kingdom, fueled by the increased agricultural productivity and resulting population, made possible by a well-developed central administration. Some of ancient Egypt's crowning achievements, the Giza pyramids and Great Sphinx, were constructed during the Old Kingdom. Under the direction of the vizier, state officials collected taxes, coordinated irrigation projects to improve crop yield, drafted peasants to work on construction projects, and established a justice system to maintain peace and order.\\nWith the rising importance of central administration in Egypt, a new class of educated scribes and officials arose who were granted estates by the king in payment for their services. Kings also made land grants to their mortuary cults and local temples, to ensure that these institutions had the resources to worship the king after his death. Scholars believe that five centuries of these practices slowly eroded the economic vitality of Egypt, and that the economy could no longer afford to support a large centralized administration. As the power of the kings diminished, regional governors called nomarchs began to challenge the supremacy of the office of king. This, coupled with severe droughts between 2200 and 2150 BC, is believed to have caused the country to enter the 140-year period of famine and strife known as the First Intermediate Period.\\n\\nFirst Intermediate Period (2181\u20132055 BC)\\nAfter Egypt's central government collapsed at the end of the Old Kingdom, the administration could no longer support or stabilize the country's economy. Regional governors could not rely on the king for help in times of crisis, and the ensuing food shortages and political disputes escalated into famines and small-scale civil wars. Yet despite difficult problems, local leaders, owing no tribute to the king, used their new-found independence to establish a thriving culture in the provinces. Once in control of their own resources, the provinces became economically richer\u2014which was demonstrated by larger and better burials among all social classes. In bursts of creativity, provincial artisans adopted and adapted cultural motifs formerly restricted to the royalty of the Old Kingdom, and scribes developed literary styles that expressed the optimism and originality of the period.Free from their loyalties to the king, local rulers began competing with each other for territorial control and political power. By 2160 BC, rulers in Herakleopolis controlled Lower Egypt in the north, while a rival clan based in Thebes, the Intef family, took control of Upper Egypt in the south. As the Intefs grew in power and expanded their control northward, a clash between the two rival dynasties became inevitable. Around 2055 BC the northern Theban forces under Nebhepetre Mentuhotep II finally defeated the Herakleopolitan rulers, reuniting the Two Lands. They inaugurated a period of economic and cultural renaissance known as the Middle Kingdom.\\n\\nMiddle Kingdom (2134\u20131690 BC)\\nThe kings of the Middle Kingdom restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects. Mentuhotep II and his Eleventh Dynasty successors ruled from Thebes, but the vizier Amenemhat I, upon assuming the kingship at the beginning of the Twelfth Dynasty around 1985 BC, shifted the kingdom's capital to the city of Itjtawy, located in Faiyum. From Itjtawy, the kings of the Twelfth Dynasty undertook a far-sighted land reclamation and irrigation scheme to increase agricultural output in the region. Moreover, the military reconquered territory in Nubia that was rich in quarries and gold mines, while laborers built a defensive structure in the Eastern Delta, called the \"Walls of the Ruler\", to defend against foreign attack.With the kings having secured the country militarily and politically and with vast agricultural and mineral wealth at their disposal, the nation's population, arts, and religion flourished. In contrast to elitist Old Kingdom attitudes towards the gods, the Middle Kingdom displayed an increase in expressions of personal piety. Middle Kingdom literature featured sophisticated themes and characters written in a confident, eloquent style. The relief and portrait sculpture of the period captured subtle, individual details that reached new heights of technical sophistication.The last great ruler of the Middle Kingdom, Amenemhat III, allowed Semitic-speaking Canaanite settlers from the Near East into the Delta region to provide a sufficient labor force for his especially active mining and building campaigns. These ambitious building and mining activities, however, combined with severe Nile floods later in his reign, strained the economy and precipitated the slow decline into the Second Intermediate Period during the later Thirteenth and Fourteenth dynasties. During this decline, the Canaanite settlers began to assume greater control of the Delta region, eventually coming to power in Egypt as the Hyksos.\\n\\nSecond Intermediate Period (1674\u20131549 BC) and the Hyksos\\nAround 1785 BC, as the power of the Middle Kingdom kings weakened, a Western Asian people called the Hyksos, who had already settled in the Delta, seized control of Egypt and established their capital at Avaris, forcing the former central government to retreat to Thebes. The king was treated as a vassal and expected to pay tribute. The Hyksos (\"foreign rulers\") retained Egyptian models of government and identified as kings, thereby integrating Egyptian elements into their culture. They and other invaders introduced new tools of warfare into Egypt, most notably the composite bow and the horse-drawn chariot.After retreating south, the native Theban kings found themselves trapped between the Canaanite Hyksos ruling the north and the Hyksos' Nubian allies, the Kushites, to the south. After years of vassalage, Thebes gathered enough strength to challenge the Hyksos in a conflict that lasted more than 30 years, until 1555 BC. The kings Seqenenre Tao II and Kamose were ultimately able to defeat the Nubians to the south of Egypt, but failed to defeat the Hyksos. That task fell to Kamose's successor, Ahmose I, who successfully waged a series of campaigns that permanently eradicated the Hyksos' presence in Egypt. He established a new dynasty and, in the New Kingdom that followed, the military became a central priority for the kings, who sought to expand Egypt's borders and attempted to gain mastery of the Near East.\\n\\nNew Kingdom (1549\u20131069 BC)\\nThe New Kingdom pharaohs established a period of unprecedented prosperity by securing their borders and strengthening diplomatic ties with their neighbours, including the Mitanni Empire, Assyria, and Canaan. Military campaigns waged under Tuthmosis I and his grandson Tuthmosis III extended the influence of the pharaohs to the largest empire Egypt had ever seen. Beginning with Merneptah the rulers of Egypt adopted the title of pharaoh.\\nBetween their reigns, Hatshepsut, a queen who established herself as pharaoh, launched many building projects, including the restoration of temples damaged by the Hyksos, and sent trading expeditions to Punt and the Sinai. When Tuthmosis III died in 1425 BC, Egypt had an empire extending from Niya in north west Syria to the Fourth Cataract of the Nile in Nubia, cementing loyalties and opening access to critical imports such as bronze and wood.The New Kingdom pharaohs began a large-scale building campaign to promote the god Amun, whose growing cult was based in Karnak. They also constructed monuments to glorify their own achievements, both real and imagined. The Karnak temple is the largest Egyptian temple ever built.Around 1350 BC, the stability of the New Kingdom was threatened when Amenhotep IV ascended the throne and instituted a series of radical and chaotic reforms. Changing his name to Akhenaten, he touted the previously obscure sun deity Aten as the supreme deity, suppressed the worship of most other deities, and moved the capital to the new city of Akhetaten (modern-day Amarna). He was devoted to his new religion and artistic style. After his death, the cult of the Aten was quickly abandoned and the traditional religious order restored. The subsequent pharaohs, Tutankhamun, Ay, and Horemheb, worked to erase all mention of Akhenaten's heresy, now known as the Amarna Period.\\nAround 1279 BC, Ramesses II, also known as Ramesses the Great, ascended the throne, and went on to build more temples, erect more statues and obelisks, and sire more children than any other pharaoh in history. A bold military leader, Ramesses II led his army against the Hittites in the Battle of Kadesh (in modern Syria) and, after fighting to a stalemate, finally agreed to the first recorded peace treaty, around 1258 BC.Egypt's wealth, however, made it a tempting target for invasion, particularly by the Libyan Berbers to the west, and the Sea Peoples, a conjectured confederation of seafarers from the Aegean Sea. Initially, the military was able to repel these invasions, but Egypt eventually lost control of its remaining territories in southern Canaan, much of it falling to the Assyrians. The effects of external threats were exacerbated by internal problems such as corruption, tomb robbery, and civil unrest. After regaining their power, the high priests at the temple of Amun in Thebes accumulated vast tracts of land and wealth, and their expanded power splintered the country during the Third Intermediate Period.\\n\\nThird Intermediate Period (1069\u2013653 BC)\\nFollowing the death of Ramesses XI in 1078 BC, Smendes assumed authority over the northern part of Egypt, ruling from the city of Tanis. The south was effectively controlled by the High Priests of Amun at Thebes, who recognized Smendes in name only. During this time, Libyans had been settling in the western delta, and chieftains of these settlers began increasing their autonomy. Libyan princes took control of the delta under Shoshenq I in 945 BC, founding the so-called Libyan or Bubastite dynasty that would rule for some 200 years. Shoshenq also gained control of southern Egypt by placing his family members in important priestly positions. Libyan control began to erode as a rival dynasty in the delta arose in Leontopolis, and Kushites threatened from the south.\\n\\nAround 727 BC the Kushite king Piye invaded northward, seizing control of Thebes and eventually the Delta, which established the 25th Dynasty. During the 25th Dynasty, Pharaoh Taharqa created an empire nearly as large as the New Kingdom's. Twenty-fifth Dynasty pharaohs built, or restored, temples and monuments throughout the Nile valley, including at Memphis, Karnak, Kawa, and Jebel Barkal. During this period, the Nile valley saw the first widespread construction of pyramids (many in modern Sudan) since the Middle Kingdom.Egypt's far-reaching prestige declined considerably toward the end of the Third Intermediate Period. Its foreign allies had fallen under the Assyrian sphere of influence, and by 700 BC war between the two states became inevitable. Between 671 and 667 BC the Assyrians began the Assyrian conquest of Egypt. The reigns of both Taharqa and his successor, Tanutamun, were filled with constant conflict with the Assyrians, against whom Egypt enjoyed several victories. Ultimately, the Assyrians pushed the Kushites back into Nubia, occupied Memphis, and sacked the temples of Thebes.\\n\\nLate Period (653\u2013332 BC)\\nThe Assyrians left control of Egypt to a series of vassals who became known as the Saite kings of the Twenty-Sixth Dynasty. By 653 BC, the Saite king Psamtik I was able to oust the Assyrians with the help of Greek mercenaries, who were recruited to form Egypt's first navy. Greek influence expanded greatly as the city-state of Naucratis became the home of Greeks in the Nile Delta. The Saite kings based in the new capital of Sais witnessed a brief but spirited resurgence in the economy and culture, but in 525 BC, the powerful Persians, led by Cambyses II, began their conquest of Egypt, eventually capturing the pharaoh Psamtik III at the Battle of Pelusium. Cambyses II then assumed the formal title of pharaoh, but ruled Egypt from Iran, leaving Egypt under the control of a satrap. A few successful revolts against the Persians marked the 5th century BC, but Egypt was never able to permanently overthrow the Persians.Following its annexation by Persia, Egypt was joined with Cyprus and Phoenicia in the sixth satrapy of the Achaemenid Persian Empire. This first period of Persian rule over Egypt, also known as the Twenty-Seventh Dynasty, ended in 402 BC, when Egypt regained independence under a series of native dynasties. The last of these dynasties, the Thirtieth, proved to be the last native royal house of ancient Egypt, ending with the kingship of Nectanebo II. A brief restoration of Persian rule, sometimes known as the Thirty-First Dynasty, began in 343 BC, but shortly after, in 332 BC, the Persian ruler Mazaces handed Egypt over to Alexander the Great without a fight.\\n\\nPtolemaic period (332\u201330 BC)\\nIn 332 BC, Alexander the Great conquered Egypt with little resistance from the Persians and was welcomed by the Egyptians as a deliverer. The administration established by Alexander's successors, the Macedonian Ptolemaic Kingdom, was based on an Egyptian model and based in the new capital city of Alexandria. The city showcased the power and prestige of Hellenistic rule, and became a centre of learning and culture, that included the famous Library of Alexandria as part of the Mouseion. The Lighthouse of Alexandria lit the way for the many ships that kept trade flowing through the city\u2014as the Ptolemies made commerce and revenue-generating enterprises, such as papyrus manufacturing, their top priority.Hellenistic culture did not supplant native Egyptian culture, as the Ptolemies supported time-honored traditions in an effort to secure the loyalty of the populace. They built new temples in Egyptian style, supported traditional cults, and portrayed themselves as pharaohs. Some traditions merged, as Greek and Egyptian gods were syncretized into composite deities, such as Serapis, and classical Greek forms of sculpture influenced traditional Egyptian motifs. Despite their efforts to appease the Egyptians, the Ptolemies were challenged by native rebellion, bitter family rivalries, and the powerful mob of Alexandria that formed after the death of Ptolemy IV. In addition, as Rome relied more heavily on imports of grain from Egypt, the Romans took great interest in the political situation in the country. Continued Egyptian revolts, ambitious politicians, and powerful opponents from the Near East made this situation unstable, leading Rome to send forces to secure the country as a province of its empire.\\n\\nRoman period (30 BC \u2013 AD 641)\\nEgypt became a province of the Roman Empire in 30 BC, following the defeat of Mark Antony and Ptolemaic Queen Cleopatra VII by Octavian (later Emperor Augustus) in the Battle of Actium. The Romans relied heavily on grain shipments from Egypt, and the Roman army, under the control of a prefect appointed by the emperor, quelled rebellions, strictly enforced the collection of heavy taxes, and prevented attacks by bandits, which had become a notorious problem during the period. Alexandria became an increasingly important center on the trade route with the orient, as exotic luxuries were in high demand in Rome.Although the Romans had a more hostile attitude than the Greeks towards the Egyptians, some traditions such as mummification and worship of the traditional gods continued. The art of mummy portraiture flourished, and some Roman emperors had themselves depicted as pharaohs, though not to the extent that the Ptolemies had. The former lived outside Egypt and did not perform the ceremonial functions of Egyptian kingship. Local administration became Roman in style and closed to native Egyptians.From the mid-first century AD, Christianity took root in Egypt and it was originally seen as another cult that could be accepted. However, it was an uncompromising religion that sought to win converts from the pagan Egyptian and Greco-Roman religions and threatened popular religious traditions. This led to the persecution of converts to Christianity, culminating in the great purges of Diocletian starting in 303, but eventually Christianity won out. In 391, the Christian emperor Theodosius introduced legislation that banned pagan rites and closed temples. Alexandria became the scene of great anti-pagan riots with public and private religious imagery destroyed. As a consequence, Egypt's native religious culture was continually in decline. While the native population continued to speak their language, the ability to read hieroglyphic writing slowly disappeared as the role of the Egyptian temple priests and priestesses diminished. The temples themselves were sometimes converted to churches or abandoned to the desert.In the fourth century, as the Roman Empire divided, Egypt found itself in the Eastern Empire with its capital at Constantinople. In the waning years of the Empire, Egypt fell to the Sasanian Persian army in the Sasanian conquest of Egypt (618\u2013628). It was then recaptured by the Byzantine emperor Heraclius (629\u2013639), and was finally captured by Muslim Rashidun army in 639\u2013641, marking the end of both Byzantine rule and of the period typically considered Ancient Egypt.\\n\\nGovernment and economy\\nAdministration and commerce\\nThe pharaoh was the absolute monarch of the country and, at least in theory, wielded complete control of the land and its resources. The king was the supreme military commander and head of the government, who relied on a bureaucracy of officials to manage his affairs. In charge of the administration was his second in command, the vizier, who acted as the king's representative and coordinated land surveys, the treasury, building projects, the legal system, and the archives. At a regional level, the country was divided into as many as 42 administrative regions called nomes each governed by a nomarch, who was accountable to the vizier for his jurisdiction. The temples formed the backbone of the economy. Not only were they places of worship, but were also responsible for collecting and storing the kingdom's wealth in a system of granaries and treasuries administered by overseers, who redistributed grain and goods.Much of the economy was centrally organized and strictly controlled. Although the ancient Egyptians did not use coinage until the Late period, they did use a type of money-barter system, with standard sacks of grain and the deben, a weight of roughly 91 grams (3 oz) of copper or silver, forming a common denominator. Workers were paid in grain; a simple laborer might earn 5+1\u20442 sacks (200 kg or 400 lb) of grain per month, while a foreman might earn 7+1\u20442 sacks (250 kg or 550 lb). Prices were fixed across the country and recorded in lists to facilitate trading; for example a shirt cost five copper deben, while a cow cost 140 deben. Grain could be traded for other goods, according to the fixed price list. During the fifth century BC coined money was introduced into Egypt from abroad. At first the coins were used as standardized pieces of precious metal rather than true money, but in the following centuries international traders came to rely on coinage.\\n\\nSocial status\\nEgyptian society was highly stratified, and social status was expressly displayed. Farmers made up the bulk of the population, but agricultural produce was owned directly by the state, temple, or noble family that owned the land. Farmers were also subject to a labor tax and were required to work on irrigation or construction projects in a corv\u00e9e system. Artists and craftsmen were of higher status than farmers, but they were also under state control, working in the shops attached to the temples and paid directly from the state treasury. Scribes and officials formed the upper class in ancient Egypt, known as the \"white kilt class\" in reference to the bleached linen garments that served as a mark of their rank. The upper class prominently displayed their social status in art and literature. Below the nobility were the priests, physicians, and engineers with specialized training in their field. It is unclear whether slavery as understood today existed in ancient Egypt; there is difference of opinions among authors.The ancient Egyptians viewed men and women, including people from all social classes, as essentially equal under the law, and even the lowliest peasant was entitled to petition the vizier and his court for redress. Although slaves were mostly used as indentured servants, they were able to buy and sell their servitude, work their way to freedom or nobility, and were usually treated by doctors in the workplace. Both men and women had the right to own and sell property, make contracts, marry and divorce, receive inheritance, and pursue legal disputes in court. Married couples could own property jointly and protect themselves from divorce by agreeing to marriage contracts, which stipulated the financial obligations of the husband to his wife and children should the marriage end. Compared with their counterparts in ancient Greece, Rome, and even more modern places around the world, ancient Egyptian women had a greater range of personal choices, legal rights, and opportunities for achievement. Women such as Hatshepsut and Cleopatra VII even became pharaohs, while others wielded power as Divine Wives of Amun. Despite these freedoms, ancient Egyptian women did not often take part in official roles in the administration, aside from the royal high priestesses, apparently served only secondary roles in the temples (not much data for many dynasties), and were not so likely to be as educated as men.\\n\\nLegal system\\nThe head of the legal system was officially the pharaoh, who was responsible for enacting laws, delivering justice, and maintaining law and order, a concept the ancient Egyptians referred to as Ma'at. Although no legal codes from ancient Egypt survive, court documents show that Egyptian law was based on a common-sense view of right and wrong that emphasized reaching agreements and resolving conflicts rather than strictly adhering to a complicated set of statutes. Local councils of elders, known as Kenbet in the New Kingdom, were responsible for ruling in court cases involving small claims and minor disputes. More serious cases involving murder, major land transactions, and tomb robbery were referred to the Great Kenbet, over which the vizier or pharaoh presided. Plaintiffs and defendants were expected to represent themselves and were required to swear an oath that they had told the truth. In some cases, the state took on both the role of prosecutor and judge, and it could torture the accused with beatings to obtain a confession and the names of any co-conspirators. Whether the charges were trivial or serious, court scribes documented the complaint, testimony, and verdict of the case for future reference.Punishment for minor crimes involved either imposition of fines, beatings, facial mutilation, or exile, depending on the severity of the offense. Serious crimes such as murder and tomb robbery were punished by execution, carried out by decapitation, drowning, or impaling the criminal on a stake. Punishment could also be extended to the criminal's family. Beginning in the New Kingdom, oracles played a major role in the legal system, dispensing justice in both civil and criminal cases. The procedure was to ask the god a \"yes\" or \"no\" question concerning the right or wrong of an issue. The god, carried by a number of priests, rendered judgement by choosing one or the other, moving forward or backward, or pointing to one of the answers written on a piece of papyrus or an ostracon.\\n\\nAgriculture\\nA combination of favorable geographical features contributed to the success of ancient Egyptian culture, the most important of which was the rich fertile soil resulting from annual inundations of the Nile River. The ancient Egyptians were thus able to produce an abundance of food, allowing the population to devote more time and resources to cultural, technological, and artistic pursuits. Land management was crucial in ancient Egypt because taxes were assessed based on the amount of land a person owned.Farming in Egypt was dependent on the cycle of the Nile River. The Egyptians recognized three seasons: Akhet (flooding), Peret (planting), and Shemu (harvesting). The flooding season lasted from June to September, depositing on the river's banks a layer of mineral-rich silt ideal for growing crops. After the floodwaters had receded, the growing season lasted from October to February. Farmers plowed and planted seeds in the fields, which were irrigated with ditches and canals. Egypt received little rainfall, so farmers relied on the Nile to water their crops. From March to May, farmers used sickles to harvest their crops, which were then threshed with a flail to separate the straw from the grain. Winnowing removed the chaff from the grain, and the grain was then ground into flour, brewed to make beer, or stored for later use.The ancient Egyptians cultivated emmer and barley, and several other cereal grains, all of which were used to make the two main food staples of bread and beer. Flax plants, uprooted before they started flowering, were grown for the fibers of their stems. These fibers were split along their length and spun into thread, which was used to weave sheets of linen and to make clothing. Papyrus growing on the banks of the Nile River was used to make paper. Vegetables and fruits were grown in garden plots, close to habitations and on higher ground, and had to be watered by hand. Vegetables included leeks, garlic, melons, squashes, pulses, lettuce, and other crops, in addition to grapes that were made into wine.\\n\\nAnimals\\nThe Egyptians believed that a balanced relationship between people and animals was an essential element of the cosmic order; thus humans, animals and plants were believed to be members of a single whole. Animals, both domesticated and wild, were therefore a critical source of spirituality, companionship, and sustenance to the ancient Egyptians. Cattle were the most important livestock; the administration collected taxes on livestock in regular censuses, and the size of a herd reflected the prestige and importance of the estate or temple that owned them. In addition to cattle, the ancient Egyptians kept sheep, goats, and pigs. Poultry, such as ducks, geese, and pigeons, were captured in nets and bred on farms, where they were force-fed with dough to fatten them. The Nile provided a plentiful source of fish. Bees were also domesticated from at least the Old Kingdom, and provided both honey and wax.The ancient Egyptians used donkeys and oxen as beasts of burden, and they were responsible for plowing the fields and trampling seed into the soil. The slaughter of a fattened ox was also a central part of an offering ritual. Horses were introduced by the Hyksos in the Second Intermediate Period. Camels, although known from the New Kingdom, were not used as beasts of burden until the Late Period. There is also evidence to suggest that elephants were briefly used in the Late Period but largely abandoned due to lack of grazing land. Cats, dogs, and monkeys were common family pets, while more exotic pets imported from the heart of Africa, such as Sub-Saharan African lions, were reserved for royalty. Herodotus observed that the Egyptians were the only people to keep their animals with them in their houses. During the Late Period, the worship of the gods in their animal form was extremely popular, such as the cat goddess Bastet and the ibis god Thoth, and these animals were kept in large numbers for the purpose of ritual sacrifice.\\n\\nNatural resources\\nEgypt is rich in building and decorative stone, copper and lead ores, gold, and semiprecious stones. These natural resources allowed the ancient Egyptians to build monuments, sculpt statues, make tools, and fashion jewelry. Embalmers used salts from the Wadi Natrun for mummification, which also provided the gypsum needed to make plaster. Ore-bearing rock formations were found in distant, inhospitable wadis in the Eastern Desert and the Sinai, requiring large, state-controlled expeditions to obtain natural resources found there. There were extensive gold mines in Nubia, and one of the first maps known is of a gold mine in this region. The Wadi Hammamat was a notable source of granite, greywacke, and gold. Flint was the first mineral collected and used to make tools, and flint handaxes are the earliest pieces of evidence of habitation in the Nile valley. Nodules of the mineral were carefully flaked to make blades and arrowheads of moderate hardness and durability even after copper was adopted for this purpose. Ancient Egyptians were among the first to use minerals such as sulfur as cosmetic substances.The Egyptians worked deposits of the lead ore galena at Gebel Rosas to make net sinkers, plumb bobs, and small figurines. Copper was the most important metal for toolmaking in ancient Egypt and was smelted in furnaces from malachite ore mined in the Sinai. Workers collected gold by washing the nuggets out of sediment in alluvial deposits, or by the more labor-intensive process of grinding and washing gold-bearing quartzite. Iron deposits found in upper Egypt were used in the Late Period. High-quality building stones were abundant in Egypt; the ancient Egyptians quarried limestone all along the Nile valley, granite from Aswan, and basalt and sandstone from the wadis of the Eastern Desert. Deposits of decorative stones such as porphyry, greywacke, alabaster, and carnelian dotted the Eastern Desert and were collected even before the First Dynasty. In the Ptolemaic and Roman Periods, miners worked deposits of emeralds in Wadi Sikait and amethyst in Wadi el-Hudi.\\n\\nTrade\\nThe ancient Egyptians engaged in trade with their foreign neighbors to obtain rare, exotic goods not found in Egypt. In the Predynastic Period, they established trade with Nubia to obtain gold and incense. They also established trade with Palestine, as evidenced by Palestinian-style oil jugs found in the burials of the First Dynasty pharaohs. An Egyptian colony stationed in southern Canaan dates to slightly before the First Dynasty. Narmer had Egyptian pottery produced in Canaan and exported back to Egypt.By the Second Dynasty at latest, ancient Egyptian trade with Byblos yielded a critical source of quality timber not found in Egypt. By the Fifth Dynasty, trade with Punt provided gold, aromatic resins, ebony, ivory, and wild animals such as monkeys and baboons. Egypt relied on trade with Anatolia for essential quantities of tin as well as supplementary supplies of copper, both metals being necessary for the manufacture of bronze. The ancient Egyptians prized the blue stone lapis lazuli, which had to be imported from far-away Afghanistan. Egypt's Mediterranean trade partners also included Greece and Crete, which provided, among other goods, supplies of olive oil.\\n\\nLanguage\\nHistorical development\\nThe Egyptian language is a northern Afro-Asiatic language closely related to the Berber and Semitic languages. It has the longest known history of any language having been written from c. 3200 BC to the Middle Ages and remaining as a spoken language for longer. The phases of ancient Egyptian are Old Egyptian, Middle Egyptian (Classical Egyptian), Late Egyptian, Demotic and Coptic. Egyptian writings do not show dialect differences before Coptic, but it was probably spoken in regional dialects around Memphis and later Thebes.Ancient Egyptian was a synthetic language, but it became more analytic later on. Late Egyptian developed prefixal definite and indefinite articles, which replaced the older inflectional suffixes. There was a change from the older verb\u2013subject\u2013object word order to subject\u2013verb\u2013object. The Egyptian hieroglyphic, hieratic, and demotic scripts were eventually replaced by the more phonetic Coptic alphabet. Coptic is still used in the liturgy of the Egyptian Orthodox Church, and traces of it are found in modern Egyptian Arabic.\\n\\nSounds and grammar\\nAncient Egyptian has 25 consonants similar to those of other Afro-Asiatic languages. These include pharyngeal and emphatic consonants, voiced and voiceless stops, voiceless fricatives and voiced and voiceless affricates. It has three long and three short vowels, which expanded in Late Egyptian to about nine. The basic word in Egyptian, similar to Semitic and Berber, is a triliteral or biliteral root of consonants and semiconsonants. Suffixes are added to form words. The verb conjugation corresponds to the person. For example, the triconsonantal skeleton S-\u1e0e-M is the semantic core of the word 'hear'; its basic conjugation is s\u1e0fm, 'he hears'. If the subject is a noun, suffixes are not added to the verb: s\u1e0fm \u1e25mt, 'the woman hears'.\\nAdjectives are derived from nouns through a process that Egyptologists call nisbation because of its similarity with Arabic. The word order is predicate\u2013subject in verbal and adjectival sentences, and subject\u2013predicate in nominal and adverbial sentences. The subject can be moved to the beginning of sentences if it is long and is followed by a resumptive pronoun. Verbs and nouns are negated by the particle n, but nn is used for adverbial and adjectival sentences. Stress falls on the ultimate or penultimate syllable, which can be open (CV) or closed (CVC).\\n\\nWriting\\nHieroglyphic writing dates from c. 3000 BC, and is composed of hundreds of symbols. A hieroglyph can represent a word, a sound, or a silent determinative; and the same symbol can serve different purposes in different contexts. Hieroglyphs were a formal script, used on stone monuments and in tombs, that could be as detailed as individual works of art. In day-to-day writing, scribes used a cursive form of writing, called hieratic, which was quicker and easier. While formal hieroglyphs may be read in rows or columns in either direction (though typically written from right to left), hieratic was always written from right to left, usually in horizontal rows. A new form of writing, Demotic, became the prevalent writing style, and it is this form of writing\u2014along with formal hieroglyphs\u2014that accompany the Greek text on the Rosetta Stone.Around the first century AD, the Coptic alphabet started to be used alongside the Demotic script. Coptic is a modified Greek alphabet with the addition of some Demotic signs. Although formal hieroglyphs were used in a ceremonial role until the fourth century, towards the end only a small handful of priests could still read them. As the traditional religious establishments were disbanded, knowledge of hieroglyphic writing was mostly lost. Attempts to decipher them date to the Byzantine and Islamic periods in Egypt, but only in the 1820s, after the discovery of the Rosetta Stone and years of research by Thomas Young and Jean-Fran\u00e7ois Champollion, were hieroglyphs substantially deciphered.\\n\\nLiterature\\nWriting first appeared in association with kingship on labels and tags for items found in royal tombs. It was primarily an occupation of the scribes, who worked out of the Per Ankh institution or the House of Life. The latter comprised offices, libraries (called House of Books), laboratories and observatories. Some of the best-known pieces of ancient Egyptian literature, such as the Pyramid and Coffin Texts, were written in Classical Egyptian, which continued to be the language of writing until about 1300 BC. Late Egyptian was spoken from the New Kingdom onward and is represented in Ramesside administrative documents, love poetry and tales, as well as in Demotic and Coptic texts. During this period, the tradition of writing had evolved into the tomb autobiography, such as those of Harkhuf and Weni. The genre known as Sebayt (\"instructions\") was developed to communicate teachings and guidance from famous nobles; the Ipuwer papyrus, a poem of lamentations describing natural disasters and social upheaval, is a famous example.\\nThe Story of Sinuhe, written in Middle Egyptian, might be the classic of Egyptian literature. Also written at this time was the Westcar Papyrus, a set of stories told to Khufu by his sons relating the marvels performed by priests. The Instruction of Amenemope is considered a masterpiece of Near Eastern literature. Towards the end of the New Kingdom, the vernacular language was more often employed to write popular pieces like the Story of Wenamun and the Instruction of Any. The former tells the story of a noble who is robbed on his way to buy cedar from Lebanon and of his struggle to return to Egypt. From about 700 BC, narrative stories and instructions, such as the popular Instructions of Onchsheshonqy, as well as personal and business documents were written in the demotic script and phase of Egyptian. Many stories written in demotic during the Greco-Roman period were set in previous historical eras, when Egypt was an independent nation ruled by great pharaohs such as Ramesses II.\\n\\nCulture\\nDaily life\\nMost ancient Egyptians were farmers tied to the land. Their dwellings were restricted to immediate family members, and were constructed of mudbrick designed to remain cool in the heat of the day. Each home had a kitchen with an open roof, which contained a grindstone for milling grain and a small oven for baking the bread. Ceramics served as household wares for the storage, preparation, transport, and consumption of food, drink, and raw materials. Walls were painted white and could be covered with dyed linen wall hangings. Floors were covered with reed mats, while wooden stools, beds raised from the floor and individual tables comprised the furniture.\\nThe ancient Egyptians placed a great value on hygiene and appearance. Most bathed in the Nile and used a pasty soap made from animal fat and chalk. Men shaved their entire bodies for cleanliness; perfumes and aromatic ointments covered bad odors and soothed skin. Clothing was made from simple linen sheets that were bleached white, and both men and women of the upper classes wore wigs, jewelry, and cosmetics. Children went without clothing until maturity, at about age 12, and at this age males were circumcised and had their heads shaved. Mothers were responsible for taking care of the children, while the father provided the family's income.Music and dance were popular entertainments for those who could afford them. Early instruments included flutes and harps, while instruments similar to trumpets, oboes, and pipes developed later and became popular. In the New Kingdom, the Egyptians played on bells, cymbals, tambourines, drums, and imported lutes and lyres from Asia. The sistrum was a rattle-like musical instrument that was especially important in religious ceremonies.\\n\\nThe ancient Egyptians enjoyed a variety of leisure activities, including games and music. Senet, a board game where pieces moved according to random chance, was particularly popular from the earliest times; another similar game was mehen, which had a circular gaming board. \"Hounds and Jackals\" also known as 58 holes is another example of board games played in ancient Egypt. The first complete set of this game was discovered from a Theban tomb of the Egyptian pharaoh Amenemhat IV that dates to the 13th Dynasty. Juggling and ball games were popular with children, and wrestling is also documented in a tomb at Beni Hasan. The wealthy members of ancient Egyptian society enjoyed hunting, fishing, and boating as well.\\nThe excavation of the workers' village of Deir el-Medina has resulted in one of the most thoroughly documented accounts of community life in the ancient world, which spans almost four hundred years. There is no comparable site in which the organization, social interactions, and working and living conditions of a community have been studied in such detail.\\n\\nCuisine\\nEgyptian cuisine remained remarkably stable over time; indeed, the cuisine of modern Egypt retains some striking similarities to the cuisine of the ancients. The staple diet consisted of bread and beer, supplemented with vegetables such as onions and garlic, and fruit such as dates and figs. Wine and meat were enjoyed by all on feast days while the upper classes indulged on a more regular basis. Fish, meat, and fowl could be salted or dried, and could be cooked in stews or roasted on a grill.\\n\\nArchitecture\\nThe architecture of ancient Egypt includes some of the most famous structures in the world: the Great Pyramids of Giza and the temples at Thebes. Building projects were organized and funded by the state for religious and commemorative purposes, but also to reinforce the wide-ranging power of the pharaoh. The ancient Egyptians were skilled builders; using only simple but effective tools and sighting instruments, architects could build large stone structures with great accuracy and precision that is still envied today.The domestic dwellings of elite and ordinary Egyptians alike were constructed from perishable materials such as mudbricks and wood, and have not survived. Peasants lived in simple homes, while the palaces of the elite and the pharaoh were more elaborate structures. A few surviving New Kingdom palaces, such as those in Malkata and Amarna, show richly decorated walls and floors with scenes of people, birds, water pools, deities and geometric designs. Important structures such as temples and tombs that were intended to last forever were constructed of stone instead of mudbricks. The architectural elements used in the world's first large-scale stone building, Djoser's mortuary complex, include post and lintel supports in the papyrus and lotus motif.The earliest preserved ancient Egyptian temples, such as those at Giza, consist of single, enclosed halls with roof slabs supported by columns. In the New Kingdom, architects added the pylon, the open courtyard, and the enclosed hypostyle hall to the front of the temple's sanctuary, a style that was standard until the Greco-Roman period. The earliest and most popular tomb architecture in the Old Kingdom was the mastaba, a flat-roofed rectangular structure of mudbrick or stone built over an underground burial chamber. The step pyramid of Djoser is a series of stone mastabas stacked on top of each other. Pyramids were built during the Old and Middle Kingdoms, but most later rulers abandoned them in favor of less conspicuous rock-cut tombs. The use of the pyramid form continued in private tomb chapels of the New Kingdom and in the royal pyramids of Nubia.\\n\\nArt\\nThe ancient Egyptians produced art to serve functional purposes. For over 3500 years, artists adhered to artistic forms and iconography that were developed during the Old Kingdom, following a strict set of principles that resisted foreign influence and internal change. These artistic standards\u2014simple lines, shapes, and flat areas of color combined with the characteristic flat projection of figures with no indication of spatial depth\u2014created a sense of order and balance within a composition. Images and text were intimately interwoven on tomb and temple walls, coffins, stelae, and even statues. The Narmer Palette, for example, displays figures that can also be read as hieroglyphs. Because of the rigid rules that governed its highly stylized and symbolic appearance, ancient Egyptian art served its political and religious purposes with precision and clarity.\\nAncient Egyptian artisans used stone as a medium for carving statues and fine reliefs, but used wood as a cheap and easily carved substitute. Paints were obtained from minerals such as iron ores (red and yellow ochres), copper ores (blue and green), soot or charcoal (black), and limestone (white). Paints could be mixed with gum arabic as a binder and pressed into cakes, which could be moistened with water when needed.Pharaohs used reliefs to record victories in battle, royal decrees, and religious scenes. Common citizens had access to pieces of funerary art, such as shabti statues and books of the dead, which they believed would protect them in the afterlife. During the Middle Kingdom, wooden or clay models depicting scenes from everyday life became popular additions to the tomb. In an attempt to duplicate the activities of the living in the afterlife, these models show laborers, houses, boats, and even military formations that are scale representations of the ideal ancient Egyptian afterlife.Despite the homogeneity of ancient Egyptian art, the styles of particular times and places sometimes reflected changing cultural or political attitudes. After the invasion of the Hyksos in the Second Intermediate Period, Minoan-style frescoes were found in Avaris. The most striking example of a politically driven change in artistic forms comes from the Amarna Period, where figures were radically altered to conform to Akhenaten's revolutionary religious ideas. This style, known as Amarna art, was quickly abandoned after Akhenaten's death and replaced by the traditional forms.\\n\\nReligious beliefs\\nBeliefs in the divine and in the afterlife were ingrained in ancient Egyptian civilization from its inception; pharaonic rule was based on the divine right of kings. The Egyptian pantheon was populated by gods who had supernatural powers and were called on for help or protection. However, the gods were not always viewed as benevolent, and Egyptians believed they had to be appeased with offerings and prayers. The structure of this pantheon changed continually as new deities were promoted in the hierarchy, but priests made no effort to organize the diverse and sometimes conflicting myths and stories into a coherent system. These various conceptions of divinity were not considered contradictory but rather layers in the multiple facets of reality.\\nGods were worshiped in cult temples administered by priests acting on the king's behalf. At the center of the temple was the cult statue in a shrine. Temples were not places of public worship or congregation, and only on select feast days and celebrations was a shrine carrying the statue of the god brought out for public worship. Normally, the god's domain was sealed off from the outside world and was only accessible to temple officials. Common citizens could worship private statues in their homes, and amulets offered protection against the forces of chaos. After the New Kingdom, the pharaoh's role as a spiritual intermediary was de-emphasized as religious customs shifted to direct worship of the gods. As a result, priests developed a system of oracles to communicate the will of the gods directly to the people.The Egyptians believed that every human being was composed of physical and spiritual parts or aspects. In addition to the body, each person had a \u0161wt (shadow), a ba (personality or soul), a ka (life-force), and a name. The heart, rather than the brain, was considered the seat of thoughts and emotions. After death, the spiritual aspects were released from the body and could move at will, but they required the physical remains (or a substitute, such as a statue) as a permanent home. The ultimate goal of the deceased was to rejoin his ka and ba and become one of the \"blessed dead\", living on as an akh, or \"effective one\". For this to happen, the deceased had to be judged worthy in a trial, in which the heart was weighed against a \"feather of truth.\" If deemed worthy, the deceased could continue their existence on earth in spiritual form. If they were not deemed worthy, their heart was eaten by Ammit the Devourer and they were erased from the Universe.\\n\\nBurial customs\\nThe ancient Egyptians maintained an elaborate set of burial customs that they believed were necessary to ensure immortality after death. These customs involved preserving the body by mummification, performing burial ceremonies, and interring with the body goods the deceased would use in the afterlife. Before the Old Kingdom, bodies buried in desert pits were naturally preserved by desiccation. The arid, desert conditions were a boon throughout the history of ancient Egypt for burials of the poor, who could not afford the elaborate burial preparations available to the elite. Wealthier Egyptians began to bury their dead in stone tombs and use artificial mummification, which involved removing the internal organs, wrapping the body in linen, and burying it in a rectangular stone sarcophagus or wooden coffin. Beginning in the Fourth Dynasty, some parts were preserved separately in canopic jars.By the New Kingdom, the ancient Egyptians had perfected the art of mummification; the best technique took 70 days and involved removing the internal organs, removing the brain through the nose, and desiccating the body in a mixture of salts called natron. The body was then wrapped in linen with protective amulets inserted between layers and placed in a decorated anthropoid coffin. Mummies of the Late Period were also placed in painted cartonnage mummy cases. Actual preservation practices declined during the Ptolemaic and Roman eras, while greater emphasis was placed on the outer appearance of the mummy, which was decorated.Wealthy Egyptians were buried with larger quantities of luxury items, but all burials, regardless of social status, included goods for the deceased. Funerary texts were often included in the grave, and, beginning in the New Kingdom, so were shabti statues that were believed to perform manual labor for them in the afterlife. Rituals in which the deceased was magically re-animated accompanied burials. After burial, living relatives were expected to occasionally bring food to the tomb and recite prayers on behalf of the deceased.\\n\\nMilitary\\nThe ancient Egyptian military was responsible for defending Egypt against foreign invasion, and for maintaining Egypt's domination in the ancient Near East. The military protected mining expeditions to the Sinai during the Old Kingdom and fought civil wars during the First and Second Intermediate Periods. The military was responsible for maintaining fortifications along important trade routes, such as those found at the city of Buhen on the way to Nubia. Forts also were constructed to serve as military bases, such as the fortress at Sile, which was a base of operations for expeditions to the Levant. In the New Kingdom, a series of pharaohs used the standing Egyptian army to attack and conquer Kush and parts of the Levant.\\nTypical military equipment included bows and arrows, spears, and round-topped shields made by stretching animal skin over a wooden frame. In the New Kingdom, the military began using chariots that had earlier been introduced by the Hyksos invaders. Weapons and armor continued to improve after the adoption of bronze: shields were now made from solid wood with a bronze buckle, spears were tipped with a bronze point, and the khopesh was adopted from Asiatic soldiers. The pharaoh was usually depicted in art and literature riding at the head of the army; it has been suggested that at least a few pharaohs, such as Seqenenre Tao II and his sons, did do so. However, it has also been argued that \"kings of this period did not personally act as frontline war leaders, fighting alongside their troops.\" Soldiers were recruited from the general population, but during, and especially after, the New Kingdom, mercenaries from Nubia, Kush, and Libya were hired to fight for Egypt.\\n\\nTechnology, medicine and mathematics\\nTechnology\\nIn technology, medicine, and mathematics, ancient Egypt achieved a relatively high standard of productivity and sophistication. Traditional empiricism, as evidenced by the Edwin Smith and Ebers papyri (c.\u20091600 BC), is first credited to Egypt. The Egyptians created their own alphabet and decimal system.\\n\\nFaience and glass\\nEven before the Old Kingdom, the ancient Egyptians had developed a glassy material known as faience, which they treated as a type of artificial semi-precious stone. Faience is a non-clay ceramic made of silica, small amounts of lime and soda, and a colorant, typically copper. The material was used to make beads, tiles, figurines, and small wares. Several methods can be used to create faience, but typically production involved application of the powdered materials in the form of a paste over a clay core, which was then fired. By a related technique, the ancient Egyptians produced a pigment known as Egyptian blue, also called blue frit, which is produced by fusing (or sintering) silica, copper, lime, and an alkali such as natron. The product can be ground up and used as a pigment.The ancient Egyptians could fabricate a wide variety of objects from glass with great skill, but it is not clear whether they developed the process independently. It is also unclear whether they made their own raw glass or merely imported pre-made ingots, which they melted and finished. However, they did have technical expertise in making objects, as well as adding trace elements to control the color of the finished glass. A range of colors could be produced, including yellow, red, green, blue, purple, and white, and the glass could be made either transparent or opaque.\\n\\nMedicine\\nThe medical problems of the ancient Egyptians stemmed directly from their environment. Living and working close to the Nile brought hazards from malaria and debilitating schistosomiasis parasites, which caused liver and intestinal damage. Dangerous wildlife such as crocodiles and hippos were also a common threat. The lifelong labors of farming and building put stress on the spine and joints, and traumatic injuries from construction and warfare all took a significant toll on the body. The grit and sand from stone-ground flour abraded teeth, leaving them susceptible to abscesses (though caries were rare).The diets of the wealthy were rich in sugars, which promoted periodontal disease. Despite the flattering physiques portrayed on tomb walls, the overweight mummies of many of the upper class show the effects of a life of overindulgence. Adult life expectancy was about 35 for men and 30 for women, but reaching adulthood was difficult as about one-third of the population died in infancy.\\nAncient Egyptian physicians were renowned in the ancient Near East for their healing skills, and some, such as Imhotep, remained famous long after their deaths. Herodotus remarked that there was a high degree of specialization among Egyptian physicians, with some treating only the head or the stomach, while others were eye-doctors and dentists. Training of physicians took place at the Per Ankh or \"House of Life\" institution, most notably those headquartered in Per-Bastet during the New Kingdom and at Abydos and Sa\u00efs in the Late period. Medical papyri show empirical knowledge of anatomy, injuries, and practical treatments.Wounds were treated by bandaging with raw meat, white linen, sutures, nets, pads, and swabs soaked with honey to prevent infection, while opium, thyme, and belladona were used to relieve pain. The earliest records of burn treatment describe burn dressings that use the milk from mothers of male babies. Prayers were made to the goddess Isis. Moldy bread, honey, and copper salts were also used to prevent infection from dirt in burns. Garlic and onions were used regularly to promote good health and were thought to relieve asthma symptoms. Ancient Egyptian surgeons stitched wounds, set broken bones, and amputated diseased limbs, but they recognized that some injuries were so serious that they could only make the patient comfortable until death occurred.\\n\\nMaritime technology\\nEarly Egyptians knew how to assemble planks of wood into a ship hull and had mastered advanced forms of shipbuilding as early as 3000 BC. The Archaeological Institute of America reports that the oldest planked ships known are the Abydos boats. A group of 14 discovered ships in Abydos were constructed of wooden planks \"sewn\" together. Discovered by Egyptologist David O'Connor of New York University, woven straps were found to have been used to lash the planks together, and reeds or grass stuffed between the planks helped to seal the seams. Because the ships are all buried together and near a mortuary belonging to Pharaoh Khasekhemwy, originally they were all thought to have belonged to him, but one of the 14 ships dates to 3000 BC, and the associated pottery jars buried with the vessels also suggest earlier dating. The ship dating to 3000 BC was 75 feet (23 m) long and is now thought to perhaps have belonged to an earlier pharaoh, perhaps one as early as Hor-Aha.Early Egyptians also knew how to assemble planks of wood with treenails to fasten them together, using pitch for caulking the seams. The \"Khufu ship\", a 43.6-metre (143 ft) vessel sealed into a pit in the Giza pyramid complex at the foot of the Great Pyramid of Giza in the Fourth Dynasty around 2500 BC, is a full-size surviving example that may have filled the symbolic function of a solar barque. Early Egyptians also knew how to fasten the planks of this ship together with mortise and tenon joints.\\nLarge seagoing ships are known to have been heavily used by the Egyptians in their trade with the city states of the eastern Mediterranean, especially Byblos (on the coast of modern-day Lebanon), and in several expeditions down the Red Sea to the Land of Punt. In fact one of the earliest Egyptian words for a seagoing ship is a \"Byblos Ship\", which originally defined a class of Egyptian seagoing ships used on the Byblos run; however, by the end of the Old Kingdom, the term had come to include large seagoing ships, whatever their destination.In 1977, an ancient north\u2013south canal was discovered extending from Lake Timsah to the Ballah Lakes. It was dated to the Middle Kingdom of Egypt by extrapolating dates of ancient sites constructed along its course.In 2011, archaeologists from Italy, the United States, and Egypt excavating a dried-up lagoon known as Mersa Gawasis have unearthed traces of an ancient harbor that once launched early voyages like Hatshepsut's Punt expedition onto the open ocean. Some of the site's most evocative evidence for the ancient Egyptians' seafaring prowess include large ship timbers and hundreds of feet of ropes, made from papyrus, coiled in huge bundles. In 2013, a team of Franco-Egyptian archaeologists discovered what is believed to be the world's oldest port, dating back about 4500 years, from the time of King Khufu on the Red Sea coast near Wadi el-Jarf (about 110 miles south of Suez).\\n\\nMathematics\\nThe earliest attested examples of mathematical calculations date to the predynastic Naqada period, and show a fully developed numeral system. The importance of mathematics to an educated Egyptian is suggested by a New Kingdom fictional letter in which the writer proposes a scholarly competition between himself and another scribe regarding everyday calculation tasks such as accounting of land, labor, and grain. Texts such as the Rhind Mathematical Papyrus and the Moscow Mathematical Papyrus show that the ancient Egyptians could perform the four basic mathematical operations\u2014addition, subtraction, multiplication, and division\u2014use fractions, calculate the areas of rectangles, triangles, and circles and compute the volumes of boxes, columns and pyramids. They understood basic concepts of algebra and geometry, and could solve simple sets of simultaneous equations.\\nMathematical notation was decimal, and based on hieroglyphic signs for each power of ten up to one million. Each of these could be written as many times as necessary to add up to the desired number; so to write the number eighty or eight hundred, the symbol for ten or one hundred was written eight times respectively. Because their methods of calculation could not handle most fractions with a numerator greater than one, they had to write fractions as the sum of several fractions. For example, they resolved the fraction two-fifths into the sum of one-third + one-fifteenth. Standard tables of values facilitated this. Some common fractions, however, were written with a special glyph\u2014the equivalent of the modern two-thirds is shown on the right.Ancient Egyptian mathematicians knew the Pythagorean theorem as an empirical formula. They were aware, for example, that a triangle had a right angle opposite the hypotenuse when its sides were in a 3\u20134\u20135 ratio. They were able to estimate the area of a circle by subtracting one-ninth from its diameter and squaring the result:\\n\\nArea \u2248 [(8\u20449)D]2 = (256\u204481)r2 \u2248 3.16r2,a reasonable approximation of the formula \u03c0r2.\\n\\nPopulation\\nEstimates of the size of the population range from 1\u20131.5 million in the 3rd millennium BC to possibly 2\u20133 million by the 1st millennium BC, before growing significantly towards the end of that millennium.\\n\\nArchaeogenetics\\nAccording to historian William Stiebling and archaeologist Susan N. Helft, conflicting DNA analysis on recent genetic samples such as the Amarna royal mummies has led to a lack of consensus on the genetic makeup of the ancient Egyptians and their geographic origins.The genetic history of Ancient Egypt remains a developing field, and is relevant for the understanding of population demographic events connecting Africa and Eurasia. To date, the amount of genome-wide aDNA analyses on ancient specimens from Egypt and Sudan remain scarce, although studies on uniparental haplogroups in ancient individuals have been carried out several times, pointing broadly to affinities with other African and Eurasian groups.The currently most advanced full genome analyses was made on three ancient specimens recovered from the Nile River Valley, Abusir el-Meleq, Egypt. Two of the individuals were dated to the Pre-Ptolemaic Period (New Kingdom to Late Period), and one individual to the Ptolemaic Period, spanning around 1300 years of Egyptian history. These results point to a genetic continuity of Ancient Egyptians with modern Egyptians. The results further point to a close genetic affinity between ancient Egyptians and Middle Eastern populations, especially ancient groups from the Levant (Natufian culture).Ancient Egyptians also displayed affinities to Nubians to the south of Egypt, in modern day Sudan. Archaeological and historical evidence support interactions between Egyptian and Nubian populations more than 5000 years ago, with socio-political dynamics between Egyptians and Nubians ranging from peaceful coexistence to variably successful attempts of conquest. A study on sixty-six ancient Nubian individuals revealed significant contact with ancient Egyptians, characterized by the presence of c. 57% Neolithic/Bronze Age Levantine ancestry in these individuals. Such geneflow of Levantine-like ancestry corresponds with archaeological and botanic evidence, pointing to a Neolithic movement around 7,000 years ago.Genetic data on other Northern African specimens, such as the c. 15,000 year old Iberomaurusian Taforalt man, but also specimens from the \"last Green Sahara\" and the Savanna Pastoral Neolithic, point to the widespread presence of an (Western) Eurasian ancestry component distributed throughout Northern Africa, the Sahara, and the Horn of Africa, having arrived via back migration(s) from the Middle East starting as early as c. 23,000 years ago.Modern Egyptians, like modern Nubians, underwent subsequent admixture events, contributing both \"Sub-Saharan\" African-like and West Asian-like ancestries, since the Roman period, with significance on the African Slave Trade and the Spread of Islam.Some scholars, such as Christopher Ehret, caution that a wider sampling area is needed and argue that the current data is inconclusive on the origin of ancient Egyptians. They also point out issues with the previously used methodology such as the sampling size, comparative approach and a \"biased interpretation\" of the genetic data. They argue in favor for a link between Ancient Egypt and the northern Horn of Africa. This latter view has been attributed to the corresponding archaeological, genetic, linguistic and biological anthropological sources of evidence which broadly indicate that the earliest Egyptians and Nubians were the descendants of populations in northeast Africa.\\n\\nLegacy\\nThe culture and monuments of ancient Egypt have left a lasting legacy on the world. Egyptian civilization significantly influenced the Kingdom of Kush and Mero\u00eb with both adopting Egyptian religious and architectural norms (hundreds of pyramids (6\u201330 meters high) were built in Egypt/Sudan), as well as using Egyptian writing as the basis of the Meroitic script. Meroitic is the oldest written language in Africa, other than Egyptian, and was used from the 2nd century BC until the early 5th century AD. The cult of the goddess Isis, for example, became popular in the Roman Empire, as obelisks and other relics were transported back to Rome. The Romans also imported building materials from Egypt to erect Egyptian-style structures. Early historians such as Herodotus, Strabo, and Diodorus Siculus studied and wrote about the land, which Romans came to view as a place of mystery.During the Middle Ages and the Renaissance, Egyptian pagan culture was in decline after the rise of Christianity and later Islam, but interest in Egyptian antiquity continued in the writings of medieval scholars such as Dhul-Nun al-Misri and al-Maqrizi. In the seventeenth and eighteenth centuries, European travelers and tourists brought back antiquities and wrote stories of their journeys, leading to a wave of Egyptomania across Europe, as evident in symbolism like the Eye of Providence and the Great Seal of the United States. This renewed interest sent collectors to Egypt, who took, purchased, or were given many important antiquities. Napoleon arranged the first studies in Egyptology when he brought some 150 scientists and artists to study and document Egypt's natural history, which was published in the Description de l'\u00c9gypte.In the 20th century, the Egyptian Government and archaeologists alike recognized the importance of cultural respect and integrity in excavations. Since the 2010s, the Ministry of Tourism and Antiquities has overseen excavations and the recovery of artifacts.\\n\\nSee also\\nEgyptology\\nGlossary of ancient Egypt artifacts\\nIndex of ancient Egypt\u2013related articles\\nOutline of ancient Egypt\\nList of ancient Egyptians\\nList of Ancient Egyptian inventions and discoveries\\nArchaeology of Ancient Egypt\\nArcheological Map of Egypt\\nBritish school of diffusionism\\n\\nNotes\\nReferences\\nCitations\\nWorks cited\\nFurther reading\\nBaines, John; M\u00e1lek, Jarom\u00edr (2000). Cultural Atlas of Ancient Egypt. Checkmark Books. ISBN 978-0-8160-4036-0.\\nBard, Kathryn A., ed. (1999). Encyclopedia of the Archaeology of Ancient Egypt. Routledge. ISBN 978-1-134-66525-9.\\nGrimal, Nicolas (1994) [1988]. A History of Ancient Egypt. Wiley. ISBN 978-0-631-19396-8.\\nHelck, Wolfgang; Otto, Eberhard, eds. (1972\u20131992). Lexikon der \u00c4gyptologie. O. Harrassowitz. ISBN 978-3-447-01441-0.\\nLehner, Mark (1997). The Complete Pyramids. London: Thames & Hudson. ISBN 978-0-500-05084-2.\\nMallory-Greenough, Leanne M. (December 2002). \"The Geographical, Spatial, and Temporal Distribution of Predynastic and First Dynasty Basalt Vessels\". Journal of Egyptian Archaeology. 88 (1): 67\u201393. doi:10.2307/3822337. JSTOR 3822337.\\nMidant-Reynes, Beatrix (2000). The Prehistory of Egypt: From the First Egyptians to the First Pharaohs. Wiley. ISBN 978-0-631-21787-9.\\nRedford, Donald B., ed. (2001). The Oxford Encyclopedia of Ancient Egypt. Oxford University Press. ISBN 978-0-19-510234-5.\\nSchuenemann, Verena J.; Peltzer, Alexander; Welte, Beatrix; et al. (2017). \"Ancient Egyptian mummy genomes suggest an increase of Sub-Saharan African ancestry in post-Roman periods\". Nature Communications. 8: 15694. Bibcode:2017NatCo...815694S. doi:10.1038/ncomms15694. PMC 5459999. PMID 28556824.\\nWilkinson, R.H. (2000). The Complete Temples of Ancient Egypt. London: Thames and Hudson. ISBN 978-0-500-05100-9.\\nWilkinson, R.H. (2003). The Complete Gods and Goddesses of Ancient Egypt. London: Thames and Hudson. ISBN 978-0-500-05120-7.\\nZakrzewski, Sonia (2007). \"Population continuity or population change: Formation of the ancient Egyptian state\" (PDF). American Journal of Physical Anthropology. 132 (4): 501\u2013509. doi:10.1002/ajpa.20569. PMID 17295300. Archived (PDF) from the original on 9 October 2022.\\n\\nExternal links\\n\\n\"Egypt/2 Ancient Egypt\" . Encyclop\u00e6dia Britannica. Vol. 9 (11th ed.). 1911.\\nBBC History: Egyptians \u2013 provides a reliable general overview and further links\\nAncient Egyptian Science: A Source Book Door Marshall Clagett, 1989\\nNapoleon on the Nile: Soldiers, Artists, and the Rediscovery of Egypt, Art History.\\nDigital Egypt for Universities. Scholarly treatment with broad coverage and cross references (internal and external). Artifacts used extensively to illustrate topics.\\nPriests of Ancient Egypt Archived 22 March 2022 at the Wayback Machine In-depth-information about Ancient Egypt's priests, religious services and temples. Much picture material and bibliography. In English and German.\\nUCLA Encyclopedia of Egyptology\\nAncient Egypt and the Role of Women by Dr Joann Fletcher\\n\"Full-length account of Ancient Egypt as part of history of the world\". Archived from the original on 24 May 2021.{{cite web}}:  CS1 maint: unfit URL (link)"}
{"article_name": "Cancer", "link": "https://en.wikipedia.org/wiki/Cancer", "text_content": "Cancer is a group of diseases involving abnormal cell growth with the potential to invade or spread to other parts of the body. These contrast with benign tumors, which do not spread. Possible signs and symptoms include a lump, abnormal bleeding, prolonged cough, unexplained weight loss, and a change in bowel movements. While these symptoms may indicate cancer, they can also have other causes. Over 100 types of cancers affect humans.Tobacco use is the cause of about 22% of cancer deaths. Another 10% are due to obesity, poor diet, lack of physical activity or excessive alcohol consumption. Other factors include certain infections, exposure to ionizing radiation, and environmental pollutants. Infection with specific viruses, bacteria and parasites is an environmental factor causing approximately 16-18% of cancers worldwide.  These infectious agents include Helicobacter pylori, hepatitis B, hepatitis C, human papillomavirus infection, Epstein\u2013Barr virus, Human T-lymphotropic virus 1, Kaposi's sarcoma-associated herpesvirus and Merkel cell polyomavirus.  Human immunodeficiency virus (HIV) does not directly cause cancer but it causes immune deficiency that can magnify the risk due to other infections, sometimes up to several thousand fold (in the case of Kaposi's sarcoma). Importantly, vaccination against hepatitis B and human papillomavirus have been shown to nearly eliminate risk of cancers caused by these viruses in persons successfully vaccinated prior to infection.  \\nThese environmental factors act, at least partly, by changing the genes of a cell. Typically, many genetic changes are required before cancer develops. Approximately 5\u201310% of cancers are due to inherited genetic defects. Cancer can be detected by certain signs and symptoms or screening tests. It is then typically further investigated by medical imaging and confirmed by biopsy.The risk of developing certain cancers can be reduced by not smoking, maintaining a healthy weight, limiting alcohol intake, eating plenty of vegetables, fruits, and whole grains, vaccination against certain infectious diseases, limiting consumption of processed meat and red meat, and limiting exposure to direct sunlight. Early detection through screening is useful for cervical and colorectal cancer. The benefits of screening for breast cancer are controversial. Cancer is often treated with some combination of radiation therapy, surgery, chemotherapy and targeted therapy. Pain and symptom management are an important part of care. Palliative care is particularly important in people with advanced disease. The chance of survival depends on the type of cancer and extent of disease at the start of treatment. In children under 15 at diagnosis, the five-year survival rate in the developed world is on average 80%. For cancer in the United States, the average five-year survival rate is 66% for all ages.In 2015, about 90.5 million people worldwide had cancer. In 2019, annual cancer cases grew by 23.6 million people, and there were 10 million deaths worldwide, representing over the previous decade increases of 26% and 21%, respectively.The most common types of cancer in males are lung cancer, prostate cancer, colorectal cancer, and stomach cancer. In females, the most common types are breast cancer, colorectal cancer, lung cancer, and cervical cancer. If skin cancer other than melanoma were included in total new cancer cases each year, it would account for around 40% of cases. In children, acute lymphoblastic leukemia and brain tumors are most common, except in Africa, where non-Hodgkin lymphoma occurs more often. In 2012, about 165,000 children under 15 years of age were diagnosed with cancer. The risk of cancer increases significantly with age, and many cancers occur more commonly in developed countries. Rates are increasing as more people live to an old age and as lifestyle changes occur in the developing world. The global total economic costs of cancer were estimated at US$1.16 trillion (equivalent to $1.56 trillion in 2022) per year as of 2010.\\n\\nEtymology and definitions\\nThe word comes from the ancient Greek \u03ba\u03b1\u03c1\u03ba\u03af\u03bd\u03bf\u03c2, meaning 'crab' and 'tumor'. Greek physicians Hippocrates and Galen, among others, noted the similarity of crabs to some tumors with swollen veins. The word was introduced in English in the modern medical sense around 1600.Cancers comprise a large family of diseases that involve abnormal cell growth with the potential to invade or spread to other parts of the body. They form a subset of neoplasms. A neoplasm or tumor is a group of cells that have undergone unregulated growth and will often form a mass or lump, but may be distributed diffusely.All tumor cells show the six hallmarks of cancer. These characteristics are required to produce a malignant tumor. They include:\\nCell growth and division absent the proper signals\\nContinuous growth and division even given contrary signals\\nAvoidance of programmed cell death\\nLimitless number of cell divisions\\nPromoting blood vessel construction\\nInvasion of tissue and formation of metastasesThe progression from normal cells to cells that can form a detectable mass to cancer involves multiple steps known as malignant progression.\\n\\nSigns and symptoms\\nWhen cancer begins, it produces no symptoms. Signs and symptoms appear as the mass grows or ulcerates. The findings that result depend on cancer's type and location. Few symptoms are specific. Many frequently occur in individuals who have other conditions. Cancer can be difficult to diagnose and can be considered a \"great imitator.\"People may become anxious or depressed post-diagnosis. The risk of suicide in people with cancer is approximately double.\\n\\nLocal symptoms\\nLocal symptoms may occur due to the mass of the tumor or its ulceration. For example, mass effects from lung cancer can block the bronchus resulting in cough or pneumonia; esophageal cancer can cause narrowing of the esophagus, making it difficult or painful to swallow; and colorectal cancer may lead to narrowing or blockages in the bowel, affecting bowel habits. Masses in breasts or testicles may produce observable lumps. Ulceration can cause bleeding that can lead to symptoms such as coughing up blood (lung cancer), anemia or rectal bleeding (colon cancer), blood in the urine (bladder cancer), or abnormal vaginal bleeding (endometrial or cervical cancer). Although localized pain may occur in advanced cancer, the initial tumor is usually painless. Some cancers can cause a buildup of fluid within the chest or abdomen.\\n\\nSystemic symptoms\\nSystemic symptoms may occur due to the body's response to the cancer. This may include fatigue, unintentional weight loss, or skin changes. Some cancers can cause a systemic inflammatory state that leads to ongoing muscle loss and weakness, known as cachexia.Some cancers, such as Hodgkin's disease, leukemias, and liver or kidney cancers, can cause a persistent fever.Shortness of breath, called dyspnea, is a common symptom of cancer and its treatment. The causes of cancer-related dyspnea can include tumors in or around the lung, blocked airways, fluid in the lungs, pneumonia, or treatment reactions including an allergic response. Treatment for dyspnea in patients with advanced cancer can include fans, bilevel ventilation, acupressure/reflexology and multicomponent nonpharmacological interventions.Some systemic symptoms of cancer are caused by hormones or other molecules produced by the tumor, known as paraneoplastic syndromes. Common paraneoplastic syndromes include hypercalcemia, which can cause altered mental state, constipation and dehydration, or hyponatremia, which can also cause altered mental status, vomiting, headaches, or seizures.\\n\\nMetastasis\\nMetastasis is the spread of cancer to other locations in the body. The dispersed tumors are called metastatic tumors, while the original is called the primary tumor. Almost all cancers can metastasize. Most cancer deaths are due to cancer that has metastasized.Metastasis is common in the late stages of cancer and it can occur via the blood or the lymphatic system or both. The typical steps in metastasis are local invasion, intravasation into the blood or lymph, circulation through the body, extravasation into the new tissue, proliferation and angiogenesis. Different types of cancers tend to metastasize to particular organs, but overall the most common places for metastases to occur are the lungs, liver, brain, and the bones.While some cancers can be cured if detected early, metastatic cancer is more difficult to treat and control. Nevertheless, some recent treatments are demonstrating encouraging results.\\n\\nCauses\\nThe majority of cancers, some 90\u201395% of cases, are due to genetic mutations from environmental and lifestyle factors. The remaining 5\u201310% are due to inherited genetics. Environmental refers to any cause that is not inherited, such as lifestyle, economic, and behavioral factors and not merely pollution. Common environmental factors that contribute to cancer death include tobacco use (25\u201330%), diet and obesity (30\u201335%), infections (15\u201320%), radiation (both ionizing and non-ionizing, up to 10%), lack of physical activity, and pollution. Psychological stress does not appear to be a risk factor for the onset of cancer, though it may worsen outcomes in those who already have cancer.Environmental or lifestyle factors that caused cancer to develop in an individual can be identified by analyzing mutational signatures from genomic sequencing of tumor DNA. For example, this can reveal if lung cancer was caused by tobacco smoke, if skin cancer was caused by UV radiation, or if secondary cancers were caused by previous chemotherapy treatment.Cancer is generally not a transmissible disease. Except for rare transmissions that occur with pregnancies and occasional organ donors. However, transmissible infectious diseases such as hepatitis B, Epstein-Barr virus, Human Papilloma Virus and HIV, can contribute to the development of cancer.\\n\\nChemicals\\nExposure to particular substances have been linked to specific types of cancer. These substances are called carcinogens.\\nTobacco smoke, for example, causes 90% of lung cancer. Tobacco use can cause cancer throughout the body including in the mouth and throat, larynx, esophagus, stomach, bladder, kidney, cervix, colon/rectum, liver and pancreas. Tobacco smoke contains over fifty known carcinogens, including nitrosamines and polycyclic aromatic hydrocarbons.Tobacco is responsible for about one in five cancer deaths worldwide and about one in three in the developed world. Lung cancer death rates in the United States have mirrored smoking patterns, with increases in smoking followed by dramatic increases in lung cancer death rates and, more recently, decreases in smoking rates since the 1950s followed by decreases in lung cancer death rates in men since 1990.In Western Europe, 10% of cancers in males and 3% of cancers in females are attributed to alcohol exposure, especially liver and digestive tract cancers. Cancer from work-related substance exposures may cause between 2 and 20% of cases, causing at least 200,000 deaths. Cancers such as lung cancer and mesothelioma can come from inhaling tobacco smoke or asbestos fibers, or leukemia from exposure to benzene.Exposure to perfluorooctanoic acid (PFOA), which is predominantly used in the production of Teflon, is known to cause two kinds of cancer.Chemotherapy drugs such as platinum-based compounds are carcinogens that increase the risk of secondary cancersAzathioprine, an immunosuppressive medication, is a carcinogen that can cause primary tumors to develop.\\n\\nDiet and exercise\\nDiet, physical inactivity, and obesity are related to up to 30\u201335% of cancer deaths. In the United States, excess body weight is associated with the development of many types of cancer and is a factor in 14\u201320% of cancer deaths. A UK study including data on over 5 million people showed higher body mass index to be related to at least 10 types of cancer and responsible for around 12,000 cases each year in that country. Physical inactivity is believed to contribute to cancer risk, not only through its effect on body weight but also through negative effects on the immune system and endocrine system. More than half of the effect from the diet is due to overnutrition (eating too much), rather than from eating too few vegetables or other healthful foods.\\nSome specific foods are linked to specific cancers. A high-salt diet is linked to gastric cancer. Aflatoxin B1, a frequent food contaminant, causes liver cancer. Betel nut chewing can cause oral cancer. National differences in dietary practices may partly explain differences in cancer incidence. For example, gastric cancer is more common in Japan due to its high-salt diet while colon cancer is more common in the United States. Immigrant cancer profiles mirror those of their new country, often within one generation.\\n\\nInfection\\nWorldwide, approximately 18% of cancer deaths are related to infectious diseases. This proportion ranges from a high of 25% in Africa to less than 10% in the developed world. Viruses are the usual infectious agents that cause cancer but bacteria and parasites may also play a role. Oncoviruses (viruses that can cause human cancer) include:\\n\\nHuman papillomavirus (cervical cancer),\\nEpstein\u2013Barr virus (B-cell lymphoproliferative disease and nasopharyngeal carcinoma),\\nKaposi's sarcoma herpesvirus (Kaposi's sarcoma and primary effusion lymphomas),\\nHepatitis B and hepatitis C viruses (hepatocellular carcinoma)\\nHuman T-cell leukemia virus-1 (T-cell leukemias).\\nMerkel cell polyomavirus (Merkel cell carcinoma)Bacterial infection may also increase the risk of cancer, as seen in \\n\\nHelicobacter pylori-induced gastric carcinoma.\\nColibactin, a genotoxin associated with Escherichia coli infection (colorectal cancer)Parasitic infections associated with cancer include:\\n\\nSchistosoma haematobium (squamous cell carcinoma of the bladder)\\nThe liver flukes, Opisthorchis viverrini and Clonorchis sinensis (cholangiocarcinoma).\\n\\nRadiation\\nRadiation exposure such as ultraviolet radiation and radioactive material is a risk factor for cancer. Many non-melanoma skin cancers are due to ultraviolet radiation, mostly from sunlight. Sources of ionizing radiation include medical imaging and radon gas.Ionizing radiation is not a particularly strong mutagen. Residential exposure to radon gas, for example, has similar cancer risks as passive smoking. Radiation is a more potent source of cancer when combined with other cancer-causing agents, such as radon plus tobacco smoke. Radiation can cause cancer in most parts of the body, in all animals and at any age. Children are twice as likely to develop radiation-induced leukemia as adults; radiation exposure before birth has ten times the effect.Medical use of ionizing radiation is a small but growing source of radiation-induced cancers. Ionizing radiation may be used to treat other cancers, but this may, in some cases, induce a second form of cancer. It is also used in some kinds of medical imaging.Prolonged exposure to ultraviolet radiation from the sun can lead to melanoma and other skin malignancies. Clear evidence establishes ultraviolet radiation, especially the non-ionizing medium wave UVB, as the cause of most non-melanoma skin cancers, which are the most common forms of cancer in the world.Non-ionizing radio frequency radiation from mobile phones, electric power transmission and other similar sources has been described as a possible carcinogen by the World Health Organization's International Agency for Research on Cancer. Evidence, however, has not supported a concern.  This includes that studies have not found a consistent link between mobile phone radiation and cancer risk.\\n\\nHeredity\\nThe vast majority of cancers are non-hereditary (sporadic). Hereditary cancers are primarily caused by an inherited genetic defect. Less than 0.3% of the population are carriers of a genetic mutation that has a large effect on cancer risk and these cause less than 3\u201310% of cancer. Some of these syndromes include: certain inherited mutations in the genes BRCA1 and BRCA2 with a more than 75% risk of breast cancer and ovarian cancer, and hereditary nonpolyposis colorectal cancer (HNPCC or Lynch syndrome), which is present in about 3% of people with colorectal cancer, among others.\\nStatistically for cancers causing most mortality, the relative risk of developing colorectal cancer when a first-degree relative (parent, sibling or child) has been diagnosed with it is about 2. The corresponding relative risk is 1.5 for lung cancer, and 1.9 for prostate cancer. For breast cancer, the relative risk is 1.8 with a first-degree relative having developed it at 50 years of age or older, and 3.3 when the relative developed it when being younger than 50 years of age.Taller people have an increased risk of cancer because they have more cells than shorter people. Since height is genetically determined to a large extent, taller people have a heritable increase of cancer risk.\\n\\nPhysical agents\\nSome substances cause cancer primarily through their physical, rather than chemical, effects. A prominent example of this is prolonged exposure to asbestos, naturally occurring mineral fibers that are a major cause of mesothelioma (cancer of the serous membrane) usually the serous membrane surrounding the lungs. Other substances in this category, including both naturally occurring and synthetic asbestos-like fibers, such as wollastonite, attapulgite, glass wool and rock wool, are believed to have similar effects. Non-fibrous particulate materials that cause cancer include powdered metallic cobalt and nickel and crystalline silica (quartz, cristobalite and tridymite). Usually, physical carcinogens must get inside the body (such as through inhalation) and require years of exposure to produce cancer.Physical trauma resulting in cancer is relatively rare. Claims that breaking bones resulted in bone cancer, for example, have not been proven. Similarly, physical trauma is not accepted as a cause for cervical cancer, breast cancer or brain cancer. One accepted source is frequent, long-term application of hot objects to the body. It is possible that repeated burns on the same part of the body, such as those produced by kanger and kairo heaters (charcoal hand warmers), may produce skin cancer, especially if carcinogenic chemicals are also present. Frequent consumption of scalding hot tea may produce esophageal cancer. Generally, it is believed that cancer arises, or a pre-existing cancer is encouraged, during the process of healing, rather than directly by the trauma. However, repeated injuries to the same tissues might promote excessive cell proliferation, which could then increase the odds of a cancerous mutation.\\nChronic inflammation has been hypothesized to directly cause mutation. Inflammation can contribute to proliferation, survival, angiogenesis and migration of cancer cells by influencing the tumor microenvironment. Oncogenes build up an inflammatory pro-tumorigenic microenvironment.\\n\\nHormones\\nSome hormones play a role in the development of cancer by promoting cell proliferation. Insulin-like growth factors and their binding proteins play a key role in cancer cell proliferation, differentiation and apoptosis, suggesting possible involvement in carcinogenesis.Hormones are important agents in sex-related cancers, such as cancer of the breast, endometrium, prostate, ovary and testis and also of thyroid cancer and bone cancer. For example, the daughters of women who have breast cancer have significantly higher levels of estrogen and progesterone than the daughters of women without breast cancer. These higher hormone levels may explain their higher risk of breast cancer, even in the absence of a breast-cancer gene. Similarly, men of African ancestry have significantly higher levels of testosterone than men of European ancestry and have a correspondingly higher level of prostate cancer. Men of Asian ancestry, with the lowest levels of testosterone-activating androstanediol glucuronide, have the lowest levels of prostate cancer.Other factors are relevant: obese people have higher levels of some hormones associated with cancer and a higher rate of those cancers. Women who take hormone replacement therapy have a higher risk of developing cancers associated with those hormones. On the other hand, people who exercise far more than average have lower levels of these hormones and lower risk of cancer. Osteosarcoma may be promoted by growth hormones. Some treatments and prevention approaches leverage this cause by artificially reducing hormone levels and thus discouraging hormone-sensitive cancers.\\n\\nAutoimmune diseases\\nThere is an association between celiac disease and an increased risk of all cancers. People with untreated celiac disease have a higher risk, but this risk decreases with time after diagnosis and strict treatment, probably due to the adoption of a gluten-free diet, which seems to have a protective role against development of malignancy in people with celiac disease. However, the delay in diagnosis and initiation of a gluten-free diet seems to increase the risk of malignancies. Rates of gastrointestinal cancers are increased in people with Crohn's disease and ulcerative colitis, due to chronic inflammation. Also, immunomodulators and biologic agents used to treat these diseases may promote developing extra-intestinal malignancies.\\n\\nPathophysiology\\nGenetics\\nCancer is fundamentally a disease of tissue growth regulation. For a normal cell to transform into a cancer cell, the genes that regulate cell growth and differentiation must be altered.The affected genes are divided into two broad categories. Oncogenes are genes that promote cell growth and reproduction. Tumor suppressor genes are genes that inhibit cell division and survival. Malignant transformation can occur through the formation of novel oncogenes, the inappropriate over-expression of normal oncogenes, or by the under-expression or disabling of tumor suppressor genes. Typically, changes in multiple genes are required to transform a normal cell into a cancer cell.Genetic changes can occur at different levels and by different mechanisms. The gain or loss of an entire chromosome can occur through errors in mitosis. More common are mutations, which are changes in the nucleotide sequence of genomic DNA.\\nLarge-scale mutations involve the deletion or gain of a portion of a chromosome. Genomic amplification occurs when a cell gains copies (often 20 or more) of a small chromosomal locus, usually containing one or more oncogenes and adjacent genetic material. Translocation occurs when two separate chromosomal regions become abnormally fused, often at a characteristic location. A well-known example of this is the Philadelphia chromosome, or translocation of chromosomes 9 and 22, which occurs in chronic myelogenous leukemia and results in production of the BCR-abl fusion protein, an oncogenic tyrosine kinase.\\nSmall-scale mutations include point mutations, deletions, and insertions, which may occur in the promoter region of a gene and affect its expression, or may occur in the gene's coding sequence and alter the function or stability of its protein product. Disruption of a single gene may also result from integration of genomic material from a DNA virus or retrovirus, leading to the expression of viral oncogenes in the affected cell and its descendants.\\nReplication of the data contained within the DNA of living cells will probabilistically result in some errors (mutations). Complex error correction and prevention are built into the process and safeguard the cell against cancer. If a significant error occurs, the damaged cell can self-destruct through programmed cell death, termed apoptosis. If the error control processes fail, then the mutations will survive and be passed along to daughter cells.\\nSome environments make errors more likely to arise and propagate. Such environments can include the presence of disruptive substances called carcinogens, repeated physical injury, heat, ionising radiation, or hypoxia.The errors that cause cancer are self-amplifying and compounding, for example:\\n\\nA mutation in the error-correcting machinery of a cell might cause that cell and its children to accumulate errors more rapidly.\\nA further mutation in an oncogene might cause the cell to reproduce more rapidly and more frequently than its normal counterparts.\\nA further mutation may cause loss of a tumor suppressor gene, disrupting the apoptosis signaling pathway and immortalizing the cell.\\nA further mutation in the signaling machinery of the cell might send error-causing signals to nearby cells.The transformation of a normal cell into cancer is akin to a chain reaction caused by initial errors, which compound into more severe errors, each progressively allowing the cell to escape more controls that limit normal tissue growth. This rebellion-like scenario is an undesirable survival of the fittest, where the driving forces of evolution work against the body's design and enforcement of order. Once cancer has begun to develop, this ongoing process, termed clonal evolution, drives progression towards more invasive stages. Clonal evolution leads to intra-tumour heterogeneity (cancer cells with heterogeneous mutations) that complicates designing effective treatment strategies and requires an evolutionary approach to designing treatment.\\nCharacteristic abilities developed by cancers are divided into categories, specifically evasion of apoptosis, self-sufficiency in growth signals, insensitivity to anti-growth signals, sustained angiogenesis, limitless replicative potential, metastasis, reprogramming of energy metabolism and evasion of immune destruction.\\n\\nEpigenetics\\nThe classical view of cancer is a set of diseases driven by progressive genetic abnormalities that include mutations in tumor-suppressor genes and oncogenes, and in chromosomal abnormalities. A role for epigenetic alterations was identified in the early 21st century.Epigenetic alterations are functionally relevant modifications to the genome that do not change the nucleotide sequence. Examples of such modifications are changes in DNA methylation (hypermethylation and hypomethylation), histone modification and changes in chromosomal architecture (caused by inappropriate expression of proteins such as HMGA2 or HMGA1). Each of these alterations regulates gene expression without altering the underlying DNA sequence. These changes may remain through cell divisions, endure for multiple generations, and can be considered as equivalent to mutations.\\nEpigenetic alterations occur frequently in cancers. As an example, one study listed protein coding genes that were frequently altered in their methylation in association with colon cancer. These included 147 hypermethylated and 27 hypomethylated genes. Of the hypermethylated genes, 10 were hypermethylated in 100% of colon cancers and many others were hypermethylated in more than 50% of colon cancers.While epigenetic alterations are found in cancers, the epigenetic alterations in DNA repair genes, causing reduced expression of DNA repair proteins, may be of particular importance. Such alterations may occur early in progression to cancer and are a possible cause of the genetic instability characteristic of cancers.Reduced expression of DNA repair genes disrupts DNA repair. This is shown in the figure at the 4th level from the top. (In the figure, red wording indicates the central role of DNA damage and defects in DNA repair in progression to cancer.) When DNA repair is deficient DNA damage remains in cells at a higher than usual level (5th level) and causes increased frequencies of mutation and/or epimutation (6th level). Mutation rates increase substantially in cells defective in DNA mismatch repair or in homologous recombinational repair (HRR). Chromosomal rearrangements and aneuploidy also increase in HRR defective cells.Higher levels of DNA damage cause increased mutation (right side of figure) and increased epimutation. During repair of DNA double strand breaks, or repair of other DNA damage, incompletely cleared repair sites can cause epigenetic gene silencing.Deficient expression of DNA repair proteins due to an inherited mutation can increase cancer risks. Individuals with an inherited impairment in any of 34 DNA repair genes (see article DNA repair-deficiency disorder) have increased cancer risk, with some defects ensuring a 100% lifetime chance of cancer (e.g. p53 mutations). Germ line DNA repair mutations are noted on the figure's left side. However, such germline mutations (which cause highly penetrant cancer syndromes) are the cause of only about 1 percent of cancers.In sporadic cancers, deficiencies in DNA repair are occasionally caused by a mutation in a DNA repair gene but are much more frequently caused by epigenetic alterations that reduce or silence expression of DNA repair genes. This is indicated in the figure at the 3rd level. Many studies of heavy metal-induced carcinogenesis show that such heavy metals cause a reduction in expression of DNA repair enzymes, some through epigenetic mechanisms. DNA repair inhibition is proposed to be a predominant mechanism in heavy metal-induced carcinogenicity. In addition, frequent epigenetic alterations of the DNA sequences code for small RNAs called microRNAs (or miRNAs). miRNAs do not code for proteins, but can \"target\" protein-coding genes and reduce their expression.\\nCancers usually arise from an assemblage of mutations and epimutations that confer a selective advantage leading to clonal expansion (see Field defects in progression to cancer). Mutations, however, may not be as frequent in cancers as epigenetic alterations. An average cancer of the breast or colon can have about 60 to 70 protein-altering mutations, of which about three or four may be \"driver\" mutations and the remaining ones may be \"passenger\" mutations.\\n\\nMetastasis\\nMetastasis is the spread of cancer to other locations in the body. The dispersed tumors are called metastatic tumors, while the original is called the primary tumor. Almost all cancers can metastasize. Most cancer deaths are due to cancer that has metastasized.Metastasis is common in the late stages of cancer and it can occur via the blood or the lymphatic system or both. The typical steps in metastasis are local invasion, intravasation into the blood or lymph, circulation through the body, extravasation into the new tissue, proliferation and angiogenesis. Different types of cancers tend to metastasize to particular organs, but overall the most common places for metastases to occur are the lungs, liver, brain and the bones.\\n\\nMetabolism\\nNormal cells typically generate only about 30% of energy from glycolysis, whereas most cancers rely on glycolysis for energy production (Warburg effect). But a minority of cancer types rely on oxidative phosphorylation as the primary energy source, including lymphoma, leukemia, and endometrial cancer. Even in these cases, however, the use of glycolysis as an energy source rarely exceeds 60%. A few cancers use glutamine as the major energy source, partly because it provides nitrogen required for nucleotide (DNA, RNA) synthesis. Cancer stem cells often use oxidative phosphorylation or glutamine as a primary energy source.\\n\\nDiagnosis\\nMost cancers are initially recognized either because of the appearance of signs or symptoms or through screening. Neither of these leads to a definitive diagnosis, which requires the examination of a tissue sample by a pathologist. People with suspected cancer are investigated with medical tests. These commonly include blood tests, X-rays, (contrast) CT scans and endoscopy.\\nThe tissue diagnosis from the biopsy indicates the type of cell that is proliferating, its histological grade, genetic abnormalities and other features. Together, this information is useful to evaluate the prognosis and to choose the best treatment.\\nCytogenetics and immunohistochemistry are other types of tissue tests. These tests provide information about molecular changes (such as mutations, fusion genes and numerical chromosome changes) and may thus also indicate the prognosis and best treatment.\\nCancer diagnosis can cause psychological distress and psychosocial interventions, such as talking therapy, may help people with this.  Some people choose to disclose the diagnosis widely; others prefer to keep the information private, especially shortly after the diagnosis, or to disclose it only partially or to selected people.\\n\\nClassification\\nCancers are classified by the type of cell that the tumor cells resemble and is therefore presumed to be the origin of the tumor. These types include:\\n\\nCarcinoma: Cancers derived from epithelial cells. This group includes many of the most common cancers and include nearly all those in the breast, prostate, lung, pancreas and colon. Most of these are of the adenocarcinoma type, which means that the cancer has gland-like differentiation.\\nSarcoma: Cancers arising from connective tissue (i.e. bone, cartilage, fat, nerve), each of which develops from cells originating in mesenchymal cells outside the bone marrow.\\nLymphoma and leukemia: These two classes arise from hematopoietic (blood-forming) cells that leave the marrow and tend to mature in the lymph nodes and blood, respectively.\\nGerm cell tumor: Cancers derived from pluripotent cells, most often presenting in the testicle or the ovary (seminoma and dysgerminoma, respectively).\\nBlastoma: Cancers derived from immature \"precursor\" cells or embryonic tissue.Cancers are usually named using -carcinoma, -sarcoma or -blastoma as a suffix, with the Latin or Greek word for the organ or tissue of origin as the root. For example, cancers of the liver parenchyma arising from malignant epithelial cells is called hepatocarcinoma, while a malignancy arising from primitive liver precursor cells is called a hepatoblastoma and a cancer arising from fat cells is called a liposarcoma. For some common cancers, the English organ name is used. For example, the most common type of breast cancer is called ductal carcinoma of the breast. Here, the adjective ductal refers to the appearance of cancer under the microscope, which suggests that it has originated in the milk ducts.\\nBenign tumors (which are not cancers) are named using -oma as a suffix with the organ name as the root. For example, a benign tumor of smooth muscle cells is called a leiomyoma (the common name of this frequently occurring benign tumor in the uterus is fibroid). Confusingly, some types of cancer use the -noma suffix, examples including melanoma and seminoma.\\nSome types of cancer are named for the size and shape of the cells under a microscope, such as giant cell carcinoma, spindle cell carcinoma and small-cell carcinoma.\\n\\nPrevention\\nCancer prevention is defined as active measures to decrease cancer risk. The vast majority of cancer cases are due to environmental risk factors. Many of these environmental factors are controllable lifestyle choices. Thus, cancer is generally preventable. Between 70% and 90% of common cancers are due to environmental factors and therefore potentially preventable.Greater than 30% of cancer deaths could be prevented by avoiding risk factors including: tobacco, excess weight/obesity, poor diet, physical inactivity, alcohol, sexually transmitted infections and air pollution. Further, poverty could be considered as an indirect risk factor in human cancers. Not all environmental causes are controllable, such as naturally occurring background radiation and cancers caused through hereditary genetic disorders and thus are not preventable via personal behavior.\\nIn 2019, ~44% of all cancer deaths \u2013 or ~4.5 M deaths or ~105 million lost disability-adjusted life years \u2013 were due to known clearly preventable risk factors, led by smoking, alcohol use and high BMI, according to a GBD systematic analysis.\\n\\nDietary\\nWhile many dietary recommendations have been proposed to reduce cancer risks, the evidence to support them is not definitive. The primary dietary factors that increase risk are obesity and alcohol consumption. Diets low in fruits and vegetables and high in red meat have been implicated but reviews and meta-analyses do not come to a consistent conclusion. A 2014 meta-analysis found no relationship between fruits and vegetables and cancer. Coffee is associated with a reduced risk of liver cancer. Studies have linked excessive consumption of red or processed meat to an increased risk of breast cancer, colon cancer and pancreatic cancer, a phenomenon that could be due to the presence of carcinogens in meats cooked at high temperatures. In 2015 the IARC reported that eating processed meat (e.g., bacon, ham, hot dogs, sausages) and, to a lesser degree, red meat was linked to some cancers.Dietary recommendations for cancer prevention typically include an emphasis on vegetables, fruit, whole grains and fish and an avoidance of processed and red meat (beef, pork, lamb), animal fats, pickled foods and refined carbohydrates.\\n\\nMedication\\nMedications can be used to prevent cancer in a few circumstances. In the general population, NSAIDs reduce the risk of colorectal cancer; however, due to cardiovascular and gastrointestinal side effects, they cause overall harm when used for prevention. Aspirin has been found to reduce the risk of death from cancer by about 7%. COX-2 inhibitors may decrease the rate of polyp formation in people with familial adenomatous polyposis; however, it is associated with the same adverse effects as NSAIDs. Daily use of tamoxifen or raloxifene reduce the risk of breast cancer in high-risk women. The benefit versus harm for 5-alpha-reductase inhibitor such as finasteride is not clear.Vitamin supplementation does not appear to be effective at preventing cancer. While low blood levels of vitamin D are correlated with increased cancer risk, whether this relationship is causal and vitamin D supplementation is protective is not determined. One 2014 review found that supplements had no significant effect on cancer risk. Another 2014 review concluded that vitamin D3 may decrease the risk of death from cancer (one fewer death in 150 people treated over 5 years), but concerns with the quality of the data were noted.Beta-Carotene supplementation increases lung cancer rates in those who are high risk. Folic acid supplementation is not effective in preventing colon cancer and may increase colon polyps. Selenium supplementation has not been shown to reduce the risk of cancer.\\n\\nVaccination\\nVaccines have been developed that prevent infection by some carcinogenic viruses. Human papillomavirus vaccine (Gardasil and Cervarix) decrease the risk of developing cervical cancer. The hepatitis B vaccine prevents infection with hepatitis B virus and thus decreases the risk of liver cancer. The administration of human papillomavirus and hepatitis B vaccinations is recommended where resources allow.\\n\\nScreening\\nUnlike diagnostic efforts prompted by symptoms and medical signs, cancer screening involves efforts to detect cancer after it has formed, but before any noticeable symptoms appear. This may involve physical examination, blood or urine tests or medical imaging.Cancer screening is not available for many types of cancers. Even when tests are available, they may not be recommended for everyone. Universal screening or mass screening involves screening everyone. Selective screening identifies people who are at higher risk, such as people with a family history. Several factors are considered to determine whether the benefits of screening outweigh the risks and the costs of screening. These factors include:\\n\\nPossible harms from the screening test: for example, X-ray images involve exposure to potentially harmful ionizing radiation\\nThe likelihood of the test correctly identifying cancer\\nThe likelihood that cancer is present: Screening is not normally useful for rare cancers.\\nPossible harms from follow-up procedures\\nWhether suitable treatment is available\\nWhether early detection improves treatment outcomes\\nWhether cancer will ever need treatment\\nWhether the test is acceptable to the people: If a screening test is too burdensome (for example, extremely painful), then people will refuse to participate.\\nCost\\n\\nRecommendations\\nU.S. Preventive Services Task Force\\nThe U.S. Preventive Services Task Force (USPSTF) issues recommendations for various cancers:\\n\\nStrongly recommends cervical cancer screening in women who are sexually active and have a cervix at least until the age of 65.\\nRecommend that Americans be screened for colorectal cancer via fecal occult blood testing, sigmoidoscopy, or colonoscopy starting at age 50 until age 75.\\nEvidence is insufficient to recommend for or against screening for skin cancer, oral cancer, lung cancer, or prostate cancer in men under 75.\\nRoutine screening is not recommended for bladder cancer, testicular cancer, ovarian cancer, pancreatic cancer, or prostate cancer.\\nRecommends mammography for breast cancer screening every two years from ages 50\u201374, but does not recommend either breast self-examination or clinical breast examination. A 2013 Cochrane review concluded that breast cancer screening by mammography had no effect in reducing mortality because of overdiagnosis and overtreatment.\\n\\nJapan\\nScreens for gastric cancer using photofluorography due to the high incidence there.\\n\\nGenetic testing\\nGenetic testing for individuals at high-risk of certain cancers is recommended by unofficial groups. Carriers of these mutations may then undergo enhanced surveillance, chemoprevention, or preventative surgery to reduce their subsequent risk.\\n\\nManagement\\nMany treatment options for cancer exist. The primary ones include surgery, chemotherapy, radiation therapy, hormonal therapy, targeted therapy and palliative care. Which treatments are used depends on the type, location and grade of the cancer as well as the patient's health and preferences. The treatment intent may or may not be curative.\\n\\nChemotherapy\\nChemotherapy is the treatment of cancer with one or more cytotoxic anti-neoplastic drugs (chemotherapeutic agents) as part of a standardized regimen. The term encompasses a variety of drugs, which are divided into broad categories such as alkylating agents and antimetabolites. Traditional chemotherapeutic agents act by killing cells that divide rapidly, a critical property of most cancer cells.\\nIt was found that providing combined cytotoxic drugs is better than a single drug, a process called the combination therapy, which has an advantage in the statistics of survival and response to the tumor and in the progress of the disease. A Cochrane review concluded that combined therapy was more effective to treat metastasized breast cancer. However, generally it is not certain whether combination chemotherapy leads to better health outcomes, when both survival and toxicity are considered.Targeted therapy is a form of chemotherapy that targets specific molecular differences between cancer and normal cells. The first targeted therapies blocked the estrogen receptor molecule, inhibiting the growth of breast cancer. Another common example is the class of Bcr-Abl inhibitors, which are used to treat chronic myelogenous leukemia (CML). Currently, targeted therapies exist for many of the most common cancer types, including bladder cancer, breast cancer, colorectal cancer, kidney cancer, leukemia, liver cancer, lung cancer, lymphoma, pancreatic cancer, prostate cancer, skin cancer, and thyroid cancer as well as other cancer types.The efficacy of chemotherapy depends on the type of cancer and the stage. In combination with surgery, chemotherapy has proven useful in cancer types including breast cancer, colorectal cancer, pancreatic cancer, osteogenic sarcoma, testicular cancer, ovarian cancer and certain lung cancers. Chemotherapy is curative for some cancers, such as some leukemias, ineffective in some brain tumors, and needless in others, such as most non-melanoma skin cancers. The effectiveness of chemotherapy is often limited by its toxicity to other tissues in the body. Even when chemotherapy does not provide a permanent cure, it may be useful to reduce symptoms such as pain or to reduce the size of an inoperable tumor in the hope that surgery will become possible in the future.\\n\\nRadiation\\nRadiation therapy involves the use of ionizing radiation in an attempt to either cure or improve symptoms. It works by damaging the DNA of cancerous tissue, causing mitotic catastrophe resulting in the death of the cancer cells. To spare normal tissues (such as skin or organs, which radiation must pass through to treat the tumor), shaped radiation beams are aimed from multiple exposure angles to intersect at the tumor, providing a much larger dose there than in the surrounding, healthy tissue. As with chemotherapy, cancers vary in their response to radiation therapy.Radiation therapy is used in about half of cases. The radiation can be either from internal sources (brachytherapy) or external sources. The radiation is most commonly low energy X-rays for treating skin cancers, while higher energy X-rays are used for cancers within the body. Radiation is typically used in addition to surgery and or chemotherapy. For certain types of cancer, such as early head and neck cancer, it may be used alone. Radiation therapy after surgery for brain metastases has been shown to not improve overall survival in patients compared to surgery alone. For painful bone metastasis, radiation therapy has been found to be effective in about 70% of patients.\\n\\nSurgery\\nSurgery is the primary method of treatment for most isolated, solid cancers and may play a role in palliation and prolongation of survival. It is typically an important part of definitive diagnosis and staging of tumors, as biopsies are usually required. In localized cancer, surgery typically attempts to remove the entire mass along with, in certain cases, the lymph nodes in the area. For some types of cancer this is sufficient to eliminate the cancer.\\n\\nPalliative care\\nPalliative care is treatment that attempts to help the patient feel better and may be combined with an attempt to treat the cancer. Palliative care includes action to reduce physical, emotional, spiritual and psycho-social distress. Unlike treatment that is aimed at directly killing cancer cells, the primary goal of palliative care is to improve quality of life.\\nPeople at all stages of cancer treatment typically receive some kind of palliative care. In some cases, medical specialty professional organizations recommend that patients and physicians respond to cancer only with palliative care. This applies to patients who:\\ndisplay low performance status, implying limited ability to care for themselves\\nreceived no benefit from prior evidence-based treatments\\nare not eligible to participate in any appropriate clinical trial\\nno strong evidence implies that treatment would be effectivePalliative care may be confused with hospice and therefore only indicated when people approach end of life. Like hospice care, palliative care attempts to help the patient cope with their immediate needs and to increase comfort. Unlike hospice care, palliative care does not require people to stop treatment aimed at the cancer.\\nMultiple national medical guidelines recommend early palliative care for patients whose cancer has produced distressing symptoms or who need help coping with their illness. In patients first diagnosed with metastatic disease, palliative care may be immediately indicated. Palliative care is indicated for patients with a prognosis of less than 12 months of life even given aggressive treatment.\\n\\nImmunotherapy\\nA variety of therapies using immunotherapy, stimulating or helping the immune system to fight cancer, have come into use since 1997. Approaches include antibodies, checkpoint therapy, and adoptive cell transfer.\\n\\nLaser therapy\\nLaser therapy uses high-intensity light to treat cancer by shrinking or destroying tumors or precancerous growths. Lasers are most commonly used to treat superficial cancers that are on the surface of the body or the lining of internal organs. It is used to treat basal cell skin cancer and the very early stages of others like cervical, penile, vaginal, vulvar, and non-small cell lung cancer. It is often combined with other treatments, such as surgery, chemotherapy, or radiation therapy. Laser-induced interstitial thermotherapy (LITT), or interstitial laser photocoagulation, uses lasers to treat some cancers using hyperthermia, which uses heat to shrink tumors by damaging or killing cancer cells. Laser are more precise than surgery and cause less damage, pain, bleeding, swelling, and scarring. A disadvantage is surgeons must have specialized training. It may be more expensive than other treatments.\\n\\nAlternative medicine\\nComplementary and alternative cancer treatments are a diverse group of therapies, practices and products that are not part of conventional medicine. \"Complementary medicine\" refers to methods and substances used along with conventional medicine, while \"alternative medicine\" refers to compounds used instead of conventional medicine. Most complementary and alternative medicines for cancer have not been studied or tested using conventional techniques such as clinical trials. Some alternative treatments have been investigated and shown to be ineffective but still continue to be marketed and promoted. Cancer researcher Andrew J. Vickers stated, \"The label 'unproven' is inappropriate for such therapies; it is time to assert that many alternative cancer therapies have been 'disproven'.\"\\n\\nPrognosis\\nSurvival rates vary by cancer type and by the stage at which it is diagnosed, ranging from majority survival to complete mortality five years after diagnosis. Once a cancer has metastasized, prognosis normally becomes much worse. About half of patients receiving treatment for invasive cancer (excluding carcinoma in situ and non-melanoma skin cancers) die from that cancer or its treatment. A majority of cancer deaths are due to metastases of the primary tumor.Survival is worse in the developing world, partly because the types of cancer that are most common there are harder to treat than those associated with developed countries.Those who survive cancer develop a second primary cancer at about twice the rate of those never diagnosed. The increased risk is believed to be due to the random chance of developing any cancer, the likelihood of surviving the first cancer, the same risk factors that produced the first cancer, unwanted side effects of treating the first cancer (particularly radiation therapy), and better compliance with screening.Predicting short- or long-term survival depends on many factors. The most important are the cancer type and the patient's age and overall health. Those who are frail with other health problems have lower survival rates than otherwise healthy people. Centenarians are unlikely to survive for five years even if treatment is successful. People who report a higher quality of life tend to survive longer. People with lower quality of life may be affected by depression and other complications and/or disease progression that both impairs quality and quantity of life. Additionally, patients with worse prognoses may be depressed or report poorer quality of life because they perceive that their condition is likely to be fatal.\\nPeople with cancer have an increased risk of blood clots in their veins which can be life-threatening. The use of blood thinners such as heparin decrease the risk of blood clots but have not been shown to increase survival in people with cancer. People who take blood thinners also have an increased risk of bleeding.Although extremely rare, some forms of cancer, even from an advanced stage, can heal spontaneously. This phenomenon is known as the spontaneous remission.\\n\\nEpidemiology\\nEstimates are that in 2018, 18.1 million new cases of cancer and 9.6 million deaths occur globally. About 20% of males and 17% of females will get cancer at some point in time while 13% of males and 9% of females will die from it.In 2008, approximately 12.7 million cancers were diagnosed (excluding non-melanoma skin cancers and other non-invasive cancers) and in 2010 nearly 7.98 million people died. Cancers account for approximately 16% of deaths. The most common as of 2018 are lung cancer (1.76 million deaths), colorectal cancer (860,000) stomach cancer (780,000), liver cancer (780,000), and breast cancer (620,000). This makes invasive cancer the leading cause of death in the developed world and the second leading in the developing world. Over half of cases occur in the developing world.Deaths from cancer were 5.8 million in 1990. Deaths have been increasing primarily due to longer lifespans and lifestyle changes in the developing world. The most significant risk factor for developing cancer is age. Although it is possible for cancer to strike at any age, most patients with invasive cancer are over 65. According to cancer researcher Robert A. Weinberg, \"If we lived long enough, sooner or later we all would get cancer.\" Some of the association between aging and cancer is attributed to immunosenescence, errors accumulated in DNA over a lifetime and age-related changes in the endocrine system. Aging's effect on cancer is complicated by factors such as DNA damage and inflammation promoting it and factors such as vascular aging and endocrine changes inhibiting it.Some slow-growing cancers are particularly common, but often are not fatal. Autopsy studies in Europe and Asia showed that up to 36% of people have undiagnosed and apparently harmless thyroid cancer at the time of their deaths and that 80% of men develop prostate cancer by age 80. As these cancers do not cause the patient's death, identifying them would have represented overdiagnosis rather than useful medical care.\\nThe three most common childhood cancers are leukemia (34%), brain tumors (23%) and lymphomas (12%). In the United States cancer affects about 1 in 285 children. Rates of childhood cancer increased by 0.6% per year between 1975 and 2002 in the United States and by 1.1% per year between 1978 and 1997 in Europe. Death from childhood cancer decreased by half between 1975 and 2010 in the United States.\\n\\nHistory\\nCancer has existed for all of human history. The earliest written record regarding cancer is from circa 1600 BC in the Egyptian Edwin Smith Papyrus and describes breast cancer. Hippocrates (c.\u2009460 BC \u2013 c.\u2009370 BC) described several kinds of cancer, referring to them with the Greek word \u03ba\u03b1\u03c1\u03ba\u03af\u03bd\u03bf\u03c2 karkinos (crab or crayfish). This name comes from the appearance of the cut surface of a solid malignant tumor, with \"the veins stretched on all sides as the animal the crab has its feet, whence it derives its name\". Galen stated that \"cancer of the breast is so called because of the fancied resemblance to a crab given by the lateral prolongations of the tumor and the adjacent distended veins\".:\u200a738\u200a Celsus (c.\u200925 BC \u2013 50 AD) translated karkinos into the Latin cancer, also meaning crab and recommended surgery as treatment. Galen (2nd century AD) disagreed with the use of surgery and recommended purgatives instead. These recommendations largely stood for 1000 years.In the 15th, 16th and 17th centuries, it became acceptable for doctors to dissect bodies to discover the cause of death. The German professor Wilhelm Fabry believed that breast cancer was caused by a milk clot in a mammary duct. The Dutch professor Francois de la Boe Sylvius, a follower of Descartes, believed that all disease was the outcome of chemical processes and that acidic lymph fluid was the cause of cancer. His contemporary Nicolaes Tulp believed that cancer was a poison that slowly spreads and concluded that it was contagious.The physician John Hill described tobacco sniffing as the cause of nose cancer in 1761. This was followed by the report in 1775 by British surgeon Percivall Pott that chimney sweeps' carcinoma, a cancer of the scrotum, was a common disease among chimney sweeps. With the widespread use of the microscope in the 18th century, it was discovered that the 'cancer poison' spread from the primary tumor through the lymph nodes to other sites (\"metastasis\"). This view of the disease was first formulated by the English surgeon Campbell De Morgan between 1871 and 1874.\\n\\nSociety and culture\\nAlthough many diseases (such as heart failure) may have a worse prognosis than most cases of cancer, cancer is the subject of widespread fear and taboos. The euphemism of \"a long illness\" to describe cancers leading to death is still commonly used in obituaries, rather than naming the disease explicitly, reflecting an apparent stigma. Cancer is also euphemised as \"the C-word\"; Macmillan Cancer Support uses the term to try to lessen the fear around the disease. In Nigeria, one local name for cancer translates into English as \"the disease that cannot be cured\". This deep belief that cancer is necessarily a difficult and usually deadly disease is reflected in the systems chosen by society to compile cancer statistics: the most common form of cancer\u2014non-melanoma skin cancers, accounting for about one-third of cancer cases worldwide, but very few deaths\u2014are excluded from cancer statistics specifically because they are easily treated and almost always cured, often in a single, short, outpatient procedure.Western conceptions of patients' rights for people with cancer include a duty to fully disclose the medical situation to the person, and the right to engage in shared decision-making in a way that respects the person's own values. In other cultures, other rights and values are preferred. For example, most African cultures value whole families rather than individualism. In parts of Africa, a diagnosis is commonly made so late that cure is not possible, and treatment, if available at all, would quickly bankrupt the family. As a result of these factors, African healthcare providers tend to let family members decide whether, when and how to disclose the diagnosis, and they tend to do so slowly and circuitously, as the person shows interest and an ability to cope with the grim news. People from Asian and South American countries also tend to prefer a slower, less candid approach to disclosure than is idealized in the United States and Western Europe, and they believe that sometimes it would be preferable not to be told about a cancer diagnosis. In general, disclosure of the diagnosis is more common than it was in the 20th century, but full disclosure of the prognosis is not offered to many patients around the world.In the United States and some other cultures, cancer is regarded as a disease that must be \"fought\" to end the \"civil insurrection\"; a War on Cancer was declared in the US. Military metaphors are particularly common in descriptions of cancer's human effects, and they emphasize both the state of the patient's health and the need to take immediate, decisive actions himself rather than to delay, to ignore or to rely entirely on others. The military metaphors also help rationalize radical, destructive treatments.In the 1970s, a relatively popular alternative cancer treatment in the US was a specialized form of talk therapy, based on the idea that cancer was caused by a bad attitude. People with a \"cancer personality\"\u2014depressed, repressed, self-loathing and afraid to express their emotions\u2014were believed to have manifested cancer through subconscious desire. Some psychotherapists claimed that treatment to change the patient's outlook on life would cure the cancer. Among other effects, this belief allowed society to blame the victim for having caused the cancer (by \"wanting\" it) or having prevented its cure (by not becoming a sufficiently happy, fearless and loving person). It also increased patients' anxiety, as they incorrectly believed that natural emotions of sadness, anger or fear shorten their lives. The idea was ridiculed by Susan Sontag, who published Illness as Metaphor while recovering from treatment for breast cancer in 1978. Although the original idea is now generally regarded as nonsense, the idea partly persists in a reduced form with a widespread, but incorrect, belief that deliberately cultivating a habit of positive thinking will increase survival. This notion is particularly strong in breast cancer culture.One idea about why people with cancer are blamed or stigmatized, called the just-world hypothesis, is that blaming cancer on the patient's actions or attitudes allows the blamers to regain a sense of control. This is based upon the blamers' belief that the world is fundamentally just and so any dangerous illness, like cancer, must be a type of punishment for bad choices, because in a just world, bad things would not happen to good people.\\n\\nEconomic effect\\nThe total health care expenditure on cancer in the US was estimated to be $80.2 billion in 2015. Even though cancer-related health care expenditure have increased in absolute terms during recent decades, the share of health expenditure devoted to cancer treatment has remained close to 5% between the 1960s and 2004. A similar pattern has been observed in Europe where about 6% of all health care expenditure are spent on cancer treatment. In addition to health care expenditure and financial toxicity, cancer causes indirect costs in the form of productivity losses due to sick days, permanent incapacity and disability as well as premature death during working age. Cancer causes also costs for informal care. Indirect costs and informal care costs are typically estimated to exceed or equal the health care costs of cancer.\\n\\nWorkplace\\nIn the United States, cancer is included as a protected condition by the Equal Employment Opportunity Commission (EEOC), mainly due to the potential for cancer having discriminating effects on workers. Discrimination in the workplace could occur if an employer holds a false belief that a person with cancer is not capable of doing a job properly, and may ask for more sick leave than other employees. Employers may also make hiring or firing decisions based on misconceptions about cancer disabilities, if present. The EEOC provides interview guidelines for employers, as well as lists of possible solutions for assessing and accommodating employees with cancer.\\n\\nDivorce gender disparity\\nWomen are six times more likely to be separated or divorced soon after a diagnosis of cancer or multiple sclerosis than men. Doctors in neuro-oncology practices noticed that divorce occurred almost exclusively when the wife was the patient.\\n\\nResearch\\nBecause cancer is a class of diseases, it is unlikely that there will ever be a single \"cure for cancer\" any more than there will be a single treatment for all infectious diseases. Angiogenesis inhibitors were once incorrectly thought to have potential as a \"silver bullet\" treatment applicable to many types of cancer. Angiogenesis inhibitors and other cancer therapeutics are used in combination to reduce cancer morbidity and mortality.Experimental cancer treatments are studied in clinical trials to compare the proposed treatment to the best existing treatment. Treatments that succeeded in one cancer type can be tested against other types. Diagnostic tests are under development to better target the right therapies to the right patients, based on their individual biology.Cancer research focuses on the following issues:\\n\\nAgents (e.g. viruses) and events (e.g. mutations) that cause or facilitate genetic changes in cells destined to become cancer.\\nThe precise nature of the genetic damage and the genes that are affected by it.\\nThe consequences of those genetic changes on the biology of the cell, both in generating the defining properties of a cancer cell and in facilitating additional genetic events that lead to further progression of the cancer.The improved understanding of molecular biology and cellular biology due to cancer research has led to new treatments for cancer since US President Richard Nixon declared the \"War on Cancer\" in 1971. Since then, the country has spent over $200 billion on cancer research, including resources from public and private sectors. The cancer death rate (adjusting for size and age of the population) declined by five percent between 1950 and 2005.Competition for financial resources appears to have suppressed the creativity, cooperation, risk-taking and original thinking required to make fundamental discoveries, unduly favoring low-risk research into small incremental advancements over riskier, more innovative research. Other consequences of competition appear to be many studies with dramatic claims whose results cannot be replicated and perverse incentives that encourage grantee institutions to grow without making sufficient investments in their own faculty and facilities.Virotherapy, which uses convert viruses, is being studied.\\nIn the wake of the COVID-19 pandemic, there has been a worry that cancer research and treatment are slowing down.\\n\\nPregnancy\\nCancer affects approximately 1 in 1,000 pregnant women. The most common cancers found during pregnancy are the same as the most common cancers found in non-pregnant women during childbearing ages: breast cancer, cervical cancer, leukemia, lymphoma, melanoma, ovarian cancer and colorectal cancer.Diagnosing a new cancer in a pregnant woman is difficult, in part because any symptoms are commonly assumed to be a normal discomfort associated with pregnancy. As a result, cancer is typically discovered at a somewhat later stage than average. Some imaging procedures, such as MRIs (magnetic resonance imaging), CT scans, ultrasounds and mammograms with fetal shielding are considered safe during pregnancy; some others, such as PET scans, are not.Treatment is generally the same as for non-pregnant women. However, radiation and radioactive drugs are normally avoided during pregnancy, especially if the fetal dose might exceed 100 cGy. In some cases, some or all treatments are postponed until after birth if the cancer is diagnosed late in the pregnancy. Early deliveries are often used to advance the start of treatment. Surgery is generally safe, but pelvic surgeries during the first trimester may cause miscarriage. Some treatments, especially certain chemotherapy drugs given during the first trimester, increase the risk of birth defects and pregnancy loss (spontaneous abortions and stillbirths).Elective abortions are not required and, for the most common forms and stages of cancer, do not improve the mother's survival. In a few instances, such as advanced uterine cancer, the pregnancy cannot be continued and in others, the patient may end the pregnancy so that she can begin aggressive chemotherapy.Some treatments can interfere with the mother's ability to give birth vaginally or to breastfeed. Cervical cancer may require birth by Caesarean section. Radiation to the breast reduces the ability of that breast to produce milk and increases the risk of mastitis. Also, when chemotherapy is given after birth, many of the drugs appear in breast milk, which could harm the baby.\\n\\nOther animals\\nVeterinary oncology, concentrating mainly on cats and dogs, is a growing specialty in wealthy countries and the major forms of human treatment such as surgery and radiotherapy may be offered. The most common types of cancer differ, but the cancer burden seems at least as high in pets as in humans. Animals, typically rodents, are often used in cancer research and studies of natural cancers in larger animals may benefit research into human cancer.Across wild animals, there is still limited data on cancer. Nonetheless, a study published in 2022, explored cancer risk in (non-domesticated) zoo mammals, belonging to 191 species, 110,148 individual, demonstrated that cancer is a ubiquitous disease of mammals and it can emerge anywhere along the mammalian phylogeny. This research also highlighted that cancer risk is not uniformly distributed along mammals. For instance, species in the order Carnivora are particularly prone to be affected by cancer (e.g. over 25% of clouded leopards, bat-eared foxes and red wolves die of cancer), while ungulates (especially even-toed ungulates) appear to face consistently low cancer risks.\\nIn non-humans, a few types of transmissible cancer have also been described, wherein the cancer spreads between animals by transmission of the tumor cells themselves. This phenomenon is seen in dogs with Sticker's sarcoma (also known as canine transmissible venereal tumor), and in Tasmanian devils with devil facial tumour disease (DFTD).\\n\\nReferences\\nFurther reading\\nExternal links\\n\\nIARC Publications\\n\"On telling cancer patients to have a positive attitude\" at The Atlantic\\nWHO fact sheet on cancer"}
{"article_name": "Black_hole", "link": "https://en.wikipedia.org/wiki/Black_hole", "text_content": "A black hole is a region of spacetime where gravity is so strong that nothing, including light and other electromagnetic waves, has enough energy to escape it. The theory of general relativity predicts that a sufficiently compact mass can deform spacetime to form a black hole. The boundary of no escape is called the event horizon. A black hole has a great effect on the fate and circumstances of an object crossing it, but it has no locally detectable features according to general relativity. In many ways, a black hole acts like an ideal black body, as it reflects no light. Moreover, quantum field theory in curved spacetime predicts that event horizons emit Hawking radiation, with the same spectrum as a black body of a temperature inversely proportional to its mass. This temperature is of the order of billionths of a kelvin for stellar black holes, making it essentially impossible to observe directly.\\nObjects whose gravitational fields are too strong for light to escape were first considered in the 18th century by John Michell and Pierre-Simon Laplace. In 1916, Karl Schwarzschild found the first modern solution of general relativity that would characterize a black hole. David Finkelstein, in 1958, first published the interpretation of \"black hole\" as a region of space from which nothing can escape. Black holes were long considered a mathematical curiosity; it was not until the 1960s that theoretical work showed they were a generic prediction of general relativity. The discovery of neutron stars by Jocelyn Bell Burnell in 1967 sparked interest in gravitationally collapsed compact objects as a possible astrophysical reality. The first black hole known was Cygnus X-1, identified by several researchers independently in 1971.Black holes of stellar mass form when massive stars collapse at the end of their life cycle. After a black hole has formed, it can grow by absorbing mass from its surroundings. Supermassive black holes of millions of solar masses (M\u2609) may form by absorbing other stars and merging with other black holes. There is consensus that supermassive black holes exist in the centres of most galaxies.\\nThe presence of a black hole can be inferred through its interaction with other matter and with electromagnetic radiation such as visible light. Any matter that falls onto a black hole can form an external accretion disk heated by friction, forming quasars, some of the brightest objects in the universe. Stars passing too close to a supermassive black hole can be shredded into streamers that shine very brightly before being \"swallowed.\" If other stars are orbiting a black hole, their orbits can be used to determine the black hole's mass and location. Such observations can be used to exclude possible alternatives such as neutron stars. In this way, astronomers have identified numerous stellar black hole candidates in binary systems and established that the radio source known as Sagittarius A*, at the core of the Milky Way galaxy, contains a supermassive black hole of about 4.3 million solar masses.\\n\\nHistory\\nThe idea of a body so big that even light could not escape was briefly proposed by English astronomical pioneer and clergyman John Michell in a letter published in November 1784. Michell's simplistic calculations assumed such a body might have the same density as the Sun, and concluded that one would form when a star's diameter exceeds the Sun's by a factor of 500, and its surface escape velocity exceeds the usual speed of light. Michell referred to these bodies as dark stars. He correctly noted that such supermassive but non-radiating bodies might be detectable through their gravitational effects on nearby visible bodies. Scholars of the time were initially excited by the proposal that giant but invisible 'dark stars' might be hiding in plain view, but enthusiasm dampened when the wavelike nature of light became apparent in the early nineteenth century, as if light were a wave rather than a particle, it was unclear what, if any, influence gravity would have on escaping light waves.The modern theory of gravity, general relativity, discredits Michell's notion of a light ray shooting directly from the surface of a supermassive star, being slowed down by the star's gravity, stopping, and then free-falling back to the star's surface. Instead, spacetime itself is curved such that the geodesic light travels on never leaves the surface of the \"star\" (black hole).\\n\\nGeneral relativity\\nIn 1915, Albert Einstein developed his theory of general relativity, having earlier shown that gravity does influence light's motion. Only a few months later, Karl Schwarzschild found a solution to the Einstein field equations that describes the gravitational field of a point mass and a spherical mass. A few months after Schwarzschild, Johannes Droste, a student of Hendrik Lorentz, independently gave the same solution for the point mass and wrote more extensively about its properties. This solution had a peculiar behaviour at what is now called the Schwarzschild radius, where it became singular, meaning that some of the terms in the Einstein equations became infinite. The nature of this surface was not quite understood at the time. \\nIn 1924, Arthur Eddington showed that the singularity disappeared after a change of coordinates, although it took until 1933 for Georges Lema\u00eetre to realize that this meant the singularity at the Schwarzschild radius was a non-physical coordinate singularity. Arthur Eddington did however comment on the possibility of a star with mass compressed to the Schwarzschild radius in a 1926 book, noting that Einstein's theory allows us to rule out overly large densities for visible stars like Betelgeuse because \"a star of 250 million km radius could not possibly have so high a density as the Sun. Firstly, the force of gravitation would be so great that light would be unable to escape from it, the rays falling back to the star like a stone to the earth. Secondly, the red shift of the spectral lines would be so great that the spectrum would be shifted out of existence. Thirdly, the mass would produce so much curvature of the spacetime metric that space would close up around the star, leaving us outside (i.e., nowhere).\"In 1931, Subrahmanyan Chandrasekhar calculated, using special relativity, that a non-rotating body of electron-degenerate matter above a certain limiting mass (now called the Chandrasekhar limit at 1.4 M\u2609) has no stable solutions. His arguments were opposed by many of his contemporaries like Eddington and Lev Landau, who argued that some yet unknown mechanism would stop the collapse. They were partly correct: a white dwarf slightly more massive than the Chandrasekhar limit will collapse into a neutron star, which is itself stable. But in 1939, Robert Oppenheimer and others predicted that neutron stars above another limit (the Tolman\u2013Oppenheimer\u2013Volkoff limit) would collapse further for the reasons presented by Chandrasekhar, and concluded that no law of physics was likely to intervene and stop at least some stars from collapsing to black holes. Their original calculations, based on the Pauli exclusion principle, gave it as 0.7 M\u2609; subsequent consideration of neutron-neutron repulsion mediated by the strong force raised the estimate to approximately 1.5 M\u2609 to 3.0 M\u2609. Observations of the neutron star merger GW170817, which is thought to have generated a black hole shortly afterward, have refined the TOV limit estimate to ~2.17 M\u2609. Oppenheimer and his co-authors interpreted the singularity at the boundary of the Schwarzschild radius as indicating that this was the boundary of a bubble in which time stopped. This is a valid point of view for external observers, but not for infalling observers. Because of this property, the collapsed stars were called \"frozen stars\", because an outside observer would see the surface of the star frozen in time at the instant where its collapse takes it to the Schwarzschild radius.Also in 1939, Einstein would attempt to prove that black holes were impossible in his publication \"On a Stationary System with Spherical Symmetry Consisting of Many Gravitating Masses\", using his theory of general relativity to defend his argument. Months later, Oppenheimer and his student Hartland Snyder would provide the Oppenheimer\u2013Snyder model in their paper \"On Continued Gravitational Contraction\", which predicted the existence of black holes. In the paper, which made no reference to Einstein's recent publication, Oppenheimer and Snyder used Einstein's own theory of general relativity to show the conditions on how a black hole could develop for the first time in contemporary physics .\\n\\nGolden age\\nIn 1958, David Finkelstein identified the Schwarzschild surface as an event horizon, \"a perfect unidirectional membrane: causal influences can cross it in only one direction\". This did not strictly contradict Oppenheimer's results, but extended them to include the point of view of infalling observers. Finkelstein's solution extended the Schwarzschild solution for the future of observers falling into a black hole. A complete extension had already been found by Martin Kruskal, who was urged to publish it.These results came at the beginning of the golden age of general relativity, which was marked by general relativity and black holes becoming mainstream subjects of research. This process was helped by the discovery of pulsars by Jocelyn Bell Burnell in 1967, which, by 1969, were shown to be rapidly rotating neutron stars. Until that time, neutron stars, like black holes, were regarded as just theoretical curiosities; but the discovery of pulsars showed their physical relevance and spurred a further interest in all types of compact objects that might be formed by gravitational collapse.In this period more general black hole solutions were found. In 1963, Roy Kerr found the exact solution for a rotating black hole. Two years later, Ezra Newman found the axisymmetric solution for a black hole that is both rotating and electrically charged. Through the work of Werner Israel, Brandon Carter, and David Robinson the no-hair theorem emerged, stating that a stationary black hole solution is completely described by the three parameters of the Kerr\u2013Newman metric: mass, angular momentum, and electric charge.At first, it was suspected that the strange features of the black hole solutions were pathological artifacts from the symmetry conditions imposed, and that the singularities would not appear in generic situations. This view was held in particular by Vladimir Belinsky, Isaak Khalatnikov, and Evgeny Lifshitz, who tried to prove that no singularities appear in generic solutions. However, in the late 1960s Roger Penrose and Stephen Hawking used global techniques to prove that singularities appear generically. For this work, Penrose received half of the 2020 Nobel Prize in Physics, Hawking having died in 2018. Based on observations in Greenwich and Toronto in the early 1970s, Cygnus X-1, a galactic X-ray source discovered in 1964, became the first astronomical object commonly accepted to be a black hole.Work by James Bardeen, Jacob Bekenstein, Carter, and Hawking in the early 1970s led to the formulation of black hole thermodynamics. These laws describe the behaviour of a black hole in close analogy to the laws of thermodynamics by relating mass to energy, area to entropy, and surface gravity to temperature. The analogy was completed when Hawking, in 1974, showed that quantum field theory implies that black holes should radiate like a black body with a temperature proportional to the surface gravity of the black hole, predicting the effect now known as Hawking radiation.\\n\\nObservation\\nOn 11 February 2016, the LIGO Scientific Collaboration and the Virgo collaboration announced the first direct detection of gravitational waves, representing the first observation of a black hole merger. On 10 April 2019, the first direct image of a black hole and its vicinity was published, following observations made by the Event Horizon Telescope (EHT) in 2017 of the supermassive black hole in Messier 87's galactic centre. As of 2023, the nearest known body thought to be a black hole, Gaia BH1, is around 1,560 light-years (480 parsecs) away. Though only a couple dozen black holes have been found so far in the Milky Way, there are thought to be hundreds of millions, most of which are solitary and do not cause emission of radiation. Therefore, they would only be detectable by gravitational lensing.\\n\\nEtymology\\nJohn Michell used the term \"dark star\" in a November 1783 letter to Henry Cavendish, and in the early 20th century, physicists used the term \"gravitationally collapsed object\". Science writer Marcia Bartusiak traces the term \"black hole\" to physicist Robert H. Dicke, who in the early 1960s reportedly compared the phenomenon to the Black Hole of Calcutta, notorious as a prison where people entered but never left alive.The term \"black hole\" was used in print by Life and Science News magazines in 1963, and by science journalist Ann Ewing in her article \"'Black Holes' in Space\", dated 18 January 1964, which was a report on a meeting of the American Association for the Advancement of Science held in Cleveland, Ohio.In December 1967, a student reportedly suggested the phrase \"black hole\" at a lecture by John Wheeler; Wheeler adopted the term for its brevity and \"advertising value\", and it quickly caught on, leading some to credit Wheeler with coining the phrase.\\n\\nProperties and structure\\nThe no-hair theorem postulates that, once it achieves a stable condition after formation, a black hole has only three independent physical properties: mass, electric charge, and angular momentum; the black hole is otherwise featureless. If the conjecture is true, any two black holes that share the same values for these properties, or parameters, are indistinguishable from one another. The degree to which the conjecture is true for real black holes under the laws of modern physics is currently an unsolved problem.These properties are special because they are visible from outside a black hole. For example, a charged black hole repels other like charges just like any other charged object. Similarly, the total mass inside a sphere containing a black hole can be found by using the gravitational analog of Gauss's law (through the ADM mass), far away from the black hole. Likewise, the angular momentum (or spin) can be measured from far away using frame dragging by the gravitomagnetic field, through for example the Lense\u2013Thirring effect.\\nWhen an object falls into a black hole, any information about the shape of the object or distribution of charge on it is evenly distributed along the horizon of the black hole, and is lost to outside observers. The behavior of the horizon in this situation is a dissipative system that is closely analogous to that of a conductive stretchy membrane with friction and electrical resistance\u2014the membrane paradigm. This is different from other field theories such as electromagnetism, which do not have any friction or resistivity at the microscopic level, because they are time-reversible. Because a black hole eventually achieves a stable state with only three parameters, there is no way to avoid losing information about the initial conditions: the gravitational and electric fields of a black hole give very little information about what went in. The information that is lost includes every quantity that cannot be measured far away from the black hole horizon, including approximately conserved quantum numbers such as the total baryon number and lepton number. This behavior is so puzzling that it has been called the black hole information loss paradox.\\n\\nPhysical properties\\nThe simplest static black holes have mass but neither electric charge nor angular momentum. These black holes are often referred to as Schwarzschild black holes after Karl Schwarzschild who discovered this solution in 1916. According to Birkhoff's theorem, it is the only vacuum solution that is spherically symmetric. This means there is no observable difference at a distance between the gravitational field of such a black hole and that of any other spherical object of the same mass. The popular notion of a black hole \"sucking in everything\" in its surroundings is therefore correct only near a black hole's horizon; far away, the external gravitational field is identical to that of any other body of the same mass.Solutions describing more general black holes also exist. Non-rotating charged black holes are described by the Reissner\u2013Nordstr\u00f6m metric, while the Kerr metric describes a non-charged rotating black hole. The most general stationary black hole solution known is the Kerr\u2013Newman metric, which describes a black hole with both charge and angular momentum.While the mass of a black hole can take any positive value, the charge and angular momentum are constrained by the mass. The total electric charge Q and the total angular momentum J are expected to satisfy the inequality\\n\\n  \\n    \\n      \\n        \\n          \\n            \\n              Q\\n              \\n                2\\n              \\n            \\n            \\n              4\\n              \u03c0\\n              \\n                \u03f5\\n                \\n                  0\\n                \\n              \\n            \\n          \\n        \\n        +\\n        \\n          \\n            \\n              \\n                c\\n                \\n                  2\\n                \\n              \\n              \\n                J\\n                \\n                  2\\n                \\n              \\n            \\n            \\n              G\\n              \\n                M\\n                \\n                  2\\n                \\n              \\n            \\n          \\n        \\n        \u2264\\n        G\\n        \\n          M\\n          \\n            2\\n          \\n        \\n      \\n    \\n    {\\displaystyle {\\frac {Q^{2}}{4\\pi \\epsilon _{0}}}+{\\frac {c^{2}J^{2}}{GM^{2}}}\\leq GM^{2}}\\n  for a black hole of mass M. Black holes with the minimum possible mass satisfying this inequality are called extremal. Solutions of Einstein's equations that violate this inequality exist, but they do not possess an event horizon. These solutions have so-called naked singularities that can be observed from the outside, and hence are deemed unphysical. The cosmic censorship hypothesis rules out the formation of such singularities, when they are created through the gravitational collapse of realistic matter. This is supported by numerical simulations.Due to the relatively large strength of the electromagnetic force, black holes forming from the collapse of stars are expected to retain the nearly neutral charge of the star. Rotation, however, is expected to be a universal feature of compact astrophysical objects. The black-hole candidate binary X-ray source GRS 1915+105 appears to have an angular momentum near the maximum allowed value. That uncharged limit is\\n\\n  \\n    \\n      \\n        J\\n        \u2264\\n        \\n          \\n            \\n              G\\n              \\n                M\\n                \\n                  2\\n                \\n              \\n            \\n            c\\n          \\n        \\n        ,\\n      \\n    \\n    {\\displaystyle J\\leq {\\frac {GM^{2}}{c}},}\\n  allowing definition of a dimensionless spin parameter such that\\n\\n  \\n    \\n      \\n        0\\n        \u2264\\n        \\n          \\n            \\n              c\\n              J\\n            \\n            \\n              G\\n              \\n                M\\n                \\n                  2\\n                \\n              \\n            \\n          \\n        \\n        \u2264\\n        1.\\n      \\n    \\n    {\\displaystyle 0\\leq {\\frac {cJ}{GM^{2}}}\\leq 1.}\\n  Black holes are commonly classified according to their mass, independent of angular momentum, J. The size of a black hole, as determined by the radius of the event horizon, or Schwarzschild radius, is proportional to the mass, M, through\\n\\n  \\n    \\n      \\n        \\n          r\\n          \\n            \\n              s\\n            \\n          \\n        \\n        =\\n        \\n          \\n            \\n              2\\n              G\\n              M\\n            \\n            \\n              c\\n              \\n                2\\n              \\n            \\n          \\n        \\n        \u2248\\n        2.95\\n        \\n        \\n          \\n            M\\n            \\n              M\\n              \\n                \u2299\\n              \\n            \\n          \\n        \\n         \\n        \\n          k\\n          m\\n          ,\\n        \\n      \\n    \\n    {\\displaystyle r_{\\mathrm {s} }={\\frac {2GM}{c^{2}}}\\approx 2.95\\,{\\frac {M}{M_{\\odot }}}~\\mathrm {km,} }\\n  where rs is the Schwarzschild radius and M\u2609 is the mass of the Sun. For a black hole with nonzero spin and/or electric charge, the radius is smaller, until an extremal black hole could have an event horizon close to\\n\\n  \\n    \\n      \\n        \\n          r\\n          \\n            \\n              +\\n            \\n          \\n        \\n        =\\n        \\n          \\n            \\n              G\\n              M\\n            \\n            \\n              c\\n              \\n                2\\n              \\n            \\n          \\n        \\n        .\\n      \\n    \\n    {\\displaystyle r_{\\mathrm {+} }={\\frac {GM}{c^{2}}}.}\\n\\nEvent horizon\\nThe defining feature of a black hole is the appearance of an event horizon\u2014a boundary in spacetime through which matter and light can pass only inward towards the mass of the black hole. Nothing, not even light, can escape from inside the event horizon. The event horizon is referred to as such because if an event occurs within the boundary, information from that event cannot reach an outside observer, making it impossible to determine whether such an event occurred.As predicted by general relativity, the presence of a mass deforms spacetime in such a way that the paths taken by particles bend towards the mass. At the event horizon of a black hole, this deformation becomes so strong that there are no paths that lead away from the black hole.To a distant observer, clocks near a black hole would appear to tick more slowly than those farther away from the black hole. Due to this effect, known as gravitational time dilation, an object falling into a black hole appears to slow as it approaches the event horizon, taking an infinite time to reach it. At the same time, all processes on this object slow down, from the viewpoint of a fixed outside observer, causing any light emitted by the object to appear redder and dimmer, an effect known as gravitational redshift. Eventually, the falling object fades away until it can no longer be seen. Typically this process happens very rapidly with an object disappearing from view within less than a second.On the other hand, indestructible observers falling into a black hole do not notice any of these effects as they cross the event horizon. According to their own clocks, which appear to them to tick normally, they cross the event horizon after a finite time without noting any singular behaviour; in classical general relativity, it is impossible to determine the location of the event horizon from local observations, due to Einstein's equivalence principle.The topology of the event horizon of a black hole at equilibrium is always spherical. For non-rotating (static) black holes the geometry of the event horizon is precisely spherical, while for rotating black holes the event horizon is oblate.\\n\\nSingularity\\nAt the centre of a black hole, as described by general relativity, may lie a gravitational singularity, a region where the spacetime curvature becomes infinite. For a non-rotating black hole, this region takes the shape of a single point; for a rotating black hole it is smeared out to form a ring singularity that lies in the plane of rotation. In both cases, the singular region has zero volume. It can also be shown that the singular region contains all the mass of the black hole solution. The singular region can thus be thought of as having infinite density.Observers falling into a Schwarzschild black hole (i.e., non-rotating and not charged) cannot avoid being carried into the singularity once they cross the event horizon. They can prolong the experience by accelerating away to slow their descent, but only up to a limit. When they reach the singularity, they are crushed to infinite density and their mass is added to the total of the black hole. Before that happens, they will have been torn apart by the growing tidal forces in a process sometimes referred to as spaghettification or the \"noodle effect\".In the case of a charged (Reissner\u2013Nordstr\u00f6m) or rotating (Kerr) black hole, it is possible to avoid the singularity. Extending these solutions as far as possible reveals the hypothetical possibility of exiting the black hole into a different spacetime with the black hole acting as a wormhole. The possibility of traveling to another universe is, however, only theoretical since any perturbation would destroy this possibility. It also appears to be possible to follow closed timelike curves (returning to one's own past) around the Kerr singularity, which leads to problems with causality like the grandfather paradox. It is expected that none of these peculiar effects would survive in a proper quantum treatment of rotating and charged black holes.The appearance of singularities in general relativity is commonly perceived as signaling the breakdown of the theory. This breakdown, however, is expected; it occurs in a situation where quantum effects should describe these actions, due to the extremely high density and therefore particle interactions. To date, it has not been possible to combine quantum and gravitational effects into a single theory, although there exist attempts to formulate such a theory of quantum gravity. It is generally expected that such a theory will not feature any singularities.\\n\\nPhoton sphere\\nThe photon sphere is a spherical boundary of zero thickness in which photons that move on tangents to that sphere would be trapped in a circular orbit about the black hole. For non-rotating black holes, the photon sphere has a radius 1.5 times the Schwarzschild radius. Their orbits would be dynamically unstable, hence any small perturbation, such as a particle of infalling matter, would cause an instability that would grow over time, either setting the photon on an outward trajectory causing it to escape the black hole, or on an inward spiral where it would eventually cross the event horizon.While light can still escape from the photon sphere, any light that crosses the photon sphere on an inbound trajectory will be captured by the black hole. Hence any light that reaches an outside observer from the photon sphere must have been emitted by objects between the photon sphere and the event horizon. For a Kerr black hole the radius of the photon sphere depends on the spin parameter and on the details of the photon orbit, which can be prograde (the photon rotates in the same sense of the black hole spin) or retrograde.\\n\\nErgosphere\\nRotating black holes are surrounded by a region of spacetime in which it is impossible to stand still, called the ergosphere. This is the result of a process known as frame-dragging; general relativity predicts that any rotating mass will tend to slightly \"drag\" along the spacetime immediately surrounding it. Any object near the rotating mass will tend to start moving in the direction of rotation. For a rotating black hole, this effect is so strong near the event horizon that an object would have to move faster than the speed of light in the opposite direction to just stand still.The ergosphere of a black hole is a volume bounded by the black hole's event horizon and the ergosurface, which coincides with the event horizon at the poles but is at a much greater distance around the equator.Objects and radiation can escape normally from the ergosphere. Through the Penrose process, objects can emerge from the ergosphere with more energy than they entered with. The extra energy is taken from the rotational energy of the black hole. Thereby the rotation of the black hole slows down. A variation of the Penrose process in the presence of strong magnetic fields, the Blandford\u2013Znajek process is considered a likely mechanism for the enormous luminosity and relativistic jets of quasars and other active galactic nuclei.\\n\\nInnermost stable circular orbit (ISCO)\\nIn Newtonian gravity, test particles can stably orbit at arbitrary distances from a central object. In general relativity, however, there exists an innermost stable circular orbit (often called the ISCO), for which any infinitesimal inward perturbations to a circular orbit will lead to spiraling into the black hole, and any outward perturbations will, depending on the energy, result in spiraling in, stably orbiting between apastron and periastron, or escaping to infinity. The location of the ISCO depends on the spin of the black hole, in the case of a Schwarzschild black hole (spin zero) is:\\n\\n  \\n    \\n      \\n        \\n          r\\n          \\n            \\n              I\\n              S\\n              C\\n              O\\n            \\n          \\n        \\n        =\\n        3\\n        \\n        \\n          r\\n          \\n            s\\n          \\n        \\n        =\\n        \\n          \\n            \\n              6\\n              \\n              G\\n              M\\n            \\n            \\n              c\\n              \\n                2\\n              \\n            \\n          \\n        \\n        ,\\n      \\n    \\n    {\\displaystyle r_{\\rm {ISCO}}=3\\,r_{s}={\\frac {6\\,GM}{c^{2}}},}\\n  and decreases with increasing black hole spin for particles orbiting in the same direction as the spin.\\n\\nFormation and evolution\\nGiven the bizarre character of black holes, it was long questioned whether such objects could actually exist in nature or whether they were merely pathological solutions to Einstein's equations. Einstein himself wrongly thought black holes would not form, because he held that the angular momentum of collapsing particles would stabilize their motion at some radius. This led the general relativity community to dismiss all results to the contrary for many years. However, a minority of relativists continued to contend that black holes were physical objects, and by the end of the 1960s, they had persuaded the majority of researchers in the field that there is no obstacle to the formation of an event horizon.Penrose demonstrated that once an event horizon forms, general relativity without quantum mechanics requires that a singularity will form within. Shortly afterwards, Hawking showed that many cosmological solutions that describe the Big Bang have singularities without scalar fields or other exotic matter. The Kerr solution, the no-hair theorem, and the laws of black hole thermodynamics showed that the physical properties of black holes were simple and comprehensible, making them respectable subjects for research. Conventional black holes are formed by gravitational collapse of heavy objects such as stars, but they can also in theory be formed by other processes.\\n\\nGravitational collapse\\nGravitational collapse occurs when an object's internal pressure is insufficient to resist the object's own gravity. For stars this usually occurs either because a star has too little \"fuel\" left to maintain its temperature through stellar nucleosynthesis, or because a star that would have been stable receives extra matter in a way that does not raise its core temperature. In either case the star's temperature is no longer high enough to prevent it from collapsing under its own weight.\\nThe collapse may be stopped by the degeneracy pressure of the star's constituents, allowing the condensation of matter into an exotic denser state. The result is one of the various types of compact star. Which type forms depends on the mass of the remnant of the original star left if the outer layers have been blown away (for example, in a Type II supernova). The mass of the remnant, the collapsed object that survives the explosion, can be substantially less than that of the original star. Remnants exceeding 5 M\u2609 are produced by stars that were over 20 M\u2609 before the collapse.If the mass of the remnant exceeds about 3\u20134 M\u2609 (the Tolman\u2013Oppenheimer\u2013Volkoff limit), either because the original star was very heavy or because the remnant collected additional mass through accretion of matter, even the degeneracy pressure of neutrons is insufficient to stop the collapse. No known mechanism (except possibly quark degeneracy pressure) is powerful enough to stop the implosion and the object will inevitably collapse to form a black hole.The gravitational collapse of heavy stars is assumed to be responsible for the formation of stellar mass black holes. Star formation in the early universe may have resulted in very massive stars, which upon their collapse would have produced black holes of up to 103 M\u2609. These black holes could be the seeds of the supermassive black holes found in the centres of most galaxies. It has further been suggested that massive black holes with typical masses of ~105 M\u2609 could have formed from the direct collapse of gas clouds in the young universe. These massive objects have been proposed as the seeds that eventually formed the earliest quasars observed already at redshift \\n  \\n    \\n      \\n        z\\n        \u223c\\n        7\\n      \\n    \\n    {\\displaystyle z\\sim 7}\\n  . Some candidates for such objects have been found in observations of the young universe.While most of the energy released during gravitational collapse is emitted very quickly, an outside observer does not actually see the end of this process. Even though the collapse takes a finite amount of time from the reference frame of infalling matter, a distant observer would see the infalling material slow and halt just above the event horizon, due to gravitational time dilation. Light from the collapsing material takes longer and longer to reach the observer, with the light emitted just before the event horizon forms delayed an infinite amount of time. Thus the external observer never sees the formation of the event horizon; instead, the collapsing material seems to become dimmer and increasingly red-shifted, eventually fading away.\\n\\nPrimordial black holes and the Big Bang\\nGravitational collapse requires great density. In the current epoch of the universe these high densities are found only in stars, but in the early universe shortly after the Big Bang densities were much greater, possibly allowing for the creation of black holes. High density alone is not enough to allow black hole formation since a uniform mass distribution will not allow the mass to bunch up. In order for primordial black holes to have formed in such a dense medium, there must have been initial density perturbations that could then grow under their own gravity. Different models for the early universe vary widely in their predictions of the scale of these fluctuations. Various models predict the creation of primordial black holes ranging in size from a Planck mass (\\n  \\n    \\n      \\n        \\n          m\\n          \\n            P\\n          \\n        \\n        =\\n        \\n          \\n            \u210f\\n            c\\n            \\n              /\\n            \\n            G\\n          \\n        \\n      \\n    \\n    {\\displaystyle m_{P}={\\sqrt {\\hbar c/G}}}\\n   \u2248 1.2\u00d71019 GeV/c2 \u2248 2.2\u00d710\u22128 kg) to hundreds of thousands of solar masses.Despite the early universe being extremely dense, it did not re-collapse into a black hole during the Big Bang, since the expansion rate was greater than the attraction. Following inflation theory there was a net repulsive gravitation in the beginning until the end of inflation. Since then the Hubble flow was slowed by the energy density of the universe.\\nModels for the gravitational collapse of objects of relatively constant size, such as stars, do not necessarily apply in the same way to rapidly expanding space such as the Big Bang.\\n\\nHigh-energy collisions\\nGravitational collapse is not the only process that could create black holes. In principle, black holes could be formed in high-energy collisions that achieve sufficient density. As of 2002, no such events have been detected, either directly or indirectly as a deficiency of the mass balance in particle accelerator experiments. This suggests that there must be a lower limit for the mass of black holes. Theoretically, this boundary is expected to lie around the Planck mass, where quantum effects are expected to invalidate the predictions of general relativity. This would put the creation of black holes firmly out of reach of any high-energy process occurring on or near the Earth. However, certain developments in quantum gravity suggest that the minimum black hole mass could be much lower: some braneworld scenarios for example put the boundary as low as 1 TeV/c2. This would make it conceivable for micro black holes to be created in the high-energy collisions that occur when cosmic rays hit the Earth's atmosphere, or possibly in the Large Hadron Collider at CERN. These theories are very speculative, and the creation of black holes in these processes is deemed unlikely by many specialists. Even if micro black holes could be formed, it is expected that they would evaporate in about 10\u221225 seconds, posing no threat to the Earth.\\n\\nGrowth\\nOnce a black hole has formed, it can continue to grow by absorbing additional matter. Any black hole will continually absorb gas and interstellar dust from its surroundings. This growth process is one possible way through which some supermassive black holes may have been formed, although the formation of supermassive black holes is still an open field of research. A similar process has been suggested for the formation of intermediate-mass black holes found in globular clusters. Black holes can also merge with other objects such as stars or even other black holes. This is thought to have been important, especially in the early growth of supermassive black holes, which could have formed from the aggregation of many smaller objects. The process has also been proposed as the origin of some intermediate-mass black holes.\\n\\nEvaporation\\nIn 1974, Hawking predicted that black holes are not entirely black but emit small amounts of thermal radiation at a temperature \u210fc3/(8\u03c0GMkB); this effect has become known as Hawking radiation. By applying quantum field theory to a static black hole background, he determined that a black hole should emit particles that display a perfect black body spectrum. Since Hawking's publication, many others have verified the result through various approaches. If Hawking's theory of black hole radiation is correct, then black holes are expected to shrink and evaporate over time as they lose mass by the emission of photons and other particles. The temperature of this thermal spectrum (Hawking temperature) is proportional to the surface gravity of the black hole, which, for a Schwarzschild black hole, is inversely proportional to the mass. Hence, large black holes emit less radiation than small black holes.A stellar black hole of 1 M\u2609 has a Hawking temperature of 62 nanokelvins. This is far less than the 2.7 K temperature of the cosmic microwave background radiation. Stellar-mass or larger black holes receive more mass from the cosmic microwave background than they emit through Hawking radiation and thus will grow instead of shrinking. To have a Hawking temperature larger than 2.7 K (and be able to evaporate), a black hole would need a mass less than the Moon. Such a black hole would have a diameter of less than a tenth of a millimeter.If a black hole is very small, the radiation effects are expected to become very strong. A black hole with the mass of a car would have a diameter of about 10\u221224 m and take a nanosecond to evaporate, during which time it would briefly have a luminosity of more than 200 times that of the Sun. Lower-mass black holes are expected to evaporate even faster; for example, a black hole of mass 1 TeV/c2 would take less than 10\u221288 seconds to evaporate completely. For such a small black hole, quantum gravity effects are expected to play an important role and could hypothetically make such a small black hole stable, although current developments in quantum gravity do not indicate this is the case.The Hawking radiation for an astrophysical black hole is predicted to be very weak and would thus be exceedingly difficult to detect from Earth. A possible exception, however, is the burst of gamma rays emitted in the last stage of the evaporation of primordial black holes. Searches for such flashes have proven unsuccessful and provide stringent limits on the possibility of existence of low mass primordial black holes. NASA's Fermi Gamma-ray Space Telescope launched in 2008 will continue the search for these flashes.If black holes evaporate via Hawking radiation, a solar mass black hole will evaporate (beginning once the temperature of the cosmic microwave background drops below that of the black hole) over a period of 1064 years. A supermassive black hole with a mass of 1011 M\u2609 will evaporate in around 2\u00d710100 years. Some monster black holes in the universe are predicted to continue to grow up to perhaps 1014 M\u2609 during the collapse of superclusters of galaxies. Even these would evaporate over a timescale of up to 10106 years.Some models of quantum gravity predict modifications of the Hawking description of black holes. In particular, the evolution equations describing the mass loss rate and charge loss rate get modified.\\n\\nObservational evidence\\nBy nature, black holes do not themselves emit any electromagnetic radiation other than the hypothetical Hawking radiation, so astrophysicists searching for black holes must generally rely on indirect observations. For example, a black hole's existence can sometimes be inferred by observing its gravitational influence on its surroundings.\\n\\nDirect interferometry\\nThe Event Horizon Telescope (EHT) is an active program that directly observes the immediate environment of black holes' event horizons, such as the black hole at the centre of the Milky Way. In April 2017, EHT began observing the black hole at the centre of Messier 87. \"In all, eight radio observatories on six mountains and four continents observed the galaxy in Virgo on and off for 10 days in April 2017\" to provide the data yielding the image in April 2019. After two years of data processing, EHT released the first direct image of a black hole; specifically, the supermassive black hole that lies in the centre of the aforementioned galaxy. What is visible is not the black hole\u2014which shows as black because of the loss of all light within this dark region. Instead, it is the gases at the edge of the event horizon (displayed as orange or red) that define the black hole.On 12 May 2022, the EHT released the first image of Sagittarius A*, the supermassive black hole at the centre of the Milky Way galaxy. The published image displayed the same ring-like structure and circular shadow as seen in the M87* black hole, and the image was created using the same techniques as for the M87 black hole. However, the imaging process for Sagittarius A*, which is more than a thousand times smaller and less massive than M87*, was significantly more complex because of the instability of its surroundings. The image of Sagittarius A* was also partially blurred by turbulent plasma on the way to the galactic centre, an effect which prevents resolution of the image at longer wavelengths.The brightening of this material in the 'bottom' half of the processed EHT image is thought to be caused by Doppler beaming, whereby material approaching the viewer at relativistic speeds is perceived as brighter than material moving away. In the case of a black hole, this phenomenon implies that the visible material is rotating at relativistic speeds (>1,000 km/s [2,200,000 mph]), the only speeds at which it is possible to centrifugally balance the immense gravitational attraction of the singularity, and thereby remain in orbit above the event horizon. This configuration of bright material implies that the EHT observed M87* from a perspective catching the black hole's accretion disc nearly edge-on, as the whole system rotated clockwise. However, the extreme gravitational lensing associated with black holes produces the illusion of a perspective that sees the accretion disc from above. In reality, most of the ring in the EHT image was created when the light emitted by the far side of the accretion disc bent around the black hole's gravity well and escaped, meaning that most of the possible perspectives on M87* can see the entire disc, even that directly behind the \"shadow\".\\nIn 2015, the EHT detected magnetic fields just outside the event horizon of Sagittarius A* and even discerned some of their properties. The field lines that pass through the accretion disc were a complex mixture of ordered and tangled. Theoretical studies of black holes had predicted the existence of magnetic fields.In April 2023, an image of the shadow of the Messier 87 black hole and the related high-energy jet, viewed together for the first time, was presented.\\n\\nDetection of gravitational waves from merging black holes\\nOn 14 September 2015, the LIGO gravitational wave observatory made the first-ever successful direct observation of gravitational waves. The signal was consistent with theoretical predictions for the gravitational waves produced by the merger of two black holes: one with about 36 solar masses, and the other around 29 solar masses. This observation provides the most concrete evidence for the existence of black holes to date. For instance, the gravitational wave signal suggests that the separation of the two objects before the merger was just 350 km (or roughly four times the Schwarzschild radius corresponding to the inferred masses). The objects must therefore have been extremely compact, leaving black holes as the most plausible interpretation.More importantly, the signal observed by LIGO also included the start of the post-merger ringdown, the signal produced as the newly formed compact object settles down to a stationary state. Arguably, the ringdown is the most direct way of observing a black hole. From the LIGO signal, it is possible to extract the frequency and damping time of the dominant mode of the ringdown. From these, it is possible to infer the mass and angular momentum of the final object, which match independent predictions from numerical simulations of the merger. The frequency and decay time of the dominant mode are determined by the geometry of the photon sphere. Hence, observation of this mode confirms the presence of a photon sphere; however, it cannot exclude possible exotic alternatives to black holes that are compact enough to have a photon sphere.The observation also provides the first observational evidence for the existence of stellar-mass black hole binaries. Furthermore, it is the first observational evidence of stellar-mass black holes weighing 25 solar masses or more.Since then, many more gravitational wave events have been observed.\\n\\nStars orbiting Sagittarius A*\\nThe proper motions of stars near the centre of our own Milky Way provide strong observational evidence that these stars are orbiting a supermassive black hole. Since 1995, astronomers have tracked the motions of 90 stars orbiting an invisible object coincident with the radio source Sagittarius A*. By fitting their motions to Keplerian orbits, the astronomers were able to infer, in 1998, that a 2.6\u00d7106 M\u2609 object must be contained in a volume with a radius of 0.02 light-years to cause the motions of those stars. Since then, one of the stars\u2014called S2\u2014has completed a full orbit. From the orbital data, astronomers were able to refine the calculations of the mass to 4.3\u00d7106 M\u2609 and a radius of less than 0.002 light-years for the object causing the orbital motion of those stars. The upper limit on the object's size is still too large to test whether it is smaller than its Schwarzschild radius; nevertheless, these observations strongly suggest that the central object is a supermassive black hole as there are no other plausible scenarios for confining so much invisible mass into such a small volume. Additionally, there is some observational evidence that this object might possess an event horizon, a feature unique to black holes.\\n\\nAccretion of matter\\nDue to conservation of angular momentum, gas falling into the gravitational well created by a massive object will typically form a disk-like structure around the object. Artists' impressions such as the accompanying representation of a black hole with corona commonly depict the black hole as if it were a flat-space body hiding the part of the disk just behind it, but in reality gravitational lensing would greatly distort the image of the accretion disk.Within such a disk, friction would cause angular momentum to be transported outward, allowing matter to fall farther inward, thus releasing potential energy and increasing the temperature of the gas.When the accreting object is a neutron star or a black hole, the gas in the inner accretion disk orbits at very high speeds because of its proximity to the compact object. The resulting friction is so significant that it heats the inner disk to temperatures at which it emits vast amounts of electromagnetic radiation (mainly X-rays). These bright X-ray sources may be detected by telescopes. This process of accretion is one of the most efficient energy-producing processes known; up to 40% of the rest mass of the accreted material can be emitted as radiation. (In nuclear fusion only about 0.7% of the rest mass will be emitted as energy.) In many cases, accretion disks are accompanied by relativistic jets that are emitted along the poles, which carry away much of the energy. The mechanism for the creation of these jets is currently not well understood, in part due to insufficient data.As such, many of the universe's more energetic phenomena have been attributed to the accretion of matter on black holes. In particular, active galactic nuclei and quasars are believed to be the accretion disks of supermassive black holes. Similarly, X-ray binaries are generally accepted to be binary star systems in which one of the two stars is a compact object accreting matter from its companion. It has also been suggested that some ultraluminous X-ray sources may be the accretion disks of intermediate-mass black holes.In November 2011 the first direct observation of a quasar accretion disk around a supermassive black hole was reported.\\n\\nX-ray binaries\\nX-ray binaries are binary star systems that emit a majority of their radiation in the X-ray part of the spectrum. These X-ray emissions are generally thought to result when one of the stars (compact object) accretes matter from another (regular) star. The presence of an ordinary star in such a system provides an opportunity for studying the central object and to determine if it might be a black hole.If such a system emits signals that can be directly traced back to the compact object, it cannot be a black hole. The absence of such a signal does, however, not exclude the possibility that the compact object is a neutron star. By studying the companion star it is often possible to obtain the orbital parameters of the system and to obtain an estimate for the mass of the compact object. If this is much larger than the Tolman\u2013Oppenheimer\u2013Volkoff limit (the maximum mass a star can have without collapsing) then the object cannot be a neutron star and is generally expected to be a black hole.The first strong candidate for a black hole, Cygnus X-1, was discovered in this way by Charles Thomas Bolton, Louise Webster, and Paul Murdin in 1972. Some doubt, however, remained due to the uncertainties that result from the companion star being much heavier than the candidate black hole. Currently, better candidates for black holes are found in a class of X-ray binaries called soft X-ray transients. In this class of system, the companion star is of relatively low mass allowing for more accurate estimates of the black hole mass. Moreover, these systems actively emit X-rays for only several months once every 10\u201350 years. During the period of low X-ray emission (called quiescence), the accretion disk is extremely faint allowing detailed observation of the companion star during this period. One of the best such candidates is V404 Cygni.\\n\\nQuasi-periodic oscillations\\nThe X-ray emissions from accretion disks sometimes flicker at certain frequencies. These signals are called quasi-periodic oscillations and are thought to be caused by material moving along the inner edge of the accretion disk (the innermost stable circular orbit). As such their frequency is linked to the mass of the compact object. They can thus be used as an alternative way to determine the mass of candidate black holes.\\n\\nGalactic nuclei\\nAstronomers use the term \"active galaxy\" to describe galaxies with unusual characteristics, such as unusual spectral line emission and very strong radio emission. Theoretical and observational studies have shown that the activity in these active galactic nuclei (AGN) may be explained by the presence of supermassive black holes, which can be millions of times more massive than stellar ones. The models of these AGN consist of a central black hole that may be millions or billions of times more massive than the Sun; a disk of interstellar gas and dust called an accretion disk; and two jets perpendicular to the accretion disk.Although supermassive black holes are expected to be found in most AGN, only some galaxies' nuclei have been more carefully studied in attempts to both identify and measure the actual masses of the central supermassive black hole candidates. Some of the most notable galaxies with supermassive black hole candidates include the Andromeda Galaxy, M32, M87, NGC 3115, NGC 3377, NGC 4258, NGC 4889, NGC 1277, OJ 287, APM 08279+5255 and the Sombrero Galaxy.It is now widely accepted that the centre of nearly every galaxy, not just active ones, contains a supermassive black hole. The close observational correlation between the mass of this hole and the velocity dispersion of the host galaxy's bulge, known as the M\u2013sigma relation, strongly suggests a connection between the formation of the black hole and that of the galaxy itself.\\n\\nMicrolensing\\nAnother way the black hole nature of an object may be tested is through observation of effects caused by a strong gravitational field in their vicinity. One such effect is gravitational lensing: The deformation of spacetime around a massive object causes light rays to be deflected, such as light passing through an optic lens. Observations have been made of weak gravitational lensing, in which light rays are deflected by only a few arcseconds. Microlensing occurs when the sources are unresolved and the observer sees a small brightening. In January 2022, astronomers reported the first possible detection of a microlensing event from an isolated black hole.Another possibility for observing gravitational lensing by a black hole would be to observe stars orbiting the black hole. There are several candidates for such an observation in orbit around Sagittarius A*.\\n\\nAlternatives\\nThe evidence for stellar black holes strongly relies on the existence of an upper limit for the mass of a neutron star. The size of this limit heavily depends on the assumptions made about the properties of dense matter. New exotic phases of matter could push up this bound. A phase of free quarks at high density might allow the existence of dense quark stars, and some supersymmetric models predict the existence of Q stars. Some extensions of the standard model posit the existence of preons as fundamental building blocks of quarks and leptons, which could hypothetically form preon stars. These hypothetical models could potentially explain a number of observations of stellar black hole candidates. However, it can be shown from arguments in general relativity that any such object will have a maximum mass.Since the average density of a black hole inside its Schwarzschild radius is inversely proportional to the square of its mass, supermassive black holes are much less dense than stellar black holes (the average density of a 108 M\u2609 black hole is comparable to that of water). Consequently, the physics of matter forming a supermassive black hole is much better understood and the possible alternative explanations for supermassive black hole observations are much more mundane. For example, a supermassive black hole could be modelled by a large cluster of very dark objects. However, such alternatives are typically not stable enough to explain the supermassive black hole candidates.The evidence for the existence of stellar and supermassive black holes implies that in order for black holes to not form, general relativity must fail as a theory of gravity, perhaps due to the onset of quantum mechanical corrections. A much anticipated feature of a theory of quantum gravity is that it will not feature singularities or event horizons and thus black holes would not be real artifacts. For example, in the fuzzball model based on string theory, the individual states of a black hole solution do not generally have an event horizon or singularity, but for a classical/semi-classical observer the statistical average of such states appears just as an ordinary black hole as deduced from general relativity.A few theoretical objects have been conjectured to match observations of astronomical black hole candidates identically or near-identically, but which function via a different mechanism. These include the gravastar, the black star, and the dark-energy star.\\n\\nOpen questions\\nEntropy and thermodynamics\\nIn 1971, Hawking showed under general conditions that the total area of the event horizons of any collection of classical black holes can never decrease, even if they collide and merge. This result, now known as the second law of black hole mechanics, is remarkably similar to the second law of thermodynamics, which states that the total entropy of an isolated system can never decrease. As with classical objects at absolute zero temperature, it was assumed that black holes had zero entropy. If this were the case, the second law of thermodynamics would be violated by entropy-laden matter entering a black hole, resulting in a decrease in the total entropy of the universe. Therefore, Bekenstein proposed that a black hole should have an entropy, and that it should be proportional to its horizon area.The link with the laws of thermodynamics was further strengthened by Hawking's discovery in 1974 that quantum field theory predicts that a black hole radiates blackbody radiation at a constant temperature. This seemingly causes a violation of the second law of black hole mechanics, since the radiation will carry away energy from the black hole causing it to shrink. The radiation, however also carries away entropy, and it can be proven under general assumptions that the sum of the entropy of the matter surrounding a black hole and one quarter of the area of the horizon as measured in Planck units is in fact always increasing. This allows the formulation of the first law of black hole mechanics as an analogue of the first law of thermodynamics, with the mass acting as energy, the surface gravity as temperature and the area as entropy.One puzzling feature is that the entropy of a black hole scales with its area rather than with its volume, since entropy is normally an extensive quantity that scales linearly with the volume of the system. This odd property led Gerard 't Hooft and Leonard Susskind to propose the holographic principle, which suggests that anything that happens in a volume of spacetime can be described by data on the boundary of that volume.Although general relativity can be used to perform a semi-classical calculation of black hole entropy, this situation is theoretically unsatisfying. In statistical mechanics, entropy is understood as counting the number of microscopic configurations of a system that have the same macroscopic qualities (such as mass, charge, pressure, etc.). Without a satisfactory theory of quantum gravity, one cannot perform such a computation for black holes. Some progress has been made in various approaches to quantum gravity. In 1995, Andrew Strominger and Cumrun Vafa showed that counting the microstates of a specific supersymmetric black hole in string theory reproduced the Bekenstein\u2013Hawking entropy. Since then, similar results have been reported for different black holes both in string theory and in other approaches to quantum gravity like loop quantum gravity.Another promising approach is constituted by treating gravity as an effective field theory. One first computes the quantum gravitational corrections to the radius of the event horizon of the black hole, then integrates over it to find the quantum gravitational corrections to the entropy as given by the Wald formula. The method was applied for Schwarzschild black holes by Calmet and Kuipers, then successfully generalised for charged black holes by Campos Delgado.\\n\\nInformation loss paradox\\nBecause a black hole has only a few internal parameters, most of the information about the matter that went into forming the black hole is lost. Regardless of the type of matter which goes into a black hole, it appears that only information concerning the total mass, charge, and angular momentum are conserved. As long as black holes were thought to persist forever this information loss is not that problematic, as the information can be thought of as existing inside the black hole, inaccessible from the outside, but represented on the event horizon in accordance with the holographic principle. However, black holes slowly evaporate by emitting Hawking radiation. This radiation does not appear to carry any additional information about the matter that formed the black hole, meaning that this information appears to be gone forever.The question whether information is truly lost in black holes (the black hole information paradox) has divided the theoretical physics community. In quantum mechanics, loss of information corresponds to the violation of a property called unitarity, and it has been argued that loss of unitarity would also imply violation of conservation of energy, though this has also been disputed. Over recent years evidence has been building that indeed information and unitarity are preserved in a full quantum gravitational treatment of the problem.One attempt to resolve the black hole information paradox is known as black hole complementarity. In 2012, the \"firewall paradox\" was introduced with the goal of demonstrating that black hole complementarity fails to solve the information paradox. According to quantum field theory in curved spacetime, a single emission of Hawking radiation involves two mutually entangled particles. The outgoing particle escapes and is emitted as a quantum of Hawking radiation; the infalling particle is swallowed by the black hole. Assume a black hole formed a finite time in the past and will fully evaporate away in some finite time in the future. Then, it will emit only a finite amount of information encoded within its Hawking radiation. According to research by physicists like Don Page and Leonard Susskind, there will eventually be a time by which an outgoing particle must be entangled with all the Hawking radiation the black hole has previously emitted. This seemingly creates a paradox: a principle called \"monogamy of entanglement\" requires that, like any quantum system, the outgoing particle cannot be fully entangled with two other systems at the same time; yet here the outgoing particle appears to be entangled both with the infalling particle and, independently, with past Hawking radiation. In order to resolve this contradiction, physicists may eventually be forced to give up one of three time-tested principles: Einstein's equivalence principle, unitarity, or local quantum field theory. One possible solution, which violates the equivalence principle, is that a \"firewall\" destroys incoming particles at the event horizon. In general, which\u2014if any\u2014of these assumptions should be abandoned remains a topic of debate.\\n\\nSee also\\nNotes\\nReferences\\nFurther reading\\nPopular reading\\nUniversity textbooks and monographs\\nReview papers\\nExternal links\\nBlack Holes on In Our Time at the BBC\\nStanford Encyclopedia of Philosophy: \"Singularities and Black Holes\" by Erik Curiel and Peter Bokulich.\\nBlack Holes: Gravity's Relentless Pull \u2013 Interactive multimedia Web site about the physics and astronomy of black holes from the Space Telescope Science Institute (HubbleSite)\\nESA's Black Hole Visualization Archived 3 May 2019 at the Wayback Machine\\nFrequently Asked Questions (FAQs) on Black Holes\\nSchwarzschild Geometry\\nBlack holes - basic (NYT; April 2021)\\n\\nVideos\\n16-year-long study tracks stars orbiting Sagittarius A*\\nMovie of Black Hole Candidate from Max Planck Institute\\nCowen, Ron (20 April 2015). \"3D simulations of colliding black holes hailed as most realistic yet\". Nature. doi:10.1038/nature.2015.17360.\\nComputer visualisation of the signal detected by LIGO\\nTwo Black Holes Merge into One (based upon the signal GW150914)"}
{"article_name": "Apollo_11", "link": "https://en.wikipedia.org/wiki/Apollo_11", "text_content": "Apollo 11 (July 16\u201324, 1969) was the American spaceflight that first landed humans on the Moon. Commander Neil Armstrong and Lunar Module Pilot Buzz Aldrin landed the Apollo Lunar Module Eagle on July 20, 1969, at 20:17 UTC, and Armstrong became the first person to step onto the Moon's surface six hours and 39 minutes later, on July 21 at 02:56 UTC. Aldrin joined him 19 minutes later, and they spent about two and a quarter hours together exploring the site they had named Tranquility Base upon landing. Armstrong and Aldrin collected 47.5 pounds (21.5 kg) of lunar material to bring back to Earth as pilot Michael Collins flew the Command Module Columbia in lunar orbit, and were on the Moon's surface for 21 hours, 36 minutes before lifting off to rejoin Columbia.\\nApollo 11 was launched by a Saturn V rocket from Kennedy Space Center on Merritt Island, Florida, on July 16 at 13:32 UTC, and it was the fifth crewed mission of NASA's Apollo program. The Apollo spacecraft had three parts: a command module (CM) with a cabin for the three astronauts, the only part that returned to Earth; a service module (SM), which supported the command module with propulsion, electrical power, oxygen, and water; and a lunar module (LM) that had two stages\u2014a descent stage for landing on the Moon and an ascent stage to place the astronauts back into lunar orbit.\\nAfter being sent to the Moon by the Saturn V's third stage, the astronauts separated the spacecraft from it and traveled for three days until they entered lunar orbit. Armstrong and Aldrin then moved into Eagle and landed in the Sea of Tranquility on July 20. The astronauts used Eagle's ascent stage to lift off from the lunar surface and rejoin Collins in the command module. They jettisoned Eagle before they performed the maneuvers that propelled Columbia out of the last of its 30 lunar orbits onto a trajectory back to Earth. They returned to Earth and splashed down in the Pacific Ocean on July 24 after more than eight days in space.\\nArmstrong's first step onto the lunar surface was broadcast on live TV to a worldwide audience. He described the event as \"one small step for [a] man, one giant leap for mankind.\" Apollo 11 effectively proved U.S. victory in the Space Race to demonstrate spaceflight superiority, by fulfilling a national goal proposed in 1961 by President John F. Kennedy, \"before this decade is out, of landing a man on the Moon and returning him safely to the Earth.\"\\n\\nBackground\\nIn the late 1950s and early 1960s, the United States was engaged in the Cold War, a geopolitical rivalry with the Soviet Union. On October 4, 1957, the Soviet Union launched Sputnik 1, the first artificial satellite. This surprise success fired fears and imaginations around the world. It demonstrated that the Soviet Union had the capability to deliver nuclear weapons over intercontinental distances, and challenged American claims of military, economic, and technological superiority. This precipitated the Sputnik crisis, and triggered the Space Race to prove which superpower would achieve superior spaceflight capability. President Dwight D. Eisenhower responded to the Sputnik challenge by creating the National Aeronautics and Space Administration (NASA), and initiating Project Mercury, which aimed to launch a man into Earth orbit. But on April 12, 1961, Soviet cosmonaut Yuri Gagarin became the first person in space, and the first to orbit the Earth. Nearly a month later, on May 5, 1961, Alan Shepard became the first American in space, completing a 15-minute suborbital journey. After being recovered from the Atlantic Ocean, he received a congratulatory telephone call from Eisenhower's successor, John F. Kennedy.Since the Soviet Union had higher lift capacity launch vehicles, Kennedy chose, from among options presented by NASA, a challenge beyond the capacity of the existing generation of rocketry, so that the US and Soviet Union would be starting from a position of equality. A crewed mission to the Moon would serve this purpose.On May 25, 1961, Kennedy addressed the United States Congress on \"Urgent National Needs\" and declared:\\n\\nI believe that this nation should commit itself to achieving the goal, before this decade [1960s] is out, of landing a man on the Moon and returning him safely to the Earth. No single space project in this period will be more impressive to mankind, or more important for the long-range exploration of space; and none will be so difficult or expensive to accomplish. We propose to accelerate the development of the appropriate lunar space craft. We propose to develop alternate liquid and solid fuel boosters, much larger than any now being developed, until certain which is superior. We propose additional funds for other engine development and for unmanned explorations\u2014explorations which are particularly important for one purpose which this nation will never overlook: the survival of the man who first makes this daring flight. But in a very real sense, it will not be one man going to the Moon\u2014if we make this judgment affirmatively, it will be an entire nation. For all of us must work to put him there. \\nOn September 12, 1962, Kennedy delivered another speech before a crowd of about 40,000 people in the Rice University football stadium in Houston, Texas. A widely quoted refrain from the middle portion of the speech reads as follows:\\n\\nThere is no strife, no prejudice, no national conflict in outer space as yet. Its hazards are hostile to us all. Its conquest deserves the best of all mankind, and its opportunity for peaceful cooperation may never come again. But why, some say, the Moon? Why choose this as our goal? And they may well ask, why climb the highest mountain? Why, 35 years ago, fly the Atlantic? Why does Rice play Texas?\\nWe choose to go to the Moon! We choose to go to the Moon ... We choose to go to the Moon in this decade and do the other things, not because they are easy, but because they are hard; because that goal will serve to organize and measure the best of our energies and skills, because that challenge is one that we are willing to accept, one we are unwilling to postpone, and one we intend to win, and the others, too.\\nIn spite of that, the proposed program faced the opposition of many Americans and was dubbed a \"moondoggle\" by Norbert Wiener, a mathematician at the Massachusetts Institute of Technology. The effort to land a man on the Moon already had a name: Project Apollo. When Kennedy met with Nikita Khrushchev, the Premier of the Soviet Union in June 1961, he proposed making the Moon landing a joint project, but Khrushchev did not take up the offer. Kennedy again proposed a joint expedition to the Moon in a speech to the United Nations General Assembly on September 20, 1963. The idea of a joint Moon mission was abandoned after Kennedy's death.An early and crucial decision was choosing lunar orbit rendezvous over both direct ascent and Earth orbit rendezvous. A space rendezvous is an orbital maneuver in which two spacecraft navigate through space and meet up. In July 1962 NASA head James Webb announced that lunar orbit rendezvous would be used and that the Apollo spacecraft would have three major parts: a command module (CM) with a cabin for the three astronauts, and the only part that returned to Earth; a service module (SM), which supported the command module with propulsion, electrical power, oxygen, and water; and a lunar module (LM) that had two stages\u2014a descent stage for landing on the Moon, and an ascent stage to place the astronauts back into lunar orbit. This design meant the spacecraft could be launched by a single Saturn V rocket that was then under development.Technologies and techniques required for Apollo were developed by Project Gemini. The Apollo project was enabled by NASA's adoption of new advances in semiconductor electronic technology, including metal\u2013oxide\u2013semiconductor field-effect transistors (MOSFETs) in the Interplanetary Monitoring Platform (IMP) and silicon integrated circuit (IC) chips in the Apollo Guidance Computer (AGC).Project Apollo was abruptly halted by the Apollo 1 fire on January 27, 1967, in which astronauts Gus Grissom, Ed White, and Roger B. Chaffee died, and the subsequent investigation. In October 1968, Apollo 7 evaluated the command module in Earth orbit, and in December Apollo 8 tested it in lunar orbit. In March 1969, Apollo 9 put the lunar module through its paces in Earth orbit, and in May Apollo 10 conducted a \"dress rehearsal\" in lunar orbit. By July 1969, all was in readiness for Apollo 11 to take the final step onto the Moon.The Soviet Union appeared  to be winning the Space Race by beating the US to firsts, but its early lead was overtaken by the US Gemini program and Soviet failure to develop the N1 launcher, which would have been comparable to the Saturn V. The Soviets tried to beat the US to return lunar material to the Earth by means of uncrewed probes. On July 13, three days before Apollo 11's launch, the Soviet Union launched Luna 15, which reached lunar orbit before Apollo 11. During descent, a malfunction caused Luna 15 to crash in Mare Crisium about two hours before Armstrong and Aldrin took off from the Moon's surface to begin their voyage home. The Nuffield Radio Astronomy Laboratories radio telescope in England recorded transmissions from Luna 15 during its descent, and these were released in July 2009 for the 40th anniversary of Apollo 11.\\n\\nPersonnel\\nPrime crew\\nThe initial crew assignment of Commander Neil Armstrong, Command Module Pilot (CMP) Jim Lovell, and Lunar Module Pilot (LMP) Buzz Aldrin on the backup crew for Apollo 9 was officially announced on November 20, 1967. Lovell and Aldrin had previously flown together as the crew of Gemini 12. Due to design and manufacturing delays in the LM, Apollo 8 and Apollo 9 swapped prime and backup crews, and Armstrong's crew became the backup for Apollo 8. Based on the normal crew rotation scheme, Armstrong was then expected to command Apollo 11.There would be one change. Michael Collins, the CMP on the Apollo 8 crew, began experiencing trouble with his legs. Doctors diagnosed the problem as a bony growth between his fifth and sixth vertebrae, requiring surgery. Lovell took his place on the Apollo 8 crew, and when Collins recovered he joined Armstrong's crew as CMP. In the meantime, Fred Haise filled in as backup LMP, and Aldrin as backup CMP for Apollo 8. Apollo 11 was the second American mission where all the crew members had prior spaceflight experience, the first being Apollo 10. The next was STS-26 in 1988.Deke Slayton gave Armstrong the option to replace Aldrin with Lovell, since some thought Aldrin was difficult to work with. Armstrong had no issues working with Aldrin but thought it over for a day before declining. He thought Lovell deserved to command his own mission (eventually Apollo 13).The Apollo 11 prime crew had none of the close cheerful camaraderie characterized by that of Apollo 12. Instead, they forged an amiable working relationship. Armstrong in particular was notoriously aloof, but Collins, who considered himself a loner, confessed to rebuffing Aldrin's attempts to create a more personal relationship. Aldrin and Collins described the crew as \"amiable strangers\". Armstrong did not agree with the assessment, and said \"... all the crews I was on worked very well together.\"\\n\\nBackup crew\\nThe backup crew consisted of Lovell as Commander, William Anders as CMP, and Haise as LMP. Anders had flown with Lovell on Apollo 8. In early 1969, Anders accepted a job with the National Aeronautics and Space Council effective August 1969, and announced he would retire as an astronaut at that time. Ken Mattingly was moved from the support crew into parallel training with Anders as backup CMP in case Apollo 11 was delayed past its intended July launch date, at which point Anders would be unavailable.By the normal crew rotation in place during Apollo, Lovell, Mattingly, and Haise were scheduled to fly on Apollo 14, but the three of them were bumped to Apollo 13: there was a crew issue for Apollo 13 as none of them except Edgar Mitchell flew in space again. George Mueller rejected the crew and this was the first time an Apollo crew was rejected. To give Alan Shepard more training time, Lovell's crew were bumped to Apollo 13. Mattingly would later be replaced by Jack Swigert as CMP on Apollo 13.\\n\\nSupport crew\\nDuring Projects Mercury and Gemini, each mission had a prime and a backup crew. For Apollo, a third crew of astronauts was added, known as the support crew. The support crew maintained the flight plan, checklists and mission ground rules, and ensured the prime and backup crews were apprised of changes. They developed procedures, especially those for emergency situations, so these were ready for when the prime and backup crews came to train in the simulators, allowing them to concentrate on practicing and mastering them. For Apollo 11, the support crew consisted of Ken Mattingly, Ronald Evans and Bill Pogue.\\n\\nCapsule communicators\\nThe capsule communicator (CAPCOM) was an astronaut at the Mission Control Center in Houston, Texas, who was the only person who communicated directly with the flight crew. For Apollo 11, the CAPCOMs were: Charles Duke, Ronald Evans, Bruce McCandless II, James Lovell, William Anders, Ken Mattingly, Fred Haise, Don L. Lind, Owen K. Garriott and Harrison Schmitt.\\n\\nFlight directors\\nThe flight directors for this mission were:\\n\\nOther key personnel\\nOther key personnel who played important roles in the Apollo 11 mission include the following.\\n\\nPreparations\\nInsignia\\nThe Apollo 11 mission emblem was designed by Collins, who wanted a symbol for \"peaceful lunar landing by the United States\". At Lovell's suggestion, he chose the bald eagle, the national bird of the United States, as the symbol. Tom Wilson, a simulator instructor, suggested an olive branch in its beak to represent their peaceful mission. Collins added a lunar background with the Earth in the distance. The sunlight in the image was coming from the wrong direction; the shadow should have been in the lower part of the Earth instead of the left. Aldrin, Armstrong and Collins decided the Eagle and the Moon would be in their natural colors, and decided on a blue and gold border. Armstrong was concerned that \"eleven\" would not be understood by non-English speakers, so they went with \"Apollo 11\", and they decided not to put their names on the patch, so it would \"be representative of everyone who had worked toward a lunar landing\".An illustrator at the Manned Spacecraft Center (MSC) did the artwork, which was then sent off to NASA officials for approval. The design was rejected. Bob Gilruth, the director of the MSC felt the talons of the eagle looked \"too warlike\". After some discussion, the olive branch was moved to the talons. When the Eisenhower dollar coin was released in 1971, the patch design provided the eagle for its reverse side. The design was also used for the smaller Susan B. Anthony dollar unveiled in 1979.\\n\\nCall signs\\nAfter the crew of Apollo 10 named their spacecraft Charlie Brown and Snoopy, assistant manager for public affairs Julian Scheer wrote to George Low, the Manager of the Apollo Spacecraft Program Office at the MSC, to suggest the Apollo 11 crew be less flippant in naming their craft. The name Snowcone was used for the CM and Haystack was used for the LM in both internal and external communications during early mission planning.The LM was named Eagle after the motif which was featured prominently on the mission insignia. At Scheer's suggestion, the CM was named Columbia after Columbiad, the giant cannon that launched a spacecraft (also from Florida) in Jules Verne's 1865 novel From the Earth to the Moon. It also referred to Columbia, a historical name of the United States.  In Collins' 1976 book, he said Columbia was in reference to Christopher Columbus.\\n\\nMementos\\nThe astronauts had personal preference kits (PPKs), small bags containing personal items of significance they wanted to take with them on the mission. Five 0.5-pound (0.23 kg) PPKs were carried on Apollo 11: three (one for each astronaut) were stowed on Columbia before launch, and two on Eagle.Neil Armstrong's LM PPK contained a piece of wood from the Wright brothers' 1903 Wright Flyer's left propeller and a piece of fabric from its wing, along with a diamond-studded astronaut pin originally given to Slayton by the widows of the Apollo 1 crew. This pin had been intended to be flown on that mission and given to Slayton afterwards, but following the disastrous launch pad fire and subsequent funerals, the widows gave the pin to Slayton. Armstrong took it with him on Apollo 11.\\n\\nSite selection\\nNASA's Apollo Site Selection Board announced five potential landing sites on February 8, 1968. These were the result of two years' worth of studies based on high-resolution photography of the lunar surface by the five uncrewed probes of the Lunar Orbiter program and information about surface conditions provided by the Surveyor program. The best Earth-bound telescopes could not resolve features with the resolution Project Apollo required. The landing site had to be close to the lunar equator to minimize the amount of propellant required, clear of obstacles to minimize maneuvering, and flat to simplify the task of the landing radar. Scientific value was not a consideration.Areas that appeared promising on photographs taken on Earth were often found to be totally unacceptable. The original requirement that the site be free of craters had to be relaxed, as no such site was found. Five sites were considered: Sites 1 and 2 were in the Sea of Tranquility (Mare Tranquillitatis); Site 3 was in the Central Bay (Sinus Medii); and Sites 4 and 5 were in the Ocean of Storms (Oceanus Procellarum).\\nThe final site selection was based on seven criteria:\\n\\nThe site needed to be smooth, with relatively few craters;\\nwith approach paths free of large hills, tall cliffs or deep craters that might confuse the landing radar and cause it to issue incorrect readings;\\nreachable with a minimum amount of propellant;\\nallowing for delays in the launch countdown;\\nproviding the Apollo spacecraft with a free-return trajectory, one that would allow it to coast around the Moon and safely return to Earth without requiring any engine firings should a problem arise on the way to the Moon;\\nwith good visibility during the landing approach, meaning the Sun would be between 7 and 20 degrees behind the LM; and\\na general slope of less than two degrees in the landing area.The requirement for the Sun angle was particularly restrictive, limiting the launch date to one day per month. A landing just after dawn was chosen to limit the temperature extremes the astronauts would experience. The Apollo Site Selection Board selected Site 2, with Sites 3 and 5 as backups in the event of the launch being delayed. In May 1969, Apollo 10's lunar module flew to within 15 kilometers (9.3 mi) of Site 2, and reported it was acceptable.\\n\\nFirst-step decision\\nDuring the first press conference after the Apollo 11 crew was announced, the first question was, \"Which one of you gentlemen will be the first man to step onto the lunar surface?\" Slayton told the reporter it had not been decided, and Armstrong added that it was \"not based on individual desire\".One of the first versions of the egress checklist had the lunar module pilot exit the spacecraft before the commander, which matched what had been done on Gemini missions, where the commander had never performed the spacewalk. Reporters wrote in early 1969 that Aldrin would be the first man to walk on the Moon, and Associate Administrator George Mueller told reporters he would be first as well. Aldrin heard that Armstrong would be the first because Armstrong was a civilian, which made Aldrin livid. Aldrin attempted to persuade other lunar module pilots he should be first, but they responded cynically about what they perceived as a lobbying campaign. Attempting to stem interdepartmental conflict, Slayton told Aldrin that Armstrong would be first since he was the commander. The decision was announced in a press conference on April 14, 1969.For decades, Aldrin believed the final decision was largely driven by the lunar module's hatch location. Because the astronauts had their spacesuits on and the spacecraft was so small, maneuvering to exit the spacecraft was difficult. The crew tried a simulation in which Aldrin left the spacecraft first, but he damaged the simulator while attempting to egress. While this was enough for mission planners to make their decision, Aldrin and Armstrong were left in the dark on the decision until late spring. Slayton told Armstrong the plan was to have him leave the spacecraft first, if he agreed. Armstrong said, \"Yes, that's the way to do it.\"The media accused Armstrong of exercising his commander's prerogative to exit the spacecraft first. Chris Kraft revealed in his 2001 autobiography that a meeting occurred between Gilruth, Slayton, Low, and himself to make sure Aldrin would not be the first to walk on the Moon. They argued that the first person to walk on the Moon should be like Charles Lindbergh, a calm and quiet person. They made the decision to change the flight plan so the commander was the first to egress from the spacecraft.\\n\\nPre-launch\\nThe ascent stage of LM-5 Eagle arrived at the Kennedy Space Center on January 8, 1969, followed by the descent stage four days later, and CSM-107 Columbia on January 23. There were several differences between Eagle and Apollo 10's LM-4 Snoopy; Eagle had a VHF radio antenna to facilitate communication with the astronauts during their EVA on the lunar surface; a lighter ascent engine; more thermal protection on the landing gear; and a package of scientific experiments known as the Early Apollo Scientific Experiments Package (EASEP). The only change in the configuration of the command module was the removal of some insulation from the forward hatch. The CSM was mated on January 29, and moved from the Operations and Checkout Building to the Vehicle Assembly Building on April 14.The S-IVB third stage of Saturn V AS-506 had arrived on January 18, followed by the S-II second stage on February 6, S-IC first stage on February 20, and the Saturn V Instrument Unit on February 27. At 12:30 on May 20, the 5,443-tonne (5,357-long-ton; 6,000-short-ton) assembly departed the Vehicle Assembly Building atop the crawler-transporter, bound for Launch Pad 39A, part of Launch Complex 39, while Apollo 10 was still on its way to the Moon. A countdown test commenced on June 26, and concluded on July 2. The launch complex was floodlit on the night of July 15, when the crawler-transporter carried the mobile service structure back to its parking area. In the early hours of the morning, the fuel tanks of the S-II and S-IVB stages were filled with liquid hydrogen. Fueling was completed by three hours before launch. Launch operations were partly automated, with 43 programs written in the ATOLL programming language.Slayton roused the crew shortly after 04:00, and they showered, shaved, and had the traditional pre-flight breakfast of steak and eggs with Slayton and the backup crew. They then donned their space suits and began breathing pure oxygen. At 06:30, they headed out to Launch Complex 39. Haise entered Columbia about three hours and ten minutes before launch time. Along with a technician, he helped Armstrong into the left-hand couch at 06:54. Five minutes later, Collins joined him, taking up his position on the right-hand couch. Finally, Aldrin entered, taking the center couch. Haise left around two hours and ten minutes before launch. The closeout crew sealed the hatch, and the cabin was purged and pressurized. The closeout crew then left the launch complex about an hour before launch time. The countdown became automated at three minutes and twenty seconds before launch time. Over 450 personnel were at the consoles in the firing room.\\n\\nMission\\nLaunch and flight to lunar orbit\\nAn estimated one million spectators watched the launch of Apollo 11 from the highways and beaches in the vicinity of the launch site. Dignitaries included the Chief of Staff of the United States Army, General William Westmoreland, four cabinet members, 19 state governors, 40 mayors, 60 ambassadors and 200 congressmen. Vice President Spiro Agnew viewed the launch with former president Lyndon B. Johnson and his wife Lady Bird Johnson. Around 3,500 media representatives were present. About two-thirds were from the United States; the rest came from 55 other countries. The launch was televised live in 33 countries, with an estimated 25 million viewers in the United States alone. Millions more around the world listened to radio broadcasts. President Richard Nixon viewed the launch from his office in the White House with his NASA liaison officer, Apollo astronaut Frank Borman.Saturn V AS-506 launched Apollo 11 on July 16, 1969, at 13:32:00 UTC (9:32:00 EDT). At 13.2 seconds into the flight, the launch vehicle began to roll into its flight azimuth of 72.058\u00b0. Full shutdown of the first-stage engines occurred about 2 minutes and 42 seconds into the mission, followed by separation of the S-IC and ignition of the S-II engines. The second stage engines then cut off and separated at about 9 minutes and 8 seconds, allowing the first ignition of the S-IVB engine a few seconds later.Apollo 11 entered a near-circular Earth orbit at an altitude of 100.4 nautical miles (185.9 km) by 98.9 nautical miles (183.2 km), twelve minutes into its flight. After one and a half orbits, a second ignition of the S-IVB engine pushed the spacecraft onto its trajectory toward the Moon with the trans-lunar injection (TLI) burn at 16:22:13 UTC. About 30 minutes later, with Collins in the left seat and at the controls, the transposition, docking, and extraction maneuver was performed. This involved separating Columbia from the spent S-IVB stage, turning around, and docking with Eagle still attached to the stage. After the LM was extracted, the combined spacecraft headed for the Moon, while the rocket stage flew on a trajectory past the Moon. This was done to avoid the third stage colliding with the spacecraft, the Earth, or the Moon. A slingshot effect from passing around the Moon threw it into an orbit around the Sun.On July 19 at 17:21:50 UTC, Apollo 11 passed behind the Moon and fired its service propulsion engine to enter lunar orbit. In the thirty orbits that followed, the crew saw passing views of their landing site in the southern Sea of Tranquility about 12 miles (19 km) southwest of the crater Sabine D. The site was selected in part because it had been characterized as relatively flat and smooth by the automated Ranger 8 and Surveyor 5 landers and the Lunar Orbiter mapping spacecraft, and because it was unlikely to present major landing or EVA challenges. It lay about 25 kilometers (16 mi) southeast of the Surveyor 5 landing site, and 68 kilometers (42 mi) southwest of Ranger 8's crash site.\\n\\nLunar descent\\nAt 12:52:00 UTC on July 20, Aldrin and Armstrong entered Eagle, and began the final preparations for lunar descent. At 17:44:00 Eagle separated from Columbia. Collins, alone aboard Columbia, inspected Eagle as it pirouetted before him to ensure the craft was not damaged, and that the landing gear was correctly deployed. Armstrong exclaimed: \"The Eagle has wings!\"As the descent began, Armstrong and Aldrin found themselves passing landmarks on the surface two or three seconds early, and reported that they were \"long\"; they would land miles west of their target point. Eagle was traveling too fast. The problem could have been mascons\u2014concen\u00adtra\u00adtions of high mass in a region or regions of the Moon's crust that contains a gravitational anomaly, potentially altering Eagle's trajectory. Flight Director Gene Kranz speculated that it could have resulted from extra air pressure in the docking tunnel, or a result of Eagle's pirouette maneuver.Five minutes into the descent burn, and 6,000 feet (1,800 m) above the surface of the Moon, the LM guidance computer (LGC) distracted the crew with the first of several unexpected 1201 and 1202 program alarms. Inside Mission Control Center, computer engineer Jack Garman told Guidance Officer Steve Bales it was safe to continue the descent, and this was relayed to the crew. The program alarms indicated \"executive overflows\", meaning the guidance computer could not complete all its tasks in real-time and had to postpone some of them. Margaret Hamilton, the Director of Apollo Flight Computer Programming at the MIT Charles Stark Draper Laboratory later recalled:\\n\\nTo blame the computer for the Apollo 11 problems is like blaming the person who spots a fire and calls the fire department. Actually, the computer was programmed to do more than recognize error conditions. A complete set of recovery programs was incorporated into the software. The software's action, in this case, was to eliminate lower priority tasks and re-establish the more important ones. The computer, rather than almost forcing an abort, prevented an abort. If the computer hadn't recognized this problem and taken recovery action, I doubt if Apollo 11 would have been the successful Moon landing it was.\\nDuring the mission, the cause was diagnosed as the rendezvous radar switch being in the wrong position, causing the computer to process data from both the rendezvous and landing radars at the same time. Software engineer Don Eyles concluded in a 2005 Guidance and Control Conference paper that the problem was due to a hardware design bug previously seen during testing of the first uncrewed LM in Apollo 5. Having the rendezvous radar on (so it was warmed up in case of an emergency landing abort) should have been irrelevant to the computer, but an electrical phasing mismatch between two parts of the rendezvous radar system could cause the stationary antenna to appear to the computer as dithering back and forth between two positions, depending upon how the hardware randomly powered up. The extra spurious cycle stealing, as the rendezvous radar updated an involuntary counter, caused the computer alarms.\\n\\nLanding\\nWhen Armstrong again looked outside, he saw that the computer's landing target was in a boulder-strewn area just north and east of a 300-foot-diameter (91 m) crater (later determined to be West crater), so he took semi-automatic control. Armstrong considered landing short of the boulder field so they could collect geological samples from it, but could not since their horizontal velocity was too high. Throughout the descent, Aldrin called out navigation data to Armstrong, who was busy piloting Eagle. Now 107 feet (33 m) above the surface, Armstrong knew their propellant supply was dwindling and was determined to land at the first possible landing site.Armstrong found a clear patch of ground and maneuvered the spacecraft towards it. As he got closer, now 250 feet (76 m) above the surface, he discovered his new landing site had a crater in it. He cleared the crater and found another patch of level ground. They were now 100 feet (30 m) from the surface, with only 90 seconds of propellant remaining. Lunar dust kicked up by the LM's engine began to impair his ability to determine the spacecraft's motion. Some large rocks jutted out of the dust cloud, and Armstrong focused on them during his descent so he could determine the spacecraft's speed.A light informed Aldrin that at least one of the 67-inch (170 cm) probes hanging from Eagle's footpads had touched the surface a few moments before the landing and he said: \"Contact light!\" Armstrong was supposed to immediately shut the engine down, as the engineers suspected the pressure caused by the engine's own exhaust reflecting off the lunar surface could make it explode, but he forgot. Three seconds later, Eagle landed and Armstrong shut the engine down. Aldrin immediately said \"Okay, engine stop. ACA\u2014out of detent.\" Armstrong acknowledged: \"Out of detent. Auto.\" Aldrin continued: \"Mode control\u2014both auto. Descent engine command override off. Engine arm\u2014off. 413 is in.\"\\nACA was the Attitude Control Assembly\u2014the LM's control stick. Output went to the LGC to command the reaction control system (RCS) jets to fire. \"Out of Detent\" meant the stick had moved away from its centered position; it was spring-centered like the turn indicator in a car. Address 413 of the Abort Guidance System (AGS) contained the variable that indicated the LM had landed.Eagle landed at 20:17:40 UTC on Sunday July 20 with 216 pounds (98 kg) of usable fuel remaining. Information available to the crew and mission controllers during the landing showed the LM had enough fuel for another 25 seconds of powered flight before an abort without touchdown would have become unsafe, but post-mission analysis showed that the real figure was probably closer to 50 seconds. Apollo 11 landed with less fuel than most subsequent missions, and the astronauts encountered a premature low fuel warning. This was later found to be the result of the propellant sloshing more than expected, uncovering a fuel sensor. On subsequent missions, extra anti-slosh baffles were added to the tanks to prevent this.Armstrong acknowledged Aldrin's completion of the post-landing checklist with \"Engine arm is off\", before responding to the CAPCOM, Charles Duke, with the words, \"Houston, Tranquility Base here. The Eagle has landed.\" Armstrong's unrehearsed change of call sign from \"Eagle\" to \"Tranquility Base\" emphasized to listeners that landing was complete and successful. Duke expressed the relief at Mission Control: \"Roger, Twan\u2014Tranquility, we copy you on the ground. You got a bunch of guys about to turn blue. We're breathing again. Thanks a lot.\"\\nTwo and a half hours after landing, before preparations began for the EVA, Aldrin radioed to Earth:\\n\\nThis is the LM pilot. I'd like to take this opportunity to ask every person listening in, whoever and wherever they may be, to pause for a moment and contemplate the events of the past few hours and to give thanks in his or her own way.\\nHe then took communion privately. At this time NASA was still fighting a lawsuit brought by atheist Madalyn Murray O'Hair (who had objected to the Apollo 8 crew reading from the Book of Genesis) demanding that their astronauts refrain from broadcasting religious activities while in space. For this reason, Aldrin chose to refrain from directly mentioning taking communion on the Moon. Aldrin was an elder at the Webster Presbyterian Church, and his communion kit was prepared by the pastor of the church, Dean Woodruff. Webster Presbyterian possesses the chalice used on the Moon and commemorates the event each year on the Sunday closest to July 20. The schedule for the mission called for the astronauts to follow the landing with a five-hour sleep period, but they chose to begin preparations for the EVA early, thinking they would be unable to sleep.\\n\\nLunar surface operations\\nPreparations for Neil Armstrong and Buzz Aldrin to walk on the Moon began at 23:43 UTC. These took longer than expected; three and a half hours instead of two. During training on Earth, everything required had been neatly laid out in advance, but on the Moon the cabin contained a large number of other items as well, such as checklists, food packets, and tools. Six hours and thirty-nine minutes after landing, Armstrong and Aldrin were ready to go outside, and Eagle was depressurized.Eagle's hatch was opened at 02:39:33. Armstrong initially had some difficulties squeezing through the hatch with his portable life support system (PLSS). Some of the highest heart rates recorded from Apollo astronauts occurred during LM egress and ingress. At 02:51 Armstrong began his descent to the lunar surface. The remote control unit on his chest kept him from seeing his feet. Climbing down the nine-rung ladder, Armstrong pulled a D-ring to deploy the modular equipment stowage assembly (MESA) folded against Eagle's side and activate the TV camera.Apollo 11 used slow-scan television (TV) incompatible with broadcast TV, so it was displayed on a special monitor and a conventional TV camera viewed this monitor (thus, a broadcast of a broadcast), significantly reducing the quality of the picture. The signal was received at Goldstone in the United States, but with better fidelity by Honeysuckle Creek Tracking Station near Canberra in Australia. Minutes later the feed was switched to the more sensitive Parkes radio telescope in Australia. Despite some technical and weather difficulties, black and white images of the first lunar EVA were received and broadcast to at least 600 million people on Earth. Copies of this video in broadcast format were saved and are widely available, but recordings of the original slow scan source transmission from the lunar surface were likely destroyed during routine magnetic tape re-use at NASA.\\n\\nAfter describing the surface dust as \"very fine-grained\" and \"almost like a powder\", at 02:56:15, six and a half hours after landing, Armstrong stepped off Eagle's landing pad and declared: \"That's one small step for [a] man, one giant leap for mankind.\"Armstrong intended to say \"That's one small step for a man\", but the word \"a\" is not audible in the transmission, and thus was not initially reported by most observers of the live broadcast. When later asked about his quote, Armstrong said he believed he said \"for a man\", and subsequent printed versions of the quote included the \"a\" in square brackets. One explanation for the absence may be that his accent caused him to slur the words \"for a\" together; another is the intermittent nature of the audio and video links to Earth, partly because of storms near Parkes Observatory. A more recent digital analysis of the tape claims to reveal the \"a\" may have been spoken but obscured by static. Other analysis points to the claims of static and slurring as \"face-saving fabrication\", and that Armstrong himself later admitted to misspeaking the line.About seven minutes after stepping onto the Moon's surface, Armstrong collected a contingency soil sample using a sample bag on a stick. He then folded the bag and tucked it into a pocket on his right thigh. This was to guarantee there would be some lunar soil brought back in case an emergency required the astronauts to abandon the EVA and return to the LM. Twelve minutes after the sample was collected, he removed the TV camera from the MESA and made a panoramic sweep, then mounted it on a tripod. The TV camera cable remained partly coiled and presented a tripping hazard throughout the EVA. Still photography was accomplished with a Hasselblad camera that could be operated hand-held or mounted on Armstrong's Apollo space suit. Aldrin joined Armstrong on the surface. He described the view with the simple phrase: \"Magnificent desolation.\"Armstrong said moving in the lunar gravity, one-sixth of Earth's, was \"even perhaps easier than the simulations ... It's absolutely no trouble to walk around.\" Aldrin joined him on the surface and tested methods for moving around, including two-footed kangaroo hops. The PLSS backpack created a tendency to tip backward, but neither astronaut had serious problems maintaining balance. Loping became the preferred method of movement. The astronauts reported that they needed to plan their movements six or seven steps ahead. The fine soil was quite slippery. Aldrin remarked that moving from sunlight into Eagle's shadow produced no temperature change inside the suit, but the helmet was warmer in sunlight, so he felt cooler in shadow. The MESA failed to provide a stable work platform and was in shadow, slowing work somewhat. As they worked, the moonwalkers kicked up gray dust, which soiled the outer part of their suits.\\nThe astronauts planted the Lunar Flag Assembly containing a flag of the United States on the lunar surface, in clear view of the TV camera. Aldrin remembered, \"Of all the jobs I had to do on the Moon the one I wanted to go the smoothest was the flag raising.\" But the astronauts struggled with the telescoping rod and could only insert the pole about 2 inches (5 cm) into the hard lunar surface. Aldrin was afraid it might topple in front of TV viewers, but gave \"a crisp West Point salute\". Before Aldrin could take a photo of Armstrong with the flag, President Richard Nixon spoke to them through a telephone-radio transmission, which Nixon called \"the most historic phone call ever made from the White House.\" Nixon originally had a long speech prepared to read during the phone call, but Frank Borman, who was at the White House as a NASA liaison during Apollo 11, convinced Nixon to keep his words brief.\\nNixon: Hello, Neil and Buzz. I'm talking to you by telephone from the Oval Room at the White House. And this certainly has to be the most historic telephone call ever made from the White House. I just can't tell you how proud we all are of what you have done. For every American, this has to be the proudest day of our lives. And for people all over the world, I am sure that they too join with Americans in recognizing what an immense feat this is. Because of what you have done, the heavens have become a part of man's world. And as you talk to us from the Sea of Tranquility, it inspires us to redouble our efforts to bring peace and tranquility to Earth. For one priceless moment in the whole history of man, all the people on this Earth are truly one: one in their pride in what you have done, and one in our prayers that you will return safely to Earth.\\nArmstrong: Thank you, Mr. President. It's a great honor and privilege for us to be here, representing not only the United States, but men of peace of all nations, and with interest and a curiosity, and men with a vision for the future. It's an honor for us to be able to participate here today.\\nThey deployed the EASEP, which included a passive seismic experiment package used to measure moonquakes and a retroreflector array used for the lunar laser ranging experiment. Then Armstrong walked 196 feet (60 m) from the LM to take photographs at the rim of Little West Crater while Aldrin collected two core samples. He used the geologist's hammer to pound in the tubes\u2014the only time the hammer was used on Apollo 11\u2014but was unable to penetrate more than 6 inches (15 cm) deep. The astronauts then collected rock samples using scoops and tongs on extension handles. Many of the surface activities took longer than expected, so they had to stop documenting sample collection halfway through the allotted 34 minutes. Aldrin shoveled 6 kilograms (13 lb) of soil into the box of rocks in order to pack them in tightly. Two types of rocks were found in the geological samples: basalt and breccia. Three new minerals were discovered in the rock samples collected by the astronauts: armalcolite, tranquillityite, and pyroxferroite. Armalcolite was named after Armstrong, Aldrin, and Collins. All have subsequently been found on Earth.\\nWhile on the surface, Armstrong uncovered a plaque mounted on the LM ladder, bearing two drawings of Earth (of the Western and Eastern Hemispheres), an inscription, and signatures of the astronauts and President Nixon. The inscription read:\\n\\nHere men from the planet Earth first set foot upon the Moon July 1969, A. D. We came in peace for all mankind.\\nAt the behest of the Nixon administration to add a reference to God, NASA included the vague date as a reason to include A.D., which stands for Anno Domini (\"in the year of our Lord\").Mission Control used a coded phrase to warn Armstrong his metabolic rates were high, and that he should slow down. He was moving rapidly from task to task as time ran out. As metabolic rates remained generally lower than expected for both astronauts throughout the walk, Mission Control granted the astronauts a 15-minute extension. In a 2010 interview, Armstrong explained that NASA limited the first moonwalk's time and distance because there was no empirical proof of how much cooling water the astronauts' PLSS backpacks would consume to handle their body heat generation while working on the Moon.\\n\\nLunar ascent\\nAldrin entered Eagle first. With some difficulty the astronauts lifted film and two sample boxes containing 21.55 kilograms (47.5 lb) of lunar surface material to the LM hatch using a flat cable pulley device called the Lunar Equipment Conveyor (LEC). This proved to be an inefficient tool, and later missions preferred to carry equipment and samples up to the LM by hand. Armstrong reminded Aldrin of a bag of memorial items in his sleeve pocket, and Aldrin tossed the bag down. Armstrong then jumped onto the ladder's third rung, and climbed into the LM. After transferring to LM life support, the explorers lightened the ascent stage for the return to lunar orbit by tossing out their PLSS backpacks, lunar overshoes, an empty Hasselblad camera, and other equipment. The hatch was closed again at 05:11:13. They then pressurized the LM and settled down to sleep.\\nPresidential speech writer William Safire had prepared an In Event of Moon Disaster announcement for Nixon to read in the event the Apollo 11 astronauts were stranded on the Moon. The remarks were in a memo from Safire to Nixon's White House Chief of Staff H. R. Haldeman, in which Safire suggested a protocol the administration might follow in reaction to such a disaster. According to the plan, Mission Control would \"close down communications\" with the LM, and a clergyman would \"commend their souls to the deepest of the deep\" in a public ritual likened to burial at sea. The last line of the prepared text contained an allusion to Rupert Brooke's World War I poem \"The Soldier\".While moving inside the cabin, Aldrin accidentally damaged the circuit breaker that would arm the main engine for liftoff from the Moon. There was a concern this would prevent firing the engine, stranding them on the Moon. The nonconductive tip of a Duro felt-tip pen was sufficient to activate the switch.After more than 21+1\u20442 hours on the lunar surface, in addition to the scientific instruments, the astronauts left behind: an Apollo 1 mission patch in memory of astronauts Roger Chaffee, Gus Grissom, and Edward White, who died when their command module caught fire during a test in January 1967; two memorial medals of Soviet cosmonauts Vladimir Komarov and Yuri Gagarin, who died in 1967 and 1968 respectively; a memorial bag containing a gold replica of an olive branch as a traditional symbol of peace; and a silicon message disk carrying the goodwill statements by Presidents Eisenhower, Kennedy, Johnson, and Nixon along with messages from leaders of 73 countries around the world. The disk also carries a listing of the leadership of the US Congress, a listing of members of the four committees of the House and Senate responsible for the NASA legislation, and the names of NASA's past and then-current top management.\\nAfter about seven hours of rest, the crew was awakened by Houston to prepare for the return flight. Two and a half hours later, at 17:54:00 UTC, they lifted off in Eagle's ascent stage to rejoin Collins aboard Columbia in lunar orbit. Film taken from the LM ascent stage upon liftoff from the Moon reveals the American flag, planted some 25 feet (8 m) from the descent stage, whipping violently in the exhaust of the ascent stage engine. Aldrin looked up in time to witness the flag topple: \"The ascent stage of the LM separated ... I was concentrating on the computers, and Neil was studying the attitude indicator, but I looked up long enough to see the flag fall over.\" Subsequent Apollo missions planted their flags farther from the LM.\\n\\nColumbia in lunar orbit\\nDuring his day flying solo around the Moon, Collins never felt lonely. Although it has been said \"not since Adam has any human known such solitude\", Collins felt very much a part of the mission. In his autobiography he wrote: \"this venture has been structured for three men, and I consider my third to be as necessary as either of the other two\". In the 48 minutes of each orbit when he was out of radio contact with the Earth while Columbia passed round the far side of the Moon, the feeling he reported was not fear or loneliness, but rather \"awareness, anticipation, satisfaction, confidence, almost exultation\".One of Collins' first tasks was to identify the lunar module on the ground. To give Collins an idea where to look, Mission Control radioed that they believed the lunar module landed about 4 miles (6.4 km) off target. Each time he passed over the suspected lunar landing site, he tried in vain to find the module. On his first orbits on the back side of the Moon, Collins performed maintenance activities such as dumping excess water produced by the fuel cells and preparing the cabin for Armstrong and Aldrin to return.Just before he reached the dark side on the third orbit, Mission Control informed Collins there was a problem with the temperature of the coolant. If it became too cold, parts of Columbia might freeze. Mission Control advised him to assume manual control and implement Environmental Control System Malfunction Procedure 17. Instead, Collins flicked the switch on the system from automatic to manual and back to automatic again, and carried on with normal housekeeping chores, while keeping an eye on the temperature. When Columbia came back around to the near side of the Moon again, he was able to report that the problem had been resolved. For the next couple of orbits, he described his time on the back side of the Moon as \"relaxing\". After Aldrin and Armstrong completed their EVA, Collins slept so he could be rested for the rendezvous. While the flight plan called for Eagle to meet up with Columbia, Collins was prepared for a contingency in which he would fly Columbia down to meet Eagle.\\n\\nReturn\\nEagle rendezvoused with Columbia at 21:24 UTC on July 21, and the two docked at 21:35. Eagle's ascent stage was jettisoned into lunar orbit at 23:41. Just before the Apollo 12 flight, it was noted that Eagle was still likely to be orbiting the Moon. Later NASA reports mentioned that Eagle's orbit had decayed, resulting in it impacting in an \"uncertain location\" on the lunar surface. In 2021, however, some calculations show that the lander may still be in orbit.On July 23, the last night before splashdown, the three astronauts made a television broadcast in which Collins commented:\\n\\n ... The Saturn V rocket which put us in orbit is an incredibly complicated piece of machinery, every piece of which worked flawlessly ... We have always had confidence that this equipment will work properly. All this is possible only through the blood, sweat, and tears of a number of people ... All you see is the three of us, but beneath the surface are thousands and thousands of others, and to all of those, I would like to say, \"Thank you very much.\"\\nAldrin added:\\n\\nThis has been far more than three men on a mission to the Moon; more, still, than the efforts of a government and industry team; more, even, than the efforts of one nation. We feel that this stands as a symbol of the insatiable curiosity of all mankind to explore the unknown ... Personally, in reflecting on the events of the past several days, a verse from Psalms comes to mind. \"When I consider the heavens, the work of Thy fingers, the Moon and the stars, which Thou hast ordained; What is man that Thou art mindful of him?\"\\nArmstrong concluded:\\n\\nThe responsibility for this flight lies first with history and with the giants of science who have preceded this effort; next with the American people, who have, through their will, indicated their desire; next with four administrations and their Congresses, for implementing that will; and then, with the agency and industry teams that built our spacecraft, the Saturn, the Columbia, the Eagle, and the little EMU, the spacesuit and backpack that was our small spacecraft out on the lunar surface. We would like to give special thanks to all those Americans who built the spacecraft; who did the construction, design, the tests, and put their hearts and all their abilities into those craft. To those people tonight, we give a special thank you, and to all the other people that are listening and watching tonight, God bless you. Good night from Apollo 11. \\nOn the return to Earth, a bearing at the Guam tracking station failed, potentially preventing communication on the last segment of the Earth return. A regular repair was not possible in the available time but the station director, Charles Force, had his ten-year-old son Greg use his small hands to reach into the housing and pack it with grease. Greg was later thanked by Armstrong.\\n\\nSplashdown and quarantine\\nThe aircraft carrier USS Hornet, under the command of Captain Carl J. Seiberlich, was selected as the primary recovery ship (PRS) for Apollo 11 on June 5, replacing its sister ship, the LPH USS Princeton, which had recovered Apollo 10 on May 26. Hornet was then at her home port of Long Beach, California. On reaching Pearl Harbor on July 5, Hornet embarked the Sikorsky SH-3 Sea King helicopters of HS-4, a unit which specialized in recovery of Apollo spacecraft, specialized divers of UDT Detachment Apollo, a 35-man NASA recovery team, and about 120 media representatives. To make room, most of Hornet's air wing was left behind in Long Beach. Special recovery equipment was also loaded, including a boilerplate command module used for training.On July 12, with Apollo 11 still on the launch pad, Hornet departed Pearl Harbor for the recovery area in the central Pacific, in the vicinity of 10\u00b036\u2032N 172\u00b024\u2032E. A presidential party consisting of Nixon, Borman, Secretary of State William P. Rogers and National Security Advisor Henry Kissinger flew to Johnston Atoll on Air Force One, then to the command ship USS Arlington in Marine One. After a night on board, they would fly to Hornet in Marine One for a few hours of ceremonies. On arrival aboard Hornet, the party was greeted by the Commander-in-Chief, Pacific Command (CINCPAC), Admiral John S. McCain Jr., and NASA Administrator Thomas O. Paine, who flew to Hornet from Pago Pago in one of Hornet's carrier onboard delivery aircraft.Weather satellites were not yet common, but US Air Force Captain Hank Brandli had access to top-secret spy satellite images. He realized that a storm front was headed for the Apollo recovery area. Poor visibility which could make locating the capsule difficult, and strong upper-level winds which \"would have ripped their parachutes to shreds\" according to Brandli, posed a serious threat to the safety of the mission. Brandli alerted Navy Captain Willard S. Houston Jr., the commander of the Fleet Weather Center at Pearl Harbor, who had the required security clearance. On their recommendation, Rear Admiral Donald C. Davis, commander of Manned Spaceflight Recovery Forces, Pacific, advised NASA to change the recovery area, each man risking his career. A new location was selected 215 nautical miles (398 km) northeast.This altered the flight plan. A different sequence of computer programs was used, one never before attempted. In a conventional entry, trajectory event P64 was followed by P67. For a skip-out re-entry, P65 and P66 were employed to handle the exit and entry parts of the skip. In this case, because they were extending the re-entry but not actually skipping out, P66 was not invoked and instead, P65 led directly to P67. The crew were also warned they would not be in a full-lift (heads-down) attitude when they entered P67. The first program's acceleration subjected the astronauts to 6.5 standard gravities (64 m/s2); the second, to 6.0 standard gravities (59 m/s2).Before dawn on July 24, Hornet launched four Sea King helicopters and three Grumman E-1 Tracers. Two of the E-1s were designated as \"air boss\" while the third acted as a communications relay aircraft. Two of the Sea Kings carried divers and recovery equipment. The third carried photographic equipment, and the fourth carried the decontamination swimmer and the flight surgeon. At 16:44 UTC (05:44 local time) Columbia's drogue parachutes were deployed. This was observed by the helicopters. Seven minutes later Columbia struck the water forcefully 2,660 km (1,440 nmi) east of Wake Island, 380 km (210 nmi) south of Johnston Atoll, and 24 km (13 nmi) from Hornet, at 13\u00b019\u2032N 169\u00b09\u2032W. 82 \u00b0F (28 \u00b0C) with 6 feet (1.8 m) seas and winds at 17 knots (31 km/h; 20 mph) from the east were reported under broken clouds at 1,500 feet (460 m) with visibility of 10 nautical miles (19 km; 12 mi) at the recovery site. Reconnaissance aircraft flying to the original splashdown location reported the conditions Brandli and Houston had predicted.During splashdown, Columbia landed upside down but was righted within ten minutes by flotation bags activated by the astronauts. A diver from the Navy helicopter hovering above attached a sea anchor to prevent it from drifting. More divers attached flotation collars to stabilize the module and positioned rafts for astronaut extraction.\\n\\nThe divers then passed biological isolation garments (BIGs) to the astronauts, and assisted them into the life raft. The possibility of bringing back pathogens from the lunar surface was considered remote, but NASA took precautions at the recovery site. The astronauts were rubbed down with a sodium hypochlorite solution and Columbia wiped with Povidone-iodine to remove any lunar dust that might be present. The astronauts were winched on board the recovery helicopter. BIGs were worn until they reached isolation facilities on board Hornet. The raft containing decontamination materials was intentionally sunk.After touchdown on Hornet at 17:53 UTC, the helicopter was lowered by the elevator into the hangar bay, where the astronauts walked the 30 feet (9.1 m) to the Mobile quarantine facility (MQF), where they would begin the Earth-based portion of their 21 days of quarantine. This practice would continue for two more Apollo missions, Apollo 12 and Apollo 14, before the Moon was proven to be barren of life, and the quarantine process dropped. Nixon welcomed the astronauts back to Earth. He told them: \"[A]s a result of what you've done, the world has never been closer together before.\"After Nixon departed, Hornet was brought alongside the 5-short-ton (4.5 t) Columbia, which was lifted aboard by the ship's crane, placed on a dolly and moved next to the MQF. It was then attached to the MQF with a flexible tunnel, allowing the lunar samples, film, data tapes and other items to be removed. Hornet returned to Pearl Harbor, where the MQF was loaded onto a Lockheed C-141 Starlifter and airlifted to the Manned Spacecraft Center. The astronauts arrived at the Lunar Receiving Laboratory at 10:00 UTC on July 28. Columbia was taken to Ford Island for deactivation, and its pyrotechnics made safe. It was then taken to Hickham Air Force Base, from whence it was flown to Houston in a Douglas C-133 Cargomaster, reaching the Lunar Receiving Laboratory on July 30.In accordance with the Extra-Terrestrial Exposure Law, a set of regulations promulgated by NASA on July 16 to codify its quarantine protocol, the astronauts continued in quarantine. After three weeks in confinement (first in the Apollo spacecraft, then in their trailer on Hornet, and finally in the Lunar Receiving Laboratory), the astronauts were given a clean bill of health. On August 10, 1969, the Interagency Committee on Back Contamination met in Atlanta and lifted the quarantine on the astronauts, on those who had joined them in quarantine (NASA physician William Carpentier and MQF project engineer John Hirasaki), and on Columbia itself. Loose equipment from the spacecraft remained in isolation until the lunar samples were released for study.\\n\\nCelebrations\\nOn August 13, the three astronauts rode in ticker-tape parades in their honor in New York and Chicago, with an estimated six million attendees. On the same evening in Los Angeles there was an official state dinner to celebrate the flight, attended by members of Congress, 44 governors, Chief Justice of the United States Warren E. Burger and his predecessor, Earl Warren, and ambassadors from 83 nations at the Century Plaza Hotel. Nixon and Agnew honored each astronaut with a presentation of the Presidential Medal of Freedom.The three astronauts spoke before a joint session of Congress on September 16, 1969. They presented two US flags, one to the House of Representatives and the other to the Senate, that they had carried with them to the surface of the Moon. The flag of American Samoa on Apollo 11 is on display at the Jean P. Haydon Museum in Pago Pago, the capital of American Samoa.This celebration began a 38-day world tour that brought the astronauts to 22 foreign countries and included visits with the leaders of many countries. The crew toured from September 29 to November 5. The world tour started in Mexico City and ended in Tokyo. Stops on the tour in order were: Mexico City, Bogota, Buenos Aires, Rio de Janeiro, Las Palmas in the Canary Islands, Madrid, Paris, Amsterdam, Brussels, Oslo, Cologne, Berlin, London, Rome, Belgrade, Ankara, Kinshasa, Tehran, Mumbai, Dhaka, Bangkok, Darwin, Sydney, Guam, Seoul, Tokyo and Honolulu.Many nations honored the first human Moon landing with special features in magazines or by issuing Apollo 11 commemorative postage stamps or coins.\\n\\nLegacy\\nCultural significance\\nHumans walking on the Moon and returning safely to Earth accomplished Kennedy's goal set eight years earlier. In Mission Control during the Apollo 11 landing, Kennedy's speech flashed on the screen, followed by the words \"TASK ACCOMPLISHED, July 1969\". The success of Apollo 11 demonstrated the United States' technological superiority; and with the success of Apollo 11, America had won the Space Race.New phrases permeated into the English language. \"If they can send a man to the Moon, why can't they ...?\" became a common saying following Apollo 11. Armstrong's words on the lunar surface also spun off various parodies.While most people celebrated the accomplishment, disenfranchised Americans saw it as a symbol of the divide in America, evidenced by protesters led by Ralph Abernathy outside of Kennedy Space Center the day before Apollo 11 launched. NASA Administrator Thomas Paine met with Abernathy at the occasion, both hoping that the space program can spur progress also in other regards, such as poverty in the US. Paine was then asked, and agreed, to host protesters as spectators at the launch, and Abernathy, awestruck by the spectacle, prayed for the astronauts. Racial and financial inequalities frustrated citizens who wondered why money spent on the Apollo program was not spent taking care of humans on Earth. A poem by Gil Scott-Heron called \"Whitey on the Moon\" (1970) illustrated the racial inequality in the United States that was highlighted by the Space Race. The poem starts with:\\n\\nTwenty percent of the world's population watched humans walk on the Moon for the first time. While Apollo 11 sparked the interest of the world, the follow-on Apollo missions did not hold the interest of the nation. One possible explanation was the shift in complexity. Landing someone on the Moon was an easy goal to understand; lunar geology was too abstract for the average person. Another is that Kennedy's goal of landing humans on the Moon had already been accomplished. A well-defined objective helped Project Apollo accomplish its goal, but after it was completed it was hard to justify continuing the lunar missions.While most Americans were proud of their nation's achievements in space exploration, only once during the late 1960s did the Gallup Poll indicate that a majority of Americans favored \"doing more\" in space as opposed to \"doing less\". By 1973, 59 percent of those polled favored cutting spending on space exploration. The Space Race had been won, and Cold War tensions were easing as the US and Soviet Union entered the era of d\u00e9tente. This was also a time when inflation was rising, which put pressure on the government to reduce spending. What saved the space program was that it was one of the few government programs that had achieved something great. Drastic cuts, warned Caspar Weinberger, the deputy director of the Office of Management and Budget, might send a signal that \"our best years are behind us\".After the Apollo 11 mission, officials from the Soviet Union said landing humans on the Moon was dangerous and unnecessary. At the time the Soviet Union was attempting to retrieve lunar samples robotically. The Soviets publicly denied there was a race to the Moon, and indicated they were not making an attempt. Mstislav Keldysh said in July 1969, \"We are concentrating wholly on the creation of large satellite systems.\" It was revealed in 1989 that the Soviets had tried to send people to the Moon, but were unable due to technological difficulties. The public's reaction in the Soviet Union was mixed. The Soviet government limited the release of information about the lunar landing, which affected the reaction. A portion of the populace did not give it any attention, and another portion was angered by it.The Apollo 11 landing is referenced in the songs \"Armstrong, Aldrin and Collins\" by the Byrds on the 1969 album Ballad of Easy Rider and \"Coon on the Moon\" by Howlin' Wolf on the 1973 album The Back Door Wolf.\\n\\nSpacecraft\\nThe command module Columbia went on a tour of the United States, visiting 49 state capitals, the District of Columbia, and Anchorage, Alaska. In 1971, it was transferred to the Smithsonian Institution, and was displayed at the National Air and Space Museum (NASM) in Washington, DC. It was in the central Milestones of Flight exhibition hall in front of the Jefferson Drive entrance, sharing the main hall with other pioneering flight vehicles such as the Wright Flyer, Spirit of St. Louis, Bell X-1, North American X-15 and Friendship 7.Columbia was moved in 2017 to the NASM Mary Baker Engen Restoration Hangar at the Steven F. Udvar-Hazy Center in Chantilly, Virginia, to be readied for a four-city tour titled Destination Moon: The Apollo 11 Mission. This included Space Center Houston from October 14, 2017, to March 18, 2018, the Saint Louis Science Center from April 14 to September 3, 2018, the Senator John Heinz History Center in Pittsburgh from September 29, 2018, to February 18, 2019, and its last location at Museum of Flight in Seattle from March 16 to September 2, 2019. Continued renovations at the Smithsonian allowed time for an additional stop for the capsule, and it was moved to the Cincinnati Museum Center. The ribbon cutting ceremony was on September 29, 2019.For 40 years Armstrong's and Aldrin's space suits were displayed in the museum's Apollo to the Moon exhibit, until it permanently closed on December 3, 2018, to be replaced by a new gallery which was scheduled to open in 2022. A special display of Armstrong's suit was unveiled for the 50th anniversary of Apollo 11 in July 2019. The quarantine trailer, the flotation collar and the flotation bags are in the Smithsonian's Steven F. Udvar-Hazy Center annex near Washington Dulles International Airport in Chantilly, Virginia, where they are on display along with a test lunar module.The descent stage of the LM Eagle remains on the Moon. In 2009, the Lunar Reconnaissance Orbiter (LRO) imaged the various Apollo landing sites on the surface of the Moon, for the first time with sufficient resolution to see the descent stages of the lunar modules, scientific instruments, and foot trails made by the astronauts. The remains of the ascent stage lie at an unknown location on the lunar surface, after being abandoned and impacting the Moon. The location is uncertain because Eagle ascent stage was not tracked after it was jettisoned, and the lunar gravity field is sufficiently non-uniform to make the orbit of the spacecraft unpredictable after a short time.\\n\\nIn March 2012 a team of specialists financed by Amazon founder Jeff Bezos located the F-1 engines from the S-IC stage that launched Apollo 11 into space. They were found on the Atlantic seabed using advanced sonar scanning. His team brought parts of two of the five engines to the surface. In July 2013, a conservator discovered a serial number under the rust on one of the engines raised from the Atlantic, which NASA confirmed was from Apollo 11. The S-IVB third stage which performed Apollo 11's trans-lunar injection remains in a solar orbit near to that of Earth.\\n\\nMoon rocks\\nThe main repository for the Apollo Moon rocks is the Lunar Sample Laboratory Facility at the Lyndon B. Johnson Space Center in Houston, Texas. For safekeeping, there is also a smaller collection stored at White Sands Test Facility near Las Cruces, New Mexico. Most of the rocks are stored in nitrogen to keep them free of moisture. They are handled only indirectly, using special tools. Over 100 research laboratories worldwide conduct studies of the samples; approximately 500 samples are prepared and sent to investigators every year.In November 1969, Nixon asked NASA to make up about 250 presentation Apollo 11 lunar sample displays for 135 nations, the fifty states of the United States and its possessions, and the United Nations. Each display included Moon dust from Apollo 11 and flags, including the one of the Soviet Union, taken along by Apollo 11. The rice-sized particles were four small pieces of Moon soil weighing about 50 mg and were enveloped in a clear acrylic button about as big as a United States half dollar coin. This acrylic button magnified the grains of lunar dust. Nixon gave the Apollo 11 lunar sample displays as goodwill gifts in 1970.\\n\\nExperiment results\\nThe Passive Seismic Experiment ran until the command uplink failed on August 25, 1969. The downlink failed on December 14, 1969. As of 2018, the Lunar Laser Ranging experiment remains operational.\\n\\nArmstrong's camera\\nArmstrong's Hasselblad camera was thought to be lost or left on the Moon surface.\\n\\nLM memorabilia\\nIn 2015, after Armstrong died in 2012, his widow contacted the National Air and Space Museum to inform them she had found a white cloth bag in one of Armstrong's closets. The bag contained various items, which should have been left behind in the lunar module, including the 16mm Data Acquisition Camera that had been used to capture images of the first Moon landing. The camera is currently on display at the National Air and Space Museum.\\n\\nAnniversary events\\n40th anniversary\\nOn July 15, 2009, Life.com released a photo gallery of previously unpublished photos of the astronauts taken by Life photographer Ralph Morse prior to the Apollo 11 launch. From July 16 to 24, 2009, NASA streamed the original mission audio on its website in real time 40 years to the minute after the events occurred. It is in the process of restoring the video footage and has released a preview of key moments. In July 2010, air-to-ground voice recordings and film footage shot in Mission Control during the Apollo 11 powered descent and landing was re-synchronized and released for the first time. The John F. Kennedy Presidential Library and Museum set up an Adobe Flash website that rebroadcasts the transmissions of Apollo 11 from launch to landing on the Moon.On July 20, 2009, Armstrong, Aldrin, and Collins met with US President Barack Obama at the White House. \"We expect that there is, as we speak, another generation of kids out there who are looking up at the sky and are going to be the next Armstrong, Collins, and Aldrin\", Obama said. \"We want to make sure that NASA is going to be there for them when they want to take their journey.\" On August 7, 2009, an act of Congress awarded the three astronauts a Congressional Gold Medal, the highest civilian award in the United States. The bill was sponsored by Florida Senator Bill Nelson and Florida Representative Alan Grayson.A group of British scientists interviewed as part of the anniversary events reflected on the significance of the Moon landing:\\n\\nIt was carried out in a technically brilliant way with risks taken ... that would be inconceivable in the risk-averse world of today ... The Apollo programme is arguably the greatest technical achievement of mankind to date ... nothing since Apollo has come close [to] the excitement that was generated by those astronauts\u2014Armstrong, Aldrin and the 10 others who followed them.\\n\\n50th anniversary\\nOn June 10, 2015, Congressman Bill Posey introduced resolution H.R. 2726 to the 114th session of the United States House of Representatives directing the United States Mint to design and sell commemorative coins in gold, silver and clad for the 50th anniversary of the Apollo 11 mission. On January 24, 2019, the Mint released the Apollo 11 Fiftieth Anniversary commemorative coins to the public on its website.A documentary film, Apollo 11, with restored footage of the 1969 event, premiered in IMAX on March 1, 2019, and broadly in theaters on March 8.The Smithsonian Institute's National Air and Space Museum and NASA sponsored the \"Apollo 50 Festival\" on the National Mall in Washington DC. The three day (July 18 to 20, 2019) outdoor festival featured hands-on exhibits and activities, live performances, and speakers such as Adam Savage and NASA scientists.\\nAs part of the festival, a projection of the 363-foot (111 m) tall Saturn V rocket was displayed on the east face of the 555-foot (169 m) tall Washington Monument from July 16 through the 20th from 9:30 pm until 11:30 pm (EDT). The program also included a 17-minute show that combined full-motion video projected on the Washington Monument to recreate the assembly and launch of the Saturn V rocket. The projection was joined by a 40-foot (12 m) wide recreation of the Kennedy Space Center countdown clock and two large video screens showing archival footage to recreate the time leading up to the moon landing. There were three shows per night on July 19\u201320, with the last show on Saturday, delayed slightly so the portion where Armstrong first set foot on the Moon would happen exactly 50 years to the second after the actual event.On July 19, 2019, the Google Doodle paid tribute to the Apollo 11 Moon Landing, complete with a link to an animated YouTube video with voiceover by astronaut Michael Collins.Aldrin, Collins, and Armstrong's sons were hosted by President Donald Trump in the Oval Office.\\n\\nFilms and documentaries\\nFootprints on the Moon, a 1969 documentary film by Bill Gibson and Barry Coe, about the Apollo 11 mission\\nMoonwalk One, a 1971 documentary film by Theo Kamecke\\nApollo 11: As It Happened, a 1994 six-hour documentary on ABC News' coverage of the event\\nFirst Man, 2018 film by Damien Chazelle based on the 2005 James R. Hansen book First Man: The Life of Neil A. Armstrong.\\nApollo 11, a 2019 documentary film by Todd Douglas Miller with restored footage of the 1969 event\\nChasing the Moon, a July 2019 PBS three-night six-hour documentary, directed by Robert Stone, examined the events leading up to the Apollo 11 mission. An accompanying book of the same name was also released.\\n8 Days: To the Moon and Back, a PBS and BBC Studios 2019 documentary film by Anthony Philipson re-enacting major portions of the Apollo 11 mission using mission audio recordings, new studio footage, NASA and news archives, and computer-generated imagery.\\n\\nSee also\\nApollo in Real Time \u2013 Interactive website of Apollo 11, 13, and 17\\nExploration of the Moon \u2013 Missions to the Moon\\nList of missions to the Moon\\nList of species that have landed on the Moon\\n\\nReferences\\nNotes\\nCitations\\nIn some of the following sources, times are shown in the format hours:minutes:seconds (e.g. 109:24:15), referring to the mission's Ground Elapsed Time (GET), based on the official launch time of July 16, 1969, 13:32:00 UTC (000:00:00 GET).\\n\\nSources\\nExternal links\\n\"Apollo 11 transcripts\" at Spacelog\\nApollo 11 in real time\\nApollo 11 Press Conference filmed by KPRC-TV at Texas Archive of the Moving Image\\nApollo 11 and 13 Checklists at The Museum of Flight Digital Collections.\\nApollo 11, 12, and 14 Traverses, at the Lunar and Planetary Institute\\n\\nMultimedia\\nGarner, Robert (ed.). \"Apollo 11 Partial Restoration HD Videos (Downloads)\". NASA. Retrieved June 13, 2013. Remastered videos of the original landing.\\nDynamic timeline of lunar excursion. Lunar Reconnaissance Orbiter Camera\\nThe short film Moonwalk One is available for free viewing and download at the Internet Archive.\\nThe short film The Eagle Has Landed: The Flight of Apollo 11 is available for free viewing and download at the Internet Archive.\\nApollo 11 Restored EVA Part 1 (1 hour of restored footage)\\nApollo 11: As They Photographed It (Augmented Reality)\u2014The New York Times, Interactive, July 18, 2019\\n\"Coverage of the Flight of Apollo 11\" provided by Todd Kosovich for RadioTapes.com. Radio station recordings (airchecks) covering the flight of Apollo 11."}
{"article_name": "Renaissance", "link": "https://en.wikipedia.org/wiki/Renaissance", "text_content": "The Renaissance (UK:  rin-AY-s\u0259nss, US:   REN-\u0259-sahnss) is a period in history and a cultural movement marking the transition from the Middle Ages to modernity, covering the 15th and 16th centuries and characterized by an effort to revive and surpass the ideas and achievements of classical antiquity; it occurred after the crisis of the Late Middle Ages and was associated with great social change in most fields and disciplines, including art, architecture, politics, literature, exploration and science. In addition to the standard periodization, proponents of a \"long Renaissance\" may put its beginning in the 14th century and its end in the 17th century.\\nThe traditional view focuses more on the Renaissance's early modern aspects and argues that it was a break from the past, but many historians today focus more on its medieval aspects and argue that it was an extension of the Middle Ages. The beginnings of the period\u2014the early Renaissance of the 15th century and the Italian Proto-Renaissance from around 1250 or 1300\u2014overlap considerably with the Late Middle Ages, conventionally dated to c.\u20091350\u20131500, and the Middle Ages themselves were a long period filled with gradual changes, like the modern age; as a transitional period between both, the Renaissance has close similarities to both, especially the late and early sub-periods of either.The Renaissance's intellectual basis was its version of humanism, derived from the concept of Roman humanitas and the rediscovery of classical Greek philosophy, such as that of Protagoras, who said that \"man is the measure of all things\". Early examples were the development of perspective in oil painting and the revived knowledge of how to make concrete. Although the invention of metal movable type sped the dissemination of ideas from the later 15th century, the changes of the Renaissance were not uniform across Europe: the first traces appear in Italy as early as the late 13th century, in particular with the writings of Dante and the paintings of Giotto.\\nAs a cultural movement, the Renaissance encompassed innovative flowering of Latin and vernacular literatures, beginning with the 14th-century resurgence of learning based on classical sources, which contemporaries credited to Petrarch; the development of linear perspective and other techniques of rendering a more natural reality in painting; and gradual but widespread educational reform. In politics, the Renaissance contributed to the development of the customs and conventions of diplomacy, and in science to an increased reliance on observation and inductive reasoning. Although the Renaissance saw revolutions in many intellectual and social scientific pursuits, as well as the introduction of modern banking and the field of accounting, it is perhaps best known for its artistic developments and the contributions of such polymaths as Leonardo da Vinci and Michelangelo, who inspired the term \"Renaissance man\".The Renaissance began in Florence, one of the many states of Italy. Various theories have been proposed to account for its origins and characteristics, focusing on a variety of factors, including Florence's social and civic peculiarities at the time: its political structure, the patronage of its dominant family, the Medici, and the migration of Greek scholars and their texts to Italy following the fall of Constantinople to the Ottoman Turks. Other major centers were Venice, Genoa, Milan, Rome during the Renaissance Papacy, and Naples. From Italy, the Renaissance spread throughout Europe and also to American, African and Asian territories ruled by the European colonial powers of the time or where Christian missionaries were active. \\nThe Renaissance has a long and complex historiography, and in line with general skepticism of discrete periodizations, there has been much debate among historians reacting to the 19th-century glorification of the \"Renaissance\" and individual cultural heroes as \"Renaissance men\", questioning the usefulness of Renaissance as a term and as a historical delineation. Some observers have questioned whether the Renaissance was a cultural \"advance\" from the Middle Ages, instead seeing it as a period of pessimism and nostalgia for classical antiquity, while social and economic historians, especially of the longue dur\u00e9e, have instead focused on the continuity between the two eras, which are linked, as Panofsky observed, \"by a thousand ties\".The term rinascita (\"rebirth\") first appeared in Giorgio Vasari's Lives of the Artists (c. 1550), the corresponding French word, renaissance, was adopted into English as the term for this period during the 1830s. The word has also been extended to other historical and cultural movements, such as the Carolingian Renaissance (8th and 9th centuries), Ottonian Renaissance (10th and 11th century), and the Renaissance of the 12th century.\\n\\nOverview\\nThe Renaissance was a cultural movement that profoundly affected European intellectual life in the early modern period. Beginning in Italy, and spreading to the rest of Europe by the 16th century, its influence was felt in art, architecture, philosophy, literature, music, science, technology, politics, religion, and other aspects of intellectual inquiry. Renaissance scholars employed the humanist method in study, and searched for realism and human emotion in art.Renaissance humanists such as Poggio Bracciolini sought out in Europe's monastic libraries the Latin literary, historical, and oratorical texts of antiquity, while the fall of Constantinople (1453) generated a wave of \u00e9migr\u00e9 Greek scholars bringing precious manuscripts in ancient Greek, many of which had fallen into obscurity in the West. It was in their new focus on literary and historical texts that Renaissance scholars differed so markedly from the medieval scholars of the Renaissance of the 12th century, who had focused on studying Greek and Arabic works of natural sciences, philosophy, and mathematics, rather than on such cultural texts.\\nIn the revival of neoplatonism, Renaissance humanists did not reject Christianity; on the contrary, many of the Renaissance's greatest works were devoted to it, and the Church patronized many works of Renaissance art. But a subtle shift took place in the way that intellectuals approached religion that was reflected in many other areas of cultural life. In addition, many Greek Christian works, including the Greek New Testament, were brought back from Byzantium to Western Europe and engaged Western scholars for the first time since late antiquity. This new engagement with Greek Christian works, and particularly the return to the original Greek of the New Testament promoted by humanists Lorenzo Valla and Erasmus, helped pave the way for the Reformation.Well after the first artistic return to classicism had been exemplified in the sculpture of Nicola Pisano, Florentine painters led by Masaccio strove to portray the human form realistically, developing techniques to render perspective and light more naturally. Political philosophers, most famously Niccol\u00f2 Machiavelli, sought to describe political life as it really was, that is to understand it rationally. A critical contribution to Italian Renaissance humanism, Giovanni Pico della Mirandola wrote De hominis dignitate (Oration on the Dignity of Man, 1486), a series of theses on philosophy, natural thought, faith, and magic defended against any opponent on the grounds of reason. In addition to studying classical Latin and Greek, Renaissance authors also began increasingly to use vernacular languages; combined with the introduction of the printing press, this allowed many more people access to books, especially the Bible.In all, the Renaissance can be viewed as an attempt by intellectuals to study and improve the secular and worldly, both through the revival of ideas from antiquity and through novel approaches to thought. Hans Kohn describes it as an age where \"Men looked for new foundations\"; some like Erasmus and Thomas More envisioned new reformed spiritual foundations, others. in the words of Machiavelli, una lunga sperienza delle cose moderne ed una continua lezione delle antiche (a long experience with modern life and a continuous learning from antiquity).Some scholars, such as Rodney Stark, play down the Renaissance in favor of the earlier innovations of the Italian city-states in the High Middle Ages, which married responsive government, Christianity and the birth of capitalism. This analysis argues that, whereas the great European states (France and Spain) were absolute monarchies, and others were under direct Church control, the independent city-republics of Italy took over the principles of capitalism invented on monastic estates and set off a vast unprecedented Commercial Revolution that preceded and financed the Renaissance.Leon Poliakov offers a critical view in his seminal study of European racist thought: The Aryan Myth.  According to Poliakov, the use of ethnic origin myths are first used by Renaissance humanists \"in the service of a new born chauvinism\".\\n\\nOrigins\\nMany argue that the ideas characterizing the Renaissance had their origin in Florence at the turn of the 13th and 14th centuries, in particular with the writings of Dante Alighieri (1265\u20131321) and Petrarch (1304\u20131374), as well as the paintings of Giotto di Bondone (1267\u20131337). Some writers date the Renaissance quite precisely; one proposed starting point is 1401, when the rival geniuses Lorenzo Ghiberti and Filippo Brunelleschi competed for the contract to build the bronze doors for the Baptistery of the Florence Cathedral (Ghiberti then won). Others see more general competition between artists and polymaths such as Brunelleschi, Ghiberti, Donatello, and Masaccio for artistic commissions as sparking the creativity of the Renaissance.\\nYet it remains much debated why the Renaissance began in Italy, and why it began when it did. Accordingly, several theories have been put forward to explain its origins. Peter Rietbergen posits that various influential Proto-Renaissance movements started from roughly 1300 onwards across many regions of Europe.\\n\\nLatin and Greek phases of Renaissance humanism\\nIn stark contrast to the High Middle Ages, when Latin scholars focused almost entirely on studying Greek and Arabic works of natural science, philosophy and mathematics, Renaissance scholars were most interested in recovering and studying Latin and Greek literary, historical, and oratorical texts. Broadly speaking, this began in the 14th century with a Latin phase, when Renaissance scholars such as Petrarch, Coluccio Salutati (1331\u20131406), Niccol\u00f2 de' Niccoli (1364\u20131437), and Poggio Bracciolini (1380\u20131459) scoured the libraries of Europe in search of works by such Latin authors as Cicero, Lucretius, Livy, and Seneca. By the early 15th century, the bulk of the surviving such Latin literature had been recovered; the Greek phase of Renaissance humanism was under way, as Western European scholars turned to recovering ancient Greek literary, historical, oratorical and theological texts.Unlike with Latin texts, which had been preserved and studied in Western Europe since late antiquity, the study of ancient Greek texts was very limited in medieval Western Europe. Ancient Greek works on science, mathematics, and philosophy had been studied since the High Middle Ages in Western Europe and in the Islamic Golden Age (normally in translation), but Greek literary, oratorical and historical works (such as Homer, the Greek dramatists, Demosthenes and Thucydides) were not studied in either the Latin or medieval Islamic worlds; in the Middle Ages these sorts of texts were only studied by Byzantine scholars. Some argue that the Timurid Renaissance in Samarkand and Herat, whose magnificence toned with Florence as the center of a cultural rebirth, were linked to the Ottoman Empire, whose conquests led to the migration of Greek scholars to Italian cities. One of the greatest achievements of Renaissance scholars was to bring this entire class of Greek cultural works back into Western Europe for the first time since late antiquity.\\nMuslim logicians, most notably Avicenna and Averroes, had inherited Greek ideas after they had invaded and conquered Egypt and the Levant. Their translations and commentaries on these ideas worked their way through the Arab West into Iberia and Sicily, which became important centers for this transmission of ideas. Between the 11th and 13th centuries, many schools dedicated to the translation of philosophical and scientific works from Classical Arabic to Medieval Latin were established in Iberia, most notably the Toledo School of Translators. This work of translation from Islamic culture, though largely unplanned and disorganized, constituted one of the greatest transmissions of ideas in history.The movement to reintegrate the regular study of Greek literary, historical, oratorical, and theological texts back into the Western European curriculum is usually dated to the 1396 invitation from Coluccio Salutati to the Byzantine diplomat and scholar Manuel Chrysoloras (c. 1355\u20131415) to teach Greek in Florence. This legacy was continued by a number of expatriate Greek scholars, from Basilios Bessarion to Leo Allatius.\\n\\nSocial and political structures in Italy\\nThe unique political structures of Italy during the Late Middle Ages have led some to theorize that its unusual social climate allowed the emergence of a rare cultural efflorescence. Italy did not exist as a political entity in the early modern period. Instead, it was divided into smaller city-states and territories: the Neapolitans controlled the south, the Florentines and the Romans at the center, the Milanese and the Genoese to the north and west respectively, and the Venetians to the east. 15th-century Italy was one of the most urbanized areas in Europe. Many of its cities stood among the ruins of ancient Roman buildings; it seems likely that the classical nature of the Renaissance was linked to its origin in the Roman Empire's heartland.Historian and political philosopher Quentin Skinner points out that Otto of Freising (c. 1114\u20131158), a German bishop visiting north Italy during the 12th century, noticed a widespread new form of political and social organization, observing that Italy appeared to have exited from feudalism so that its society was based on merchants and commerce. Linked to this was anti-monarchical thinking, represented in the famous early Renaissance fresco cycle The Allegory of Good and Bad Government by Ambrogio Lorenzetti (painted 1338\u20131340), whose strong message is about the virtues of fairness, justice, republicanism and good administration. Holding both Church and Empire at bay, these city republics were devoted to notions of liberty. Skinner reports that there were many defences of liberty such as the Matteo Palmieri (1406\u20131475) celebration of Florentine genius not only in art, sculpture and architecture, but \"the remarkable efflorescence of moral, social and political philosophy that occurred in Florence at the same time\".Even cities and states beyond central Italy, such as the Republic of Florence at this time, were also notable for their merchant republics, especially the Republic of Venice. Although in practice these were oligarchical, and bore little resemblance to a modern democracy, they did have democratic features and were responsive states, with forms of participation in governance and belief in liberty. The relative political freedom they afforded was conducive to academic and artistic advancement. Likewise, the position of Italian cities such as Venice as great trading centres made them intellectual crossroads. Merchants brought with them ideas from far corners of the globe, particularly the Levant. Venice was Europe's gateway to trade with the East, and a producer of fine glass, while Florence was a capital of textiles. The wealth such business brought to Italy meant large public and private artistic projects could be commissioned and individuals had more leisure time for study.\\n\\nBlack Death\\nOne theory that has been advanced is that the devastation in Florence caused by the Black Death, which hit Europe between 1348 and 1350, resulted in a shift in the world view of people in 14th century Italy. Italy was particularly badly hit by the plague, and it has been speculated that the resulting familiarity with death caused thinkers to dwell more on their lives on Earth, rather than on spirituality and the afterlife. It has also been argued that the Black Death prompted a new wave of piety, manifested in the sponsorship of religious works of art. However, this does not fully explain why the Renaissance occurred specifically in Italy in the 14th century. The Black Death was a pandemic that affected all of Europe in the ways described, not only Italy. The Renaissance's emergence in Italy was most likely the result of the complex interaction of the above factors.The plague was carried by fleas on sailing vessels returning from the ports of Asia, spreading quickly due to lack of proper sanitation: the population of England, then about 4.2 million, lost 1.4 million people to the bubonic plague. Florence's population was nearly halved in the year 1347. As a result of the decimation in the populace the value of the working class increased, and commoners came to enjoy more freedom. To answer the increased need for labor, workers traveled in search of the most favorable position economically.The demographic decline due to the plague had economic consequences: the prices of food dropped and land values declined by 30\u201340% in most parts of Europe between 1350 and 1400. Landholders faced a great loss, but for ordinary men and women it was a windfall. The survivors of the plague found not only that the prices of food were cheaper but also that lands were more abundant, and many of them inherited property from their dead relatives.\\nThe spread of disease was significantly more rampant in areas of poverty. Epidemics ravaged cities, particularly children. Plagues were easily spread by lice, unsanitary drinking water, armies, or by poor sanitation. Children were hit the hardest because many diseases, such as typhus and congenital syphilis, target the immune system, leaving young children without a fighting chance. Children in city dwellings were more affected by the spread of disease than the children of the wealthy.The Black Death caused greater upheaval to Florence's social and political structure than later epidemics. Despite a significant number of deaths among members of the ruling classes, the government of Florence continued to function during this period. Formal meetings of elected representatives were suspended during the height of the epidemic due to the chaotic conditions in the city, but a small group of officials was appointed to conduct the affairs of the city, which ensured continuity of government.\\n\\nCultural conditions in Florence\\nIt has long been a matter of debate why the Renaissance began in Florence, and not elsewhere in Italy. Scholars have noted several features unique to Florentine cultural life that may have caused such a cultural movement. Many have emphasized the role played by the Medici, a banking family and later ducal ruling house, in patronizing and stimulating the arts. Lorenzo de' Medici (1449\u20131492) was the catalyst for an enormous amount of arts patronage, encouraging his countrymen to commission works from the leading artists of Florence, including Leonardo da Vinci, Sandro Botticelli, and Michelangelo Buonarroti. Works by Neri di Bicci, Botticelli, Leonardo, and Filippino Lippi had been commissioned additionally by the Convent of San Donato in Scopeto in Florence.The Renaissance was certainly underway before Lorenzo de' Medici came to power \u2013 indeed, before the Medici family itself achieved hegemony in Florentine society. Some historians have postulated that Florence was the birthplace of the Renaissance as a result of luck, i.e., because \"Great Men\" were born there by chance: Leonardo, Botticelli and Michelangelo were all born in Tuscany. Arguing that such chance seems improbable, other historians have contended that these \"Great Men\" were only able to rise to prominence because of the prevailing cultural conditions at the time.\\n\\nCharacteristics\\nHumanism\\nIn some ways, Renaissance humanism was not a philosophy but a method of learning. In contrast to the medieval scholastic mode, which focused on resolving contradictions between authors, Renaissance humanists would study ancient texts in the original and appraise them through a combination of reasoning and empirical evidence. Humanist education was based on the programme of Studia Humanitatis, the study of five humanities: poetry, grammar, history, moral philosophy, and rhetoric. Although historians have sometimes struggled to define humanism precisely, most have settled on \"a middle of the road definition... the movement to recover, interpret, and assimilate the language, literature, learning and values of ancient Greece and Rome\". Above all, humanists asserted \"the genius of man ... the unique and extraordinary ability of the human mind\".\\nHumanist scholars shaped the intellectual landscape throughout the early modern period. Political philosophers such as Niccol\u00f2 Machiavelli and Thomas More revived the ideas of Greek and Roman thinkers and applied them in critiques of contemporary government, following the Islamic steps of Ibn Khaldun. Pico della Mirandola wrote the \"manifesto\" of the Renaissance, the Oration on the Dignity of Man, a vibrant defence of thinking. Matteo Palmieri (1406\u20131475), another humanist, is most known for his work Della vita civile (\"On Civic Life\"; printed 1528), which advocated civic humanism, and for his influence in refining the Tuscan vernacular to the same level as Latin. Palmieri drew on Roman philosophers and theorists, especially Cicero, who, like Palmieri, lived an active public life as a citizen and official, as well as a theorist and philosopher and also Quintilian. Perhaps the most succinct expression of his perspective on humanism is in a 1465 poetic work La citt\u00e0 di vita, but an earlier work, Della vita civile, is more wide-ranging. Composed as a series of dialogues set in a country house in the Mugello countryside outside Florence during the plague of 1430, Palmieri expounds on the qualities of the ideal citizen. The dialogues include ideas about how children develop mentally and physically, how citizens can conduct themselves morally, how citizens and states can ensure probity in public life, and an important debate on the difference between that which is pragmatically useful and that which is honest.The humanists believed that it is important to transcend to the afterlife with a perfect mind and body, which could be attained with education. The purpose of humanism was to create a universal man whose person combined intellectual and physical excellence and who was capable of functioning honorably in virtually any situation. This ideology was referred to as the uomo universale, an ancient Greco-Roman ideal. Education during the Renaissance was mainly composed of ancient literature and history as it was thought that the classics provided moral instruction and an intensive understanding of human behavior.\\n\\nHumanism and libraries\\nA unique characteristic of some Renaissance libraries is that they were open to the public. These libraries were places where ideas were exchanged and where scholarship and reading were considered both pleasurable and beneficial to the mind and soul. As freethinking was a hallmark of the age, many libraries contained a wide range of writers. Classical texts could be found alongside humanist writings. These informal associations of intellectuals profoundly influenced Renaissance culture. Some of the richest \"bibliophiles\" built libraries as temples to books and knowledge. A number of libraries appeared as manifestations of immense wealth joined with a love of books. In some cases, cultivated library builders were also committed to offering others the opportunity to use their collections. Prominent aristocrats and princes of the Church created great libraries for the use of their courts, called \"court libraries\", and were housed in lavishly designed monumental buildings decorated with ornate woodwork, and the walls adorned with frescoes (Murray, Stuart A.P.).\\n\\nArt\\nRenaissance art marks a cultural rebirth at the close of the Middle Ages and rise of the Modern world. One of the distinguishing features of Renaissance art was its development of highly realistic linear perspective. Giotto di Bondone (1267\u20131337) is credited with first treating a painting as a window into space, but it was not until the demonstrations of architect Filippo Brunelleschi (1377\u20131446) and the subsequent writings of Leon Battista Alberti (1404\u20131472) that perspective was formalized as an artistic technique.\\nThe development of perspective was part of a wider trend toward realism in the arts. Painters developed other techniques, studying light, shadow, and, famously in the case of Leonardo da Vinci, human anatomy. Underlying these changes in artistic method was a renewed desire to depict the beauty of nature and to unravel the axioms of aesthetics, with the works of Leonardo, Michelangelo and Raphael representing artistic pinnacles that were much imitated by other artists. Other notable artists include Sandro Botticelli, working for the Medici in Florence, Donatello, another Florentine, and Titian in Venice, among others.\\nIn the Netherlands, a particularly vibrant artistic culture developed. The work of Hugo van der Goes and Jan van Eyck was particularly influential on the development of painting in Italy, both technically with the introduction of oil paint and canvas, and stylistically in terms of naturalism in representation. Later, the work of Pieter Brueghel the Elder would inspire artists to depict themes of everyday life.In architecture, Filippo Brunelleschi was foremost in studying the remains of ancient classical buildings. With rediscovered knowledge from the 1st-century writer Vitruvius and the flourishing discipline of mathematics, Brunelleschi formulated the Renaissance style that emulated and improved on classical forms. His major feat of engineering was building the dome of the Florence Cathedral. Another building demonstrating this style is the church of St. Andrew in Mantua, built by Alberti. The outstanding architectural work of the High Renaissance was the rebuilding of St. Peter's Basilica, combining the skills of Bramante, Michelangelo, Raphael, Sangallo and Maderno.\\nDuring the Renaissance, architects aimed to use columns, pilasters, and entablatures as an integrated system. The Roman orders types of columns are used: Tuscan and Composite. These can either be structural, supporting an arcade or architrave, or purely decorative, set against a wall in the form of pilasters. One of the first buildings to use pilasters as an integrated system was in the Old Sacristy (1421\u20131440) by Brunelleschi. Arches, semi-circular or (in the Mannerist style) segmental, are often used in arcades, supported on piers or columns with capitals. There may be a section of entablature between the capital and the springing of the arch. Alberti was one of the first to use the arch on a monumental. Renaissance vaults do not have ribs; they are semi-circular or segmental and on a square plan, unlike the Gothic vault, which is frequently rectangular.\\nRenaissance artists were not pagans, although they admired antiquity and kept some ideas and symbols of the medieval past. Nicola Pisano (c. 1220 \u2013 c. 1278) imitated classical forms by portraying scenes from the Bible. His Annunciation, from the Baptistry at Pisa, demonstrates that classical models influenced Italian art before the Renaissance took root as a literary movement.\\n\\nScience\\nApplied innovation extended to commerce. At the end of the 15th century, Luca Pacioli published the first work on bookkeeping, making him the founder of accounting.The rediscovery of ancient texts and the invention of the printing press in about 1440 democratized learning and allowed a faster propagation of more widely distributed ideas. In the first period of the Italian Renaissance, humanists favored the study of humanities over natural philosophy or applied mathematics, and their reverence for classical sources further enshrined the Aristotelian and Ptolemaic views of the universe. Writing around 1450, Nicholas Cusanus anticipated the heliocentric worldview of Copernicus, but in a philosophical fashion.\\nScience and art were intermingled in the early Renaissance, with polymath artists such as Leonardo da Vinci making observational drawings of anatomy and nature. Leonardo set up controlled experiments in water flow, medical dissection, and systematic study of movement and aerodynamics, and he devised principles of research method that led Fritjof Capra to classify him as the \"father of modern science\". Other examples of Da Vinci's contribution during this period include machines designed to saw marbles and lift monoliths, and new discoveries in acoustics, botany, geology, anatomy, and mechanics.A suitable environment had developed to question classical scientific doctrine. The discovery in 1492 of the New World by Christopher Columbus challenged the classical worldview. The works of Ptolemy (in geography) and Galen (in medicine) were found to not always match everyday observations. As the Reformation and Counter-Reformation clashed, the Northern Renaissance showed a decisive shift in focus from Aristotelean natural philosophy to chemistry and the biological sciences (botany, anatomy, and medicine). The willingness to question previously held truths and search for new answers resulted in a period of major scientific advancements.\\nSome view this as a \"scientific revolution\", heralding the beginning of the modern age, others as an acceleration of a continuous process stretching from the ancient world to the present day. Significant scientific advances were made during this time by Galileo Galilei, Tycho Brahe, and Johannes Kepler. Copernicus, in De revolutionibus orbium coelestium (On the Revolutions of the Heavenly Spheres), posited that the Earth moved around the Sun. De humani corporis fabrica (On the Workings of the Human Body) by Andreas Vesalius, gave a new confidence to the role of dissection, observation, and the mechanistic view of anatomy.Another important development was in the process for discovery, the scientific method, focusing on empirical evidence and the importance of mathematics, while discarding much of Aristotelian science. Early and influential proponents of these ideas included Copernicus, Galileo, and Francis Bacon. The new scientific method led to great contributions in the fields of astronomy, physics, biology, and anatomy.\\n\\nNavigation and geography\\nDuring the Renaissance, extending from 1450 to 1650, every continent was visited and mostly mapped by Europeans, except the south polar continent now known as Antarctica. This development is depicted in the large world map Nova Totius Terrarum Orbis Tabula made by the Dutch cartographer Joan Blaeu in 1648 to commemorate the Peace of Westphalia.\\nIn 1492, Christopher Columbus sailed across the Atlantic Ocean from Spain seeking a direct route to India of the Delhi Sultanate. He accidentally stumbled upon the Americas, but believed he had reached the East Indies.\\nIn 1606, the Dutch navigator Willem Janszoon sailed from the East Indies in the VOC ship Duyfken and landed in Australia. He charted about 300 km of the west coast of Cape York Peninsula in Queensland. More than thirty Dutch expeditions followed, mapping sections of the north, west, and south coasts. In 1642\u20131643, Abel Tasman circumnavigated the continent, proving that it was not joined to the imagined south polar continent.\\nBy 1650, Dutch cartographers had mapped most of the coastline of the continent, which they named New Holland, except the east coast which was charted in 1770 by James Cook.\\nThe long-imagined south polar continent was eventually sighted in 1820. Throughout the Renaissance it had been known as Terra Australis, or 'Australia' for short. However, after that name was transferred to New Holland in the nineteenth century, the new name of 'Antarctica' was bestowed on the south polar continent.\\n\\nMusic\\nFrom this changing society emerged a common, unifying musical language, in particular the polyphonic style of the Franco-Flemish school. The development of printing made distribution of music possible on a wide scale. Demand for music as entertainment and as an activity for educated amateurs increased with the emergence of a bourgeois class. Dissemination of chansons, motets, and masses throughout Europe coincided with the unification of polyphonic practice into the fluid style that culminated in the second half of the sixteenth century in the work of composers such as Palestrina, Lassus, Victoria, and William Byrd.\\n\\nReligion\\nThe new ideals of humanism, although more secular in some aspects, developed against a Christian backdrop, especially in the Northern Renaissance. Much, if not most, of the new art was commissioned by or in dedication to the Church. However, the Renaissance had a profound effect on contemporary theology, particularly in the way people perceived the relationship between man and God. Many of the period's foremost theologians were followers of the humanist method, including Erasmus, Huldrych Zwingli, Thomas More, Martin Luther, and John Calvin.\\n\\nThe Renaissance began in times of religious turmoil. The Late Middle Ages was a period of political intrigue surrounding the Papacy, culminating in the Western Schism, in which three men simultaneously claimed to be true Bishop of Rome. While the schism was resolved by the Council of Constance (1414), a resulting reform movement known as Conciliarism sought to limit the power of the pope. Although the papacy eventually emerged supreme in ecclesiastical matters by the Fifth Council of the Lateran (1511), it was dogged by continued accusations of corruption, most famously in the person of Pope Alexander VI, who was accused variously of simony, nepotism, and fathering children (most of whom were married off, presumably for the consolidation of power) while a cardinal.Churchmen such as Erasmus and Luther proposed reform to the Church, often based on humanist textual criticism of the New Testament. In October 1517, Luther published the Ninety-five Theses, challenging papal authority and criticizing its perceived corruption, particularly with regard to instances of sold indulgences. The 95 Theses led to the Reformation, a break with the Roman Catholic Church that previously claimed hegemony in Western Europe. Humanism and the Renaissance therefore played a direct role in sparking the Reformation, as well as in many other contemporaneous religious debates and conflicts.\\nPope Paul III came to the papal throne (1534\u20131549) after the sack of Rome in 1527, with uncertainties prevalent in the Catholic Church following the Reformation. Nicolaus Copernicus dedicated De revolutionibus orbium coelestium (On the Revolutions of the Celestial Spheres) to Paul III, who became the grandfather of Alessandro Farnese, who had paintings by Titian, Michelangelo, and Raphael, as well as an important collection of drawings, and who commissioned the masterpiece of Giulio Clovio, arguably the last major illuminated manuscript, the Farnese Hours.\\n\\nSelf-awareness\\nBy the 15th century, writers, artists, and architects in Italy were well aware of the transformations that were taking place and were using phrases such as modi antichi (in the antique manner) or alle romana et alla antica (in the manner of the Romans and the ancients) to describe their work. In the 1330s Petrarch referred to pre-Christian times as antiqua (ancient) and to the Christian period as nova (new). From Petrarch's Italian perspective, this new period (which included his own time) was an age of national eclipse.Leonardo Bruni was the first to use tripartite periodization in his History of the Florentine People (1442). Bruni's first two periods were based on those of Petrarch, but he added a third period because he believed that Italy was no longer in a state of decline. Flavio Biondo used a similar framework in Decades of History from the Deterioration of the Roman Empire (1439\u20131453).\\nHumanist historians argued that contemporary scholarship restored direct links to the classical period, thus bypassing the Medieval period, which they then named for the first time the \"Middle Ages\". The term first appears in Latin in 1469 as media tempestas (middle times). The term rinascita (rebirth) first appeared, however, in its broad sense in Giorgio Vasari's Lives of the Artists, 1550, revised 1568. Vasari divides the age into three phases: the first phase contains Cimabue, Giotto, and Arnolfo di Cambio; the second phase contains Masaccio, Brunelleschi, and Donatello; the third centers on Leonardo da Vinci and culminates with Michelangelo. It was not just the growing awareness of classical antiquity that drove this development, according to Vasari, but also the growing desire to study and imitate nature.\\n\\nSpread\\nIn the 15th century, the Renaissance spread rapidly from its birthplace in Florence to the rest of Italy and soon to the rest of Europe. The invention of the printing press by German printer Johannes Gutenberg allowed the rapid transmission of these new ideas. As it spread, its ideas diversified and changed, being adapted to local culture. In the 20th century, scholars began to break the Renaissance into regional and national movements.\\n\\nEngland\\nThe Elizabethan era in the second half of the 16th century is usually regarded as the height of the English Renaissance. Many scholars see its beginnings in the early 16th century during the reign of Henry VIII.The English Renaissance is different from the Italian Renaissance in several ways. The dominant art forms of the English Renaissance were literature and music, which had a rich flowering. Visual arts in the English Renaissance were much less significant than in the Italian Renaissance. The English Renaissance period in art began far later than the Italian, which had moved into Mannerism by the 1530s.In literature the later part of the 16th century saw the flowering of Elizabethan literature, with poetry heavily influenced by Italian Renaissance literature but Elizabethan theatre a distinctive native style. Writers include William Shakespeare (1564\u20131616), Christopher Marlowe (1564\u20131593), Edmund Spenser (1552\u2013599), Sir Thomas More (1478\u20131535), and Sir Philip Sidney (1554\u20131586). English Renaissance music competed with that in Europe with composers such as Thomas Tallis (1505\u20131585), John Taverner (1490\u20131545), and William Byrd (1540\u20131623).  Elizabethan architecture produced the large prodigy houses of courtiers, and in the next century Inigo Jones (1573\u20131652), who introduced Italianate architecture to England.Elsewhere, Sir Francis Bacon (1561\u20131626) was the pioneer of modern scientific thought, and is commonly regarded as one of the founders of the Scientific Revolution.\\n\\nFrance\\nThe word \"Renaissance\" is borrowed from the French language, where it means \"re-birth\". It was first used in the eighteenth century and was later popularized by French historian Jules Michelet (1798\u20131874) in his 1855 work, Histoire de France (History of France).In 1495 the Italian Renaissance arrived in France, imported by King Charles VIII after his invasion of Italy. A factor that promoted the spread of secularism was the inability of the Church to offer assistance against the Black Death. Francis I imported Italian art and artists, including Leonardo da Vinci, and built ornate palaces at great expense. Writers such as Fran\u00e7ois Rabelais, Pierre de Ronsard, Joachim du Bellay, and Michel de Montaigne, painters such as Jean Clouet, and musicians such as Jean Mouton also borrowed from the spirit of the Renaissance.\\nIn 1533, a fourteen-year-old Caterina de' Medici (1519\u20131589), born in Florence to Lorenzo de' Medici, Duke of Urbino and Madeleine de la Tour d'Auvergne, married Henry II of France, second son of King Francis I and Queen Claude. Though she became famous and infamous for her role in France's religious wars, she made a direct contribution in bringing arts, sciences, and music (including the origins of ballet) to the French court from her native Florence.\\n\\nGermany\\nIn the second half of the 15th century, the Renaissance spirit spread to Germany and the Low Countries, where the development of the printing press (ca. 1450) and Renaissance artists such as Albrecht D\u00fcrer (1471\u20131528) predated the influence from Italy. In the early Protestant areas of the country humanism became closely linked to the turmoil of the Reformation, and the art and writing of the German Renaissance frequently reflected this dispute. However, the Gothic style and medieval scholastic philosophy remained exclusively until the turn of the 16th century. Emperor Maximilian I of Habsburg (ruling 1493\u20131519) was the first truly Renaissance monarch of the Holy Roman Empire.\\n\\nHungarian trecento and quattrocento\\nAfter Italy, Hungary was the first European country where the Renaissance appeared. The Renaissance style came directly from Italy during the Quattrocento (1400s) to Hungary first in the Central European region, thanks to the development of early Hungarian-Italian relationships \u2014 not only in dynastic connections, but also in cultural, humanistic and commercial relations \u2013 growing in strength from the 14th century. The relationship between Hungarian and Italian Gothic styles was a second reason \u2013 exaggerated breakthrough of walls is avoided, preferring clean and light structures. Large-scale building schemes provided ample and long term work for the artists, for example, the building of the Friss (New) Castle in Buda, the castles of Visegr\u00e1d, Tata, and V\u00e1rpalota. In Sigismund's court there were patrons such as Pipo Spano, a descendant of the Scolari family of Florence, who invited Manetto Ammanatini and Masolino da Pannicale to Hungary.The new Italian trend combined with existing national traditions to create a particular local Renaissance art. Acceptance of Renaissance art was furthered by the continuous arrival of humanist thought in the country. Many young Hungarians studying at Italian universities came closer to the Florentine humanist center, so a direct connection with Florence evolved. The growing number of Italian traders moving to Hungary, specially to Buda, helped this process. New thoughts were carried by the humanist prelates, among them Vit\u00e9z J\u00e1nos, archbishop of Esztergom, one of the founders of Hungarian humanism. During the long reign of emperor Sigismund of Luxemburg the Royal Castle of Buda became probably the largest Gothic palace of the late Middle Ages. King Matthias Corvinus (r. 1458\u20131490) rebuilt the palace in early Renaissance style and further expanded it.After the marriage in 1476 of King Matthias to Beatrice of Naples, Buda became one of the most important artistic centers of the Renaissance north of the Alps. The most important humanists living in Matthias' court were Antonio Bonfini and the famous Hungarian poet Janus Pannonius. Andr\u00e1s Hess set up a printing press in Buda in 1472. Matthias Corvinus's library, the Bibliotheca Corviniana, was Europe's greatest collections of secular books: historical chronicles, philosophic and scientific works in the 15th century. His library was second only in size to the Vatican Library. (However, the Vatican Library mainly contained Bibles and religious materials.) In 1489, Bartolomeo della Fonte of Florence wrote that Lorenzo de' Medici founded his own Greek-Latin library encouraged by the example of the Hungarian king. Corvinus's library is part of UNESCO World Heritage.Matthias started at least two major building projects. The works in Buda and Visegr\u00e1d began in about 1479. Two new wings and a hanging garden were built at the royal castle of Buda, and the palace at Visegr\u00e1d was rebuilt in Renaissance style. Matthias appointed the Italian Chimenti Camicia and the Dalmatian Giovanni Dalmata to direct these projects.  Matthias commissioned the leading Italian artists of his age to embellish his palaces: for instance, the sculptor Benedetto da Majano and the painters Filippino Lippi and Andrea Mantegna worked for him. A copy of Mantegna's portrait of Matthias survived. Matthias also hired the Italian military engineer Aristotele Fioravanti to direct the rebuilding of the forts along the southern frontier. He had new monasteries built in Late Gothic style for the Franciscans in Kolozsv\u00e1r, Szeged and Hunyad, and for the Paulines in Fej\u00e9regyh\u00e1za.  In the spring of 1485, Leonardo da Vinci travelled to Hungary on behalf of Sforza to meet king Matthias Corvinus, and was commissioned by him to paint a Madonna.Matthias enjoyed the company of Humanists and had lively discussions on various topics with them. The fame of his magnanimity encouraged many scholars\u2014mostly Italian\u2014to settle in Buda. Antonio Bonfini, Pietro Ranzano, Bartolomeo Fonzio, and Francesco Bandini spent many years in Matthias's court. This circle of educated men introduced the ideas of Neoplatonism to Hungary. Like all intellectuals of his age, Matthias was convinced that the movements and combinations of the stars and planets exercised influence on individuals' life and on the history of nations. Galeotto Marzio described him as \"king and astrologer\", and Antonio Bonfini said Matthias \"never did anything without consulting the stars\". Upon his request, the famous astronomers of the age, Johannes Regiomontanus and Marcin Bylica, set up an observatory in Buda and installed it with astrolabes and celestial globes. Regiomontanus dedicated his book on navigation that was used by Christopher Columbus to Matthias.Other important figures of Hungarian Renaissance include B\u00e1lint Balassi (poet), Sebesty\u00e9n Tin\u00f3di Lantos (poet), B\u00e1lint Bakfark (composer and lutenist), and Master MS (fresco painter).\\n\\nRenaissance in the Low Countries\\nCulture in the Netherlands at the end of the 15th century was influenced by the Italian Renaissance through trade via Bruges, which made Flanders wealthy. Its nobles commissioned artists who became known across Europe. In science, the anatomist Andreas Vesalius led the way; in cartography, Gerardus Mercator's map assisted explorers and navigators. In art, Dutch and Flemish Renaissance painting ranged from the strange work of Hieronymus Bosch to the everyday life depictions of Pieter Brueghel the Elder.Erasmus was arguably the Netherlands' best known humanist and Catholic intellectual during the Renaissance.\\n\\nNorthern Europe\\nThe Renaissance in Northern Europe has been termed the \"Northern Renaissance\". While Renaissance ideas were moving north from Italy, there was a simultaneous southward spread of some areas of innovation, particularly in music. The music of the 15th-century Burgundian School defined the beginning of the Renaissance in music, and the polyphony of the Netherlanders, as it moved with the musicians themselves into Italy, formed the core of the first true international style in music since the standardization of Gregorian Chant in the 9th century. The culmination of the Netherlandish school was in the music of the Italian composer Palestrina. At the end of the 16th century Italy again became a center of musical innovation, with the development of the polychoral style of the Venetian School, which spread northward into Germany around 1600. In Denmark, the Renaissance sparked the translation of the works of Saxo Grammaticus into Danish as well as Frederick II and Christian IV ordering the redecoration or construction of several important works of architecture, i.e. Kronborg, Rosenborg and B\u00f8rsen. Danish astronomer Tycho Brahe greatly contributed to turn astronomy into the first modern science and also helped launch the Scientific Revolution.The paintings of the Italian Renaissance differed from those of the Northern Renaissance. Italian Renaissance artists were among the first to paint secular scenes, breaking away from the purely religious art of medieval painters. Northern Renaissance artists initially remained focused on religious subjects, such as the contemporary religious upheaval portrayed by Albrecht D\u00fcrer. Later, the works of Pieter Bruegel influenced artists to paint scenes of daily life rather than religious or classical themes. It was also during the Northern Renaissance that Flemish brothers Hubert and Jan van Eyck perfected the oil painting technique, which enabled artists to produce strong colors on a hard surface that could survive for centuries. A feature of the Northern Renaissance was its use of the vernacular in place of Latin or Greek, which allowed greater freedom of expression. This movement had started in Italy with the decisive influence of Dante Alighieri on the development of vernacular languages; in fact the focus on writing in Italian has neglected a major source of Florentine ideas expressed in Latin. The spread of the printing press technology boosted the Renaissance in Northern Europe as elsewhere, with Venice becoming a world center of printing.\\n\\nPoland\\nAn early Italian humanist who came to Poland in the mid-15th century was Filippo Buonaccorsi. Many Italian artists came to Poland with Bona Sforza of Milan, when she married King Sigismund I in 1518. This was supported by temporarily strengthened monarchies in both areas, as well as by newly established universities. The Polish Renaissance lasted from the late 15th to the late 16th century and was the Golden Age of Polish culture. Ruled by the Jagiellonian dynasty, the Kingdom of Poland (from 1569 known as the Polish\u2013Lithuanian Commonwealth) actively participated in the broad European Renaissance. The multi-national Polish state experienced a substantial period of cultural growth thanks in part to a century without major wars \u2013 aside from conflicts in the sparsely populated eastern and southern borderlands. The Reformation spread peacefully throughout the country (giving rise to the Polish Brethren), while living conditions improved, cities grew, and exports of agricultural products enriched the population, especially the nobility (szlachta) who gained dominance in the new political system of Golden Liberty. The Polish Renaissance architecture has three periods of development.\\nThe greatest monument of this style in the territory of the former Duchy of Pomerania is the Ducal Castle in Szczecin.\\n\\nPortugal\\nAlthough Italian Renaissance had a modest impact in Portuguese arts, Portugal was influential in broadening the European worldview, stimulating humanist inquiry. Renaissance arrived through the influence of wealthy Italian and Flemish merchants who invested in the profitable commerce overseas. As the pioneer headquarters of European exploration, Lisbon flourished in the late 15th century, attracting experts who made several breakthroughs in mathematics, astronomy and naval technology, including Pedro Nunes, Jo\u00e3o de Castro, Abraham Zacuto, and Martin Behaim. Cartographers Pedro Reinel, Lopo Homem, Est\u00eav\u00e3o Gomes, and Diogo Ribeiro made crucial advances in mapping the world. Apothecary Tom\u00e9 Pires and physicians Garcia de Orta and Crist\u00f3v\u00e3o da Costa collected and published works on plants and medicines, soon translated by Flemish pioneer botanist Carolus Clusius.\\n\\nIn architecture, the huge profits of the spice trade financed a sumptuous composite style in the first decades of the 16th century, the Manueline, incorporating maritime elements. The primary painters were Nuno Gon\u00e7alves, Greg\u00f3rio Lopes, and Vasco Fernandes. In music, Pedro de Escobar and Duarte Lobo produced four songbooks, including the Cancioneiro de Elvas. In literature, S\u00e1 de Miranda introduced Italian forms of verse. Bernardim Ribeiro developed pastoral romance, plays by Gil Vicente fused it with popular culture, reporting the changing times, and Lu\u00eds de Cam\u00f5es inscribed the Portuguese feats overseas in the epic poem Os Lus\u00edadas. Travel literature especially flourished: Jo\u00e3o de Barros, Castanheda, Ant\u00f3nio Galv\u00e3o, Gaspar Correia, Duarte Barbosa, and Fern\u00e3o Mendes Pinto, among others, described new lands and were translated and spread with the new printing press. After joining the Portuguese exploration of Brazil in 1500, Amerigo Vespucci coined the term New World, in his letters to Lorenzo di Pierfrancesco de' Medici.\\nThe intense international exchange produced several cosmopolitan humanist scholars, including Francisco de Holanda, Andr\u00e9 de Resende, and Dami\u00e3o de G\u00f3is, a friend of Erasmus who wrote with rare independence on the reign of King Manuel I. Diogo and Andr\u00e9 de Gouveia made relevant teaching reforms via France. Foreign news and products in the Portuguese factory in Antwerp attracted the interest of Thomas More and Albrecht D\u00fcrer to the wider world. There, profits and know-how helped nurture the Dutch Renaissance and Golden Age, especially after the arrival of the wealthy cultured Jewish community expelled from Portugal.\\n\\nSpain\\nThe Renaissance arrived in the Iberian peninsula through the Mediterranean possessions of the Aragonese Crown and the city of Valencia. Many early Spanish Renaissance writers come from the Kingdom of Aragon, including Ausi\u00e0s March and Joanot Martorell. In the Kingdom of Castile, the early Renaissance was heavily influenced by the Italian humanism, starting with writers and poets such as the Marquis of Santillana, who introduced the new Italian poetry to Spain in the early 15th century. Other writers, such as Jorge Manrique, Fernando de Rojas, Juan del Encina, Juan Bosc\u00e1n Almog\u00e1ver, and Garcilaso de la Vega, kept a close resemblance to the Italian canon. Miguel de Cervantes's masterpiece Don Quixote is credited as the first Western novel. Renaissance humanism flourished in the early 16th century, with influential writers such as philosopher Juan Luis Vives, grammarian Antonio de Nebrija and natural historian Pedro de Mex\u00eda.\\nLater Spanish Renaissance tended toward religious themes and mysticism, with poets such as Luis de Le\u00f3n, Teresa of \u00c1vila, and John of the Cross, and treated issues related to the exploration of the New World, with chroniclers and writers such as Inca Garcilaso de la Vega and Bartolom\u00e9 de las Casas, giving rise to a body of work, now known as Spanish Renaissance literature. The late Renaissance in Spain produced artists such as El Greco and composers such as Tom\u00e1s Luis de Victoria and Antonio de Cabez\u00f3n.\\n\\nFurther countries\\nRenaissance in Croatia\\nRenaissance in Scotland\\n\\nHistoriography\\nConception\\nThe Italian artist and critic Giorgio Vasari (1511\u20131574) first used the term rinascita in his book The Lives of the Artists (published 1550). In the book Vasari attempted to define what he described as a break with the barbarities of Gothic art: the arts (he held) had fallen into decay with the collapse of the Roman Empire and only the Tuscan artists, beginning with Cimabue (1240\u20131301) and Giotto (1267\u20131337) began to reverse this decline in the arts. Vasari saw ancient art as central to the rebirth of Italian art.However, only in the 19th century did the French word renaissance achieve popularity in describing the self-conscious cultural movement based on revival of Roman models that began in the late 13th century. French historian Jules Michelet (1798\u20131874) defined \"The Renaissance\" in his 1855 work Histoire de France as an entire historical period, whereas previously it had been used in a more limited sense. For Michelet, the Renaissance was more a development in science than in art and culture. He asserted that it spanned the period from Columbus to Copernicus to Galileo; that is, from the end of the 15th century to the middle of the 17th century. Moreover, Michelet distinguished between what he called, \"the bizarre and monstrous\" quality of the Middle Ages and the democratic values that he, as a vocal Republican, chose to see in its character. A French nationalist, Michelet also sought to claim the Renaissance as a French movement.The Swiss historian Jacob Burckhardt (1818\u20131897) in his The Civilization of the Renaissance in Italy (1860), by contrast, defined the Renaissance as the period between Giotto and Michelangelo in Italy, that is, the 14th to mid-16th centuries. He saw in the Renaissance the emergence of the modern spirit of individuality, which the Middle Ages had stifled. His book was widely read and became influential in the development of the modern interpretation of the Italian Renaissance.More recently, some historians have been much less keen to define the Renaissance as a historical age, or even as a coherent cultural movement. The historian Randolph Starn, of the University of California Berkeley, stated in 1998:\\n\\nRather than a period with definitive beginnings and endings and consistent content in between, the Renaissance can be (and occasionally has been) seen as a movement of practices and ideas to which specific groups and identifiable persons variously responded in different times and places. It would be in this sense a network of diverse, sometimes converging, sometimes conflicting cultures, not a single, time-bound culture.\\n\\nDebates about progress\\nThere is debate about the extent to which the Renaissance improved on the culture of the Middle Ages. Both Michelet and Burckhardt were keen to describe the progress made in the Renaissance toward the modern age. Burckhardt likened the change to a veil being removed from man's eyes, allowing him to see clearly.\\nIn the Middle Ages both sides of human consciousness \u2013 that which was turned within as that which was turned without \u2013 lay dreaming or half awake beneath a common veil. The veil was woven of faith, illusion, and childish prepossession, through which the world and history were seen clad in strange hues.\\nOn the other hand, many historians now point out that most of the negative social factors popularly associated with the medieval period \u2013 poverty, warfare, religious and political persecution, for example \u2013 seem to have worsened in this era, which saw the rise of Machiavellian politics, the Wars of Religion, the corrupt Borgia Popes, and the intensified witch-hunts of the 16th century. Many people who lived during the Renaissance did not view it as the \"golden age\" imagined by certain 19th-century authors, but were concerned by these social maladies. Significantly, though, the artists, writers, and patrons involved in the cultural movements in question believed they were living in a new era that was a clean break from the Middle Ages. Some Marxist historians prefer to describe the Renaissance in material terms, holding the view that the changes in art, literature, and philosophy were part of a general economic trend from feudalism toward capitalism, resulting in a bourgeois class with leisure time to devote to the arts.Johan Huizinga (1872\u20131945) acknowledged the existence of the Renaissance but questioned whether it was a positive change. In his book The Autumn of the Middle Ages, he argued that the Renaissance was a period of decline from the High Middle Ages, destroying much that was important. The Medieval Latin language, for instance, had evolved greatly from the classical period and was still a living language used in the church and elsewhere. The Renaissance obsession with classical purity halted its further evolution and saw Latin revert to its classical form. This view is however somewhat contested by recent studies. Robert S. Lopez has contended that it was a period of deep economic recession. Meanwhile, George Sarton and Lynn Thorndike have both argued that scientific progress was perhaps less original than has traditionally been supposed. Finally, Joan Kelly argued that the Renaissance led to greater gender dichotomy, lessening the agency women had had during the Middle Ages.Some historians have begun to consider the word Renaissance to be unnecessarily loaded, implying an unambiguously positive rebirth from the supposedly more primitive \"Dark Ages\", the Middle Ages. Most political and economic historians now prefer to use the term \"early modern\" for this period (and a considerable period afterwards), a designation intended to highlight the period as a transitional one between the Middle Ages and the modern era. Others such as Roger Osborne have come to consider the Italian Renaissance as a repository of the myths and ideals of western history in general, and instead of rebirth of ancient ideas as a period of great innovation.The art historian Erwin Panofsky observed of this resistance to the concept of \"Renaissance\":\\n\\nIt is perhaps no accident that the factuality of the Italian Renaissance has been most vigorously questioned by those who are not obliged to take a professional interest in the aesthetic aspects of civilization \u2013 historians of economic and social developments, political and religious situations, and, most particularly, natural science \u2013 but only exceptionally by students of literature and hardly ever by historians of Art.\\n\\nOther Renaissances\\nThe term Renaissance has also been used to define periods outside of the 15th and 16th centuries. Charles H. Haskins (1870\u20131937), for example, made a case for a Renaissance of the 12th century. Other historians have argued for a Carolingian Renaissance in the 8th and 9th centuries, Ottonian Renaissance in the 10th century and for the Timurid Renaissance of the 14th century. The Islamic Golden Age has been also sometimes termed with the Islamic Renaissance. The Macedonian Renaissance is a term used for a period in the Roman Empire in the 9th-11th centuries CE. \\nOther periods of cultural rebirth have also been termed \"renaissances\", such as the Bengal Renaissance, Tamil Renaissance, Nepal Bhasa renaissance, al-Nahda or the Harlem Renaissance. The term can also be used in cinema. In animation, the Disney Renaissance is a period that spanned the years from 1989 to 1999 which saw the studio return to the level of quality not witnessed since their Golden Age of Animation. The San Francisco Renaissance was a vibrant period of exploratory poetry and fiction writing in that city in the mid-20th century.\\n\\nSee also\\nIndex of Renaissance articles\\nOutline of the Renaissance\\nList of Renaissance figures\\nList of Renaissance structures\\nRoman Renaissance\\nVenetian Renaissance\\n\\nReferences\\nExplanatory notes\\nCitations\\nGeneral sources\\nFurther reading\\nHistoriography\\nPrimary sources\\nExternal links\\n\\n\"The Renaissance\" episode of In Our Time, a BBC Radio 4 discussion with Francis Ames-Lewis, Peter Burke and Evelyn Welch (June 8, 2000).\\nSymonds, John Addington (1911). \"Renaissance, The\" . Encyclop\u00e6dia Britannica. Vol. 23 (11th ed.). pp. 83\u201393.\\nRenaissance Philosophy entry in the Internet Encyclopedia of Philosophy\\nOfficial website of the Society for Renaissance Studies"}
{"article_name": "Einstein", "link": "https://en.wikipedia.org/wiki/Einstein", "text_content": "Albert Einstein ( EYEN-styne; German: [\u02c8alb\u025b\u0250t \u02c8\u0294a\u026an\u0283ta\u026an] ; 14 March 1879 \u2013 18 April 1955) was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, Einstein also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His mass\u2013energy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world's most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made the word Einstein broadly synonymous with genius.Born in the German Empire, Einstein moved to Switzerland in 1895, forsaking his German citizenship (as a subject of the Kingdom of W\u00fcrttemberg) the following year. In 1897, at the age of seventeen, he enrolled in the mathematics and physics teaching diploma program at the Swiss Federal polytechnic school in Z\u00fcrich, graduating in 1900. In 1901, he acquired Swiss citizenship, which he kept for the rest of his life. In 1903, he secured a permanent position at the Swiss Patent Office in Bern. In 1905, he submitted a successful PhD dissertation to the University of Zurich. In 1914, he moved to Berlin in order to join the Prussian Academy of Sciences and the Humboldt University of Berlin. In 1917, he became director of the Kaiser Wilhelm Institute for Physics; he also became a German citizen again, this time as a subject of the Kingdom of Prussia.In 1933, while he was visiting the United States, Adolf Hitler came to power in Germany. Horrified by the Nazi \"war of extermination\" against his fellow Jews, Einstein decided to remain in the US, and was granted American citizenship in 1940. On the eve of World War II, he endorsed a letter to President Franklin D. Roosevelt alerting him to the potential German nuclear weapons program and recommending that the US begin similar research. Einstein supported the Allies but generally viewed the idea of nuclear weapons with great dismay.In 1905, sometimes described as his annus mirabilis (miracle year), Einstein published four groundbreaking papers. These outlined a theory of the photoelectric effect, explained Brownian motion, introduced his special theory of relativity\u2014a theory which addressed the inability of classical mechanics to account satisfactorily for the behavior of the electromagnetic field\u2014and demonstrated that if the special theory is correct, mass and energy are equivalent to each other. In 1915, he proposed a general theory of relativity that extended his system of mechanics to incorporate gravitation. A cosmological paper that he published the following year laid out the implications of general relativity for the modeling of the structure and evolution of the universe as a whole. The middle part of his career also saw him making important contributions to statistical mechanics and quantum theory. Especially notable was his work on the quantum physics of radiation, in which light consists of particles, subsequently called photons. For much of the last phase of his academic life, Einstein worked on two endeavors that proved ultimately unsuccessful. Firstly, he advocated against quantum theory's introduction of fundamental randomness into science's picture of the world, objecting that \"God does not play dice\". Secondly, he attempted to devise a unified field theory by generalizing his geometric theory of gravitation to include electromagnetism too. As a result, he became increasingly isolated from the mainstream of modern physics.\\n\\nLife and career\\nChildhood, youth and education\\nAlbert Einstein was born in Ulm, in the Kingdom of W\u00fcrttemberg in the German Empire, on 14 March 1879. His parents, secular Ashkenazi Jews, were Hermann Einstein, a salesman and engineer, and Pauline Koch. In 1880, the family moved to Munich's borough of Ludwigsvorstadt-Isarvorstadt, where Einstein's father and his uncle Jakob founded Elektrotechnische Fabrik J. Einstein & Cie, a company that manufactured electrical equipment based on direct current.Albert attended a Catholic elementary school in Munich from the age of five. When he was eight, he was transferred to the Luitpold-Gymnasium (now known as the Albert-Einstein-Gymnasium) where he received advanced primary and then secondary school education.In 1894, Hermann and Jakob's company tendered for a contract to install electric lighting in Munich, but without success\u2014they lacked the capital that would have been required to update their technology from direct current to the more efficient, alternating current alternative. The failure of their bid forced them to sell their Munich factory and search for new opportunities elsewhere. The Einstein family moved to Italy, first to Milan and a few months later to Pavia, where they settled in Palazzo Cornazzani. Einstein, then fifteen, stayed behind in Munich in order to finish his schooling. His father wanted him to study electrical engineering, but he was a fractious pupil who found the Gymnasium's regimen and teaching methods far from congenial. He later wrote that the school's policy of strict rote learning was harmful to creativity. At the end of December 1894, a letter from a doctor persuaded the Luitpold's authorities to release him from its care, and he joined his family in Pavia. While in Italy as a teenager, he wrote an essay entitled \"On the Investigation of the State of the Ether in a Magnetic Field\".Einstein excelled at physics and mathematics from an early age, and soon acquired the mathematical expertise normally only found in a child several years his senior. He began teaching himself algebra, calculus and Euclidean geometry when he was twelve; he made such rapid progress that he discovered an original proof of the Pythagorean theorem before his thirteenth birthday. A family tutor, Max Talmud, said that only a short time after he had given the twelve year old Einstein a geometry textbook, the boy \"had worked through the whole book. He thereupon devoted himself to higher mathematics ... Soon the flight of his mathematical genius was so high I could not follow.\" Einstein recorded that he had \"mastered integral and differential calculus\" while still just fourteen. His love of algebra and geometry was so great that at twelve, he was already confident that nature could be understood as a \"mathematical structure\".\\nAt thirteen, when his range of enthusiasms had broadened to include music and philosophy, Einstein was introduced to Kant's Critique of Pure Reason. Kant became his favorite philosopher; according to his tutor, \"At the time he was still a child, only thirteen years old, yet Kant's works, incomprehensible to ordinary mortals, seemed to be clear to him.\"\\nIn 1895, at the age of sixteen, Einstein sat the entrance examination for the Federal polytechnic school (later the Eidgen\u00f6ssische Technische Hochschule, ETH) in Z\u00fcrich, Switzerland. He failed to reach the required standard in the general part of the test, but performed with distinction in physics and mathematics. On the advice of the polytechnic's principal, he completed his secondary education at the Argovian cantonal school (a gymnasium) in Aarau, Switzerland, graduating in 1896. While lodging in Aarau with the family of Jost Winteler, he fell in love with Winteler's daughter, Marie. (His sister, Maja, later married Winteler's son Paul.)\\nIn January 1896, with his father's approval, Einstein renounced his citizenship of the German Kingdom of W\u00fcrttemberg in order to avoid conscription into military service. The Matura (graduation for the successful completion of higher secondary schooling) awarded to him in the September of that year acknowledged him to have performed well across most of the curriculum, allotting him a top grade of 6 for history, physics, algebra, geometry, and descriptive geometry. At seventeen, he enrolled in the four-year mathematics and physics teaching diploma program at the Federal polytechnic school. Marie Winteler, a year older than him, took up a teaching post in Olsberg, Switzerland.The five other polytechnic school freshmen following the same course as Einstein included just one woman, a twenty year old Serbian, Mileva Mari\u0107. Over the next few years, the pair spent many hours discussing their shared interests and learning about topics in physics that the polytechnic school's lectures did not cover. In his letters to Mari\u0107, Einstein confessed that exploring science with her by his side was much more enjoyable than reading a textbook in solitude. Eventually the two students became not only friends but also lovers.Historians of physics are divided on the question of the extent to which Mari\u0107 contributed to the insights of Einstein's annus mirabilis publications. There is at least some evidence that he was influenced by her scientific ideas, but there are scholars who doubt whether her impact on his thought was of any great significance at all.\\n\\nMarriages, relationships and children\\nCorrespondence between Einstein and Mari\u0107, discovered and published in 1987, revealed that in early 1902, while Mari\u0107 was visiting her parents in Novi Sad, she gave birth to a daughter, Lieserl. When Mari\u0107 returned to Switzerland it was without the child, whose fate is uncertain. A letter of Einstein's that he wrote in September 1903 suggests that the girl was either given up for adoption or died of scarlet fever in infancy.Einstein and Mari\u0107 married in January 1903. In May 1904, their son Hans Albert was born in Bern, Switzerland. Their son Eduard was born in Z\u00fcrich in July 1910. In letters that Einstein wrote to Marie Winteler in the months before Eduard's arrival, he described his love for his wife as \"misguided\" and mourned the \"missed life\" that he imagined he would have enjoyed if he had married Winteler instead: \"I think of you in heartfelt love every spare minute and am so unhappy as only a man can be.\"In 1912, Einstein entered into a relationship with Elsa L\u00f6wenthal, who was both his first cousin on his mother's side and his second cousin on his father's. When Mari\u0107 learned of his infidelity soon after moving to Berlin with him in April 1914, she returned to Z\u00fcrich, taking Hans Albert and Eduard with her. Einstein and Mari\u0107 were granted a divorce on 14 February 1919 on the grounds of having lived apart for five years. As part of the divorce settlement, Einstein agreed that if he were to win a Nobel Prize, he would give the money that he received to Mari\u0107; she had to wait only two years before her foresight in extracting this promise from him was rewarded.Einstein married L\u00f6wenthal in 1919. In 1923, he began a relationship with a secretary named Betty Neumann, the niece of his close friend Hans M\u00fchsam. L\u00f6wenthal nevertheless remained loyal to him, accompanying him when he emigrated to the United States in 1933. In 1935, she was diagnosed with heart and kidney problems. She died in December 1936.A volume of Einstein's letters released by Hebrew University of Jerusalem in 2006 added further names to the catalog of women with whom he was romantically involved. They included Margarete Lebach (a married Austrian), Estella Katzenellenbogen (the rich owner of a florist business), Toni Mendel (a wealthy Jewish widow) and Ethel Michanowski (a Berlin socialite), with whom he spent time and from whom he accepted gifts while married to L\u00f6wenthal. After being widowed, Einstein was briefly in a relationship with Margarita Konenkova, thought by some to be a Russian spy; her husband, the Russian sculptor Sergei Konenkov, created the bronze bust of Einstein at the Institute for Advanced Study at Princeton.Following an episode of acute mental illness at about the age of twenty, Einstein's son Eduard was diagnosed with schizophrenia. He spent the remainder of his life either in the care of his mother or in temporary confinement in an asylum. After her death, he was committed permanently to Burgh\u00f6lzli, the Psychiatric University Hospital in Z\u00fcrich.\\n\\n1902\u20131909: Assistant at the Swiss Patent Office\\nEinstein graduated from the Federal polytechnic school in 1900, duly certified as competent to teach mathematics and physics. His successful acquisition of Swiss citizenship in February 1901 was not followed by the usual sequel of conscription; the Swiss authorities deemed him medically unfit for military service. He found that Swiss schools too appeared to have no use for him, failing to offer him a teaching position despite the almost two years that he spent applying for one. Eventually it was with the help of Marcel Grossmann's father that he secured a post in Bern at the Swiss Patent Office, as an assistant examiner \u2013 level III.Patent applications that landed on Einstein's desk for his evaluation included ideas for a gravel sorter and an electric typewriter. His employers were pleased enough with his work to make his position permanent in 1903, although they did not think that he should be promoted until he had \"fully mastered machine technology\". It is conceivable that his labors at the patent office had a bearing on his development of his special theory of relativity. He arrived at his revolutionary ideas about space, time and light through thought experiments about the transmission of signals and the synchronization of clocks, matters which also figured in some of the inventions submitted to him for assessment.In 1902, Einstein and some friends whom he had met in Bern formed a group that held regular meetings to discuss science and philosophy. Their choice of a name for their club, the Olympia Academy, was an ironic comment upon its far from Olympian status. Sometimes they were joined by Mari\u0107, who limited her participation in their proceedings to careful listening. The thinkers whose works they reflected upon included Henri Poincar\u00e9, Ernst Mach and David Hume, all of whom significantly influenced Einstein's own subsequent ideas and beliefs.\\n\\n1900\u20131905: First scientific papers\\nEinstein's first paper, \"Folgerungen aus den Capillarit\u00e4tserscheinungen\" (\"Conclusions drawn from the phenomena of capillarity\"), in which he proposed a model of intermolecular attraction that he afterwards disavowed as worthless, was published in the journal Annalen der Physik in 1900. His 24-page doctoral dissertation also addressed a topic in molecular physics. Titled \"Eine neue Bestimmung der Molek\u00fcldimensionen\" (\"A New Determination of Molecular Dimensions\") and dedicated to his friend Marcel Grossman, it was completed on 30 April 1905 and approved by Professor Alfred Kleiner of the University of Zurich three months later. (Einstein was formally awarded his PhD on 15 January 1906.) Four other pieces of work that Einstein completed in 1905\u2014his famous papers on the photoelectric effect, Brownian motion, his special theory of relativity and the equivalence of mass and energy\u2014have led to the year's being celebrated as an annus mirabilis for physics almost as wonderful as 1666 (the year in which Isaac Newton experienced his greatest epiphanies). The publications deeply impressed Einstein's contemporaries.\\n\\n1908\u20131933: Early academic career\\nEinstein's sabbatical as a civil servant approached its end in 1908, when he secured a junior teaching position at the University of Bern. In 1909, a lecture on relativistic electrodynamics that he gave at the University of Zurich, much admired by Alfred Kleiner, led to Z\u00fcrich's luring him away from Bern with a newly created associate professorship. Promotion to a full professorship followed in April 1911, when he accepted a chair at the German Charles-Ferdinand University in Prague, a move which required him to become an Austrian citizen of the Austro-Hungarian Empire. His time in Prague saw him producing eleven research papers.\\n In July 1912, he returned to his alma mater, the ETH Zurich, to take up a chair in theoretical physics. His teaching activities there centred on thermodynamics and analytical mechanics, and his research interests included the molecular theory of heat, continuum mechanics and the development of a relativistic theory of gravitation. In his work on the latter topic, he was assisted by his friend, Marcel Grossmann, whose knowledge of the kind of mathematics required was greater than his own.In the spring of 1913, two German visitors, Max Planck and Walther Nernst, called upon Einstein in Z\u00fcrich in the hope of persuading him to relocate to Berlin. They offered him membership of the Prussian Academy of Sciences, the directorship of the planned Kaiser Wilhelm Institute for Physics and a chair at the Humboldt University of Berlin that would allow him to pursue his research supported by a professorial salary but with no teaching duties to burden him. Their invitation was all the more appealing to him because Berlin happened to be the home of his latest girlfriend, Elsa L\u00f6wenthal. He duly joined the Academy on 24\\nJuly 1913, and moved into an apartment in the Berlin district of Dahlem on 1 April 1914. He was installed in his Humboldt University position shortly thereafter.The outbreak of the First World War in July 1914 marked the beginning of Einstein's gradual estrangement from the nation of his birth. When the \"Manifesto of the Ninety-Three\" was published in October 1914\u2014a document signed by a host of prominent German thinkers that justified Germany's belligerence\u2014Einstein was one of the few German intellectuals to distance himself from it and sign the alternative, eirenic \"Manifesto to the Europeans\" instead. But this expression of his doubts about German policy did not prevent him from being elected to a two-year term as president of the German Physical Society in 1916. And when the Kaiser Wilhelm Institute for Physics opened its doors the following year\u2014its foundation delayed because of the war\u2014Einstein was appointed its first director, just as Planck and Nernst had promised.Einstein was elected a Foreign Member of the Royal Netherlands Academy of Arts and Sciences in 1920, and a Foreign Member of the Royal Society in 1921. In 1922, he was awarded the 1921 Nobel Prize in Physics \"for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect\". At this point some physicists still regarded the general theory of relativity sceptically, and the Nobel citation displayed a degree of doubt even about the work on photoelectricity that it acknowledged: it did not assent to Einstein's notion of the particulate nature of light, which only won over the entire scientific community when S. N. Bose derived the Planck spectrum in 1924. That same year, Einstein was elected an International Honorary Member of the American Academy of Arts and Sciences. Britain's closest equivalent of the Nobel award, the Royal Society's Copley Medal, was not hung around Einstein's neck until 1925. He was elected an International Member of the American Philosophical Society in 1930.Einstein resigned from the Prussian Academy in March 1933. His accomplishments in Berlin had included the completion of the general theory of relativity, proving the Einstein\u2013de Haas effect, contributing to the quantum theory of radiation, and the development of Bose\u2013Einstein statistics.\\n\\n1919: Putting general relativity to the test\\nIn 1907, Einstein reached a milestone on his long journey from his special theory of relativity to a new idea of gravitation with the formulation of his equivalence principle, which asserts that an observer in an infinitesimally small box falling freely in a gravitational field would be unable to find any evidence that the field exists. In 1911, he used the principle to estimate the amount by which a ray of light from a distant star would be bent by the gravitational pull of the Sun as it passed close to the Sun's photosphere (that is, the Sun's apparent surface). He reworked his calculation in 1913, having now found a way to model gravitation with the Riemann curvature tensor of a non-Euclidean four-dimensional spacetime. By the fall of 1915, his reimagining of the mathematics of gravitation in terms of Riemannian geometry was complete, and he applied his new theory not just to the behavior of the Sun as a gravitational lens but also to another astronomical phenomenon, the precession of the perihelion of Mercury (a slow drift in the point in Mercury's elliptical orbit at which it approaches the Sun most closely). A total eclipse of the Sun that took place on 29 May 1919 provided an opportunity to put his theory of gravitational lensing to the test, and observations performed by Sir Arthur Eddington yielded results that were consistent with his calculations. Eddington's work was reported at length in newspapers around the world. On 7 November 1919, for example, the leading British newspaper, The Times, printed a banner headline that read: \"Revolution in Science \u2013 New Theory of the Universe \u2013 Newtonian Ideas Overthrown\".\\n\\n1921\u20131923: Coming to terms with fame\\nWith Eddington's eclipse observations widely reported not just in academic journals but by the popular press as well, Einstein became \"perhaps the world's first celebrity scientist\", a genius who had shattered a paradigm that had been basic to physicists' understanding of the universe since the seventeenth century.Einstein began his new life as an intellectual icon in America, where he arrived on 2 April 1921. He was welcomed to New York City by Mayor John Francis Hylan, and then spent three weeks giving lectures and attending receptions. He spoke several times at Columbia University and Princeton, and in Washington, he visited the White House with representatives of the National Academy of Sciences. He returned to Europe via London, where he was the guest of the philosopher and statesman Viscount Haldane. He used his time in the British capital to meet several people prominent in British scientific, political or intellectual life, and to deliver a lecture at King's College. In July 1921, he published an essay, \"My First Impression of the U.S.A.\", in which he sought to sketch the American character, much as had Alexis de Tocqueville in Democracy in America (1835). He wrote of his transatlantic hosts in highly approving terms: \"What strikes a visitor is the joyous, positive attitude to life ... The American is friendly, self-confident, optimistic, and without envy.\"In 1922, Einstein's travels were to the old world rather than the new. He devoted six months to a tour of Asia that saw him speaking in Japan, Singapore and Sri Lanka (then known as Ceylon). After his first public lecture in Tokyo, he met Emperor Yoshihito and his wife at the Imperial Palace, with thousands of spectators thronging the streets in the hope of catching a glimpse of him. (In a letter to his sons, he wrote that Japanese people seemed to him to be generally modest, intelligent and considerate, and to have a true appreciation of art. But his picture of them in his diary was less flattering: \"[the] intellectual needs of this nation seem to be weaker than their artistic ones \u2013 natural disposition?\" His journal also contains views of China and India which were uncomplimentary. Of Chinese people, he wrote that \"even the children are spiritless and look obtuse... It would be a pity if these Chinese supplant all other races. For the likes of us the mere thought is unspeakably dreary\".) He was greeted with even greater enthusiasm on the last leg of his tour, in which he spent twelve days in Mandatory Palestine, newly entrusted to British rule by the League of Nations in the aftermath of the First World War. Sir Herbert Samuel, the British High Commissioner, welcomed him with a degree of ceremony normally only accorded to a visiting head of state, including a cannon salute. One reception held in his honor was stormed by people determined to hear him speak: he told them that he was happy that Jews were beginning to be recognized as a force in the world.Einstein's decision to tour the eastern hemisphere in 1922 meant that he was unable to go to Stockholm in the December of that year to participate in the Nobel prize ceremony. His place at the traditional Nobel banquet was taken by a German diplomat, who gave a speech praising him not only as a physicist but also as a campaigner for peace. A two week visit to Spain that he undertook in 1923 saw him collecting another award, a membership of the Spanish Academy of Sciences signified by a diploma handed to him by King Alfonso XIII. (His Spanish trip also gave him a chance to meet a fellow Nobel laureate, the neuroanatomist Santiago Ram\u00f3n y Cajal.)\\n\\n1922\u20131932: Serving the League of Nations\\nFrom 1922 until 1932, with the exception of a few months in 1923 and 1924, Einstein was a member of the Geneva-based International Committee on Intellectual Cooperation of the League of Nations, a group set up by the League to encourage scientists, artists, scholars, teachers and other people engaged in the life of the mind to work more closely with their counterparts in other countries. He was appointed as a German delegate rather than as a representative of Switzerland because of the machinations of two Catholic activists, Oskar Halecki and Giuseppe Motta. By persuading Secretary General Eric Drummond to deny Einstein the place on the committee reserved for a Swiss thinker, they created an opening for Gonzague de Reynold, who used his League of Nations position as a platform from which to promote traditional Catholic doctrine. Einstein's former physics professor Hendrik Lorentz and the Polish chemist Marie Curie were also members of the committee.\\n\\n1925: Touring South America\\nIn March and April 1925, Einstein and his wife visited South America, where they spent about a week in Brazil, a week in Uruguay and a month in Argentina. Their tour was suggested by Jorge Duclout (1856\u20131927) and Mauricio Nirenstein (1877\u20131935) with the support of several Argentine scholars, including Julio Rey Pastor, Jakob Laub, and Leopoldo Lugones. and was financed primarily by the Council of the University of Buenos Aires and the Asociaci\u00f3n Hebraica Argentina (Argentine Hebraic Association) with a smaller contribution from the Argentine-Germanic Cultural Institution.\\n\\n1930\u20131931: Touring the US\\nIn December 1930, Einstein began another significant sojourn in the United States, drawn back to the US by the offer of a two month research fellowship at the California Institute of Technology. Caltech supported him in his wish that he should not be exposed to quite as much attention from the media as he had experienced when visiting the US in 1921, and he therefore declined all the invitations to receive prizes or make speeches that his admirers poured down upon him. But he remained willing to allow his fans at least some of the time with him that they requested.After arriving in New York City, Einstein was taken to various places and events, including Chinatown, a lunch with the editors of The New York Times, and a performance of Carmen at the Metropolitan Opera, where he was cheered by the audience on his arrival. During the days following, he was given the keys to the city by Mayor Jimmy Walker and met Nicholas Murray Butler, the president of Columbia University, who described Einstein as \"the ruling monarch of the mind\". Harry Emerson Fosdick, pastor at New York's Riverside Church, gave Einstein a tour of the church and showed him a full-size statue that the church made of Einstein, standing at the entrance. Also during his stay in New York, he joined a crowd of 15,000 people at Madison Square Garden during a Hanukkah celebration.\\nEinstein next traveled to California, where he met Caltech president and Nobel laureate Robert A. Millikan. His friendship with Millikan was \"awkward\", as Millikan \"had a penchant for patriotic militarism\", where Einstein was a pronounced pacifist. During an address to Caltech's students, Einstein noted that science was often inclined to do more harm than good.This aversion to war also led Einstein to befriend author Upton Sinclair and film star Charlie Chaplin, both noted for their pacifism. Carl Laemmle, head of Universal Studios, gave Einstein a tour of his studio and introduced him to Chaplin. They had an instant rapport, with Chaplin inviting Einstein and his wife, Elsa, to his home for dinner. Chaplin said Einstein's outward persona, calm and gentle, seemed to conceal a \"highly emotional temperament\", from which came his \"extraordinary intellectual energy\".Chaplin's film, City Lights, was to premiere a few days later in Hollywood, and Chaplin invited Einstein and Elsa to join him as his special guests. Walter Isaacson, Einstein's biographer, described this as \"one of the most memorable scenes in the new era of celebrity\". Chaplin visited Einstein at his home on a later trip to Berlin and recalled his \"modest little flat\" and the piano at which he had begun writing his theory. Chaplin speculated that it was \"possibly used as kindling wood by the Nazis\".\\n\\n1933: Emigration to the US\\nIn February 1933, while on a visit to the United States, Einstein knew he could not return to Germany with the rise to power of the Nazis under Germany's new chancellor, Adolf Hitler.While at American universities in early 1933, he undertook his third two-month visiting professorship at the California Institute of Technology in Pasadena. In February and March 1933, the Gestapo repeatedly raided his family's apartment in Berlin. He and his wife Elsa returned to Europe in March, and during the trip, they learned that the German Reichstag had passed the Enabling Act on 23 March, transforming Hitler's government into a de facto legal dictatorship, and that they would not be able to proceed to Berlin. Later on, they heard that their cottage had been raided by the Nazis and Einstein's personal sailboat confiscated. Upon landing in Antwerp, Belgium on 28 March, Einstein immediately went to the German consulate and surrendered his passport, formally renouncing his German citizenship. The Nazis later sold his boat and converted his cottage into a Hitler Youth camp.\\n\\nRefugee status\\nIn April 1933, Einstein discovered that the new German government had passed laws barring Jews from holding any official positions, including teaching at universities. Historian Gerald Holton describes how, with \"virtually no audible protest being raised by their colleagues\", thousands of Jewish scientists were suddenly forced to give up their university positions and their names were removed from the rolls of institutions where they were employed.A month later, Einstein's works were among those targeted by the German Student Union in the Nazi book burnings, with Nazi propaganda minister Joseph Goebbels proclaiming, \"Jewish intellectualism is dead.\" One German magazine included him in a list of enemies of the German regime with the phrase, \"not yet hanged\", offering a $5,000 bounty on his head. In a subsequent letter to physicist and friend Max Born, who had already emigrated from Germany to England, Einstein wrote, \"... I must confess that the degree of their brutality and cowardice came as something of a surprise.\" After moving to the US, he described the book burnings as a \"spontaneous emotional outburst\" by those who \"shun popular enlightenment\", and \"more than anything else in the world, fear the influence of men of intellectual independence\".Einstein was now without a permanent home, unsure where he would live and work, and equally worried about the fate of countless other scientists still in Germany. Aided by the Academic Assistance Council, founded in April 1933 by British Liberal politician William Beveridge to help academics escape Nazi persecution, Einstein was able to leave Germany. He rented a house in De Haan, Belgium, where he lived for a few months. In late July 1933, he visited England for about six weeks at the invitation of the British Member of Parliament Commander Oliver Locker-Lampson, who had become friends with him in the preceding years. Locker-Lampson invited him to stay near his Cromer home in a secluded wooden cabin on Roughton Heath in the Parish of Roughton, Norfolk. To protect Einstein, Locker-Lampson had two bodyguards watch over him; a photo of them carrying shotguns and guarding Einstein was published in the Daily Herald on 24 July 1933.Locker-Lampson took Einstein to meet Winston Churchill at his home, and later, Austen Chamberlain and former Prime Minister Lloyd George. Einstein asked them to help bring Jewish scientists out of Germany. British historian Martin Gilbert notes that Churchill responded immediately, and sent his friend, physicist Frederick Lindemann, to Germany to seek out Jewish scientists and place them in British universities. Churchill later observed that as a result of Germany having driven the Jews out, they had lowered their \"technical standards\" and put the Allies' technology ahead of theirs.Einstein later contacted leaders of other nations, including Turkey's Prime Minister, \u0130smet \u0130n\u00f6n\u00fc, to whom he wrote in September 1933 requesting placement of unemployed German-Jewish scientists. As a result of Einstein's letter, Jewish invitees to Turkey eventually totaled over \"1,000 saved individuals\".Locker-Lampson also submitted a bill to parliament to extend British citizenship to Einstein, during which period Einstein made a number of public appearances describing the crisis brewing in Europe. In one of his speeches he denounced Germany's treatment of Jews, while at the same time he introduced a bill promoting Jewish citizenship in Palestine, as they were being denied citizenship elsewhere. In his speech he described Einstein as a \"citizen of the world\" who should be offered a temporary shelter in the UK. Both bills failed, however, and Einstein then accepted an earlier offer from the Institute for Advanced Study, in Princeton, New Jersey, US, to become a resident scholar.\\n\\nResident scholar at the Institute for Advanced Study\\nOn 3 October 1933, Einstein delivered a speech on the importance of academic freedom before a packed audience at the Royal Albert Hall in London, with The Times reporting he was wildly cheered throughout. Four days later he returned to the US and took up a position at the Institute for Advanced Study, noted for having become a refuge for scientists fleeing Nazi Germany. At the time, most American universities, including Harvard, Princeton and Yale, had minimal or no Jewish faculty or students, as a result of their Jewish quotas, which lasted until the late 1940s.Einstein was still undecided on his future. He had offers from several European universities, including Christ Church, Oxford, where he stayed for three short periods between May 1931 and June 1933 and was offered a five-year research fellowship (called a \"studentship\" at Christ Church), but in 1935, he arrived at the decision to remain permanently in the United States and apply for citizenship.Einstein's affiliation with the Institute for Advanced Study would last until his death in 1955. He was one of the four first selected (along with John von Neumann, Kurt G\u00f6del, and Hermann Weyl) at the new Institute. He soon developed a close friendship with G\u00f6del; the two would take long walks together discussing their work. Bruria Kaufman, his assistant, later became a physicist. During this period, Einstein tried to develop a unified field theory and to refute the accepted interpretation of quantum physics, both unsuccessfully. He lived in Princeton at his home from 1935 onwards. The Albert Einstein House was made a National Historic Landmark in 1976.\\n\\nWorld War II and the Manhattan Project\\nIn 1939, a group of Hungarian scientists that included \u00e9migr\u00e9 physicist Le\u00f3 Szil\u00e1rd attempted to alert Washington to ongoing Nazi atomic bomb research. The group's warnings were discounted. Einstein and Szil\u00e1rd, along with other refugees such as Edward Teller and Eugene Wigner, \"regarded it as their responsibility to alert Americans to the possibility that German scientists might win the race to build an atomic bomb, and to warn that Hitler would be more than willing to resort to such a weapon.\" To make certain the US was aware of the danger, in July 1939, a few months before the beginning of World War II in Europe, Szil\u00e1rd and Wigner visited Einstein to explain the possibility of atomic bombs, which Einstein, a pacifist, said he had never considered. He was asked to lend his support by writing a letter, with Szil\u00e1rd, to President Roosevelt, recommending the US pay attention and engage in its own nuclear weapons research.\\nThe letter is believed to be \"arguably the key stimulus for the U.S. adoption of serious investigations into nuclear weapons on the eve of the U.S. entry into World War II\". In addition to the letter, Einstein used his connections with the Belgian royal family and the Belgian queen mother to get access with a personal envoy to the White House's Oval Office. Some say that as a result of Einstein's letter and his meetings with Roosevelt, the US entered the \"race\" to develop the bomb, drawing on its \"immense material, financial, and scientific resources\" to initiate the Manhattan Project.\\nFor Einstein, \"war was a disease ... [and] he called for resistance to war.\" By signing the letter to Roosevelt, some argue he went against his pacifist principles. In 1954, a year before his death, Einstein said to his old friend, Linus Pauling, \"I made one great mistake in my life\u2014when I signed the letter to President Roosevelt recommending that atom bombs be made; but there was some justification\u2014the danger that the Germans would make them ...\" In 1955, Einstein and ten other intellectuals and scientists, including British philosopher Bertrand Russell, signed a manifesto highlighting the danger of nuclear weapons. In 1960 Einstein was included posthumously as a charter member of the World Academy of Art and Science (WAAS), an organization founded by distinguished scientists and intellectuals who committed themselves to the responsible and ethical advances of science, particularly in light of the development of nuclear weapons.\\n\\nUS citizenship\\nEinstein became an American citizen in 1940. Not long after settling into his career at the Institute for Advanced Study in Princeton, New Jersey, he expressed his appreciation of the meritocracy in American culture compared to Europe. He recognized the \"right of individuals to say and think what they pleased\" without social barriers. As a result, individuals were encouraged, he said, to be more creative, a trait he valued from his early education.Einstein joined the National Association for the Advancement of Colored People (NAACP) in Princeton, where he campaigned for the civil rights of African Americans. He considered racism America's \"worst disease\", seeing it as \"handed down from one generation to the next\". As part of his involvement, he corresponded with civil rights activist W. E. B. Du Bois and was prepared to testify on his behalf during his trial as an alleged foreign agent in 1951. When Einstein offered to be a character witness for Du Bois, the judge decided to drop the case.In 1946, Einstein visited Lincoln University in Pennsylvania, a historically black college, where he was awarded an honorary degree. Lincoln was the first university in the United States to grant college degrees to African Americans; alumni include Langston Hughes and Thurgood Marshall. Einstein gave a speech about racism in America, adding, \"I do not intend to be quiet about it.\" A resident of Princeton recalls that Einstein had once paid the college tuition for a black student. Einstein has said, \"Being a Jew myself, perhaps I can understand and empathize with how black people feel as victims of discrimination\".\\n\\nPersonal views\\nPolitical views\\nIn 1918, Einstein was one of the signatories of the founding proclamation of the German Democratic Party, a liberal party. Later in his life, Einstein's political view was in favor of socialism and critical of capitalism, which he detailed in his essays such as \"Why Socialism?\". His opinions on the Bolsheviks also changed with time. In 1925, he criticized them for not having a \"well-regulated system of government\" and called their rule a \"regime of terror and a tragedy in human history\". He later adopted a more moderated view, criticizing their methods but praising them, which is shown by his 1929 remark on Vladimir Lenin:\\n\\nIn Lenin I honor a man, who in total sacrifice of his own person has committed his entire energy to realizing social justice. I do not find his methods advisable. One thing is certain, however: men like him are the guardians and renewers of mankind's conscience.\\nEinstein offered and was called on to give judgments and opinions on matters often unrelated to theoretical physics or mathematics. He strongly advocated the idea of a democratic global government that would check the power of nation-states in the framework of a world federation. He wrote \"I advocate world government because I am convinced that there is no other possible way of eliminating the most terrible danger in which man has ever found himself.\" The FBI created a secret dossier on Einstein in 1932; by the time of his death, it was 1,427 pages long.Einstein was deeply impressed by Mahatma Gandhi, with whom he corresponded. He described Gandhi as \"a role model for the generations to come\". The initial connection was established on 27 September 1931, when Wilfrid Israel took his Indian guest V. A. Sundaram to meet his friend Einstein at his summer home in the town of Caputh. Sundaram was Gandhi's disciple and special envoy, whom Wilfrid Israel met while visiting India and visiting the Indian leader's home in 1925. During the visit, Einstein wrote a short letter to Gandhi that was delivered to him through his envoy, and Gandhi responded quickly with his own letter. Although in the end Einstein and Gandhi were unable to meet as they had hoped, the direct connection between them was established through Wilfrid Israel.\\n\\nRelationship with Zionism\\nEinstein was a figurehead leader in the establishment of the Hebrew University of Jerusalem, which opened in 1925. Earlier, in 1921, he was asked by the biochemist and president of the World Zionist Organization, Chaim Weizmann, to help raise funds for the planned university. He made suggestions for the creation of an Institute of Agriculture, a Chemical Institute and an Institute of Microbiology in order to fight the various ongoing epidemics such as malaria, which he called an \"evil\" that was undermining a third of the country's development. He also promoted the establishment of an Oriental Studies Institute, to include language courses given in both Hebrew and Arabic.Einstein referred to himself as a member of the Zionist movement and supported the right of Jewish people to return to Palestine, but favored a \u201cfree, bi-national Palestine\u201d in which Jews and Arabs would share sovereignty. In a 1945 letter to Judge Jerome Frank, Einstein wrote, \u201cZionism has also a very good influence on the Jewish people\u2026Jews who have a vivid feeling of Jewish national solidarity are much better equipped to overcome with dignity all the dangers and hardships which we have to face.\u201d He continued, however, \u201cI dislike nationalism very much \u2014 even Jewish nationalism. But our own national solidarity is forced upon us by a hostile world, and not the aggressive feelings which we connect with the word \u2018Nationalism\u2019.\u201d In a 1946 letter to Maurice Dunay, he wrote, \u201cI am in favor of Palestine being developed as a Jewish Homeland, but not as a separate state.\u201dUpon the death of Israeli president Weizmann in November 1952, Prime Minister David Ben-Gurion offered Einstein the largely ceremonial position of President of Israel at the urging of Ezriel Carlebach. The offer was presented by Israel's ambassador in Washington, Abba Eban, who explained that the offer \"embodies the deepest respect which the Jewish people can repose in any of its sons\". Einstein wrote that he was \"deeply moved\", but \"at once saddened and ashamed\" that he could not accept it.\\n\\nReligious and philosophical views\\nEinstein expounded his spiritual outlook in a wide array of writings and interviews. He said he had sympathy for the impersonal pantheistic God of Baruch Spinoza's philosophy. He did not believe in a personal god who concerns himself with fates and actions of human beings, a view which he described as na\u00efve. He clarified, however, that \"I am not an atheist\", preferring to call himself an agnostic, or a \"deeply religious nonbeliever\". When asked if he believed in an afterlife, Einstein replied, \"No. And one life is enough for me.\"Einstein was primarily affiliated with non-religious humanist and Ethical Culture groups in both the UK and US. He served on the advisory board of the First Humanist Society of New York, and was an honorary associate of the Rationalist Association, which publishes New Humanist in Britain. For the 75th anniversary of the New York Society for Ethical Culture, he stated that the idea of Ethical Culture embodied his personal conception of what is most valuable and enduring in religious idealism. He observed, \"Without 'ethical culture' there is no salvation for humanity.\"\\nIn a German-language letter to philosopher Eric Gutkind, dated 3 January 1954, Einstein wrote:The word God is for me nothing more than the expression and product of human weaknesses, the Bible a collection of honorable, but still primitive legends which are nevertheless pretty childish. No interpretation no matter how subtle can (for me) change this. ... For me the Jewish religion like all other religions is an incarnation of the most childish superstitions. And the Jewish people to whom I gladly belong and with whose mentality I have a deep affinity have no different quality for me than all other people. ... I cannot see anything 'chosen' about them.\\nEinstein had been sympathetic toward vegetarianism for a long time. In a letter in 1930 to Hermann Huth, vice-president of the German Vegetarian Federation (Deutsche Vegetarier-Bund), he wrote:Although I have been prevented by outward circumstances from observing a strictly vegetarian diet, I have long been an adherent to the cause in principle. Besides agreeing with the aims of vegetarianism for aesthetic and moral reasons, it is my view that a vegetarian manner of living by its purely physical effect on the human temperament would most beneficially influence the lot of mankind.\\nHe became a vegetarian himself only during the last part of his life. In March 1954 he wrote in a letter: \"So I am living without fats, without meat, without fish, but am feeling quite well this way. It almost seems to me that man was not born to be a carnivore.\"\\n\\nLove of music\\nEinstein developed an appreciation for music at an early age. In his late journals he wrote:\\n\\nIf I were not a physicist, I would probably be a musician. I often think in music. I live my daydreams in music. I see my life in terms of music ... I get most joy in life out of music.\\nHis mother played the piano reasonably well and wanted her son to learn the violin, not only to instill in him a love of music but also to help him assimilate into German culture. According to conductor Leon Botstein, Einstein began playing when he was 5. However, he did not enjoy it at that age.When he turned 13, he discovered the violin sonatas of Mozart, whereupon he became enamored of Mozart's compositions and studied music more willingly. Einstein taught himself to play without \"ever practicing systematically\". He said that \"love is a better teacher than a sense of duty\". At the age of 17, he was heard by a school examiner in Aarau while playing Beethoven's violin sonatas. The examiner stated afterward that his playing was \"remarkable and revealing of 'great insight'\". What struck the examiner, writes Botstein, was that Einstein \"displayed a deep love of the music, a quality that was and remains in short supply. Music possessed an unusual meaning for this student.\"Music took on a pivotal and permanent role in Einstein's life from that period on. Although the idea of becoming a professional musician himself was not on his mind at any time, among those with whom Einstein played chamber music were a few professionals, including Kurt Appelbaum, and he performed for private audiences and friends. Chamber music had also become a regular part of his social life while living in Bern, Z\u00fcrich, and Berlin, where he played with Max Planck and his son, among others. He is sometimes erroneously credited as the editor of the 1937 edition of the K\u00f6chel catalog of Mozart's work; that edition was prepared by Alfred Einstein, who may have been a distant relation.In 1931, while engaged in research at the California Institute of Technology, he visited the Zoellner family conservatory in Los Angeles, where he played some of Beethoven and Mozart's works with members of the Zoellner Quartet. Near the end of his life, when the young Juilliard Quartet visited him in Princeton, he played his violin with them, and the quartet was \"impressed by Einstein's level of coordination and intonation\".\\n\\nDeath\\nOn 17 April 1955, Einstein experienced internal bleeding caused by the rupture of an abdominal aortic aneurysm, which had previously been reinforced surgically by Rudolph Nissen in 1948. He took the draft of a speech he was preparing for a television appearance commemorating the state of Israel's seventh anniversary with him to the hospital, but he did not live to complete it.Einstein refused surgery, saying, \"I want to go when I want. It is tasteless to prolong life artificially. I have done my share; it is time to go. I will do it elegantly.\" He died in the Princeton Hospital early the next morning at the age of 76, having continued to work until near the end.During the autopsy, the pathologist Thomas Stoltz Harvey removed Einstein's brain for preservation without the permission of his family, in the hope that the neuroscience of the future would be able to discover what made Einstein so intelligent. Einstein's remains were cremated in Trenton, New Jersey, and his ashes were scattered at an undisclosed location.In a memorial lecture delivered on 13 December 1965 at UNESCO headquarters, nuclear physicist J. Robert Oppenheimer summarized his impression of Einstein as a person: \"He was almost wholly without sophistication and wholly without worldliness ... There was always with him a wonderful purity at once childlike and profoundly stubborn.\"Einstein bequeathed his personal archives, library, and intellectual assets to the Hebrew University of Jerusalem in Israel.\\n\\nScientific career\\nThroughout his life, Einstein published hundreds of books and articles. He published more than 300 scientific papers and 150 non-scientific ones. On 5 December 2014, universities and archives announced the release of Einstein's papers, comprising more than 30,000 unique documents. Einstein's intellectual achievements and originality have made the word \"Einstein\" synonymous with \"genius\". In addition to the work he did by himself he also collaborated with other scientists on additional projects including the Bose\u2013Einstein statistics, the Einstein refrigerator and others.There is some evidence from Einstein's writings that he collaborated with his first wife, Mileva Mari\u0107. In 13 December 1900, a first article on capillarity signed only under his name was submitted. The decision to publish only under his name seems to have been mutual, but the exact reason is unknown.\\n\\n1905 \u2013 Annus Mirabilis papers\\nThe Annus Mirabilis papers are four articles pertaining to the photoelectric effect (which gave rise to quantum theory), Brownian motion, the special theory of relativity, and E = mc2 that Einstein published in the Annalen der Physik scientific journal in 1905. These four works contributed substantially to the foundation of modern physics and changed views on space, time, and matter. The four papers are:\\n\\nStatistical mechanics\\nThermodynamic fluctuations and statistical physics\\nEinstein's first paper submitted in 1900 to Annalen der Physik was on capillary attraction. It was published in 1901 with the title \"Folgerungen aus den Capillarit\u00e4tserscheinungen\", which translates as \"Conclusions from the capillarity phenomena\". Two papers he published in 1902\u20131903 (thermodynamics) attempted to interpret atomic phenomena from a statistical point of view. These papers were the foundation for the 1905 paper on Brownian motion, which showed that Brownian movement can be construed as firm evidence that molecules exist. His research in 1903 and 1904 was mainly concerned with the effect of finite atomic size on diffusion phenomena.\\n\\nTheory of critical opalescence\\nEinstein returned to the problem of thermodynamic fluctuations, giving a treatment of the density variations in a fluid at its critical point. Ordinarily the density fluctuations are controlled by the second derivative of the free energy with respect to the density. At the critical point, this derivative is zero, leading to large fluctuations. The effect of density fluctuations is that light of all wavelengths is scattered, making the fluid look milky white. Einstein relates this to Rayleigh scattering, which is what happens when the fluctuation size is much smaller than the wavelength, and which explains why the sky is blue. Einstein quantitatively derived critical opalescence from a treatment of density fluctuations, and demonstrated how both the effect and Rayleigh scattering originate from the atomistic constitution of matter.\\n\\nSpecial relativity\\nEinstein's \"Zur Elektrodynamik bewegter K\u00f6rper\" (\"On the Electrodynamics of Moving Bodies\") was received on 30 June 1905 and published 26 September of that same year. It reconciled conflicts between Maxwell's equations (the laws of electricity and magnetism) and the laws of Newtonian mechanics by introducing changes to the laws of mechanics. Observationally, the effects of these changes are most apparent at high speeds (where objects are moving at speeds close to the speed of light). The theory developed in this paper later became known as Einstein's special theory of relativity.\\nThis paper predicted that, when measured in the frame of a relatively moving observer, a clock carried by a moving body would appear to slow down, and the body itself would contract in its direction of motion. This paper also argued that the idea of a luminiferous aether\u2014one of the leading theoretical entities in physics at the time\u2014was superfluous.In his paper on mass\u2013energy equivalence, Einstein produced E = mc2 as a consequence of his special relativity equations. Einstein's 1905 work on relativity remained controversial for many years, but was accepted by leading physicists, starting with Max Planck.Einstein originally framed special relativity in terms of kinematics (the study of moving bodies). In 1908, Hermann Minkowski reinterpreted special relativity in geometric terms as a theory of spacetime. Einstein adopted Minkowski's formalism in his 1915 general theory of relativity.\\n\\nGeneral relativity\\nGeneral relativity and the equivalence principle\\nGeneral relativity (GR) is a theory of gravitation that was developed by Einstein between 1907 and 1915. According to it, the observed gravitational attraction between masses results from the warping of spacetime by those masses. General relativity has developed into an essential tool in modern astrophysics; it provides the foundation for the current understanding of black holes, regions of space where gravitational attraction is so strong that not even light can escape.As Einstein later said, the reason for the development of general relativity was that the preference of inertial motions within special relativity was unsatisfactory, while a theory which from the outset prefers no state of motion (even accelerated ones) should appear more satisfactory. Consequently, in 1907 he published an article on acceleration under special relativity. In that article titled \"On the Relativity Principle and the Conclusions Drawn from It\", he argued that free fall is really inertial motion, and that for a free-falling observer the rules of special relativity must apply. This argument is called the equivalence principle. In the same article, Einstein also predicted the phenomena of gravitational time dilation, gravitational redshift and gravitational lensing.In 1911, Einstein published another article \"On the Influence of Gravitation on the Propagation of Light\" expanding on the 1907 article, in which he estimated the amount of deflection of light by massive bodies. Thus, the theoretical prediction of general relativity could for the first time be tested experimentally.\\n\\nGravitational waves\\nIn 1916, Einstein predicted gravitational waves, ripples in the curvature of spacetime which propagate as waves, traveling outward from the source, transporting energy as gravitational radiation. The existence of gravitational waves is possible under general relativity due to its Lorentz invariance which brings the concept of a finite speed of propagation of the physical interactions of gravity with it. By contrast, gravitational waves cannot exist in the Newtonian theory of gravitation, which postulates that the physical interactions of gravity propagate at infinite speed.\\nThe first, indirect, detection of gravitational waves came in the 1970s through observation of a pair of closely orbiting neutron stars, PSR B1913+16. The explanation for the decay in their orbital period was that they were emitting gravitational waves. Einstein's prediction was confirmed on 11 February 2016, when researchers at LIGO published the first observation of gravitational waves, detected on Earth on 14 September 2015, nearly one hundred years after the prediction.\\n\\nHole argument and Entwurf theory\\nWhile developing general relativity, Einstein became confused about the gauge invariance in the theory. He formulated an argument that led him to conclude that a general relativistic field theory is impossible. He gave up looking for fully generally covariant tensor equations and searched for equations that would be invariant under general linear transformations only.In June 1913, the Entwurf ('draft') theory was the result of these investigations. As its name suggests, it was a sketch of a theory, less elegant and more difficult than general relativity, with the equations of motion supplemented by additional gauge fixing conditions. After more than two years of intensive work, Einstein realized that the hole argument was mistaken and abandoned the theory in November 1915.\\n\\nPhysical cosmology\\nIn 1917, Einstein applied the general theory of relativity to the structure of the universe as a whole. He discovered that the general field equations predicted a universe that was dynamic, either contracting or expanding. As observational evidence for a dynamic universe was lacking at the time, Einstein introduced a new term, the cosmological constant, into the field equations, in order to allow the theory to predict a static universe. The modified field equations predicted a static universe of closed curvature, in accordance with Einstein's understanding of Mach's principle in these years. This model became known as the Einstein World or Einstein's static universe.Following the discovery of the recession of the galaxies by Edwin Hubble in 1929, Einstein abandoned his static model of the universe, and proposed two dynamic models of the cosmos, the Friedmann\u2013Einstein universe of 1931 and the Einstein\u2013de Sitter universe of 1932. In each of these models, Einstein discarded the cosmological constant, claiming that it was \"in any case theoretically unsatisfactory\".In many Einstein biographies, it is claimed that Einstein referred to the cosmological constant in later years as his \"biggest blunder\", based on a letter George Gamow claimed to have received from him. The astrophysicist Mario Livio has cast doubt on this claim.In late 2013, a team led by the Irish physicist Cormac O'Raifeartaigh discovered evidence that, shortly after learning of Hubble's observations of the recession of the galaxies, Einstein considered a steady-state model of the universe. In a hitherto overlooked manuscript, apparently written in early 1931, Einstein explored a model of the expanding universe in which the density of matter remains constant due to a continuous creation of matter, a process that he associated with the cosmological constant. As he stated in the paper, \"In what follows, I would like to draw attention to a solution to equation (1) that can account for Hubbel's [sic] facts, and in which the density is constant over time\" ... \"If one considers a physically bounded volume, particles of matter will be continually leaving it. For the density to remain constant, new particles of matter must be continually formed in the volume from space.\"\\nIt thus appears that Einstein considered a steady-state model of the expanding universe many years before Hoyle, Bondi and Gold. However, Einstein's steady-state model contained a fundamental flaw and he quickly abandoned the idea.\\n\\nEnergy momentum pseudotensor\\nGeneral relativity includes a dynamical spacetime, so it is difficult to see how to identify the conserved energy and momentum. Noether's theorem allows these quantities to be determined from a Lagrangian with translation invariance, but general covariance makes translation invariance into something of a gauge symmetry. The energy and momentum derived within general relativity by Noether's prescriptions do not make a real tensor for this reason.Einstein argued that this is true for a fundamental reason: the gravitational field could be made to vanish by a choice of coordinates. He maintained that the non-covariant energy momentum pseudotensor was, in fact, the best description of the energy momentum distribution in a gravitational field. While the use of non-covariant objects like pseudotensors was criticized by Erwin Schr\u00f6dinger and others, Einstein's approach has been echoed by physicists including Lev Landau and Evgeny Lifshitz.\\n\\nWormholes\\nIn 1935, Einstein collaborated with Nathan Rosen to produce a model of a wormhole, often called Einstein\u2013Rosen bridges. His motivation was to model elementary particles with charge as a solution of gravitational field equations, in line with the program outlined in the paper \"Do Gravitational Fields play an Important Role in the Constitution of the Elementary Particles?\". These solutions cut and pasted Schwarzschild black holes to make a bridge between two patches. Because these solutions included spacetime curvature without the presence of a physical body, Einstein and Rosen suggested that they could provide the beginnings of a theory that avoided the notion of point particles. However, it was later found that Einstein\u2013Rosen bridges are not stable.\\n\\nEinstein\u2013Cartan theory\\nIn order to incorporate spinning point particles into general relativity, the affine connection needed to be generalized to include an antisymmetric part, called the torsion. This modification was made by Einstein and Cartan in the 1920s.\\n\\nEquations of motion\\nIn general relativity, gravitational force is reimagined as curvature of spacetime. A curved path like an orbit is not the result of a force deflecting a body from an ideal straight-line path, but rather the body's attempt to fall freely through a background that is itself curved by the presence of other masses. A remark by John Archibald Wheeler that has become proverbial among physicists summarizes the theory: \"Spacetime tells matter how to move; matter tells spacetime how to curve.\" The Einstein field equations cover the latter aspect of the theory, relating the curvature of spacetime to the distribution of matter and energy. The geodesic equation covers the former aspect, stating that freely falling bodies follow lines that are as straight as possible in a curved spacetime. Einstein regarded this as an \"independent fundamental assumption\" that had to be postulated in addition to the field equations in order to complete the theory. Believing this to be a shortcoming in how general relativity was originally presented, he wished to derive it from the field equations themselves. Since the equations of general relativity are non-linear, a lump of energy made out of pure gravitational fields, like a black hole, would move on a trajectory which is determined by the Einstein field equations themselves, not by a new law. Accordingly, Einstein proposed that the field equations would determine the path of a singular solution, like a black hole, to be a geodesic. Both physicists and philosophers have often repeated the assertion that the geodesic equation can be obtained from applying the field equations to the motion of a gravitational singularity, but this claim remains disputed.\\n\\nOld quantum theory\\nPhotons and energy quanta\\nIn a 1905 paper, Einstein postulated that light itself consists of localized particles (quanta). Einstein's light quanta were nearly universally rejected by all physicists, including Max Planck and Niels Bohr. This idea only became universally accepted in 1919, with Robert Millikan's detailed experiments on the photoelectric effect, and with the measurement of Compton scattering.\\nEinstein concluded that each wave of frequency f is associated with a collection of photons with energy hf each, where h is Planck's constant. He did not say much more, because he was not sure how the particles were related to the wave. But he did suggest that this idea would explain certain experimental results, notably the photoelectric effect.\\n\\nQuantized atomic vibrations\\nIn 1907, Einstein proposed a model of matter where each atom in a lattice structure is an independent harmonic oscillator. In the Einstein model, each atom oscillates independently\u2014a series of equally spaced quantized states for each oscillator. Einstein was aware that getting the frequency of the actual oscillations would be difficult, but he nevertheless proposed this theory because it was a particularly clear demonstration that quantum mechanics could solve the specific heat problem in classical mechanics. Peter Debye refined this model.\\n\\nBose\u2013Einstein statistics\\nIn 1924, Einstein received a description of a statistical model from Indian physicist Satyendra Nath Bose, based on a counting method that assumed that light could be understood as a gas of indistinguishable particles. Einstein noted that Bose's statistics applied to some atoms as well as to the proposed light particles, and submitted his translation of Bose's paper to the Zeitschrift f\u00fcr Physik. Einstein also published his own articles describing the model and its implications, among them the Bose\u2013Einstein condensate phenomenon that some particulates should appear at very low temperatures. It was not until 1995 that the first such condensate was produced experimentally by Eric Allin Cornell and Carl Wieman using ultra-cooling equipment built at the NIST\u2013JILA laboratory at the University of Colorado at Boulder. Bose\u2013Einstein statistics are now used to describe the behaviors of any assembly of bosons. Einstein's sketches for this project may be seen in the Einstein Archive in the library of the Leiden University.\\n\\nWave\u2013particle duality\\nAlthough the patent office promoted Einstein to Technical Examiner Second Class in 1906, he had not given up on academia. In 1908, he became a Privatdozent at the University of Bern. In \"\u00dcber die Entwicklung unserer Anschauungen \u00fcber das Wesen und die Konstitution der Strahlung\" (\"The Development of our Views on the Composition and Essence of Radiation\"), on the quantization of light, and in an earlier 1909 paper, Einstein showed that Max Planck's energy quanta must have well-defined momenta and act in some respects as independent, point-like particles. This paper introduced the photon concept (although the name photon was introduced later by Gilbert N. Lewis in 1926) and inspired the notion of wave\u2013particle duality in quantum mechanics. Einstein saw this wave\u2013particle duality in radiation as concrete evidence for his conviction that physics needed a new, unified foundation.\\n\\nZero-point energy\\nIn a series of works completed from 1911 to 1913, Planck reformulated his 1900 quantum theory and introduced the idea of zero-point energy in his \"second quantum theory\". Soon, this idea attracted the attention of Einstein and his assistant Otto Stern. Assuming the energy of rotating diatomic molecules contains zero-point energy, they then compared the theoretical specific heat of hydrogen gas with the experimental data. The numbers matched nicely. However, after publishing the findings, they promptly withdrew their support, because they no longer had confidence in the correctness of the idea of zero-point energy.\\n\\nStimulated emission\\nIn 1917, at the height of his work on relativity, Einstein published an article in Physikalische Zeitschrift that proposed the possibility of stimulated emission, the physical process that makes possible the maser and the laser.\\nThis article showed that the statistics of absorption and emission of light would only be consistent with Planck's distribution law if the emission of light into a mode with n photons would be enhanced statistically compared to the emission of light into an empty mode. This paper was enormously influential in the later development of quantum mechanics, because it was the first paper to show that the statistics of atomic transitions had simple laws.\\n\\nMatter waves\\nEinstein discovered Louis de Broglie's work and supported his ideas, which were received skeptically at first. In another major paper from this era, Einstein observed that de Broglie waves could explain the quantization rules of Bohr and Sommerfeld. This paper would inspire Schr\u00f6dinger's work of 1926.\\n\\nQuantum mechanics\\nEinstein's objections to quantum mechanics\\nEinstein played a major role in developing quantum theory, beginning with his 1905 paper on the photoelectric effect. However, he became displeased with modern quantum mechanics as it had evolved after 1925, despite its acceptance by other physicists. He was skeptical that the randomness of quantum mechanics was fundamental rather than the result of determinism, stating that God \"is not playing at dice\". Until the end of his life, he continued to maintain that quantum mechanics was incomplete.\\n\\nBohr versus Einstein\\nThe Bohr\u2013Einstein debates were a series of public disputes about quantum mechanics between Einstein and Niels Bohr, who were two of its founders. Their debates are remembered because of their importance to the philosophy of science. Their debates would influence later interpretations of quantum mechanics.\\n\\nEinstein\u2013Podolsky\u2013Rosen paradox\\nEinstein never fully accepted quantum mechanics. While he recognized that it made correct predictions, he believed a more fundamental description of nature must be possible. Over the years he presented multiple arguments to this effect, but the one he preferred most dated to a debate with Bohr in 1930. Einstein suggested a thought experiment in which two objects are allowed to interact and then moved apart a great distance from each other. The quantum-mechanical description of the two objects is a mathematical entity known as a wavefunction. If the wavefunction that describes the two objects before their interaction is given, then the Schr\u00f6dinger equation provides the wavefunction that describes them after their interaction. But because of what would later be called quantum entanglement, measuring one object would lead to an instantaneous change of the wavefunction describing the other object, no matter how far away it is. Moreover, the choice of which measurement to perform upon the first object would affect what wavefunction could result for the second object. Einstein reasoned that no influence could propagate from the first object to the second instantaneously fast. Indeed, he argued, physics depends on being able to tell one thing apart from another, and such instantaneous influences would call that into question. Because the true \"physical condition\" of the second object could not be immediately altered by an action done to the first, Einstein concluded, the wavefunction could not be that true physical condition, only an incomplete description of it.A more famous version of this argument came in 1935, when Einstein published a paper with Boris Podolsky and Nathan Rosen that laid out what would become known as the EPR paradox. In this thought experiment, two particles interact in such a way that the wavefunction describing them is entangled. Then, no matter how far the two particles were separated, a precise position measurement on one particle would imply the ability to predict, perfectly, the result of measuring the position of the other particle. Likewise, a precise momentum measurement of one particle would result in an equally precise prediction for of the momentum of the other particle, without needing to disturb the other particle in any way. They argued that no action taken on the first particle could instantaneously affect the other, since this would involve information being transmitted faster than light, which is forbidden by the theory of relativity. They invoked a principle, later known as the \"EPR criterion of reality\", positing that: \"If, without in any way disturbing a system, we can predict with certainty (i.e., with probability equal to unity) the value of a physical quantity, then there exists an element of reality corresponding to that quantity.\" From this, they inferred that the second particle must have a definite value of both position and of momentum prior to either quantity being measured. But quantum mechanics considers these two observables incompatible and thus does not associate simultaneous values for both to any system. Einstein, Podolsky, and Rosen therefore concluded that quantum theory does not provide a complete description of reality.In 1964, John Stewart Bell carried the analysis of quantum entanglement much further. He deduced that if measurements are performed independently on the two separated particles of an entangled pair, then the assumption that the outcomes depend upon hidden variables within each half implies a mathematical constraint on how the outcomes on the two measurements are correlated. This constraint would later be called a Bell inequality. Bell then showed that quantum physics predicts correlations that violate this inequality. Consequently, the only way that hidden variables could explain the predictions of quantum physics is if they are \"nonlocal\", which is to say that somehow the two particles are able to interact instantaneously no matter how widely they ever become separated. Bell argued that because an explanation of quantum phenomena in terms of hidden variables would require nonlocality, the EPR paradox \"is resolved in the way which Einstein would have liked least\".Despite this, and although Einstein personally found the argument in the EPR paper overly complicated, that paper became among the most influential papers published in Physical Review. It is considered a centerpiece of the development of quantum information theory.\\n\\nUnified field theory\\nEncouraged by his success with general relativity, Einstein sought an even more ambitious geometrical theory that would treat gravitation and electromagnetism as aspects of a single entity. In 1950, he described his unified field theory in a Scientific American article titled \"On the Generalized Theory of Gravitation\". His attempt to find the most fundamental laws of nature won him praise but not success: a particularly conspicuous blemish of his model was that it did not accommodate the strong and weak nuclear forces, neither of which was well understood until many years after his death. Although most researchers now believe that Einstein's approach to unifying physics was mistaken, his goal of a theory of everything is one to which his successors still aspire.\\n\\nOther investigations\\nEinstein conducted other investigations that were unsuccessful and abandoned. These pertain to force, superconductivity, and other research.\\n\\nCollaboration with other scientists\\nIn addition to longtime collaborators Leopold Infeld, Nathan Rosen, Peter Bergmann and others, Einstein also had some one-shot collaborations with various scientists.\\n\\nEinstein\u2013de Haas experiment\\nIn 1908, Owen Willans Richardson predicted that a change in the magnetic moment of a free body will cause this body to rotate. This effect is a consequence of the conservation of angular momentum and is strong enough to be observable in ferromagnetic materials. Einstein and Wander Johannes de Haas published two papers in 1915 claiming the first experimental observation of the effect. Measurements of this kind demonstrate that the phenomenon of magnetization is caused by the alignment (polarization) of the angular momenta of the electrons in the material along the axis of magnetization. These measurements also allow the separation of the two contributions to the magnetization: that which is associated with the spin and with the orbital motion of the electrons.\\n\\nEinstein as an inventor\\nIn 1926, Einstein and his former student Le\u00f3 Szil\u00e1rd co-invented (and in 1930, patented) the Einstein refrigerator. This absorption refrigerator was then revolutionary for having no moving parts and using only heat as an input. On 11 November 1930, U.S. patent 1,781,541 was awarded to Einstein and Le\u00f3 Szil\u00e1rd for the refrigerator. Their invention was not immediately put into commercial production, but the most promising of their patents were acquired by the Swedish company Electrolux.Einstein also invented an electromagnetic pump, sound reproduction device, and several other household devices.\\n\\nNon-scientific legacy\\nWhile traveling, Einstein wrote daily to his wife Elsa and adopted stepdaughters Margot and Ilse. The letters were included in the papers bequeathed to the Hebrew University of Jerusalem. Margot Einstein permitted the personal letters to be made available to the public, but requested that it not be done until twenty years after her death (she died in 1986). Barbara Wolff, of the Hebrew University's Albert Einstein Archives, told the BBC that there are about 3,500 pages of private correspondence written between 1912 and 1955.Einstein's right of publicity was litigated in 2015 in a federal district court in California. Although the court initially held that the right had expired, that ruling was immediately appealed, and the decision was later vacated in its entirety. The underlying claims between the parties in that lawsuit were ultimately settled. The right is enforceable, and the Hebrew University of Jerusalem is the exclusive representative of that right. Corbis, successor to The Roger Richman Agency, licenses the use of his name and associated imagery, as agent for the university.Mount Einstein in the Chugach Mountains of Alaska was named in 1955.\\nMount Einstein in New Zealand's Paparoa Range was named after him in 1970 by the Department of Scientific and Industrial Research.\\n\\nIn popular culture\\nEinstein became one of the most famous scientific celebrities after the confirmation of his general theory of relativity in 1919. Although most of the public had little understanding of his work, he was widely recognized and admired. In the period before World War II, The New Yorker published a vignette in their \"The Talk of the Town\" feature saying that Einstein was so well known in America that he would be stopped on the street by people wanting him to explain \"that theory\". Eventually he came to cope with unwanted enquirers by pretending to be someone else: \"Pardon me, sorry! Always I am mistaken for Professor Einstein.\"Einstein has been the subject of or inspiration for many novels, films, plays, and works of music. He is a favorite model for depictions of absent-minded professors; his expressive face and distinctive hairstyle have been widely copied and exaggerated. Time magazine's Frederic Golden wrote that Einstein was \"a cartoonist's dream come true\".Many popular quotations are often misattributed to him. For example, it is often claimed, erroneously, that he said, \"The definition of insanity is doing the same thing over and over and expecting different results.\"\\n\\nAwards and honors\\nEinstein received numerous awards and honors, and in 1922, he was awarded the 1921 Nobel Prize in Physics \"for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect\". None of the nominations in 1921 met the criteria set by Alfred Nobel, so the 1921 prize was carried forward and awarded to Einstein in 1922.Einsteinium, a synthetic chemical element, was named in his honor in 1955, a few months after his death.\\n\\nPublications\\nScientific\\nOthers\\nSee also\\nNotes\\nReferences\\nWorks cited\\nFurther reading\\nExternal links\\n\\nAlbert Einstein at Curlie\\nWorks by Albert Einstein at Project Gutenberg\\nWorks by or about Albert Einstein at Internet Archive\\nWorks by Albert Einstein at LibriVox (public domain audiobooks) \\nEinstein's Personal Correspondence: Religion, Politics, The Holocaust, and Philosophy Shapell Manuscript Foundation\\nFederal Bureau of Investigation file on Albert Einstein\\nEinstein and his love of music, Physics World\\nAlbert Einstein on Nobelprize.org  including the Nobel Lecture 11 July 1923 Fundamental ideas and problems of the theory of relativity\\nAlbert Einstein Archives Online (80,000+ Documents) Archived 11 August 2011 at the Wayback Machine (MSNBC, 19 March 2012)\\nEinstein's declaration of intention for American citizenship on the World Digital Library\\nAlbert Einstein Collection at Brandeis University\\nThe Collected Papers of Albert Einstein \"Digital Einstein\" at Princeton University\\nNewspaper clippings about Albert Einstein in the 20th Century Press Archives of the ZBW\\nHome page of Albert Einstein at The Institute for Advanced Study\\nAlbert \u2013 The Digital Repository of the IAS, which contains many digitized original documents and photographs\\nAlbert Einstein at IMDb"}
{"article_name": "Climate_change", "link": "https://en.wikipedia.org/wiki/Climate_change", "text_content": "In common usage, climate change describes global warming\u2014the ongoing increase in global average temperature\u2014and its effects on Earth's climate system. Climate change in a broader sense also includes previous long-term changes to Earth's climate. The current rise in global average temperature is more rapid than previous changes, and is primarily caused by humans burning fossil fuels. Fossil fuel use, deforestation, and some agricultural and industrial practices add to greenhouse gases, notably carbon dioxide and methane. Greenhouse gases absorb some of the heat that the Earth radiates after it warms from sunlight. Larger amounts of these gases trap more heat in Earth's lower atmosphere, causing global warming.\\nClimate change has an increasing impact on the environment. Deserts are expanding, while heat waves and wildfires are becoming more common. Amplified warming in the Arctic has contributed to melting permafrost, glacial retreat and sea ice loss. Higher temperatures are also causing more intense storms, droughts, and other weather extremes. Rapid environmental change in mountains, coral reefs, and the Arctic is forcing many species to relocate or become extinct. Even if efforts to minimise future warming are successful, some effects will continue for centuries. These include ocean heating, ocean acidification and sea level rise.Climate change threatens people with increased flooding, extreme heat, increased food and water scarcity, more disease, and economic loss. Human migration and conflict can also be a result. The World Health Organization (WHO) calls climate change the greatest threat to global health in the 21st century. Societies and ecosystems will experience more severe risks without action to limit warming. Adapting to climate change through efforts like flood control measures or drought-resistant crops partially reduces climate change risks, although some limits to adaptation have already been reached. Poorer communities are responsible for a small share of global emissions, yet have the least ability to adapt and are most vulnerable to climate change.\\n\\nMany climate change impacts have been felt in recent years, with 2023 the warmest on record at +1.48 \u00b0C (2.66 \u00b0F). Additional warming will increase these impacts and can trigger tipping points, such as the melting of the Greenland ice sheet. Under the 2015 Paris Agreement, nations collectively agreed to keep warming \"well under 2 \u00b0C\". However, with pledges made under the Agreement, global warming would still reach about 2.7 \u00b0C (4.9 \u00b0F) by the end of the century. Limiting warming to 1.5 \u00b0C will require halving emissions by 2030 and achieving net-zero emissions by 2050.Strategies to phase out fossil fuels involve conserving energy, generating electricity cleanly, and using electricity to power transportation, heat buildings, and operate industrial facilities. The electricity supply can be made cleaner and more plentiful by vastly increasing deployment of wind, and solar power, alongside other forms of renewable energy and nuclear power. Carbon can also be removed from the atmosphere, for instance by increasing forest cover and farming with methods that capture carbon in soil.\\n\\nTerminology\\nBefore the 1980s, when it was unclear whether the warming effect of increased greenhouse gases was stronger than the cooling effect of airborne particulates in air pollution, scientists used the term inadvertent climate modification to refer to human impacts on the climate.In the 1980s, the terms global warming and climate change became more common. Though the two terms are sometimes used interchangeably, scientifically, global warming refers only to increased surface warming, while climate change describes the totality of changes to Earth's climate system. Global warming\u2014used as early as 1975\u2014became the more popular term after NASA climate scientist James Hansen used it in his 1988 testimony in the U.S. Senate. Since the 2000s, climate change has increased in usage. Climate change can also refer more broadly to both human-caused changes or natural changes throughout Earth's history.Various scientists, politicians and media now use the terms climate crisis or climate emergency to talk about climate change, and global heating instead of global warming.\\n\\nGlobal temperature rise\\nTemperature records prior to global warming\\nHuman beings evolved over the last few million years in a climate that cycled through ice ages, with global average temperature ranging between current levels and 5\u20136 \u00b0C colder than today. The temperature record prior to human evolution includes hotter temperatures and occasional abrupt changes, such as the Paleocene\u2013Eocene Thermal Maximum 55.5 million years ago.Historical patterns of warming and cooling, like the Medieval Warm Period and the Little Ice Age, did not occur at the same time across different regions. Temperatures may have reached as high as those of the late 20th century in a limited set of regions. Climate information for that period comes from climate proxies, such as trees and ice cores.\\n\\nWarming since the Industrial Revolution\\nThermometer records began to provide global coverage around 1850. There was little net warming between the 18th century and 1970, as aerosols offset the warming impact of greenhouse gas emissions. Increasing accumulation of greenhouse gases coupled with aerosol polution controls caused temperatures to then begin markedly increasing.Multiple independent instrumental datasets show that the climate system is warming in recent years. A so-called \"global warming hiatus\" from 1998 to 2013 when warming was relatively slow was likely caused by negative phases of the Pacific Decadal Oscillation (PDO) and Atlantic Multidecadal Oscillation (AMO). The 2013-2022 decade warmed to an average 1.15 \u00b0C [1.00\u20131.25 \u00b0C] compared to the pre-industrial baseline (1850\u20131900). Surface temperatures are rising by about 0.2 \u00b0C per decade.Evidence of warming from air temperature measurements is reinforced by a wide range of other observations. For example, changes to the natural water cycle have been predicted and observed, such as an increase in the frequency and intensity of heavy precipitation, melting of snow and land ice, and increased atmospheric humidity. Flora and fauna are also behaving in a manner consistent with warming; for instance, plants are flowering earlier in spring. Another key indicator is the cooling of the upper atmosphere, which demonstrates that greenhouse gases are trapping heat near the Earth's surface and preventing it from radiating into space.\\n\\nDifferences by region\\nDifferent regions of the world warm at different rates. The pattern is independent of where greenhouse gases are emitted, because the gases persist long enough to diffuse across the planet. Since the pre-industrial period, the average surface temperature over land regions has increased almost twice as fast as the global-average surface temperature. This is because of the larger heat capacity of oceans, and because oceans lose more heat by evaporation. The thermal energy in the global climate system has grown with only brief pauses since at least 1970, and over 90% of this extra energy has been stored in the ocean. The rest has heated the atmosphere, melted ice, and warmed the continents.The Northern Hemisphere and the North Pole have warmed much faster than the South Pole and Southern Hemisphere. The Northern Hemisphere not only has much more land, but also more seasonal snow cover and sea ice. As these surfaces flip from reflecting a lot of light to being dark after the ice has melted, they start absorbing more heat. Local black carbon deposits on snow and ice also contribute to Arctic warming. Arctic temperatures are increasing at over twice the rate of the rest of the world. Melting of glaciers and ice sheets in the Arctic disrupts ocean circulation, including a weakened Gulf Stream, further changing the climate.\\n\\nFuture global temperatures\\nThe IPCC Sixth Assessment Report uses a 20 year temperature average to define global warming temperature rise, and it expects that 1.5 \u00b0C limit to be exceeded in the early 2030s. As annual temperatures fluctuate, the World Meteorological Organization estimates that there is a 66% chance that global temperature will exceed a rise of 1.5 \u00b0C for at least one year between 2023 and 2027. By the end of the 21st century, the IPCC projects that global warming is very likely to reach 1.0 \u00b0C to 1.8 \u00b0C under a very low GHG emissions scenario, 2.1 \u00b0C to 3.5 \u00b0C under an intermediate emissions scenario, or 3.3 \u00b0C to 5.7 \u00b0C under a very high GHG emissions scenario.The remaining carbon budget for staying beneath certain temperature increases is determined by modelling the carbon cycle and climate sensitivity to greenhouse gases. According to the IPCC, global warming can be kept below 1.5 \u00b0C with a two-thirds chance if emissions after 2018 do not exceed 420 or 570 gigatonnes of CO2. This corresponds to 10 to 13 years of current emissions. There are high uncertainties about the budget. For instance, it may be 100 gigatonnes of CO2 smaller due to methane release from permafrost and wetlands. However, it is clear that fossil fuel resources are too abundant for shortages to be relied on to limit carbon emissions in the 21st century.\\n\\nCauses of recent global temperature rise\\nThe climate system experiences various cycles on its own which can last for years, decades or even centuries. For example, El Ni\u00f1o events cause short-term spikes in surface temperature while La Ni\u00f1a events cause short term cooling. Their relative frequency can affect global temperature trends on a decadal timescale. Other changes are caused by an imbalance of energy from external forcings. Examples of these include changes in the concentrations of greenhouse gases, solar luminosity, volcanic eruptions, and variations in the Earth's orbit around the Sun.To determine the human contribution to climate change, unique \"fingerprints\" for all potential causes are developed and compared with both observed patterns and known internal climate variability. For example, solar forcing\u2014whose fingerprint involves warming the entire atmosphere\u2014is ruled out because only the lower atmosphere has warmed. Atmospheric aerosols produce a smaller, cooling effect. Other drivers, such as changes in albedo, are less impactful.\\n\\nGreenhouse gases\\nGreenhouse gases are transparent to sunlight, and thus allow it to pass through the atmosphere to heat the Earth's surface. The Earth radiates it as heat, and greenhouse gases absorb a portion of it. This absorption slows the rate at which heat escapes into space, trapping heat near the Earth's surface and warming it over time.While water vapour (\u224850%) and clouds (\u224825%) are the biggest contributors to the greenhouse effect, they primarily change as a function of temperature and are therefore mostly considered to be feedbacks that change climate sensitivity. On the other hand, concentrations of gases such as CO2 (\u224820%), tropospheric ozone, CFCs and nitrous oxide are added or removed independently from temperature, and are therefore considered to be external forcings that change global temperatures.Before the Industrial Revolution, naturally-occurring amounts of greenhouse gases caused the air near the surface to be about 33 \u00b0C warmer than it would have been in their absence. Human activity since the Industrial Revolution, mainly extracting and burning fossil fuels (coal, oil, and natural gas), has increased the amount of greenhouse gases in the atmosphere, resulting in a radiative imbalance. In 2019, the concentrations of CO2 and methane had increased by about 48% and 160%, respectively, since 1750. These CO2 levels are higher than they have been at any time during the last 2 million years. Concentrations of methane are far higher than they were over the last 800,000 years.\\nGlobal anthropogenic greenhouse gas emissions in 2019 were equivalent to 59 billion tonnes of CO2. Of these emissions, 75% was CO2, 18% was methane, 4% was nitrous oxide, and 2% was fluorinated gases. CO2 emissions primarily come from burning fossil fuels to provide energy for transport, manufacturing, heating, and electricity. Additional CO2 emissions come from deforestation and industrial processes, which include the CO2 released by the chemical reactions for making cement, steel, aluminum, and fertiliser. Methane emissions come from livestock, manure, rice cultivation, landfills, wastewater, and coal mining, as well as oil and gas extraction. Nitrous oxide emissions largely come from the microbial decomposition of fertiliser.The Earth's surface absorbs CO2 as part of the carbon cycle. Despite the contribution of deforestation to greenhouse gas emissions, the Earth's land surface, particularly its forests, remain a significant carbon sink for CO2. Land-surface sink processes, such as carbon fixation in the soil and photosynthesis, remove about 29% of annual global CO2 emissions. The ocean also serves as a significant carbon sink via a two-step process. First, CO2 dissolves in the surface water. Afterwards, the ocean's overturning circulation distributes it deep into the ocean's interior, where it accumulates over time as part of the carbon cycle. Over the last two decades, the world's oceans have absorbed 20 to 30% of emitted CO2.\\n\\nAerosols and clouds\\nAir pollution, in the form of aerosols, affects the climate on a large scale. Aerosols scatter and absorb solar radiation. From 1961 to 1990, a gradual reduction in the amount of sunlight reaching the Earth's surface was observed. This phenomenon is popularly known as global dimming, and is primarily attributed to sulfate aerosols produced by the combustion of fossil fuels with heavy sulfur concentrations like coal and bunker fuel. Smaller contributions come from black carbon, organic carbon from combustion of fossil fuels and biofuels, and from anthropogenic dust. Globally, aerosols have been declining since 1990 due to pollution controls, meaning that they no longer mask greenhouse gas warming as much.Aerosols also have indirect effects on the Earth's energy budget. Sulfate aerosols act as cloud condensation nuclei and lead to clouds that have more and smaller cloud droplets. These clouds reflect solar radiation more efficiently than clouds with fewer and larger droplets. They also reduce the growth of raindrops, which makes clouds more reflective to incoming sunlight. Indirect effects of aerosols are the largest uncertainty in radiative forcing.While aerosols typically limit global warming by reflecting sunlight, black carbon in soot that falls on snow or ice can contribute to global warming. Not only does this increase the absorption of sunlight, it also increases melting and sea-level rise. Limiting new black carbon deposits in the Arctic could reduce global warming by 0.2 \u00b0C by 2050.\\n\\nLand surface changes\\nHumans change the Earth's surface mainly to create more agricultural land. Today, agriculture takes up 34% of Earth's land area, while 26% is forests, and 30% is uninhabitable (glaciers, deserts, etc.). The amount of forested land continues to decrease, which is the main land use change that causes global warming. Deforestation releases CO2 contained in trees when they are destroyed, plus it prevents those trees from absorbing more CO2. The main causes of deforestation are: permanent land-use change from forest to agricultural land producing products such as beef and palm oil (27%), logging to produce forestry/forest products (26%), short term shifting cultivation (24%), and wildfires (23%).The type of vegetation in a region affects the local temperature. It impacts how much of the sunlight gets reflected back into space (albedo), and how much heat is lost by evaporation. For instance, the change from a dark forest to grassland makes the surface lighter, causing it to reflect more sunlight. Deforestation can also affect temperatures by modifying the release of chemical compounds that influence clouds, and by changing wind patterns. In tropic and temperate areas the net effect is to produce significant warming, while at latitudes closer to the poles a gain of albedo (as forest is replaced by snow cover) leads to a cooling effect. Globally, these effects are estimated to have led to a slight cooling, dominated by an increase in surface albedo. According to FAO, forest degradation aggravates the impacts of climate change as it reduces the carbon sequestration abilities of forests. Indeed, among their many benefits, forests also have the potential to reduce the impact of high temperatures.\\n\\nSolar and volcanic activity\\nAs the Sun is the Earth's primary energy source, changes in incoming sunlight directly affect the climate system. Solar irradiance has been measured directly by satellites, and indirect measurements are available from the early 1600s onwards. Since 1880, there has been no upward trend in the amount of the Sun's energy reaching the Earth.Explosive volcanic eruptions represent the largest natural forcing over the industrial era. Eruptions can produce gases, dust and ash that partially block sunlight and reduce temperatures, or they can produce water vapor, which adds to greenhouse gases and increases temperatures. Gases in the stratosphere can cause atmospheric changes that last a couple years, with the temperature signal lasting about twice as long. In the industrial era, volcanic activity has had negligible impacts on global temperature trends. Present-day volcanic CO2 emissions are equivalent to less than 1% of current anthropogenic CO2 emissions.Physical climate models are unable to reproduce the rapid warming observed in recent decades when taking into account only variations in solar output and volcanic activity. Further evidence for greenhouse gases causing global warming comes from measurements that show a warming of the lower atmosphere (the troposphere), coupled with a cooling of the upper atmosphere (the stratosphere). If solar variations were responsible for the observed warming, the troposphere and stratosphere would both warm.\\n\\nClimate change feedback\\nThe response of the climate system to an initial forcing is modified by feedbacks: increased by \"self-reinforcing\" or \"positive\" feedbacks and reduced by \"balancing\" or \"negative\" feedbacks. The main reinforcing feedbacks are the water-vapour feedback, the ice\u2013albedo feedback, and the net effect of clouds. The primary balancing mechanism is radiative cooling, as Earth's surface gives off more heat to space in response to rising temperature. In addition to temperature feedbacks, there are feedbacks in the carbon cycle, such as the fertilizing effect of CO2 on plant growth.Uncertainty over feedbacks, particularly cloud cover, is the major reason why different climate models project different magnitudes of warming for a given amount of emissions. As air warms, it can hold more moisture. Water vapour, as a potent greenhouse gas, holds heat in the atmosphere. If cloud cover increases, more sunlight will be reflected back into space, cooling the planet. If clouds become higher and thinner, they act as an insulator, reflecting heat from below back downwards and warming the planet.Another major feedback is the reduction of snow cover and sea ice in the Arctic, which reduces the reflectivity of the Earth's surface.\\nMore of the Sun's energy is now absorbed in these regions, contributing to amplification of Arctic temperature changes. Arctic amplification is also melting permafrost, which releases methane and CO2 into the atmosphere. Climate change can also cause methane releases from wetlands, marine systems, and freshwater systems. Overall, climate feedbacks are expected to become increasingly positive.Around half of human-caused CO2 emissions have been absorbed by land plants and by the oceans. Climate change increases droughts and heat waves that inhibit plant growth, which makes it uncertain whether this carbon sink will continue to grow. Soils contain large quantities of carbon and may release some when they heat up. As more CO2 and heat are absorbed by the ocean, it acidifies, its circulation changes and phytoplankton takes up less carbon, decreasing the rate at which the ocean absorbs atmospheric carbon. Overall, at higher CO2 concentrations the Earth will absorb a reduced fraction of our emissions.\\n\\nModelling\\nA climate model is a representation of the physical, chemical and biological processes that affect the climate system. Models include natural processes like changes in the Earth's orbit, historical changes in the Sun's activity, and volcanic forcing. Models are used to estimate the degree of warming future emissions will cause when accounting for the strength of climate feedbacks,. Models also predict the circulation of the oceans, the annual cycle of the seasons, and the flows of carbon between the land surface and the atmosphere.The physical realism of models is tested by examining their ability to simulate contemporary or past climates. Past models have underestimated the rate of Arctic shrinkage and underestimated the rate of precipitation increase. Sea level rise since 1990 was underestimated in older models, but more recent models agree well with observations. The 2017 United States-published National Climate Assessment notes that \"climate models may still be underestimating or missing relevant feedback processes\". Additionally, climate models may be unable to adequately predict short-term regional climatic shifts.A subset of climate models add societal factors to a physical climate model. These models simulate how population, economic growth, and energy use affect\u2014and interact with\u2014the physical climate. With this information, these models can produce scenarios of future greenhouse gas emissions. This is then used as input for physical climate models and carbon cycle models to predict how atmospheric concentrations of greenhouse gases might change. Depending on the socioeconomic scenario and the mitigation scenario, models produce atmospheric CO2 concentrations that range widely between 380 and 1400 ppm.\\n\\nImpacts\\nEnvironmental effects\\nThe environmental effects of climate change are broad and far-reaching, affecting oceans, ice, and weather. Changes may occur gradually or rapidly. Evidence for these effects comes from studying climate change in the past, from modelling, and from modern observations. Since the 1950s, droughts and heat waves have appeared simultaneously with increasing frequency. Extremely wet or dry events within the monsoon period have increased in India and East Asia. Monsoonal precipitation over the Northern Hemisphere has increased since 1980. The rainfall rate and intensity of hurricanes and typhoons is likely increasing, and the geographic range likely expanding poleward in response to climate warming. Frequency of tropical cyclones has not increased as a result of climate change.\\nGlobal sea level is rising as a consequence of glacial melt, melt of the Greenland ice sheets and Antarctica, and thermal expansion. Between 1993 and 2020, the rise increased over time, averaging 3.3 \u00b1 0.3 mm per year. Over the 21st century, the IPCC projects that in a very high emissions scenario the sea level could rise by 61\u2013110 cm. Increased ocean warmth is undermining and threatening to unplug Antarctic glacier outlets, risking a large melt of the ice sheet and the possibility of a 2-meter sea level rise by 2100 under high emissions.Climate change has led to decades of shrinking and thinning of the Arctic sea ice. While ice-free summers are expected to be rare at 1.5 \u00b0C degrees of warming, they are set to occur once every three to ten years at a warming level of 2 \u00b0C. Higher atmospheric CO2 concentrations have led to changes in ocean chemistry. An increase in dissolved CO2 is causing oceans to acidify. In addition, oxygen levels are decreasing as oxygen is less soluble in warmer water. Dead zones in the ocean, regions with very little oxygen, are expanding too.\\n\\nTipping points and long-term impacts\\nGreater degrees of global warming increase the risk of passing through 'tipping points'\u2014thresholds beyond which certain impacts can no longer be avoided even if temperatures are reduced. An example is the collapse of West Antarctic and Greenland ice sheets, where a temperature rise of 1.5 to 2 \u00b0C may commit the ice sheets to melt, although the time scale of melt is uncertain and depends on future warming. Some large-scale changes could occur over a short time period, such as a shutdown of certain ocean currents like the Atlantic meridional overturning circulation (AMOC). Tipping points can also include irreversible damage to ecosystems like the Amazon rainforest and coral reefs.The long-term effects of climate change on oceans include further ice melt, ocean warming, sea level rise, and ocean acidification. The timescale of long term impacts are centuries to millennia due to CO2's long atmospheric lifetime. When net emissions stabilize surface air temperatures will also stabilize, but oceans and ice caps will continue to absorb excess heat from the atmosphere. The result is an estimated total sea level rise of 2.3 metres per degree Celsius (4.2 ft/\u00b0F) after 2000 years. Oceanic CO2 uptake is slow enough that ocean acidification will also continue for hundreds to thousands of years.\\n\\nNature and wildlife\\nRecent warming has driven many terrestrial and freshwater species poleward and towards higher altitudes. Higher atmospheric CO2 levels and an extended growing season have resulted in global greening. However, heatwaves and drought have reduced ecosystem productivity in some regions. The future balance of these opposing effects is unclear. Climate change has contributed to the expansion of drier climate zones, such as the expansion of deserts in the subtropics. The size and speed of global warming is making abrupt changes in ecosystems more likely. Overall, it is expected that climate change will result in the extinction of many species.The oceans have heated more slowly than the land, but plants and animals in the ocean have migrated towards the colder poles faster than species on land. Just as on land, heat waves in the ocean occur more frequently due to climate change, harming a wide range of organisms such as corals, kelp, and seabirds. Ocean acidification makes it harder for marine calcifying organisms such as mussels, barnacles and corals to produce shells and skeletons; and heatwaves have bleached coral reefs. Harmful algal blooms enhanced by climate change and eutrophication lower oxygen levels, disrupt food webs and cause great loss of marine life. Coastal ecosystems are under particular stress. Almost half of global wetlands have disappeared due to climate change and other human impacts.\\n\\nHumans\\nThe effects of climate change are impacting humans everywhere in the world. Impacts can be observed on all continents and ocean regions, with low-latitude, less developed areas facing the greatest risk. Continued warming has potentially \"severe, pervasive and irreversible impacts\" for people and ecosystems. The risks are unevenly distributed, but are generally greater for disadvantaged people in developing and developed countries.\\n\\nFood and health\\nThe WHO calls climate change the greatest threat to global health in the 21st century. Extreme weather leads to injury and loss of life, and crop failures to malnutrition. Various infectious diseases are more easily transmitted in a warmer climate, such as dengue fever and malaria. Young children are the most vulnerable to food shortages. Both children and older people are vulnerable to extreme heat. The World Health Organization (WHO) has estimated that between 2030 and 2050, climate change would cause around 250,000 additional deaths per year. They assessed deaths from heat exposure in elderly people, increases in diarrhea, malaria, dengue, coastal flooding, and childhood malnutrition. Over 500,000 more adult deaths are projected yearly by 2050 due to reductions in food availability and quality. By 2100, 50% to 75% of the global population may face climate conditions that are life-threatening due to combined effects of extreme heat and humidity.Climate change is affecting food security. It has caused reduction in global yields of maize, wheat, and soybeans between 1981 and 2010. Future warming could further reduce global yields of major crops. Crop production will probably be negatively affected in low-latitude countries, while effects at northern latitudes may be positive or negative. Up to an additional 183 million people worldwide, particularly those with lower incomes, are at risk of hunger as a consequence of these impacts. Climate change also impacts fish populations. Globally, less will be available to be fished. Regions dependent on glacier water, regions that are already dry, and small islands have a higher risk of water stress due to climate change.\\n\\nInequality\\nEconomic damages due to climate change may be severe and there is a chance of disastrous consequences. Climate change has likely already increased global economic inequality, and this trend is projected to continue. Severe impacts are expected in South-East Asia and sub-Saharan Africa, where most of the local inhabitants are dependent upon natural and agricultural resources. The World Bank estimates that climate change could drive over 120 million people into poverty by 2030.Inequalities based on wealth and social status have worsened due to climate change. Major difficulties in mitigating, adapting, and recovering to climate shocks are faced by marginalized people who have less control over resources. Indigenous people, who are subsistent on their land and ecosystems, will face endangerment to their wellness and lifestyles due to climate change. An expert elicitation concluded that the role of climate change in armed conflict has been small compared to factors such as socio-economic inequality and state capabilities.While women are not inherently more at risk from climate change and shocks, limits on women's resources and discriminatory gender norms constrain their adaptive capacity and resilience. For example, women's work burdens, including hours worked in agriculture, tend to decline less than men's during climate shocks such as heat stress.\\n\\nClimate migration\\nLow-lying islands and coastal communities are threatened by sea level rise, which makes urban flooding more common. Sometimes, land is permanently lost to the sea. This could lead to statelessness for people in island nations, such as the Maldives and Tuvalu. In some regions, the rise in temperature and humidity may be too severe for humans to adapt to. With worst-case climate change, models project that almost one-third of humanity might live in extremely hot and uninhabitable climates.These factors can drive climate or environmental migration, within and between countries. More people are expected to be displaced because of sea level rise, extreme weather and conflict from increased competition over natural resources. Climate change may also increase vulnerability, leading to \"trapped populations\" who are not able to move due to a lack of resources.\\n\\nReducing and recapturing emissions\\nClimate change can be mitigated by reducing the rate at which greenhouse gases are emitted into the atmosphere, and by increasing the rate at which carbon dioxide is removed from the atmosphere. In order to limit global warming to less than 1.5 \u00b0C global greenhouse gas emissions needs to be net-zero by 2050, or by 2070 with a 2 \u00b0C target. This requires far-reaching, systemic changes on an unprecedented scale in energy, land, cities, transport, buildings, and industry.The United Nations Environment Programme estimates that countries need to triple their pledges under the Paris Agreement within the next decade to limit global warming to 2 \u00b0C. An even greater level of reduction is required to meet the 1.5 \u00b0C goal. With pledges made under the Paris Agreement as of October 2021, global warming would still have a 66% chance of reaching about 2.7 \u00b0C (range: 2.2\u20133.2 \u00b0C) by the end of the century. Globally, limiting warming to 2 \u00b0C may result in higher economic benefits than economic costs.Although there is no single pathway to limit global warming to 1.5 or 2 \u00b0C, most scenarios and strategies see a major increase in the use of renewable energy in combination with increased energy efficiency measures to generate the needed greenhouse gas reductions. To reduce pressures on ecosystems and enhance their carbon sequestration capabilities, changes would also be necessary in agriculture and forestry, such as preventing deforestation and restoring natural ecosystems by reforestation.Other approaches to mitigating climate change have a higher level of risk. Scenarios that limit global warming to 1.5 \u00b0C typically project the large-scale use of carbon dioxide removal methods over the 21st century. There are concerns, though, about over-reliance on these technologies, and environmental impacts. Solar radiation modification (SRM) is also a possible supplement to deep reductions in emissions. However, SRM raises significant ethical and legal concerns, and the risks are imperfectly understood.\\n\\nClean energy\\nRenewable energy is key to limiting climate change. For decades, fossil fuels have accounted for roughly 80% of the world's energy use. The remaining share has been split between nuclear power and renewables (including hydropower, bioenergy, wind and solar power and geothermal energy). Fossil fuel use is expected to peak in absolute terms prior to 2030 and then to decline, with coal use experiencing the sharpest reductions. Renewables represented 75% of all new electricity generation installed in 2019, nearly all solar and wind. Other forms of clean energy, such as nuclear and hydropower, currently have a larger share of the energy supply. However, their future growth forecasts appear limited in comparison.While solar panels and onshore wind are now among the cheapest forms of adding new power generation capacity in many locations, green energy policies are needed to achieve a rapid transition from fossil fuels to renewables. To achieve carbon neutrality by 2050, renewable energy would become the dominant form of electricity generation, rising to 85% or more by 2050 in some scenarios. Investment in coal would be eliminated and coal use nearly phased out by 2050.Electricity generated from renewable sources would also need to become the main energy source for heating and transport. Transport can switch away from internal combustion engine vehicles and towards electric vehicles, public transit, and active transport (cycling and walking). For shipping and flying, low-carbon fuels would reduce emissions. Heating could be increasingly decarbonised with technologies like heat pumps.There are obstacles to the continued rapid growth of clean energy, including renewables. For wind and solar, there are environmental and land use concerns for new projects. Wind and solar also produce energy intermittently and with seasonal variability. Traditionally, hydro dams with reservoirs and conventional power plants have been used when variable energy production is low. Going forward, battery storage can be expanded, energy demand and supply can be matched, and long-distance transmission can smooth variability of renewable outputs. Bioenergy is often not carbon-neutral and may have negative consequences for food security. The growth of nuclear power is constrained by controversy around radioactive waste, nuclear weapon proliferation, and accidents. Hydropower growth is limited by the fact that the best sites have been developed, and new projects are confronting increased social and environmental concerns.Low-carbon energy improves human health by minimising climate change as well as reducing air pollution deaths, which were estimated at 7 million annually in 2016. Meeting the Paris Agreement goals that limit warming to a 2 \u00b0C increase could save about a million of those lives per year by 2050, whereas limiting global warming to 1.5 \u00b0C could save millions and simultaneously increase energy security and reduce poverty. Improving air quality also has economic benefits which may be larger than mitigation costs.\\n\\nEnergy conservation\\nReducing energy demand is another major aspect of reducing emissions. If less energy is needed, there is more flexibility for clean energy development. It also makes it easier to manage the electricity grid, and minimises carbon-intensive infrastructure development. Major increases in energy efficiency investment will be required to achieve climate goals, comparable to the level of investment in renewable energy. Several COVID-19 related changes in energy use patterns, energy efficiency investments, and funding have made forecasts for this decade more difficult and uncertain.Strategies to reduce energy demand vary by sector. In the transport sector, passengers and freight can switch to more efficient travel modes, such as buses and trains, or use electric vehicles. Industrial strategies to reduce energy demand include improving heating systems and motors, designing less energy-intensive products, and increasing product lifetimes. In the building sector the focus is on better design of new buildings, and higher levels of energy efficiency in retrofitting. The use of technologies like heat pumps can also increase building energy efficiency.\\n\\nAgriculture and industry\\nAgriculture and forestry face a triple challenge of limiting greenhouse gas emissions, preventing the further conversion of forests to agricultural land, and meeting increases in world food demand. A set of actions could reduce agriculture and forestry-based emissions by two thirds from 2010 levels. These include reducing growth in demand for food and other agricultural products, increasing land productivity, protecting and restoring forests, and reducing greenhouse gas emissions from agricultural production.On the demand side, a key component of reducing emissions is shifting people towards plant-based diets. Eliminating the production of livestock for meat and dairy would eliminate about 3/4ths of all emissions from agriculture and other land use. Livestock also occupy 37% of ice-free land area on Earth and consume feed from the 12% of land area used for crops, driving deforestation and land degradation.Steel and cement production are responsible for about 13% of industrial CO2 emissions. In these industries, carbon-intensive materials such as coke and lime play an integral role in the production, so that reducing CO2 emissions requires research into alternative chemistries.\\n\\nCarbon sequestration\\nNatural carbon sinks can be enhanced to sequester significantly larger amounts of CO2 beyond naturally occurring levels. Reforestation and afforestation (planting forests where there were none before) are among the most mature sequestration techniques, although the latter raises food security concerns. Farmers can promote sequestration of carbon in soils through practices such as use of winter cover crops, reducing the intensity and frequency of tillage, and using compost and manure as soil amendments. Forest and landscape restoration yields many benefits for the climate, including greenhouse gas emissions sequestration and reduction. Restoration/recreation of coastal wetlands, prairie plots and seagrass meadows increases the uptake of carbon into organic matter. When carbon is sequestered in soils and in organic matter such as trees, there is a risk of the carbon being re-released into the atmosphere later through changes in land use, fire, or other changes in ecosystems.Where energy production or CO2-intensive heavy industries continue to produce waste CO2, the gas can be captured and stored instead of released to the atmosphere. Although its current use is limited in scale and expensive, carbon capture and storage (CCS) may be able to play a significant role in limiting CO2 emissions by mid-century. This technique, in combination with bioenergy (BECCS) can result in net negative emissions as CO2 is drawn from the atmosphere. It remains highly uncertain whether carbon dioxide removal techniques will be able to play a large role in limiting warming to 1.5 \u00b0C. Policy decisions that rely on carbon dioxide removal increase the risk of global warming rising beyond international goals.\\n\\nAdaptation\\nAdaptation is \"the process of adjustment to current or expected changes in climate and its effects\".:\u200a5\u200a Without additional mitigation, adaptation cannot avert the risk of \"severe, widespread and irreversible\" impacts. More severe climate change requires more transformative adaptation, which can be prohibitively expensive. The capacity and potential for humans to adapt is unevenly distributed across different regions and populations, and developing countries generally have less. The first two decades of the 21st century saw an increase in adaptive capacity in most low- and middle-income countries with improved access to basic sanitation and electricity, but progress is slow. Many countries have implemented adaptation policies. However, there is a considerable gap between necessary and available finance.Adaptation to sea level rise consists of avoiding at-risk areas, learning to live with increased flooding, and building flood controls. If that fails, managed retreat may be needed. There are economic barriers for tackling dangerous heat impact. Avoiding strenuous work or having air conditioning is not possible for everybody. In agriculture, adaptation options include a switch to more sustainable diets, diversification, erosion control, and genetic improvements for increased tolerance to a changing climate. Insurance allows for risk-sharing, but is often difficult to get for people on lower incomes. Education, migration and early warning systems can reduce climate vulnerability. Planting mangroves or encouraging other coastal vegetation can buffer storms.Ecosystems adapt to climate change, a process that can be supported by human intervention. By increasing connectivity between ecosystems, species can migrate to more favourable climate conditions. Species can also be introduced to areas acquiring a favorable climate. Protection and restoration of natural and semi-natural areas helps build resilience, making it easier for ecosystems to adapt. Many of the actions that promote adaptation in ecosystems, also help humans adapt via ecosystem-based adaptation. For instance, restoration of natural fire regimes makes catastrophic fires less likely, and reduces human exposure. Giving rivers more space allows for more water storage in the natural system, reducing flood risk. Restored forest acts as a carbon sink, but planting trees in unsuitable regions can exacerbate climate impacts.There are synergies but also trade-offs between adaptation and mitigation. An example for synergy is increased food productivity, which has large benefits for both adaptation and mitigation. An example of a trade-off is that increased use of air conditioning allows people to better cope with heat, but increases energy demand. Another trade-off example is that more compact urban development may reduce emissions from transport and construction, but may also increase the urban heat island effect, exposing people to heat-related health risks.\\n\\nPolicies and politics\\nCountries that are most vulnerable to climate change have typically been responsible for a small share of global emissions. This raises questions about justice and fairness. Limiting global warming makes it much easier to achieve the UN's Sustainable Development Goals, such as eradicating poverty and reducing inequalities. The connection is recognised in Sustainable Development Goal 13 which is to \"take urgent action to combat climate change and its impacts\". The goals on food, clean water and ecosystem protection have synergies with climate mitigation.The geopolitics of climate change is complex. It has often been framed as a free-rider problem, in which all countries benefit from mitigation done by other countries, but individual countries would lose from switching to a low-carbon economy themselves. Sometimes mitigation also has localized benefits though. For instance, the benefits of a coal phase-out to public health and local environments exceed the costs in almost all regions. Furthermore, net importers of fossil fuels win economically from switching to clean energy, causing net exporters to face stranded assets: fossil fuels they cannot sell.\\n\\nPolicy options\\nA wide range of policies, regulations, and laws are being used to reduce emissions. As of 2019, carbon pricing covers about 20% of global greenhouse gas emissions. Carbon can be priced with carbon taxes and emissions trading systems. Direct global fossil fuel subsidies reached $319 billion in 2017, and $5.2 trillion when indirect costs such as air pollution are priced in. Ending these can cause a 28% reduction in global carbon emissions and a 46% reduction in air pollution deaths. Money saved on fossil subsidies could be used to support the transition to clean energy instead. More direct methods to reduce greenhouse gases include vehicle efficiency standards, renewable fuel standards, and air pollution regulations on heavy industry. Several countries require utilities to increase the share of renewables in power production.\\n\\nClimate justice\\nPolicy designed through the lens of climate justice tries to address human rights issues and social inequality. According to proponents of climate justice, the costs of climate adaptation should be paid by those most responsible for climate change, while the beneficiaries of payments should be those suffering impacts. One way this can be addressed in practice is to have wealthy nations pay poorer countries to adapt.Oxfam found that in 2023 the wealthiest 10% of people were responsible for 50% of global emissions, while the bottom 50% were responsible for just 8%. Production is another way to look at responsibility, with a 2023 study published in One Earth estimating that the top 21 fossil fuel companies would owe cumulative climate reparations of $5.4 trillion over the period 2025\u20132050. To achieve a just transition, people working in the fossil fuel sector would also need other jobs, and their communities would need investments.\\n\\nInternational climate agreements\\nNearly all countries in the world are parties to the 1994 United Nations Framework Convention on Climate Change (UNFCCC). The goal of the UNFCCC is to prevent dangerous human interference with the climate system. As stated in the convention, this requires that greenhouse gas concentrations are stabilised in the atmosphere at a level where ecosystems can adapt naturally to climate change, food production is not threatened, and economic development can be sustained. The UNFCCC does not itself restrict emissions but rather provides a framework for protocols that do. Global emissions have risen since the UNFCCC was signed. Its yearly conferences are the stage of global negotiations.The 1997 Kyoto Protocol extended the UNFCCC and included legally binding commitments for most developed countries to limit their emissions. During the negotiations, the G77 (representing developing countries) pushed for a mandate requiring developed countries to \"[take] the lead\" in reducing their emissions, since developed countries contributed most to the accumulation of greenhouse gases in the atmosphere. Per-capita emissions were also still relatively low in developing countries and developing countries would need to emit more to meet their development needs.The 2009 Copenhagen Accord has been widely portrayed as disappointing because of its low goals, and was rejected by poorer nations including the G77. Associated parties aimed to limit the global temperature rise to below 2 \u00b0C. The Accord set the goal of sending $100 billion per year to developing countries for mitigation and adaptation by 2020, and proposed the founding of the Green Climate Fund. As of 2020, only 83.3 billion were delivered. Only in 2023 the target is expected to be achieved.In 2015 all UN countries negotiated the Paris Agreement, which aims to keep global warming well below 2.0 \u00b0C and contains an aspirational goal of keeping warming under 1.5 \u00b0C. The agreement replaced the Kyoto Protocol. Unlike Kyoto, no binding emission targets were set in the Paris Agreement. Instead, a set of procedures was made binding. Countries have to regularly set ever more ambitious goals and reevaluate these goals every five years. The Paris Agreement restated that developing countries must be financially supported. As of October 2021, 194 states and the European Union have signed the treaty and 191 states and the EU have ratified or acceded to the agreement.The 1987 Montreal Protocol, an international agreement to stop emitting ozone-depleting gases, may have been more effective at curbing greenhouse gas emissions than the Kyoto Protocol specifically designed to do so. The 2016 Kigali Amendment to the Montreal Protocol aims to reduce the emissions of hydrofluorocarbons, a group of powerful greenhouse gases which served as a replacement for banned ozone-depleting gases. This made the Montreal Protocol a stronger agreement against climate change.\\n\\nNational responses\\nIn 2019, the United Kingdom parliament became the first national government to declare a climate emergency. Other countries and jurisdictions followed suit. That same year, the European Parliament declared a \"climate and environmental emergency\". The European Commission presented its European Green Deal with the goal of making the EU carbon-neutral by 2050. In 2021, the European Commission released its \"Fit for 55\" legislation package, which contains guidelines for the car industry; all new cars on the European market must be zero-emission vehicles from 2035.Major countries in Asia have made similar pledges: South Korea and Japan have committed to become carbon-neutral by 2050, and China by 2060. While India has strong incentives for renewables, it also plans a significant expansion of coal in the country. Vietnam is among very few coal-dependent fast developing countries that pledged to phase out unabated coal power by the 2040s or as soon as possible thereafter.As of 2021, based on information from 48 national climate plans, which represent 40% of the parties to the Paris Agreement, estimated total greenhouse gas emissions will be 0.5% lower compared to 2010 levels, below the 45% or 25% reduction goals to limit global warming to 1.5 \u00b0C or 2 \u00b0C, respectively.\\n\\nSociety\\nDenial and misinformation\\nPublic debate about climate change has been strongly affected by climate change denial and misinformation, which originated in the United States and has since spread to other countries, particularly Canada and Australia. Climate change denial has originated from fossil fuel companies, industry groups, conservative think tanks, and contrarian scientists. Like the tobacco industry, the main strategy of these groups has been to manufacture doubt about scientific data and results. People who hold unwarranted doubt about climate change are called climate change \"skeptics\", although \"contrarians\" or \"deniers\" are more appropriate terms.There are different variants of climate denial: some deny that warming takes place at all, some acknowledge warming but attribute it to natural influences, and some minimise the negative impacts of climate change. Manufacturing uncertainty about the science later developed into a manufactured controversy: creating the belief that there is significant uncertainty about climate change within the scientific community in order to delay policy changes. Strategies to promote these ideas include criticism of scientific institutions, and questioning the motives of individual scientists. An echo chamber of climate-denying blogs and media has further fomented misunderstanding of climate change.\\n\\nPublic awareness and opinion\\nClimate change came to international public attention in the late 1980s. Due to media coverage in the early 1990s, people often confused climate change with other environmental issues like ozone depletion. In popular culture, the climate fiction movie The Day After Tomorrow (2004) and the Al Gore documentary An Inconvenient Truth (2006) focused on climate change.Significant regional, gender, age and political differences exist in both public concern for, and understanding of, climate change. More highly educated people, and in some countries, women and younger people, were more likely to see climate change as a serious threat. Partisan gaps also exist in many countries, and countries with high CO2 emissions tend to be less concerned. Views on causes of climate change vary widely between countries. Concern has increased over time, to the point where in 2021 a majority of citizens in many countries express a high level of worry about climate change, or view it as a global emergency. Higher levels of worry are associated with stronger public support for policies that address climate change.\\n\\nClimate movement\\nClimate protests demand that political leaders take action to prevent climate change. They can take the form of public demonstrations, fossil fuel divestment, lawsuits and other activities. Prominent demonstrations include the School Strike for Climate. In this initiative, young people across the globe have been protesting since 2018 by skipping school on Fridays, inspired by Swedish teenager Greta Thunberg. Mass civil disobedience actions by groups like Extinction Rebellion have protested by disrupting roads and public transport.Litigation is increasingly used as a tool to strengthen climate action from public institutions and companies. Activists also initiate lawsuits which target governments and demand that they take ambitious action or enforce existing laws on climate change. Lawsuits against fossil-fuel companies generally seek compensation for loss and damage.\\n\\nHistory\\nEarly discoveries\\nScientists in the 19th century such as Alexander von Humboldt began to foresee the effects of climate change. In the 1820s, Joseph Fourier proposed the greenhouse effect to explain why Earth's temperature was higher than the sun's energy alone could explain. Earth's atmosphere is transparent to sunlight, so sunlight reaches the surface where it is converted to heat. However, the atmosphere is not transparent to heat radiating from the surface, and captures some of that heat, which in turn warms the planet.In 1856 Eunice Newton Foote demonstrated that the warming effect of the sun is greater for air with water vapour than for dry air, and that the effect is even greater with carbon dioxide (CO2). She concluded that \"An atmosphere of that gas would give to our earth a high temperature...\"\\nStarting in 1859, John Tyndall established that nitrogen and oxygen\u2014together totaling 99% of dry air\u2014are transparent to radiated heat. However, water vapour and gases such as methane and carbon dioxide absorb radiated heat and re-radiate that heat into the atmosphere. Tyndall proposed that changes in the concentrations of these gases may have caused climatic changes in the past, including ice ages.Svante Arrhenius noted that water vapour in air continuously varied, but the CO2 concentration in air was influenced by long-term geological processes. Warming from increased CO2 levels would increase the amount of water vapour, amplifying warming in a positive feedback loop. In 1896, he published the first climate model of its kind, projecting that halving CO2 levels could have produced a drop in temperature initiating an ice age. Arrhenius calculated the temperature increase expected from doubling CO2 to be around 5\u20136 \u00b0C. Other scientists were initially skeptical and believed that the greenhouse effect was saturated so that adding more CO2 would make no difference, and that the climate would be self-regulating. Beginning in 1938, Guy Stewart Callendar published evidence that climate was warming and CO2 levels were rising, but his calculations met the same objections.\\n\\nDevelopment of a scientific consensus\\nIn the 1950s, Gilbert Plass created a detailed computer model that included different atmospheric layers and the infrared spectrum. This model predicted that increasing CO2 levels would cause warming. Around the same time, Hans Suess found evidence that CO2 levels had been rising, and Roger Revelle showed that the oceans would not absorb the increase. The two scientists subsequently helped Charles Keeling to begin a record of continued increase, which has been termed the \"Keeling Curve\". Scientists alerted the public, and the dangers were highlighted at James Hansen's 1988 Congressional testimony. The Intergovernmental Panel on Climate Change (IPCC), set up in 1988 to provide formal advice to the world's governments, spurred interdisciplinary research. As part of the IPCC reports, scientists assess the scientific discussion that takes place in peer-reviewed journal articles.There is a near-complete scientific consensus that the climate is warming and that this is caused by human activities. As of 2019, agreement in recent literature reached over 99%. No scientific body of national or international standing disagrees with this view. Consensus has further developed that some form of action should be taken to protect people against the impacts of climate change. National science academies have called on world leaders to cut global emissions. The 2021 IPCC Assessment Report stated that it is \"unequivocal\" that climate change is caused by humans.\\n\\nSee also\\nAnthropocene \u2013 proposed new geological time interval in which humans are having significant geological impact\\nList of climate scientists\\n\\nReferences\\nSources\\nThis article incorporates text from a free content work.  Licensed under CC BY-SA 3.0 (license statement/permission). Text taken from The status of women in agrifood systems \u2013 Overview\u200b,  FAO, FAO.\\n\\nIPCC reports\\nOther peer-reviewed sources\\nBooks, reports and legal documents\\nNon-technical sources\\nExternal links\\n\\nIntergovernmental Panel on Climate Change\\nUK Met Office: Climate Guide\\nNOAA Climate website \u2013 National Oceanic and Atmospheric Administration in the United States"}
{"article_name": "The_Great_Gatsby", "link": "https://en.wikipedia.org/wiki/The_Great_Gatsby", "text_content": "The Great Gatsby is a 1925 novel by American writer F. Scott Fitzgerald. Set in the Jazz Age on Long Island, near New York City, the novel depicts first-person narrator Nick Carraway's interactions with mysterious millionaire Jay Gatsby and Gatsby's obsession to reunite with his former lover, Daisy Buchanan.\\nThe novel was inspired by a youthful romance Fitzgerald had with socialite Ginevra King, and the riotous parties he attended on Long Island's North Shore in 1922. Following a move to the French Riviera, Fitzgerald completed a rough draft of the novel in 1924. He submitted it to editor Maxwell Perkins, who persuaded Fitzgerald to revise the work over the following winter. After making revisions, Fitzgerald was satisfied with the text, but remained ambivalent about the book's title and considered several alternatives. Painter Francis Cugat's dust jacket art greatly impressed Fitzgerald, and he incorporated its imagery into the novel.\\nAfter its publication by Scribner's in April 1925, The Great Gatsby received generally favorable reviews, though some literary critics believed it did not equal Fitzgerald's previous efforts. Compared to his earlier novels, This Side of Paradise (1920) and The Beautiful and Damned (1922), the novel was a commercial disappointment. It sold fewer than 20,000 copies by October, and Fitzgerald's hopes of a monetary windfall from the novel were unrealized. When the author died in 1940, he believed himself to be a failure and his work forgotten.\\nDuring World War II, the novel experienced an abrupt surge in popularity when the Council on Books in Wartime distributed free copies to American soldiers serving overseas. This new-found popularity launched a critical and scholarly re-examination, and the work soon became a core part of most American high school curricula and a part of American popular culture. Numerous stage and film adaptations followed in the subsequent decades.\\nGatsby continues to attract popular and scholarly attention. Scholars emphasize the novel's treatment of social class, inherited versus self-made wealth, gender, race, and environmentalism, and its cynical attitude towards the American Dream. The Great Gatsby is widely considered to be a literary masterpiece and a contender for the title of the Great American Novel.\\n\\nHistorical and biographical context\\nSet on the prosperous Long Island of 1922, The Great Gatsby provides a critical social history of Prohibition-era America during the Jazz Age. F. Scott Fitzgerald's fictional narrative fully renders that period\u2014known for its jazz music, economic prosperity, flapper culture, libertine mores, rebellious youth, and ubiquitous speakeasies. Fitzgerald uses many of these 1920s societal developments to tell his story, from simple details like petting in automobiles to broader themes such as bootlegging as the illicit source of Gatsby's fortune.Fitzgerald conveys the hedonism of Jazz Age society by placing a relatable plotline within the historical context of the most raucous and flashiest era in American history. In Fitzgerald's eyes, the era represented a morally permissive time when Americans of all ages became disillusioned with prevailing social norms and obsessed with pleasure-seeking. Fitzgerald himself had a certain ambivalence towards the Jazz Age, an era whose themes he would later regard as reflective of events in his own life.The Great Gatsby reflects various events in Fitzgerald's youth. He was a young Midwesterner from Minnesota. Like the novel's narrator who went to Yale, he was educated at an Ivy League school, Princeton. There the 18-year-old Fitzgerald met Ginevra King, a 16-year-old socialite with whom he fell deeply in love. Although Ginevra was madly in love with him, her upper-class family openly discouraged his courtship of their daughter because of his lower-class status, and her father purportedly told him that \"poor boys shouldn't think of marrying rich girls\".Rejected by Ginevra's family as a suitor because of his lack of financial prospects, a suicidal Fitzgerald enlisted in the United States Army amid World War I and was commissioned as a second lieutenant. While awaiting deployment to the Western front where he hoped to die in combat, he was stationed at Camp Sheridan in Montgomery, Alabama, where he met Zelda Sayre, a vivacious 17-year-old Southern belle. After learning that Ginevra had married wealthy Chicago businessman William \"Bill\" Mitchell, Fitzgerald asked Zelda to marry him. Zelda agreed but postponed their marriage until he became financially successful. Fitzgerald is thus similar to Jay Gatsby in that he became engaged while a military officer stationed far from home and then sought immense wealth in order to provide for the lifestyle to which his fianc\u00e9e had become accustomed.After his success as a short-story writer and as a novelist, Fitzgerald married Zelda in New York City, and the newly-wed couple soon relocated to Long Island. Despite enjoying the exclusive Long Island milieu, Fitzgerald quietly disapproved of the extravagant parties, and the wealthy persons he encountered often disappointed him. While striving to emulate the rich, he found their privileged lifestyle to be morally disquieting. Although Fitzgerald\u2014like Gatsby\u2014had always admired the rich, he nonetheless possessed a smoldering resentment towards them.\\n\\nPlot summary\\nIn spring 1922, Nick Carraway\u2014a Yale alumnus from the Midwest and a World War I veteran\u2014journeys to New York City to obtain employment as a bond salesman. He rents a bungalow in the Long Island village of West Egg, next to a luxurious estate inhabited by Jay Gatsby, an enigmatic multi-millionaire who hosts dazzling soir\u00e9es yet doesn't partake in them.\\nOne evening, Nick dines with a distant cousin, Daisy Buchanan, in the fashionable town of East Egg. Daisy is married to Tom Buchanan, formerly a Yale football star whom Nick knew during his college days. The couple has recently relocated from Chicago to a mansion directly across the bay from Gatsby's estate. There, Nick encounters Jordan Baker, an insolent flapper and golf champion who is a childhood friend of Daisy's. Jordan confides to Nick that Tom keeps a mistress, Myrtle Wilson, who brazenly telephones him at his home and who lives in the \"valley of ashes\", a sprawling refuse dump. That evening, Nick sees Gatsby standing alone on his lawn, staring at a green light across the bay.\\nDays later, Nick reluctantly accompanies a drunken and agitated Tom to New York City by train. En route, they stop at a garage inhabited by mechanic George Wilson and his wife Myrtle. Myrtle joins them, and the trio proceed to a small New York apartment that Tom has rented for trysts with her. Guests arrive and a party ensues, which ends with Tom slapping Myrtle and breaking her nose after she mentions Daisy.\\nOne morning, Nick receives a formal invitation to a party at Gatsby's mansion. Once there, Nick is embarrassed that he recognizes no one and begins drinking heavily until he encounters Jordan. While chatting with her, he is approached by a man who introduces himself as Jay Gatsby and insists that both he and Nick served in the 3rd Infantry Division during the war. Gatsby attempts to ingratiate himself with Nick and when Nick leaves the party, he notices Gatsby watching him.\\n\\nIn late July, Nick and Gatsby have lunch at a speakeasy. Gatsby tries impressing Nick with tales of his war heroism and his Oxford days. Afterward, Nick meets Jordan again at the Plaza Hotel. Jordan reveals that Gatsby and Daisy met around 1917 when Gatsby was an officer in the American Expeditionary Forces. They fell in love, but when Gatsby was deployed overseas, Daisy reluctantly married Tom. Gatsby hopes that his newfound wealth and dazzling parties will make Daisy reconsider. Gatsby uses Nick to stage a reunion with Daisy, and the two embark upon an affair.\\nIn September, Tom discovers the affair when Daisy carelessly addresses Gatsby with unabashed intimacy in front of him. Later, at a Plaza Hotel suite, Gatsby and Tom argue about the affair. Gatsby insists Daisy declare that she never loved Tom. Daisy claims she loves Tom and Gatsby, upsetting both. Tom reveals Gatsby is a swindler whose money comes from bootlegging alcohol. Upon hearing this, Daisy chooses to stay with Tom. Tom scornfully tells Gatsby to drive her home, knowing that Daisy will never leave him.\\nWhile returning to East Egg, Gatsby and Daisy drive by Wilson's garage and their car strikes Myrtle, killing her instantly. Later Gatsby reveals to Nick that Daisy was driving the car, but that he intends to take the blame for the accident to protect her. Nick urges Gatsby to flee to avoid prosecution, but he refuses. After Tom tells George that Gatsby owns the car that struck Myrtle, a distraught George assumes the owner of the vehicle must be Myrtle's lover. George fatally shoots Gatsby in his mansion's swimming pool, then kills himself.\\nSeveral days after Gatsby's murder, his father Henry Gatz arrives for the sparsely attended funeral. After Gatsby's death, Nick comes to hate New York and decides that Gatsby, Daisy, Tom, and he were all Midwesterners unsuited to Eastern life. Nick encounters Tom and initially refuses to shake his hand. Tom admits he was the one who told George that Gatsby owned the vehicle that killed Myrtle. Before returning to the Midwest, Nick returns to Gatsby's mansion and stares across the bay at the green light emanating from the end of Daisy's dock.\\n\\nMajor characters\\nNick Carraway \u2013 a Yale University alumnus from the Midwest, a World War I veteran, and a newly arrived resident of West Egg, age 29 (later 30) who serves as the first-person narrator. He is Gatsby's neighbor and a bond salesman. Carraway is easy-going and optimistic, although this latter quality fades as the novel progresses. He ultimately returns to the Midwest after despairing of the decadence and indifference of the eastern United States.\\nJay Gatsby (originally James \"Jimmy\" Gatz) \u2013 a young, mysterious millionaire with shady business connections (later revealed to be a bootlegger), originally from North Dakota. During World War I, when he was a young military officer stationed at the United States Army's Camp Taylor in Louisville, Kentucky, Gatsby encountered the love of his life, the debutante Daisy Buchanan. Later, after the war, he studied briefly at Trinity College, Oxford, in England. According to Fitzgerald's wife Zelda, he partly based Gatsby on their enigmatic Long Island neighbor, Max Gerlach. A military veteran, Gerlach became a self-made millionaire due to his bootlegging endeavors and was fond of using the phrase \"old sport\" in his letters to Fitzgerald.\\nDaisy Buchanan \u2013 a shallow, self-absorbed, and young debutante and socialite from Louisville, Kentucky, identified as a flapper. She is Nick's second cousin, once removed, and the wife of Tom Buchanan. Before marrying Tom, Daisy had a romantic relationship with Gatsby. Her choice between Gatsby and Tom is one of the novel's central conflicts. Fitzgerald's romance and life-long obsession with Ginevra King inspired the character of Daisy.\\nThomas \"Tom\" Buchanan \u2013 Daisy's husband, a millionaire who lives in East Egg. Tom is an imposing man of muscular build with a gruff voice and contemptuous demeanor. He was a football star at Yale and is a white supremacist. Among other literary models, Buchanan has certain parallels with William \"Bill\" Mitchell, the Chicago businessman who married Ginevra King. Buchanan and Mitchell were both Chicagoans with an interest in polo. Also, like Ginevra's father Charles King whom Fitzgerald resented, Buchanan is an imperious Yale man and polo player from Lake Forest, Illinois.\\nJordan Baker \u2013 an amateur golfer with a sarcastic streak and an aloof attitude, and Daisy's long-time friend. She is Nick Carraway's girlfriend for most of the novel, though they grow apart towards the end. She has a shady reputation because of rumors that she had cheated in a tournament, which harmed her reputation both socially and as a golfer. Fitzgerald based Jordan on Ginevra's friend Edith Cummings, a premier amateur golfer known in the press as \"The Fairway Flapper\". Unlike Jordan Baker, Cummings was never suspected of cheating. The character's name is a play on two popular automobile brands, the Jordan Motor Car Company and the Baker Motor Vehicle, both of Cleveland, Ohio, alluding to Jordan's \"fast\" reputation and the new freedom presented to American women, especially flappers, in the 1920s.\\nGeorge B. Wilson \u2013 a mechanic and owner of a garage. He is disliked by both his wife, Myrtle Wilson, and Tom Buchanan, who describes him as \"so dumb he doesn't know he's alive\". At the end of the novel, George kills Gatsby, wrongly believing he had been driving the car that killed Myrtle, and then kills himself.\\nMyrtle Wilson \u2013 George's wife and Tom Buchanan's mistress. Myrtle, who possesses a fierce vitality, is desperate to find refuge from her disappointing marriage. She is accidentally killed by Gatsby's car, as she mistakenly thinks Tom is still driving it and runs after it.\\n\\nWriting and production\\nFitzgerald began outlining his third novel in June 1922. He longed to produce an exquisite work that was beautiful and intricately patterned, but the troubled production of his stage play The Vegetable repeatedly interrupted his progress. The play flopped, and Fitzgerald wrote magazine stories that winter to pay debts incurred by its production. He viewed these stories as all worthless, although included among them was \"Winter Dreams\", which Fitzgerald described as his first attempt at the Gatsby idea. \"The whole idea of Gatsby\", he later explained to a friend, \"is the unfairness of a poor young man not being able to marry a girl with money. This theme comes up again and again because I lived it\".In October 1922, after the birth of their only child, Frances Scott \"Scottie\" Fitzgerald, the Fitzgeralds moved to Great Neck, New York, on Long Island. Their neighbors in Great Neck included such newly wealthy personages as writer Ring Lardner, actor Lew Fields and comedian Ed Wynn. These figures were all considered to be nouveau riche, unlike those who came from Manhasset Neck, which sat across the bay from Great Neck\u2014places that were home to many of New York's wealthiest established families. This real-life juxtaposition gave Fitzgerald his idea for \"West Egg\" and \"East Egg\". In the novel, Great Neck (Kings Point) became the \"new money\" peninsula of West Egg and Port Washington (Sands Point) became the \"old money\" East Egg. Several Gold Coast mansions in the area served as inspiration for Gatsby's estate including Land's End, Oheka Castle, and the since-demolished Beacon Towers.While living on Long Island, the Fitzgeralds' enigmatic neighbor was Max Gerlach. Purportedly born in America to a German immigrant family, Gerlach had been a major in the American Expeditionary Forces during World War I, and he later became a gentleman bootlegger who lived like a millionaire in New York. Flaunting his new wealth, Gerlach threw lavish parties, never wore the same shirt twice, used the phrase \"old sport\", and fostered myths about himself including that he was a relation of the German Kaiser. These details about Gerlach inspired Fitzgerald in his creation of Jay Gatsby.During this same time period, the daily newspapers sensationalized the Hall\u2013Mills murder case over many months, and the highly publicized case likely influenced the plot of Fitzgerald's novel. The case involved the double-murder of a man and his lover on September 14, 1922, mere weeks before Fitzgerald arrived in Great Neck. Scholars have speculated that Fitzgerald based certain aspects of the ending of The Great Gatsby and various characterizations on this factual incident.Inspired by the Halls\u2013Mills case, the mysterious persona of Gerlach and the riotous parties he attended on Long Island, Fitzgerald had written 18,000 words for his novel by mid-1923 but discarded most of his new story as a false start. Some of this early draft resurfaced in the 1924 short story \"Absolution\". In earlier drafts, Daisy was originally named Ada and Nick was Dud, and the two characters had shared a previous romance prior to their reunion on Long Island. These earlier drafts were written from the viewpoint of an omniscient narrator as opposed to Nick's perspective. A key difference in earlier drafts is a less complete failure of Gatsby's dream. Another difference is that the argument between Tom Buchanan and Gatsby is more balanced, although Daisy still returns to Tom.Work on The Great Gatsby resumed in earnest in April 1924. Fitzgerald decided to depart from the writing process of his previous novels and told Perkins that he was intent on creating an artistic achievement. He wished to eschew the realism of his previous two novels and to compose a creative work of sustained imagination. To this end, he consciously imitated the literary styles of Joseph Conrad and Willa Cather. He was particularly influenced by Cather's 1923 work, A Lost Lady, which features a wealthy married socialite pursued by a variety of romantic suitors and who symbolically embodies the American dream. He later wrote a letter to Cather apologizing for any unintentional plagiarism. During this period of revisions, Scott saw and was influenced by early sketches for the book's dust jacket art. Soon after this burst of effort, work slowed while the Fitzgeralds moved to the Villa Marie in Saint-Rapha\u00ebl on the French Riviera, where a marital crisis soon developed.Despite his ongoing marital tension, Fitzgerald continued to write steadily and submitted a near-final version of the manuscript to his editor, Maxwell Perkins, on October 27. Perkins informed him in a November letter that Gatsby was too vague as a character and that his wealth and business, respectively, needed a convincing explanation. Fitzgerald thanked Perkins for his detailed criticisms and claimed that such feedback would enable him to perfect the manuscript. Having relocated with his wife to Rome, Fitzgerald made revisions to the manuscript throughout the winter.Content after a few rounds of revision, Fitzgerald submitted the final version in February 1925. Fitzgerald's alterations included extensive revisions of the sixth and eighth chapters. He declined an offer of $10,000 for the serial rights to the book so that it could be published sooner. He received a $3,939 advance in 1923 and would receive $1,981.25 upon publication.\\n\\nAlternative titles\\nFitzgerald had difficulty choosing a title for his novel and entertained many choices before reluctantly deciding on The Great Gatsby, a title inspired by Alain-Fournier's Le Grand Meaulnes. Previously he had shifted between Among Ash Heaps and Millionaires, Trimalchio, Trimalchio in West Egg, On the Road to West Egg, Under the Red, White, and Blue, The Gold-Hatted Gatsby, and The High-Bouncing Lover. The titles The Gold-Hatted Gatsby and The High-Bouncing Lover came from Fitzgerald's epigraph for the novel, one which he wrote himself under the pen name of Thomas Parke D'Invilliers.Fitzgerald initially preferred titles referencing Trimalchio, the crude upstart in Petronius's Satyricon, and even refers to Gatsby as Trimalchio once in the novel.\\nUnlike Gatsby's spectacular parties, Trimalchio participated in the orgies he hosted but, according to literary critic Tony Tanner, there are subtle similarities between the two characters. By November 1924, Fitzgerald wrote to Perkins that he had settled upon the title of Trimalchio in West Egg.Disliking Fitzgerald's chosen title of Trimalchio in West Egg, editor Max Perkins persuaded him that the reference was too obscure and that people would be unable to pronounce it. Zelda and Perkins both expressed their preference for The Great Gatsby, and the next month Fitzgerald agreed. A month before publication, after a final review of the proofs, he asked if it would be possible to re-title it Trimalchio or Gold-Hatted Gatsby, but Perkins advised against it. On March 19, 1925, Fitzgerald expressed enthusiasm for the title Under the Red, White, and Blue, but it was too late to change it at that stage. The novel was published as The Great Gatsby on April 10, 1925. Fitzgerald believed the book's final title to be merely acceptable and often expressed his ambivalence with the name.\\n\\nDust jacket art\\nThe artwork for the first edition of The Great Gatsby is among the most celebrated in American literature and represents a unique instance in literary history in which a novel's commissioned artwork directly influenced the composition of the text. Rendered in an Art Deco visual style, the artwork depicts the disembodied face of a Jazz Age flapper with celestial eyes and rouged mouth over a dark blue skyline. A little-known Barcelonan painter named Francis Cugat\u2014born Francisco Coradal-Cougat\u2014was commissioned by an unknown individual in Scribner's art department to illustrate the cover while Fitzgerald was composing the novel.In a preliminary sketch, Cugat drew a concept of a dismal gray landscape inspired by Fitzgerald's original title for the novel, Among Ash Heaps and Millionaires. Discarding this gloomy concept, Cugat next drew a divergent study which became the prefiguration to the final cover: A pencil and crayon drawing of a flapper's half-hidden visage over Long Island Sound with scarlet lips, one celestial eye, and a single diagonal tear. Expanding upon this study, his subsequent drawing featured two bright eyes looming over a shadowy New York cityscape. In later iterations, Cugat replaced the shadowy cityscape with dazzling carnival lights evoking a Ferris wheel and likely referencing the glittering amusement park at New York's Coney Island. Cugat affixed reclining nudes within the flapper's irises and added a green tint to the streaming tear. Cugat's final cover, which Max Perkins hailed as a masterpiece, was the only work he completed for Scribner's and the only book cover he ever designed.Although Fitzgerald likely never saw the final gouache painting prior to the novel's publication, Cugat's preparatory drafts influenced his writing. Upon viewing Cugat's drafts before sailing for France in April\u2013May 1924, Fitzgerald was so enamored that he later told editor Max Perkins that he had incorporated Cugat's imagery into the novel. This statement has led many to analyze interrelations between Cugat's art and Fitzgerald's text. One popular interpretation is that the celestial eyes are reminiscent of those of optometrist T. J. Eckleburg depicted on a faded commercial billboard near George Wilson's auto repair shop. Author Ernest Hemingway supported this latter interpretation and claimed that Fitzgerald had told him the cover referred to a billboard in the valley of the ashes. Although this passage has some resemblance to the imagery, a closer explanation can be found in Fitzgerald's explicit description of Daisy Buchanan as the \"girl whose disembodied face floated along the dark cornices and blinding signs\".\\n\\nCritical reception\\nInitial reviews\\nCharles Scribner's Sons published The Great Gatsby on April 10, 1925. Fitzgerald cabled Perkins the day after publication to monitor reviews: \"Any news?\" \"Sales situation doubtful [but] excellent reviews\", read a telegram from Perkins on April 20. Fitzgerald responded on April 24, saying the cable dispirited him, closing the letter with \"Yours in great depression\". Fitzgerald soon received letters from contemporaries Willa Cather, Edith Wharton, and poet T. S. Eliot praising the novel. Although gratified by such correspondence, Fitzgerald sought public acclaim from professional critics.\\nThe Great Gatsby received generally favorable reviews from literary critics of the day. Edwin Clark of The New York Times felt the novel was a mystical and glamorous tale of the Jazz Age. Similarly, Lillian C. Ford of the Los Angeles Times hailed the novel as a revelatory work of art that \"leaves the reader in a mood of chastened wonder\". The New York Post described Fitzgerald's prose style as scintillating and genuinely brilliant. The New York Herald Tribune was less impressed, referring to The Great Gatsby as \"a literary lemon meringue\" that nonetheless \"contains some of the nicest little touches of contemporary observation you could imagine\u2014so light, so delicate, so sharp\". In The Chicago Daily Tribune, H. L. Mencken judged the work's plot to be highly improbable, although he praised the writing as elegant and the \"careful and brilliant finish\".Several reviewers felt the novel left much to be desired following Fitzgerald's previous works and criticized him accordingly. Harvey Eagleton of The Dallas Morning News predicted that the novel signaled the end of Fitzgerald's artistic success. Ralph Coghlan of the St. Louis Post-Dispatch dismissed the work as an inconsequential performance by a once-promising author who had grown bored and cynical. Ruth Snyder of New York Evening World lambasted the book's style as painfully forced and declared the editors of her newspaper were \"quite convinced after reading The Great Gatsby that Mr. Fitzgerald is not one of the great American writers of today\". John McClure of The Times-Picayune insisted the plot was implausible and the book itself seemed raw in its construction.After reading these reviews, Fitzgerald believed that many critics misunderstood the novel. He despaired that \"of all the reviews, even the most enthusiastic, not one had the slightest idea what the book was about\". In particular, Fitzgerald resented criticisms of the novel's plot as implausible since he had never intended for the story to be realistic. Instead, he crafted the work to be a romanticized depiction that was largely scenic and symbolic. According to his friend John Peale Bishop, Fitzgerald further resented the fact that critics failed to perceive the many parallels between the author's life and the character of Jay Gatsby; in particular, that both created a mythical version of themselves and attempted to live up to this legend. Dispirited by critics failing to understand the novel, Fitzgerald remained hopeful that the novel would at least be a commercial success, perhaps selling as many as 75,000 copies.To Fitzgerald's great disappointment, Gatsby was a commercial failure in comparison with his previous efforts, This Side of Paradise (1920) and The Beautiful and Damned (1922). By October, the book had sold fewer than 20,000 copies.\\nAlthough the novel went through two initial printings, many copies remained unsold years later. Fitzgerald attributed the poor sales to the fact that women tended to be the primary audience for novels during this time, and Gatsby did not contain an admirable female character. According to his ledger, he earned only $2,000 from the book. Although Owen Davis' 1926 stage adaptation and the Paramount-issued silent film version brought in money for the author, Fitzgerald lamented that the novel fell far short of the success he had hoped for and would not bring him recognition as a serious novelist in the public eye. With the onset of the Great Depression, The Great Gatsby was regarded as little more than a nostalgic period piece. By the time Fitzgerald died in 1940, the novel had fallen into near obscurity.\\n\\nRevival and reassessment\\nIn 1940, Fitzgerald suffered a third and fatal heart attack and died believing his work forgotten. His obituary in The New York Times hailed him as a brilliant novelist and cited Gatsby as his greatest work. In the wake of Fitzgerald's death, a strong appreciation for the book gradually developed in writers' circles. Future authors Budd Schulberg and Edward Newhouse were deeply affected by it, and John O'Hara acknowledged its influence on his work. By the time that Gatsby was republished in Edmund Wilson's edition of The Last Tycoon in 1941, the prevailing opinion in writers' circles deemed the novel to be an enduring work of fiction.In the spring of 1942, mere months after the United States' entrance into World War II, an association of publishing executives created the Council on Books in Wartime with the stated purpose of distributing paperback Armed Services Editions books to combat troops. The Great Gatsby was one of them. Within the next several years, 155,000 copies of Gatsby were distributed to U.S. soldiers overseas, and the book proved popular among beleaguered troops, according to the Saturday Evening Post's 1945 report.By 1944, a full-scale Fitzgerald revival had occurred. Full-length scholarly articles on Fitzgerald's works were being published in periodicals and, by the following year, the earlier consensus among professional critics that The Great Gatsby was merely a sensational story or a nostalgic period piece had effectively vanished. The tireless promotional efforts of literary critic Edmund Wilson, who was Fitzgerald's Princeton classmate and his close friend, led this Fitzgerald revival. In 1951, three years after Zelda's death in a hospital fire, Professor Arthur Mizener of Cornell University published The Far Side of Paradise, the first biography of Fitzgerald. Mizener's best-selling biography emphasized The Great Gatsby's positive reception by literary critics, which may have further influenced public opinion and renewed interest in it.By 1960\u2014thirty-five years after the novel's original publication\u2014the book was steadily selling 100,000 copies per year. Renewed interest in it led The New York Times editorialist Mizener to proclaim the novel was a masterwork of 20th-century American literature. By 1974, The Great Gatsby had attained its status as a literary masterwork and was deemed a contender for the title of the \"Great American Novel\". Hunter S. Thompson retyped pages of The Great Gatsby \"just to get a feeling of what it was like to write that way.\" According to Thompson's friend William Nack, Thompson once retyped the entirety of the novel. Roger Ebert wrote that \"perhaps Fitzgerald's words 'compelled into an aesthetic contemplation he neither understood nor desired' is the best possible description of Thompson's life's work.\" By the mid-2000s, many literary critics considered The Great Gatsby to be one of the greatest novels ever written, and the work was part of the assigned curricula in the near majority of U.S. high schools. As of early 2020, The Great Gatsby had sold almost 30 million copies worldwide and continues to sell an additional 500,000 copies annually. Numerous foreign editions of the novel have been published, and the text has been translated into 42 different languages. The work is Scribner's most popular title; in 2013, the e-book alone sold 185,000 copies. The novel's U.S. copyright expired on January 1, 2021, when all works published in 1925 entered the public domain. Since then, numerous altered and incomplete reprints have flooded the market.\\n\\nCritical analysis\\nMajor themes\\nThe American Dream\\nFollowing the novel's revival, later critical writings on The Great Gatsby focused on Fitzgerald's disillusionment with the American Dream in the hedonistic Jazz Age, a name for the era which Fitzgerald claimed to have coined. In 1970, scholar Roger L. Pearson asserted that Fitzgerald's work\u2014more so than other twentieth century novels\u2014is especially linked with this conceptualization of the American dream. Pearson traced the literary origins of this dream to Colonial America. The dream is the belief that every individual, regardless of their origins, may seek and achieve their desired goals, \"be they political, monetary, or social. It is the literary expression of the concept of America: The land of opportunity\".However, Pearson noted that Fitzgerald's particular treatment of this theme is devoid of the discernible optimism in the writings of earlier American authors. He suggests Gatsby serves as a false prophet of the American dream, and pursuing the dream only results in dissatisfaction for those who chase it, owing to its unattainability. In this analytical context, the green light on the Buchanans' dock (visible across Long Island Sound from Gatsby's house) is frequently interpreted as a symbol of Gatsby's unrealizable goal to win Daisy and, consequently, to achieve the American Dream. Also, scholar Sarah Churchwell points out that adultery in the novel is linked to the loss of faith and broken promises, which symbolizes the corruption of the American Dream.\\n\\nClass permanence\\nScholars and writers commonly ascribe Gatsby's inability to achieve the American Dream to entrenched class disparities in American society. The novel underscores the limits of the American lower class to transcend their station of birth. Scholar Sarah Churchwell contends that Fitzgerald's novel is a tale of class warfare in a status-obsessed country that refuses to acknowledge publicly it even has a class system.Although scholars posit different explanations for the continuation of class differences in the United States, there is a consensus regarding the novel's message in conveying its underlying permanence. Although Gatsby's fundamental conflict occurs between entrenched sources of socio-economic power and upstarts like Gatsby who threaten their interests, Fitzgerald's novel shows that a class permanence persists despite the country's capitalist economy that prizes innovation and adaptability. Dianne Bechtel argues Fitzgerald plotted the novel to illustrate that class transcends wealth in America. Even if the poorer Americans become rich, they remain inferior to those Americans with \"old money\". Consequently, Gatsby and other characters in the novel are trapped in a rigid American class system.\\n\\nGender relations\\nBesides exploring the difficulties of achieving the American dream, The Great Gatsby explores societal gender expectations during the Jazz Age. The character of Daisy Buchanan has been identified specifically as personifying the emerging cultural archetype of the flapper. Flappers were typically young, modern women who bobbed their hair and wore short skirts. They also drank alcohol and had premarital sex.Despite the newfound societal freedoms attained by flappers in the 1920s, Fitzgerald's work critically examines the continued limitations upon women's agency during this period. In this context, although early critics viewed the character of Daisy to be a \"monster of bitchery\", later scholars such as Leland S. Person Jr. asserted that Daisy's character exemplifies the marginalization of women in the elite social environment that Fitzgerald depicts.Writing in 1978, Person noted Daisy is more of a hapless victim than a manipulative victimizer. She is the target first of Tom's callous domination and next of Gatsby's dehumanizing adoration. She involuntarily becomes the holy grail at the center of Gatsby's unrealistic quest to be steadfast to a youthful concept of himself. The ensuing contest of wills between Tom and Gatsby reduces Daisy to a trophy wife whose sole existence is to augment her possessor's socio-economic success.As an upper-class white woman living in East Egg during this time period, Daisy must adhere to societal expectations and gender norms such as actively fulfilling the roles of dutiful wife, nurturing mother, and charming socialite. Many of Daisy's choices\u2014ultimately culminating in the fatal car crash and misery for all those involved\u2014can be partly attributed to her prescribed role as a \"beautiful little fool\" who is reliant on her husband for financial and societal security. Her decision to remain with her husband, despite her feelings for Gatsby, is because of the security that her marriage to Tom Buchanan provides.\\n\\nRace and displacement\\nMany scholars have analyzed the novel's treatment of race and displacement; in particular, a perceived threat posed by newer immigrants to older Americans, triggering concerns over a loss of socio-economic status. In one instance, Tom Buchanan\u2014the novel's antagonist\u2014claims that he, Nick, and Jordan are racially superior Nordics. Tom decries immigration and advocates white supremacy. A fictional book alluded to by Tom is Stoddard's The Rise of the Colored Empires, which is a parody by Fitzgerald of Lothrop Stoddard's The Rising Tide of Color, a 1920s bestseller. Stoddard warned that immigration would alter America's racial composition and destroy the country.Analyzing these elements, literary theorist Walter Benn Michaels contends that Fitzgerald's novel reflects a historical period in American literature characterized by fears over the influx of Southern and Eastern European immigrants whose \"otherness\" challenged Americans' sense of national identity. Such anxieties were more salient in national discourse than the societal consequences of World War I, and the defining question of the period was who constituted \"a real American\".In this context of immigration and displacement, Tom's hostility towards Gatsby, who is the embodiment of \"latest America\", has been interpreted as partly embodying status anxieties of the time involving anti-immigrant sentiment. Gatsby\u2014whom Tom belittles as \"Mr. Nobody from Nowhere\"\u2014functions as a cipher because of his obscure origins, his unclear ethno-religious identity and his indeterminate class status. Although his ethnicity is vague, his last name Gatz and his father's adherence to the Lutheran religion indicate his family are recent German immigrants. This would preclude them from the coveted status of Old Stock Americans. Consequently, Gatsby's socio-economic ascent is deemed a threat not only due to his status as nouveau riche, but because he is perceived as an outsider.Because of such themes, The Great Gatsby captures the perennial American experience as it is a story about change and those who resist it\u2014whether such change comes in the form of a new wave of immigrants, the nouveau riche, or successful minorities. Since Americans living in the 1920s to the present are largely defined by their fluctuating socio-economic circumstances and must navigate a society with entrenched racial and ethnic prejudices, Fitzgerald's depiction of resultant status anxieties and social conflict has been highlighted by scholars as still enduringly relevant nearly a hundred years after the novel's publication.\\n\\nSexuality and identity\\nQuestions regarding the sexuality of characters have been raised for decades and\u2014augmented by biographical details about the author\u2014have given rise to queer readings. During his lifetime, Fitzgerald's sexuality became a subject of debate among his friends and acquaintances. As a youth, Fitzgerald had a close relationship with Father Sigourney Fay, a possibly gay Catholic priest, and Fitzgerald later used his last name for the idealized romantic character of Daisy Fay. After college, Fitzgerald cross-dressed during outings in Minnesota. Years later, while drafting The Great Gatsby, rumors dogged Fitzgerald among the American expat community in Paris that he was gay. Soon after, Fitzgerald's wife Zelda Fitzgerald likewise doubted his heterosexuality and asserted that he was a closeted homosexual. She publicly belittled him with homophobic slurs, and she alleged that Fitzgerald and fellow writer Ernest Hemingway engaged in homosexual relations. These incidents strained the Fitzgeralds' marriage at the time of the novel's publication.Although Fitzgerald's sexuality is a subject of scholarly debate, such biographical details lent credence to critical interpretations that his fictional characters are either gay or bisexual surrogates. As early as 1945, critics such as Lionel Trilling noted that characters in The Great Gatsby, such as Jordan Baker, were implied to be \"vaguely homosexual\", and, in 1960, writer Otto Friedrich commented upon the ease of examining the thwarted relations depicted in Fitzgerald's fiction through a queer lens. In recent decades, scholarship has focused sharply on the sexuality of Nick Carraway. In one instance in the novel, Carraway departs a drunken orgy with a \"pale, feminine\" man named Mr. McKee and\u2014following suggestive ellipses\u2014Nick next finds himself standing beside a bed while McKee sits between the sheets clad only in his underwear. Such scenes have led scholars to describe Nick as possessing an overt queerness and prompted analyses about his emotional attachment to Jay Gatsby. For these reasons, the novel has been described as an exploration of sexual identity during a historical era typified by the societal transition towards modernity.\\n\\nTechnology and environment\\nTechnological and environmental criticisms of Gatsby seek to place the novel and its characters in a broader historical context. In 1964, Leo Marx argued in The Machine in the Garden that Fitzgerald's work evinces a tension between a complex pastoral ideal of a bygone America and the societal transformations caused by industrialization and machine technology. Specifically, the valley of the ashes, in between East and West Egg, represents a man-made wasteland which is a byproduct of the industrialization that has made Gatsby's booming lifestyle, including his automobile, possible. Marx argues that Fitzgerald, via Nick, expresses a pastoral longing typical of other 1920s American writers like William Faulkner and Ernest Hemingway. Although such writers cherish the pastoral ideal, they accept that technological progress has deprived this ideal of nearly all meaning. In this context, Nick's repudiation of the eastern United States represents a futile attempt to withdraw into nature. Yet, as Fitzgerald's work shows, any technological demarcation between the eastern and western United States has vanished, and one cannot escape into a pastoral past.In 2018, scholar Kyle Keeler argued that the voracious pursuit of wealth as criticized in Fitzgerald's novel offers a warning about the perils of environmental destruction in pursuit of self-interest. According to Kyle Keeler, Gatsby's quest for greater status manifests as self-centered, anthropocentric resource acquisition. Inspired by the predatory mining practices of his fictional mentor Dan Cody, Gatsby participates in extensive deforestation amid World War I and then undertakes bootlegging activities reliant upon exploiting South American agriculture. Gatsby conveniently ignores the wasteful devastation of the valley of ashes to pursue a consumerist lifestyle and exacerbates the wealth gap that became increasingly salient in 1920s America. For these reasons, Keeler argues that\u2014while Gatsby's socioeconomic ascent and self-transformation depend upon these very factors\u2014each one is nonetheless partially responsible for the ongoing ecological crisis.\\n\\nAntisemitism\\nThe Great Gatsby has been accused of antisemitism because of its use of Jewish stereotypes. One of the novel's supporting characters is Meyer Wolfsheim, a Jewish friend and mentor of Gatsby. A corrupt profiteer who assists Gatsby's bootlegging operations and who fixed the 1919 World Series, he appears only twice in the novel, the second time refusing to attend Gatsby's funeral. Fitzgerald describes Wolfsheim as \"a small, flat-nosed Jew\", with \"tiny eyes\" and \"two fine growths of hair\" in his nostrils. Evoking ethnic stereotypes regarding the Jewish nose, he describes Wolfsheim's nose as \"expressive\", \"tragic\", and able to \"flash ... indignantly\". The fictional character of Wolfsheim is an allusion to real-life Jewish gambler Arnold Rothstein, a notorious New York crime kingpin whom Fitzgerald met once in undetermined circumstances. Rothstein was blamed for match fixing in the Black Sox Scandal that tainted the 1919 World Series.Wolfsheim has been interpreted as representing the Jewish miser stereotype. Richard Levy, author of Antisemitism: A Historical Encyclopedia of Prejudice and Persecution, claims that Wolfsheim serves to link Jewishness with corruption. In a 1947 article for Commentary, Milton Hindus, an assistant professor of humanities at the University of Chicago, stated that while he believed the book was a superb literary achievement, Wolfsheim was its most abrasive character, and the work contains an antisemitic undertone. However, Hindus argued the Jewish stereotypes displayed by Wolfsheim were typical of the time when the novel was written and set and that its antisemitism was of the \"habitual, customary, 'harmless,' unpolitical variety\". A 2015 article by essayist Arthur Krystal agreed with Hindus' assessment that Fitzgerald's use of Jewish caricatures was not driven by malice and merely reflected commonly held beliefs of his time. He notes the accounts of Frances Kroll, a Jewish woman and secretary to Fitzgerald, who claimed that Fitzgerald was hurt by accusations of antisemitism and responded to critiques of Wolfsheim by claiming he merely \"fulfilled a function in the story and had nothing to do with race or religion\".\\n\\nAdaptations\\nStage\\nGatsby has been adapted for the stage. The first known stage adaptation was by American dramatist Owen Davis, which became the 1926 film version. The play, directed by George Cukor, opened on Broadway on February 2, 1926, and had 112 curtain calls. A successful tour later in the year included performances in Chicago, August 1 through October 2. In July 2006, Simon Levy's stage adaptation, directed by David Esbjornson, premiered at the Guthrie Theater to commemorate the opening of its new theater. In 2010, critic Ben Brantley of The New York Times highly praised the debut of Gatz, an Off-Broadway production by Elevator Repair Service.The New York Metropolitan Opera commissioned John Harbison to compose an operatic treatment of the novel to commemorate the 25th anniversary of James Levine's debut. The work, called The Great Gatsby, premiered on December 20, 1999.The novel has also been adapted for ballet performances. In 2009, BalletMet premiered a version at the Capitol Theatre in Columbus, Ohio. In 2010, The Washington Ballet premiered a version at the Kennedy Center. The show received an encore run the following year. The Comedy Theatre of Budapest created a musical.Also, in 2023, the second musical adaptation, The Great Gatsby: A New Musical, with music and lyrics by Jason Howland and Nathan Tysen and a book by Kait Kerrigan announced a one-month limited engagement at the Paper Mill Playhouse. The Broadway tryout began its previews on October 12, 2023, followed by an official opening night scheduled for ten days later. The production concluded on November 12 of the same year. Jeremy Jordan and Eva Noblezada starred as the leading roles of Jay Gatsby and Daisy Buchanan, with Samantha Pauly and Noah J. Ricketts as Jordan Baker and Nick Carraway.Gatsby, a third musical adaptation with music and lyrics by Florence Welch and Thomas Bartlett and a book by Martyna Majok is set to have its world premiere the American Repertory Theater. On May 25, 2024, the show will begin previews and will open officially on June 5 of the same year. It will run for about 2 months with a closing night set for July 21.\\n\\nFilm\\nThe first movie version of the novel debuted in 1926. Itself a version of Owen Davis's Broadway play, it was directed by Herbert Brenon and starred Warner Baxter, Lois Wilson and William Powell. It is a famous example of a lost film. Reviews suggest it may have been the most faithful adaptation of the novel, but a trailer of the film at the National Archives is all that is known to exist. Reportedly, Fitzgerald and his wife Zelda loathed the silent version. Zelda wrote to an acquaintance that the film was \"rotten\". She and Scott left the cinema midway through the film.Following the 1926 movie was 1949's The Great Gatsby, directed by Elliott Nugent and starring Alan Ladd, Betty Field and Macdonald Carey. Twenty-five years later in 1974, The Great Gatsby appeared onscreen again. It was directed by Jack Clayton and starred Robert Redford as Gatsby, Mia Farrow as Daisy, and Sam Waterston as Nick Carraway. Most recently, The Great Gatsby was directed by Baz Luhrmann in 2013 and starred Leonardo DiCaprio as Gatsby, Carey Mulligan as Daisy, and Tobey Maguire as Nick.In 2021, visual effects company DNEG Animation announced they would be producing an animated film adaptation of the novel directed by William Joyce and written by Brian Selznick.\\n\\nTelevision\\nGatsby has been recast multiple times as a short-form television movie. The first was in 1955 as an NBC episode for Robert Montgomery Presents starring Robert Montgomery, Phyllis Kirk, and Lee Bowman. The episode was directed by Alvin Sapinsley. In 1958, CBS filmed another adaptation as an episode of Playhouse 90, also titled The Great Gatsby, which was directed by Franklin J. Schaffner and starred Robert Ryan, Jeanne Crain and Rod Taylor. Most recently, the novel was adapted as an A&E movie in 2000. The Great Gatsby was directed by Robert Markowitz and starred Toby Stephens as Gatsby, Mira Sorvino as Daisy, and Paul Rudd as Nick.\\n\\nLiterature\\nSince entering the public domain in 2021, retellings and expansions of The Great Gatsby have become legal to publish. Nick by Michael Farris Smith (2021) imagines the backstory of Nick Carraway. That same year saw the publication of The Chosen and the Beautiful by Nghi Vo, a retelling with elements of the fantasy genre while tackling issues of race and sexuality, and The Pursued and the Pursuing by AJ Odasso, a queer partial retelling and sequel in which Jay Gatsby survives. Anna-Marie McLemore's own queer retelling, Self-Made Boys: A Great Gatsby Remix, was released in 2022 and was longlisted for the National Book Award for Young People's Literature.\\n\\nGraphic novels\\nThe Great Gatsby has been adapted into three graphic novels. The first was in 2007 by Nicki Greenberg, who published The Great Gatsby: A Graphic Adaptation in Australia. Because the original novel was still protected by United States copyright laws, this version was never published in the U.S. The second version, The Great Gatsby: The Graphic Novel, was adapted by Fred Fordham and illustrated by Aya Morton in 2020. In 2021, K. Woodman-Maynard adapted and illustrated The Great Gatsby: A Graphic Novel Adaptation, which was published by Candlewick Press. This was the first graphic novel adaptation of the original novel to be published after it entered the public domain in 2021. In June 2021, Clover Press debuted the first of seven periodical comic books, faithfully adapting The Great Gatsby.\\n\\nRadio\\nThe novel has been adapted into a series of radio episodes. The first radio episode was a 1950 half-hour-long adaptation for CBS' Family Hour of Stars starring Kirk Douglas as Gatsby. The novel was read aloud by the BBC World Service in ten parts in 2008. In a 2012 BBC Radio 4 broadcast, The Great Gatsby took the form of a Classic Serial dramatization. It was created by dramatist Robert Forrest.\\n\\nVideo games\\nIn 2010, Oberon Media released a casual hidden object game called Classic Adventures: The Great Gatsby. In 2011, developer Charlie Hoey and editor Pete Smith created an 8-bit-style online game of The Great Gatsby called The Great Gatsby for NES; in 2022, after the Adobe Flash end of life they adapted this game to an actual NES ROM file, which can also be played on their website. In 2013, Slate released a short symbolic adaptation called The Great Gatsby: The Video Game.\\n\\nNotes\\nReferences\\nCitations\\nPrint sources\\nOnline sources\\nExternal links\\n\\nThe Great Gatsby at Standard Ebooks\\nThe Great Gatsby at Google Books\\n\\n The Great Gatsby at Project Gutenberg\\n The Great Gatsby public domain audiobook at LibriVox\\nThe Great Gatsby at Faded Page (Canada)\\n\"An Index to The Great Gatsby\"\\nThe Great Gatsby \u2013 \"A Book by Its Covers\" at T: The New York Times Style Magazine."}
{"article_name": "Neptune", "link": "https://en.wikipedia.org/wiki/Neptune", "text_content": "Neptune is the eighth and farthest planet from the Sun. It is the fourth-largest planet in the Solar System by diameter, the third-most-massive planet, and the densest giant planet. It is 17 times the mass of Earth, and slightly more massive than its near-twin Uranus. Neptune is denser and physically smaller than Uranus because its greater mass causes more gravitational compression of its atmosphere. Being composed primarily of gases and liquids, it has no well-defined solid surface. The planet orbits the Sun once every 164.8 years at an orbital distance of 30.1 astronomical units (4.5 billion kilometres; 2.8 billion miles). It is named after the Roman god of the sea and has the astronomical symbol , representing Neptune's trident.Neptune is not visible to the unaided eye and is the only planet in the Solar System found by mathematical predictions rather than by empirical observation. Unexpected changes in the orbit of Uranus led Alexis Bouvard to hypothesise that its orbit was subject to gravitational perturbation by an unknown planet. After Bouvard's death, the position of Neptune was predicted from his observations, independently, by John Couch Adams and Urbain Le Verrier. Neptune was subsequently observed with a telescope on 23 September 1846 by Johann Gottfried Galle within a degree of the position predicted by Le Verrier. Its largest moon, Triton, was discovered shortly thereafter, though none of the planet's remaining 14 known moons were located telescopically until the 20th century. The planet's distance from Earth gives it a very small apparent size, making it challenging to study with Earth-based telescopes. Neptune was visited by Voyager 2, when it flew by the planet on 25 August 1989; Voyager 2 remains the only spacecraft to have visited Neptune. The advent of the Hubble Space Telescope and large ground-based telescopes with adaptive optics has allowed for additional detailed observations from afar.\\nLike the gas giants (Jupiter and Saturn), Neptune's atmosphere is composed primarily of hydrogen and helium, along with traces of hydrocarbons and possibly nitrogen, but contains a higher proportion of ices such as water, ammonia and methane. Similar to Uranus, its interior is primarily composed of ices and rock; both planets are normally considered \"ice giants\" to distinguish them. Along with Rayleigh scattering, traces of methane in the outermost regions in part account for the planet's blue appearance. The blue colour is slightly more saturated than that of Uranus due to the thinner haze of Neptune's more active atmosphere.In contrast to the strongly seasonal atmosphere of Uranus, which can appear featureless for long periods of time, Neptune's atmosphere has consistently active and visible weather patterns. For example, at the time of the Voyager 2 flyby in 1989, the planet's southern hemisphere had a Great Dark Spot comparable to the Great Red Spot on Jupiter. In 2018, a newer main dark spot and smaller dark spot were identified and studied. These weather patterns are driven by the strongest sustained winds of any planet in the Solar System, with recorded wind speeds as high as 2,100 km/h (580 m/s; 1,300 mph). Because of its great distance from the Sun, Neptune's outer atmosphere is one of the coldest places in the Solar System, with temperatures at its cloud tops approaching 55 K (\u2212218 \u00b0C; \u2212361 \u00b0F). Temperatures at the planet's centre are approximately 5,400 K (5,100 \u00b0C; 9,300 \u00b0F). Neptune has a faint and fragmented ring system (labelled \"arcs\"), which was discovered in 1984, then later confirmed by Voyager 2.\\n\\nHistory\\nDiscovery\\nSome of the earliest recorded observations ever made through a telescope, Galileo Galilei's drawings on 28 December 1612 and 27 January 1613 contain plotted points that match with what is now known to have been the positions of Neptune on those dates. On both occasions, Galileo seems to have mistaken Neptune for a fixed star when it appeared close\u2014in conjunction\u2014to Jupiter in the night sky. Hence, he is not credited with Neptune's discovery. At his first observation in December 1612, Neptune was almost stationary in the sky because it had just turned retrograde that day. This apparent backward motion is created when Earth's orbit takes it past an outer planet. Because Neptune was only beginning its yearly retrograde cycle, the motion of the planet was far too slight to be detected with Galileo's small telescope. In 2009, a study suggested that Galileo was at least aware that the \"star\" he had observed had moved relative to fixed stars.In 1821, Alexis Bouvard published astronomical tables of the orbit of Neptune's neighbour Uranus. Subsequent observations revealed substantial deviations from the tables, leading Bouvard to hypothesise that an unknown body was perturbing the orbit through gravitational interaction. In 1843, John Couch Adams began work on the orbit of Uranus using the data he had. He requested extra data from Sir George Airy, the Astronomer Royal, who supplied it in February 1844. Adams continued to work in 1845\u20131846 and produced several different estimates of a new planet.\\nIn 1845\u20131846, Urbain Le Verrier, independently of Adams, developed his own calculations but aroused no enthusiasm in his compatriots. In June 1846, upon seeing Le Verrier's first published estimate of the planet's longitude and its similarity to Adams's estimate, Airy persuaded James Challis to search for the planet. Challis vainly scoured the sky throughout August and September. Challis had, in fact, observed Neptune a year before the planet's subsequent discoverer, Johann Gottfried Galle, and on two occasions, 4 and 12 August 1845. However, his out-of-date star maps and poor observing techniques meant that he failed to recognise the observations as such until he carried out later analysis. Challis was full of remorse but blamed his neglect on his maps and the fact that he was distracted by his concurrent work on comet observations.Meanwhile, Le Verrier sent a letter and urged Berlin Observatory astronomer Galle to search with the observatory's refractor. Heinrich d'Arrest, a student at the observatory, suggested to Galle that they could compare a recently drawn chart of the sky in the region of Le Verrier's predicted location with the current sky to seek the displacement characteristic of a planet, as opposed to a fixed star. On the evening of 23 September 1846, the day Galle received the letter, he discovered Neptune just northeast of Iota Aquarii, 1\u00b0 from the \"five degrees east of Delta Capricorn\" position Le Verrier had predicted it to be, about 12\u00b0 from Adams's prediction, and on the border of Aquarius and Capricornus according to the modern IAU constellation boundaries.\\nIn the wake of the discovery, there was a heated nationalistic rivalry between the French and the British over who deserved credit for the discovery. Eventually, an international consensus emerged that Le Verrier and Adams deserved joint credit. Since 1966, Dennis Rawlins has questioned the credibility of Adams's claim to co-discovery, and the issue was re-evaluated by historians with the return in 1998 of the \"Neptune papers\" (historical documents) to the Royal Observatory, Greenwich.\\n\\nNaming\\nShortly after its discovery, Neptune was referred to simply as \"the planet exterior to Uranus\" or as \"Le Verrier's planet\". The first suggestion for a name came from Galle, who proposed the name Janus. In England, Challis put forward the name Oceanus.Claiming the right to name his discovery, Le Verrier quickly proposed the name Neptune for this new planet, though falsely stating that this had been officially approved by the French Bureau des Longitudes. In October, he sought to name the planet Le Verrier, after himself, and he had loyal support in this from the observatory director, Fran\u00e7ois Arago. This suggestion met with stiff resistance outside France. French almanacs quickly reintroduced the name Herschel for Uranus, after that planet's discoverer Sir William Herschel, and Leverrier for the new planet.Struve came out in favour of the name Neptune on 29 December 1846, to the Saint Petersburg Academy of Sciences, after the colour of the planet as viewed through a telescope. Soon, Neptune became the internationally accepted name. In Roman mythology, Neptune was the god of the sea, identified with the Greek Poseidon. The demand for a mythological name seemed to be in keeping with the nomenclature of the other planets, all of which were named for deities in Greek and Roman mythology.Most languages today use some variant of the name \"Neptune\" for the planet; indeed, in Chinese, Vietnamese, Japanese, and Korean, the planet's name was translated as \"sea king star\" (\u6d77\u738b\u661f). In Mongolian, Neptune is called Dalain van (\u0414\u0430\u043b\u0430\u0439\u043d \u0432\u0430\u043d), reflecting its namesake god's role as the ruler of the sea. In modern Greek the planet is called Poseidon (\u03a0\u03bf\u03c3\u03b5\u03b9\u03b4\u03ce\u03bd\u03b1\u03c2, Poseidonas), the Greek counterpart of Neptune. In Hebrew, Rahab (\u05e8\u05d4\u05d1), from a Biblical sea monster mentioned in the Book of Psalms, was selected in a vote managed by the Academy of the Hebrew Language in 2009 as the official name for the planet, even though the existing Latin term Neptun (\u05e0\u05e4\u05d8\u05d5\u05df) is commonly used. In M\u0101ori, the planet is called Tangaroa, named after the M\u0101ori god of the sea. In Nahuatl, the planet is called Tl\u0101locc\u012btlalli, named after the rain god Tl\u0101loc. In Thai, Neptune is referred to by its Westernised name Dao Nepchun/Nepjun (\u0e14\u0e32\u0e27\u0e40\u0e19\u0e1b\u0e08\u0e39\u0e19), but is also called Dao Ket (\u0e14\u0e32\u0e27\u0e40\u0e01\u0e15\u0e38, lit.\u2009'star of Ketu'), after Ketu (\u0915\u0947\u0924\u0941), the descending lunar node, who plays a role in Hindu astrology. In Malay, the name Waruna, after the Hindu god of seas, is attested as far back as the 1970s, but was eventually superseded by the Latinate equivalents Neptun (in Malaysian) or Neptunus (in Indonesian).\\nThe usual adjectival form is Neptunian. The nonce form Poseidean (), from Poseidon, has also been used, though the usual adjectival form of Poseidon is Poseidonian ().\\n\\nStatus\\nFrom its discovery in 1846 until the discovery of Pluto in 1930, Neptune was the farthest known planet. When Pluto was discovered, it was considered a planet, and Neptune thus became the second-farthest known planet, except for a 20-year period between 1979 and 1999 when Pluto's elliptical orbit brought it closer than Neptune to the Sun, making Neptune the ninth planet from the Sun during this period. The increasingly accurate estimations of Pluto's mass from ten times that of Earth's to far less than that of the Moon and the discovery of the Kuiper belt in 1992 led many astronomers to debate whether Pluto should be considered a planet or as part of the Kuiper belt. In 2006, the International Astronomical Union defined the word \"planet\" for the first time, reclassifying Pluto as a \"dwarf planet\" and making Neptune once again the outermost-known planet in the Solar System.\\n\\nPhysical characteristics\\nNeptune's mass of 1.0243\u00d71026 kg is intermediate between Earth and the larger gas giants: it is 17 times that of Earth but just 1/19th that of Jupiter. Its gravity at 1 bar is 11.15 m/s2, 1.14 times the surface gravity of Earth, and surpassed only by Jupiter. Neptune's equatorial radius of 24,764 km is nearly four times that of Earth. Neptune, like Uranus, is an ice giant, a subclass of giant planet, because they are smaller and have higher concentrations of volatiles than Jupiter and Saturn. In the search for exoplanets, Neptune has been used as a metonym: discovered bodies of similar mass are often referred to as \"Neptunes\", just as scientists refer to various extrasolar bodies as \"Jupiters\".\\n\\nInternal structure\\nNeptune's internal structure resembles that of Uranus. Its atmosphere forms about 5 to 10% of its mass and extends perhaps 10 to 20% of the way towards the core. Pressure in the atmosphere reaches about 10 GPa, or about 100,000 times that of Earth's atmosphere. Increasing concentrations of methane, ammonia and water are found in the lower regions of the atmosphere.\\nThe mantle is equivalent to 10 to 15 Earth masses and is rich in water, ammonia and methane. As is customary in planetary science, this mixture is referred to as icy even though it is a hot, dense fluid (supercritical fluid). This fluid, which has a high electrical conductivity, is sometimes called a water\u2013ammonia ocean. The mantle may consist of a layer of ionic water in which the water molecules break down into a soup of hydrogen and oxygen ions, and deeper down superionic water in which the oxygen crystallises but the hydrogen ions float around freely within the oxygen lattice. At a depth of 7,000 km, the conditions may be such that methane decomposes into diamond crystals that rain downwards like hailstones. Scientists also believe that this kind of diamond rain occurs on Jupiter, Saturn, and Uranus. Very-high-pressure experiments at the Lawrence Livermore National Laboratory suggest that the top of the mantle may be an ocean of liquid carbon with floating solid 'diamonds'.The core of Neptune is likely composed of iron, nickel and silicates, with an interior model giving a mass about 1.2 times that of Earth. The pressure at the centre is 7 Mbar (700 GPa), about twice as high as that at the centre of Earth, and the temperature may be 5,400 K.\\n\\nAtmosphere\\nAt high altitudes, Neptune's atmosphere is 80% hydrogen and 19% helium. A trace amount of methane is also present. Prominent absorption bands of methane exist at wavelengths above 600 nm, in the red and infrared portion of the spectrum. As with Uranus, this absorption of red light by atmospheric methane is part of what gives Neptune its blue hue, although Neptune's blue differs from Uranus's milder light blue due to concentrated haze in the latter atmosphere.\\nNeptune's atmosphere is subdivided into two main regions: the lower troposphere, where temperature decreases with altitude, and the stratosphere, where temperature increases with altitude. The boundary between the two, the tropopause, lies at a pressure of 0.1 bars (10 kPa). The stratosphere then gives way to the thermosphere at a pressure lower than 10\u22125 to 10\u22124 bars (1 to 10 Pa). The thermosphere gradually transitions to the exosphere.\\n\\nModels suggest that Neptune's troposphere is banded by clouds of varying compositions depending on altitude. The upper-level clouds lie at pressures below one bar, where the temperature is suitable for methane to condense. For pressures between one and five bars (100 and 500 kPa), clouds of ammonia and hydrogen sulfide are thought to form. Above a pressure of five bars, the clouds may consist of ammonia, ammonium sulfide, hydrogen sulfide and water. Deeper clouds of water ice should be found at pressures of about 50 bars (5.0 MPa), where the temperature reaches 273 K (0 \u00b0C). Underneath, clouds of ammonia and hydrogen sulfide may be found.High-altitude clouds on Neptune have been observed casting shadows on the opaque cloud deck below. There are also high-altitude cloud bands that wrap around the planet at constant latitudes. These circumferential bands have widths of 50\u2013150 km and lie about 50\u2013110 km above the cloud deck. These altitudes are in the layer where weather occurs, the troposphere. Weather does not occur in the higher stratosphere or thermosphere. In August 2023, the clouds of Neptune vanished, possibly due to \"solar flare\". Thirty years of observations by Hubble Space Telescope and ground-based telescopes showed that Neptune's cloud activity is bound to Solar cycles, and not to the planet's seasons.Neptune's spectra suggest that its lower stratosphere is hazy due to condensation of products of ultraviolet photolysis of methane, such as ethane and ethyne. The stratosphere is also home to trace amounts of carbon monoxide and hydrogen cyanide. The stratosphere of Neptune is warmer than that of Uranus due to the elevated concentration of hydrocarbons.For reasons that remain obscure, the planet's thermosphere is at an anomalously high temperature of about 750 K. The planet is too far from the Sun for this heat to be generated by ultraviolet radiation. One candidate for a heating mechanism is atmospheric interaction with ions in the planet's magnetic field. Other candidates are gravity waves from the interior that dissipate in the atmosphere. The thermosphere contains traces of carbon dioxide and water, which may have been deposited from external sources such as meteorites and dust.\\n\\nMagnetosphere\\nNeptune resembles Uranus in its magnetosphere, with a magnetic field strongly tilted relative to its rotational axis at 47\u00b0 and offset at least 0.55 radius, or about 13,500 km from the planet's physical centre. Before Voyager 2's arrival at Neptune, it was hypothesised that Uranus's tilted magnetosphere was the result of its sideways rotation. In comparing the magnetic fields of the two planets, scientists now think the extreme orientation may be characteristic of flows in the planets' interiors. This field may be generated by convective fluid motions in a thin spherical shell of electrically conducting liquids (probably a combination of ammonia, methane and water) resulting in a dynamo action.The dipole component of the magnetic field at the magnetic equator of Neptune is about 14 microteslas (0.14 G). The dipole magnetic moment of Neptune is about 2.2 \u00d7 1017 T\u00b7m3 (14 \u03bcT\u00b7RN3, where RN is the radius of Neptune). Neptune's magnetic field has a complex geometry that includes relatively large contributions from non-dipolar components, including a strong quadrupole moment that may exceed the dipole moment in strength. By contrast, Earth, Jupiter and Saturn have only relatively small quadrupole moments, and their fields are less tilted from the polar axis. The large quadrupole moment of Neptune may be the result of an offset from the planet's centre and geometrical constraints of the field's dynamo generator.Measurements by Voyager 2 in extreme-ultraviolet and radio frequencies revealed that Neptune has faint and weak but complex and unique aurorae; however, these observations were limited in time and did not contain infrared. Subsequent astronomers using the Hubble Space Telescope have not glimpsed the aurorae, in contrast to the more well-defined aurorae of Uranus.Neptune's bow shock, where the magnetosphere begins to slow the solar wind, occurs at a distance of 34.9 times the radius of the planet. The magnetopause, where the pressure of the magnetosphere counterbalances the solar wind, lies at a distance of 23\u201326.5 times the radius of Neptune. The tail of the magnetosphere extends out to at least 72 times the radius of Neptune, and likely much farther.\\n\\nClimate\\nNeptune's weather is characterised by extremely dynamic storm systems, with winds reaching speeds of almost 600 m/s (2,200 km/h; 1,300 mph)\u2014exceeding supersonic flow. More typically, by tracking the motion of persistent clouds, wind speeds have been shown to vary from 20 m/s in the easterly direction to 325 m/s westward. At the cloud tops, the prevailing winds range in speed from 400 m/s along the equator to 250 m/s at the poles. Most of the winds on Neptune move in a direction opposite the planet's rotation. The general pattern of winds showed prograde rotation at high latitudes vs. retrograde rotation at lower latitudes. The difference in flow direction is thought to be a \"skin effect\" and not due to any deeper atmospheric processes. At 70\u00b0 S latitude, a high-speed jet travels at a speed of 300 m/s.Neptune differs from Uranus in its typical level of meteorological activity. Voyager 2 observed weather phenomena on Neptune during its 1989 flyby, but no comparable phenomena on Uranus during its 1986 fly-by.\\nThe abundance of methane, ethane and acetylene at Neptune's equator is 10\u2013100 times greater than at the poles. This is interpreted as evidence for upwelling at the equator and subsidence near the poles because photochemistry cannot account for the distribution without meridional circulation.In 2007, it was discovered that the upper troposphere of Neptune's south pole was about 10 K warmer than the rest of its atmosphere, which averages approximately 73 K (\u2212200 \u00b0C). The temperature differential is enough to let methane, which elsewhere is frozen in the troposphere, escape into the stratosphere near the pole. The relative \"hot spot\" is due to Neptune's axial tilt, which has exposed the south pole to the Sun for the last quarter of Neptune's year, or roughly 40 Earth years. As Neptune slowly moves towards the opposite side of the Sun, the south pole will be darkened and the north pole illuminated, causing the methane release to shift to the north pole.Because of seasonal changes, the cloud bands in the southern hemisphere of Neptune have been observed to increase in size and albedo. This trend was first seen in 1980. The long orbital period of Neptune results in seasons lasting forty years.\\n\\nStorms\\nIn 1989, the Great Dark Spot, an anticyclonic storm system spanning 13,000 km \u00d7 6,600 km (8,100 mi \u00d7 4,100 mi) was discovered by NASA's Voyager 2 spacecraft. The storm resembled the Great Red Spot of Jupiter. Some five years later, on 2 November 1994, the Hubble Space Telescope did not see the Great Dark Spot on the planet. Instead, a new storm similar to the Great Dark Spot was found in Neptune's northern hemisphere.The Scooter is another storm, a white cloud group farther south than the Great Dark Spot. This nickname first arose during the months leading up to the Voyager 2 encounter in 1989, when they were observed moving at speeds faster than the Great Dark Spot (and images acquired later would subsequently reveal the presence of clouds moving even faster than those that had initially been detected by Voyager 2). The Small Dark Spot is a southern cyclonic storm, the second-most-intense storm observed during the 1989 encounter. It was initially completely dark, but as Voyager 2 approached the planet, a bright core developed and can be seen in most of the highest-resolution images. In 2018, a newer main dark spot and smaller dark spot were identified and studied. In 2023, the first ground-based observation of a dark spot on Neptune was announced.Neptune's dark spots are thought to occur in the troposphere at lower altitudes than the brighter cloud features, so they appear as holes in the upper cloud decks. As they are stable features that can persist for several months, they are thought to be vortex structures. Often associated with dark spots are brighter, persistent methane clouds that form around the tropopause layer. The persistence of companion clouds shows that some former dark spots may continue to exist as cyclones even though they are no longer visible as a dark feature. Dark spots may dissipate when they migrate too close to the equator or possibly through some other, unknown mechanism.\\n\\nInternal heating\\nNeptune's more varied weather when compared to Uranus is due in part to its higher internal heating. The upper regions of Neptune's troposphere reach a low temperature of 51.8 K (\u2212221.3 \u00b0C). At a depth where the atmospheric pressure equals 1 bar (100 kPa), the temperature is 72.00 K (\u2212201.15 \u00b0C). Deeper inside the layers of gas, the temperature rises steadily. As with Uranus, the source of this heating is unknown, but the discrepancy is larger: Uranus only radiates 1.1 times as much energy as it receives from the Sun; whereas Neptune radiates about 2.61 times as much energy as it receives from the Sun. Neptune is the farthest planet from the Sun, and lies over 50% farther from the Sun than Uranus, and receives only 40% of its amount of sunlight, yet its internal energy is sufficient to drive the fastest planetary winds seen in the Solar System. Depending on the thermal properties of its interior, the heat left over from Neptune's formation may be sufficient to explain its current heat flow, though it is more difficult to simultaneously explain Uranus's lack of internal heat while preserving the apparent similarity between the two planets.\\n\\nOrbit and rotation\\nThe average distance between Neptune and the Sun is 4.5 billion km (about 30.1 astronomical units (AU)), and it completes an orbit on average every 164.79 years, subject to a variability of around \u00b10.1 years. The perihelion distance is 29.81 AU; the aphelion distance is 30.33 AU.On 11 July 2011, Neptune completed its first full barycentric orbit since its discovery in 1846, although it did not appear at its exact discovery position in the sky, because Earth was in a different location in its 365.26 day orbit. Because of the motion of the Sun in relation to the barycentre of the Solar System, on 11 July Neptune was also not at its exact discovery position in relation to the Sun; if the more common heliocentric coordinate system is used, the discovery longitude was reached on 12 July 2011.Neptune's orbital eccentricity is only at 0.008678. This makes it the planet in the Solar System with the second most circular orbit after Venus. The orbit of Neptune is inclined 1.77\u00b0 compared to that of Earth.\\nThe axial tilt of Neptune is 28.32\u00b0, which is similar to the tilts of Earth (23\u00b0) and Mars (25\u00b0). As a result, Neptune experiences similar seasonal changes to Earth. The long orbital period of Neptune means that the seasons last for forty Earth years. Its sidereal rotation period (day) is roughly 16.11 hours. Because its axial tilt is comparable to Earth's, the variation in the length of its day over the course of its long year is not any more extreme.\\nBecause Neptune is not a solid body, its atmosphere undergoes differential rotation. The wide equatorial zone rotates with a period of about 18 hours, which is slower than the 16.1-hour rotation of the planet's magnetic field. By contrast, the reverse is true for the polar regions where the rotation period is 12 hours. This differential rotation is the most pronounced of any planet in the Solar System, and it results in strong latitudinal wind shear.\\n\\nOrbital resonances\\nNeptune's orbit has a profound impact on the region directly beyond it, known as the Kuiper belt. The Kuiper belt is a ring of small icy worlds, similar to the asteroid belt but far larger, extending from Neptune's orbit at 30 AU out to about 55 AU from the Sun. Much in the same way that Jupiter's gravity dominates the asteroid belt, shaping its structure, so Neptune's gravity dominates the Kuiper belt. Over the age of the Solar System, certain regions of the Kuiper belt became destabilised by Neptune's gravity, creating gaps in its structure. The region between 40 and 42 AU is an example.There do exist orbits within these empty regions where objects can survive for the age of the Solar System. These resonances occur when Neptune's orbital period is a precise fraction of that of the object, such as 1:2, or 3:4. If, say, an object orbits the Sun once for every two Neptune orbits, it will only complete half an orbit by the time Neptune returns to its original position. The most heavily populated resonance in the Kuiper belt, with over 200 known objects, is the 2:3 resonance. Objects in this resonance complete 2 orbits for every 3 of Neptune, and are known as plutinos because the largest of the known Kuiper belt objects, Pluto, is among them. Although Pluto crosses Neptune's orbit regularly, the 2:3 resonance ensures they can never collide. The 3:4, 3:5, 4:7 and 2:5 resonances are less populated.Neptune has a number of known trojan objects occupying both the Sun\u2013Neptune L4 and L5 Lagrangian points\u2014gravitationally stable regions leading and trailing Neptune in its orbit, respectively. Neptune trojans can be viewed as being in a 1:1 resonance with Neptune. Some Neptune trojans are remarkably stable in their orbits, and are likely to have formed alongside Neptune rather than being captured. The first object identified as associated with Neptune's trailing L5 Lagrangian point was 2008 LC18. Neptune also has a temporary quasi-satellite, (309239) 2007 RW10. The object has been a quasi-satellite of Neptune for about 12,500 years and it will remain in that dynamical state for another 12,500 years.\\n\\nFormation and migration\\nThe formation of the ice giants, Neptune and Uranus, has proven difficult to model precisely. Current models suggest that the matter density in the outer regions of the Solar System was too low to account for the formation of such large bodies from the traditionally accepted method of core accretion, and various hypotheses have been advanced to explain their formation. One is that the ice giants were not formed by core accretion but from instabilities within the original protoplanetary disc and later had their atmospheres blasted away by radiation from a nearby massive OB star.An alternative concept is that they formed closer to the Sun, where the matter density was higher, and then subsequently migrated to their current orbits after the removal of the gaseous protoplanetary disc. This hypothesis of migration after formation is favoured, due to its ability to better explain the occupancy of the populations of small objects observed in the trans-Neptunian region. The current most widely accepted explanation of the details of this hypothesis is known as the Nice model, which explores the effect of a migrating Neptune and the other giant planets on the structure of the Kuiper belt.\\n\\nMoons and rings\\nNeptune has 14 known moons. Triton is the largest Neptunian moon, comprising more than 99.5% of the mass in orbit around Neptune, and it is the only one massive enough to be spheroidal. Triton was discovered by William Lassell just 17 days after the discovery of Neptune itself. Unlike all other large planetary moons in the Solar System, Triton has a retrograde orbit, indicating that it was captured rather than forming in place; it was probably once a dwarf planet in the Kuiper belt. It is close enough to Neptune to be locked into a synchronous rotation, and it is slowly spiralling inward because of tidal acceleration. It will eventually be torn apart, in about 3.6 billion years, when it reaches the Roche limit. In 1989, Triton was the coldest object that had yet been measured in the Solar System, with estimated temperatures of 38 K (\u2212235 \u00b0C). This very low temperature is due to Triton's very high albedo which causes it to reflect a lot of sunlight instead of absorbing it.Neptune's second-known satellite (by order of discovery), the irregular moon Nereid, has one of the most eccentric orbits of any satellite in the Solar System. The eccentricity of 0.7512 gives it an apoapsis that is seven times its periapsis distance from Neptune.From July to September 1989, Voyager 2 discovered six moons of Neptune. Of these, the irregularly shaped Proteus is notable for being as large as a body of its density can be without being pulled into a spherical shape by its own gravity. Although the second-most-massive Neptunian moon, it is only 0.25% the mass of Triton. Neptune's innermost four moons\u2014Naiad, Thalassa, Despina and Galatea\u2014orbit close enough to be within Neptune's rings. The next-farthest out, Larissa, was originally discovered in 1981 when it had occulted a star. This occultation had been attributed to ring arcs, but when Voyager 2 observed Neptune in 1989, Larissa was found to have caused it. Five new irregular moons discovered between 2002 and 2003 were announced in 2004. A new moon and the smallest yet, Hippocamp, was found in 2013 by combining multiple Hubble images. Because Neptune was the Roman god of the sea, Neptune's moons have been named after lesser sea gods.\\n\\nPlanetary rings\\nNeptune has a planetary ring system, though one much less substantial than that of Saturn. The rings may consist of ice particles coated with silicates or carbon-based material, which most likely gives them a reddish hue. The three main rings are the narrow Adams Ring, 63,000 km from the centre of Neptune, the Le Verrier Ring, at 53,000 km, and the broader, fainter Galle Ring, at 42,000 km. A faint outward extension to the Le Verrier Ring has been named Lassell; it is bounded at its outer edge by the Arago Ring at 57,000 km.The first of these planetary rings was detected in 1968 by a team led by Edward Guinan. In the early 1980s, analysis of this data along with newer observations led to the hypothesis that this ring might be incomplete.\\nEvidence that the rings might have gaps first arose during a stellar occultation in 1984 when the rings obscured a star on immersion but not on emersion. Images from Voyager 2 in 1989 settled the issue by showing several faint rings.\\nThe outermost ring, Adams, contains five prominent arcs now named Courage, Libert\u00e9, Egalit\u00e9 1, Egalit\u00e9 2 and Fraternit\u00e9 (Courage, Liberty, Equality and Fraternity). The existence of arcs was difficult to explain because the laws of motion would predict that arcs would spread out into a uniform ring over short timescales. Astronomers now estimate that the arcs are corralled into their current form by the gravitational effects of Galatea, a moon just inward from the ring.Earth-based observations announced in 2005 appeared to show that Neptune's rings were much more unstable than previously thought. Images taken from the W. M. Keck Observatory in 2002 and 2003 show considerable decay in the rings when compared to images by Voyager 2. In particular, it seems that the Libert\u00e9 arc might disappear in as little as one century.\\n\\nObservation\\nNeptune brightened about 10% between 1980 and 2000 mostly due to the changing of the seasons. Neptune may continue to brighten as it approaches perihelion in 2042. The apparent magnitude currently ranges from 7.67 to 7.89 with a mean of 7.78 and a standard deviation of 0.06. Prior to 1980, the planet was as faint as magnitude 8.0. Neptune is too faint to be visible to the naked eye. It can be outshone by Jupiter's Galilean moons, the dwarf planet Ceres and the asteroids 4 Vesta, 2 Pallas, 7 Iris, 3 Juno, and 6 Hebe. A telescope or strong binoculars will resolve Neptune as a small blue disk, similar in appearance to Uranus.Because of the distance of Neptune from Earth, its angular diameter only ranges from 2.2 to 2.4 arcseconds, the smallest of the Solar System planets. Its small apparent size makes it challenging to study visually. Most telescopic data was fairly limited until the advent of the Hubble Space Telescope and large ground-based telescopes with adaptive optics (AO). The first scientifically useful observation of Neptune from ground-based telescopes using adaptive optics was commenced in 1997 from Hawaii. Neptune is currently approaching perihelion (closest approach to the Sun) and has been shown to be heating up, with increased atmospheric activity and brightness as a consequence. Combined with technological advancements, ground-based telescopes with adaptive optics are recording increasingly more detailed images of it. Both Hubble and the adaptive-optics telescopes on Earth have made many new discoveries within the Solar System since the mid-1990s, with a large increase in the number of known satellites and moons around the outer planet, among others. In 2004 and 2005, five new small satellites of Neptune with diameters between 38 and 61 kilometres were discovered.From Earth, Neptune goes through apparent retrograde motion every 367 days, resulting in a looping motion against the background stars during each opposition. These loops carried it close to the 1846 discovery coordinates in April and July 2010 and again in October and November 2011.Neptune's 164-year orbital period means that the planet takes an average of 13 years to move through each constellation of the zodiac. In 2011, it completed its first full orbit of the Sun since being discovered and returned to where it was first spotted northeast of Iota Aquarii.Observation of Neptune in the radio-frequency band shows that it is a source of both continuous emission and irregular bursts. Both sources are thought to originate from its rotating magnetic field. In the infrared part of the spectrum, Neptune's storms appear bright against the cooler background, allowing the size and shape of these features to be readily tracked.\\n\\nExploration\\nVoyager 2 is the only spacecraft that has visited Neptune. The spacecraft's closest approach to the planet occurred on 25 August 1989. Because this was the last major planet the spacecraft could visit, it was decided to make a close flyby of the moon Triton, regardless of the consequences to the trajectory, similarly to what was done for Voyager 1's encounter with Saturn and its moon Titan. The images relayed back to Earth from Voyager 2 became the basis of a 1989 PBS all-night program, Neptune All Night.During the encounter, signals from the spacecraft required 246 minutes to reach Earth. Hence, for the most part, Voyager 2's mission relied on preloaded commands for the Neptune encounter. The spacecraft performed a near-encounter with the moon Nereid before it came within 4,400 km of Neptune's atmosphere on 25 August, then passed close to the planet's largest moon Triton later the same day.The spacecraft verified the existence of a magnetic field surrounding the planet and discovered that the field was offset from the centre and tilted in a manner similar to the field around Uranus. Neptune's rotation period was determined using measurements of radio emissions and Voyager 2 also showed that Neptune had a surprisingly active weather system. Six new moons were discovered, and the planet was shown to have more than one ring.The flyby also provided the first accurate measurement of Neptune's mass which was found to be 0.5 percent less than previously calculated. The new figure disproved the hypothesis that an undiscovered Planet X acted upon the orbits of Neptune and Uranus.Since 2018, the China National Space Administration has been studying a concept for a pair of Voyager-like interstellar probes tentatively known as Shensuo. Both probes would be launched in the 2020s and take differing paths to explore opposing ends of the heliosphere; the second probe, IHP-2, would fly by Neptune in January 2038, passing only 1,000 km above the cloud tops, and potentially carry an atmospheric impactor to be released during its approach. Afterward, it will continue on its mission throughout the Kuiper belt toward the tail of the heliosphere, so far unexplored.\\nAfter Voyager 2 and IHP-2's flybys, the next step in scientific exploration of the Neptunian system is considered to be an orbital mission; most proposals have been by NASA, most often for a Flagship orbiter. Such a hypothetical mission is envisioned to be possible in the late 2020s or early 2030s. However, there have been discussions to launch Neptune missions sooner. In 2003, there was a proposal in NASA's \"Vision Missions Studies\" for a \"Neptune Orbiter with Probes\" mission that does Cassini-level science. A subsequent proposal was for Argo, a flyby spacecraft to be launched in 2019, that would visit Jupiter, Saturn, Neptune, and a Kuiper belt object. The focus would be on Neptune and its largest moon Triton to be investigated around 2029. The proposed New Horizons 2 mission (which was later scrapped) might also have done a close flyby of the Neptunian system. Currently a pending proposal for the Discovery program, Trident would conduct a flyby of Neptune and Triton; however, the mission was not selected for Discovery 15 or 16. Neptune Odyssey is the current mission concept for a Neptune orbiter and atmospheric probe being studied as a possible large strategic science mission by NASA that would launch between 2031 and 2033, and arrive at Neptune by 2049. Two notable proposals for a Triton-focused Neptune orbiter mission that would be costed right between the Trident and Odyssey missions (under the New Frontiers program) are Triton Ocean Worlds Surveyor and Nautilus, with cruise stages taking place in the 2031-47 and 2041-56 time periods, respectively.\\n\\nSee also\\nNotes\\nReferences\\nBibliography\\nBurgess, Eric (1991). Far Encounter: The Neptune system. Columbia University Press. ISBN 978-0-231-07412-4.\\nMoore, Patrick (2000). The Data Book of Astronomy. CRC Press. ISBN 978-0-7503-0620-1.\\n\\nFurther reading\\nMiner, Ellis D.; Wessen, Randii R. (2002). Neptune: The Planet, Rings, and Satellites. Springer-Verlag. ISBN 978-1-85233-216-7.\\nStandage, Tom (2001). The Neptune File. Penguin. ISBN 978-0-8027-1363-6.\\n\\nExternal links\\n\\nNASA's Neptune fact sheet\\nNeptune from Bill Arnett's nineplanets.org\\nNeptune Astronomy Cast episode No. 63, includes full transcript.\\nNeptune Profile (archived 15 November 2002) at NASA's Solar System Exploration site\\nInteractive 3D gravity simulation of Neptune and its inner moons Archived 22 September 2020 at the Wayback Machine"}
{"article_name": "Human_evolution", "link": "https://en.wikipedia.org/wiki/Human_evolution", "text_content": "Human evolution is the evolutionary process within the history of primates that led to the emergence of Homo sapiens as a distinct species of the hominid family, which includes all the great apes. This process involved the gradual development of traits such as human bipedalism, dexterity and complex language, as well as interbreeding with other hominins (a tribe of the African hominid subfamily), indicating that human evolution was not linear but weblike. The study of the origins of humans, also called anthropogeny,  anthropogenesis, or  anthropogony, involves several scientific disciplines, including physical and evolutionary anthropology, paleontology, and genetics.Primates diverged from other mammals about 85 million years ago (mya), in the Late Cretaceous period, with their earliest fossils appearing over 55 mya, during the Paleocene. Primates produced successive clades leading to the ape superfamily, which gave rise to the hominid and the gibbon families; these diverged some 15\u201320 mya. African and Asian hominids (including orangutans) diverged about 14 mya. Hominins (including the Australopithecine and Panina subtribes) parted from the Gorillini tribe (gorillas) between 8\u20139 mya; Australopithecine (including the extinct biped ancestors of humans) separated from the Pan genus (containing chimpanzees and bonobos) 4\u20137 mya. The Homo genus is evidenced by the appearance of H. habilis over 2 mya, while anatomically modern humans emerged in Africa approximately 300,000 years ago.\\n\\nBefore Homo\\nEarly evolution of primates\\nThe evolutionary history of primates can be traced back 65 million years. One of the oldest known primate-like mammal species, the Plesiadapis, came from North America; another, Archicebus, came from China. Other similar basal primates were widespread in Eurasia and Africa during the tropical conditions of the Paleocene and Eocene.\\n\\nDavid R. Begun concluded that early primates flourished in Eurasia and that a lineage leading to the African apes and humans, including to Dryopithecus, migrated south from Europe or Western Asia into Africa. The surviving tropical population of primates\u2014which is seen most completely in the Upper Eocene and lowermost Oligocene fossil beds of the Faiyum depression southwest of Cairo\u2014gave rise to all extant primate species, including the lemurs of Madagascar, lorises of Southeast Asia, galagos or \"bush babies\" of Africa, and to the anthropoids, which are the Platyrrhines or New World monkeys, the Catarrhines or Old World monkeys, and the great apes, including humans and other hominids.\\nThe earliest known catarrhine is Kamoyapithecus from the uppermost Oligocene at Eragaleit in the northern Great Rift Valley in Kenya, dated to 24 million years ago. Its ancestry is thought to be species related to Aegyptopithecus, Propliopithecus, and Parapithecus from the Faiyum, at around 35 mya. In 2010, Saadanius was described as a close relative of the last common ancestor of the crown catarrhines, and tentatively dated to 29\u201328 mya, helping to fill an 11-million-year gap in the fossil record.\\nIn the Early Miocene, about 22 million years ago, the many kinds of arboreally adapted primitive catarrhines from East Africa suggest a long history of prior diversification. Fossils at 20 million years ago include fragments attributed to Victoriapithecus, the earliest Old World monkey. Among the genera thought to be in the ape lineage leading up to 13 million years ago are Proconsul, Rangwapithecus, Dendropithecus, Limnopithecus, Nacholapithecus, Equatorius, Nyanzapithecus, Afropithecus, Heliopithecus, and Kenyapithecus, all from East Africa.\\nThe presence of other generalized non-cercopithecids of Middle Miocene from sites far distant\u2014Otavipithecus from cave deposits in Namibia, and Pierolapithecus and Dryopithecus from France, Spain and Austria\u2014is evidence of a wide diversity of forms across Africa and the Mediterranean basin during the relatively warm and equable climatic regimes of the Early and Middle Miocene. The youngest of the Miocene hominoids, Oreopithecus, is from coal beds in Italy that have been dated to 9 million years ago.\\nMolecular evidence indicates that the lineage of gibbons diverged from the line of great apes some 18\u201312 mya, and that of orangutans (subfamily Ponginae) diverged from the other great apes at about 12 million years; there are no fossils that clearly document the ancestry of gibbons, which may have originated in a so-far-unknown Southeast Asian hominoid population, but fossil proto-orangutans may be represented by Sivapithecus from India and Griphopithecus from Turkey, dated to around 10 mya.Hominidae subfamily Homininae (African hominids) diverged from Ponginae (orangutans) about 14 mya. Hominins (including humans and the Australopithecine and Panina subtribes) parted from the Gorillini tribe (gorillas) between 8\u20139 mya; Australopithecine (including the extinct biped ancestors of humans) separated from the Pan genus (containing chimpanzees and bonobos) 4\u20137 mya. The Homo genus is evidenced by the appearance of H. habilis over 2 mya, while anatomically modern humans emerged in Africa approximately 300,000 years ago.\\n\\nDivergence of the human clade from other great apes\\nSpecies close to the last common ancestor of gorillas, chimpanzees and humans may be represented by Nakalipithecus fossils found in Kenya and Ouranopithecus found in Greece. Molecular evidence suggests that between 8 and 4 million years ago, first the gorillas, and then the chimpanzees (genus Pan) split off from the line leading to the humans. Human DNA is approximately 98.4% identical to that of chimpanzees when comparing single nucleotide polymorphisms (see human evolutionary genetics). The fossil record, however, of gorillas and chimpanzees is limited; both poor preservation \u2013 rain forest soils tend to be acidic and dissolve bone \u2013 and sampling bias probably contribute to this problem.\\nOther hominins probably adapted to the drier environments outside the equatorial belt; and there they encountered antelope, hyenas, dogs, pigs, elephants, horses, and others. The equatorial belt contracted after about 8 million years ago, and there is very little fossil evidence for the split\u2014thought to have occurred around that time\u2014of the hominin lineage from the lineages of gorillas and chimpanzees. The earliest fossils argued by some to belong to the human lineage are Sahelanthropus tchadensis (7 Ma) and Orrorin tugenensis (6 Ma), followed by Ardipithecus (5.5\u20134.4 Ma), with species Ar. kadabba and Ar. ramidus.\\nIt has been argued in a study of the life history of Ar. ramidus that the species provides evidence for a suite of anatomical and behavioral adaptations in very early hominins unlike any species of extant great ape. This study demonstrated affinities between the skull morphology of Ar. ramidus and that of infant and juvenile chimpanzees, suggesting the species evolved a juvenalised or paedomorphic craniofacial morphology via heterochronic dissociation of growth trajectories. It was also argued that the species provides support for the notion that very early hominins, akin to bonobos (Pan paniscus) the less aggressive species of the genus Pan, may have evolved via the process of self-domestication. Consequently, arguing against the so-called \"chimpanzee referential model\" the authors suggest it is no longer tenable to use chimpanzee (Pan troglodytes) social and mating behaviors in models of early hominin social evolution. When commenting on the absence of aggressive canine morphology in Ar. ramidus and the implications this has for the evolution of hominin social psychology, they wrote:\\n\\nOf course Ar. ramidus differs significantly from bonobos, bonobos having retained a functional canine honing complex. However, the fact that Ar. ramidus shares with bonobos reduced sexual dimorphism, and a more paedomorphic form relative to chimpanzees, suggests that the developmental and social adaptations evident in bonobos may be of assistance in future reconstructions of early hominin social and sexual psychology. In fact the trend towards increased maternal care, female mate selection and self-domestication may have been stronger and more refined in Ar. ramidus than what we see in bonobos.:\u200a128\u200a\\nThe authors argue that many of the basic human adaptations evolved in the ancient forest and woodland ecosystems of late Miocene and early Pliocene Africa. Consequently, they argue that humans may not represent evolution from a chimpanzee-like ancestor as has traditionally been supposed. This suggests many modern human adaptations represent phylogenetically deep traits and that the behavior and morphology of chimpanzees may have evolved subsequent to the split with the common ancestor they share with humans.\\n\\nGenus Australopithecus\\nThe genus Australopithecus evolved in eastern Africa around 4 million years ago before spreading throughout the continent and eventually becoming extinct 2 million years ago. During this time period various forms of australopiths existed, including Australopithecus anamensis, Au. afarensis, Au. sediba, and Au. africanus. There is still some debate among academics whether certain African hominid species of this time, such as Au. robustus and Au. boisei, constitute members of the same genus; if so, they would be considered to be Au. robust australopiths whilst the others would be considered Au. gracile australopiths. However, if these species do indeed constitute their own genus, then they may be given their own name, Paranthropus.\\n\\nAustralopithecus (4\u20131.8 Ma), with species Au. anamensis, Au. afarensis, Au. africanus, Au. bahrelghazali, Au. garhi, and Au. sediba;\\nKenyanthropus (3\u20132.7 Ma), with species K. platyops;\\nParanthropus (3\u20131.2 Ma), with species P. aethiopicus, P. boisei, and P. robustusA new proposed species Australopithecus deyiremeda is claimed to have been discovered living at the same time period of Au. afarensis. There is debate if Au. deyiremeda is a new species or is Au. afarensis. Australopithecus prometheus, otherwise known as Little Foot has recently been dated at 3.67 million years old through a new dating technique, making the genus Australopithecus as old as afarensis. Given the opposable big toe found on Little Foot, it seems that the specimen was a good climber. It is thought given the night predators of the region that he built a nesting platform at night in the trees in a similar fashion to chimpanzees and gorillas.\\n\\nEvolution of genus Homo\\nThe earliest documented representative of the genus Homo is Homo habilis, which evolved around 2.8 million years ago, and is arguably the earliest species for which there is positive evidence of the use of stone tools. The brains of these early hominins were about the same size as that of a chimpanzee, although it has been suggested that this was the time in which the human SRGAP2 gene doubled, producing a more rapid wiring of the frontal cortex. During the next million years a process of rapid encephalization occurred, and with the arrival of Homo erectus and Homo ergaster in the fossil record, cranial capacity had doubled to 850 cm3. (Such an increase in human brain size is equivalent to each generation having 125,000 more neurons than their parents.) It is believed that H. erectus and H. ergaster were the first to use fire and complex tools, and were the first of the hominin line to leave Africa, spreading throughout Africa, Asia, and Europe between 1.3 to 1.8 million years ago.\\n\\nAccording to the recent African origin of modern humans theory, modern humans evolved in Africa possibly from H. heidelbergensis, H. rhodesiensis or H. antecessor and migrated out of the continent some 50,000 to 100,000 years ago, gradually replacing local populations of H. erectus, Denisova hominins, H. floresiensis, H. luzonensis and H. neanderthalensis. Archaic Homo sapiens, the forerunner of anatomically modern humans, evolved in the Middle Paleolithic between 400,000 and 250,000 years ago. Recent DNA evidence suggests that several haplotypes of Neanderthal origin are present among all non-African populations, and Neanderthals and other hominins, such as Denisovans, may have contributed up to 6% of their genome to present-day humans, suggestive of a limited interbreeding between these species. The transition to behavioral modernity with the development of symbolic culture, language, and specialized lithic technology happened around 50,000 years ago, according to some anthropologists, although others point to evidence that suggests that a gradual change in behavior took place over a longer time span.Homo sapiens is the only extant species of its genus, Homo. While some (extinct) Homo species might have been ancestors of Homo sapiens, many, perhaps most, were likely \"cousins\", having speciated away from the ancestral hominin line. There is yet no consensus as to which of these groups should be considered a separate species and which should be a subspecies; this may be due to the dearth of fossils or to the slight differences used to classify species in the genus Homo. The Sahara pump theory (describing an occasionally passable \"wet\" Sahara desert) provides one possible explanation of the early variation in the genus Homo.\\nBased on archaeological and paleontological evidence, it has been possible to infer, to some extent, the ancient dietary practices of various Homo species and to study the role of diet in physical and behavioral evolution within Homo.Some anthropologists and archaeologists subscribe to the Toba catastrophe theory, which posits that the supereruption of Lake Toba on Sumatran island in Indonesia some 70,000 years ago caused global consequences, killing the majority of humans and creating a population bottleneck that affected the genetic inheritance of all humans today. The genetic and archaeological evidence for this remains in question however. Nonetheless, on 31 August 2023, researchers reported, based on genetic studies, that a human ancestor population bottleneck (from a possible 100,000 to 1000 individuals) occurred \"around 930,000 and 813,000 years ago ... lasted for about 117,000 years and brought human ancestors close to extinction.\"\\n\\nH. habilis and H. gautengensis\\nHomo habilis lived from about 2.8 to 1.4 Ma. The species evolved in South and East Africa in the Late Pliocene or Early Pleistocene, 2.5\u20132 Ma, when it diverged from the australopithecines with the development of smaller molars and larger brains. One of the first known hominins, it made tools from stone and perhaps animal bones, leading to its name homo habilis (Latin 'handy man') bestowed by discoverer Louis Leakey. Some scientists have proposed moving this species from Homo into Australopithecus due to the morphology of its skeleton being more adapted to living in trees rather than walking on two legs like later hominins.In May 2010, a new species, Homo gautengensis, was discovered in South Africa.\\n\\nH. rudolfensis and H. georgicus\\nThese are proposed species names for fossils from about 1.9\u20131.6 Ma, whose relation to Homo habilis is not yet clear.\\n\\nHomo rudolfensis refers to a single, incomplete skull from Kenya. Scientists have suggested that this was a specimen of Homo habilis, but this has not been confirmed.\\nHomo georgicus, from Georgia, may be an intermediate form between Homo habilis and Homo erectus, or a subspecies of Homo erectus.\\n\\nH. ergaster and H. erectus\\nThe first fossils of Homo erectus were discovered by Dutch physician Eugene Dubois in 1891 on the Indonesian island of Java. He originally named the material Anthropopithecus erectus (1892\u20131893, considered at this point as a chimpanzee-like fossil primate) and Pithecanthropus erectus (1893\u20131894, changing his mind as of based on its morphology, which he considered to be intermediate between that of humans and apes). Years later, in the 20th century, the German physician and paleoanthropologist Franz Weidenreich (1873\u20131948) compared in detail the characters of Dubois' Java Man, then named Pithecanthropus erectus, with the characters of the Peking Man, then named Sinanthropus pekinensis. Weidenreich concluded in 1940 that because of their anatomical similarity with modern humans it was necessary to gather all these specimens of Java and China in a single species of the genus Homo, the species H. erectus.Homo erectus lived from about 1.8 Ma to about 70,000 years ago \u2013 which would indicate that they were probably wiped out by the Toba catastrophe; however, nearby H. floresiensis survived it. The early phase of H. erectus, from 1.8 to 1.25 Ma, is considered by some to be a separate species, H. ergaster, or as H. erectus ergaster, a subspecies of H. erectus. Many paleoanthropologists now use the term Homo ergaster for the non-Asian forms of this group, and reserve H. erectus only for those fossils that are found in Asia and meet certain skeletal and dental requirements which differ slightly from H. ergaster.\\nIn Africa in the Early Pleistocene, 1.5\u20131 Ma, some populations of Homo habilis are thought to have evolved larger brains and to have made more elaborate stone tools; these differences and others are sufficient for anthropologists to classify them as a new species, Homo erectus\u2014in Africa. The evolution of locking knees and the movement of the foramen magnum are thought to be likely drivers of the larger population changes. This species also may have used fire to cook meat. Richard Wrangham  notes that Homo seems to have been ground dwelling, with reduced intestinal length, smaller dentition, and \"brains [swollen] to their current, horrendously fuel-inefficient size\", and hypothesizes that control of fire and cooking, which released increased nutritional value, was the key adaptation that separated Homo from tree-sleeping Australopithecines.\\n\\nH. cepranensis and H. antecessor\\nThese are proposed as species intermediate between H. erectus and H. heidelbergensis.\\n\\nH. antecessor is known from fossils from Spain and England that are dated 1.2 Ma\u2013500 ka.\\nH. cepranensis refers to a single skull cap from Italy, estimated to be about 800,000 years old.\\n\\nH. heidelbergensis\\nH. heidelbergensis (\"Heidelberg Man\") lived from about 800,000 to about 300,000 years ago. Also proposed as Homo sapiens heidelbergensis or Homo sapiens paleohungaricus.\\n\\nH. rhodesiensis, and the Gawis cranium\\nH. rhodesiensis, estimated to be 300,000\u2013125,000 years old. Most current researchers place Rhodesian Man within the group of Homo heidelbergensis, though other designations such as archaic Homo sapiens and Homo sapiens rhodesiensis have been proposed.\\nIn February 2006 a fossil, the Gawis cranium, was found which might possibly be a species intermediate between H. erectus and H. sapiens or one of many evolutionary dead ends. The skull from Gawis, Ethiopia, is believed to be 500,000\u2013250,000 years old. Only summary details are known, and the finders have not yet released a peer-reviewed study. Gawis man's facial features suggest its being either an intermediate species or an example of a \"Bodo man\" female.\\n\\nNeanderthal and Denisovan\\nHomo neanderthalensis, alternatively designated as Homo sapiens neanderthalensis, lived in Europe and Asia from 400,000 to about 28,000 years ago.\\nThere are a number of clear anatomical differences between anatomically modern humans (AMH) and Neanderthal specimens, many relating to the superior Neanderthal adaptation to cold environments. Neanderthal surface to volume ratio was even lower than that among modern Inuit populations, indicating superior retention of body heat.\\nNeanderthals also had significantly larger brains, as shown from brain endocasts, casting doubt on their intellectual inferiority to modern humans. However, the higher body mass of Neanderthals may have required larger brain mass for body control. Also, recent research by Pearce, Stringer, and Dunbar has shown important differences in brain architecture. The larger size of the Neanderthal orbital chamber and occipital lobe suggests that they had a better visual acuity than modern humans, useful in the dimmer light of glacial Europe.\\nNeanderthals may have had less brain capacity available for social functions. Inferring social group size from endocranial volume (minus occipital lobe size) suggests that Neanderthal groups may have been limited to 120 individuals, compared to 144 possible relationships for modern humans. Larger social groups could imply that modern humans had less risk of inbreeding within their clan, trade over larger areas (confirmed in the distribution of stone tools), and faster spread of social and technological innovations. All these may have all contributed to modern Homo sapiens replacing Neanderthal populations by 28,000 BP.Earlier evidence from sequencing mitochondrial DNA suggested that no significant gene flow occurred between H. neanderthalensis and H. sapiens, and that the two were separate species that shared a common ancestor about 660,000 years ago. However, a sequencing of the Neanderthal genome in 2010 indicated that Neanderthals did indeed interbreed with anatomically modern humans c. 45,000-80,000 years ago, around the time modern humans migrated out from Africa, but before they dispersed throughout Europe, Asia and elsewhere. The genetic sequencing of a 40,000-year-old human skeleton from Romania showed that 11% of its genome was Neanderthal, implying the individual had a Neanderthal ancestor 4\u20136 generations previously, in addition to a contribution from earlier interbreeding in the Middle East. Though this interbred Romanian population seems not to have been ancestral to modern humans, the finding indicates that interbreeding happened repeatedly.All modern non-African humans have about 1% to 4% (or 1.5% to 2.6% by more recent data) of their DNA derived from Neanderthals. This finding is consistent with recent studies indicating that the divergence of some human alleles dates to one Ma, although this interpretation has been questioned. Neanderthals and AMH Homo sapiens could have co-existed in Europe for as long as 10,000 years, during which AMH populations exploded, vastly outnumbering Neanderthals, possibly outcompeting them by sheer numbers.In 2008, archaeologists working at the site of Denisova Cave in the Altai Mountains of Siberia uncovered a small bone fragment from the fifth finger of a juvenile member of another human species, the Denisovans. Artifacts, including a bracelet, excavated in the cave at the same level were carbon dated to around 40,000 BP. As DNA had survived in the fossil fragment due to the cool climate of the Denisova Cave, both mtDNA and nuclear DNA were sequenced.While the divergence point of the mtDNA was unexpectedly deep in time, the full genomic sequence suggested the Denisovans belonged to the same lineage as Neanderthals, with the two diverging shortly after their line split from the lineage that gave rise to modern humans. Modern humans are known to have overlapped with Neanderthals in Europe and the Near East for possibly more than 40,000 years, and the discovery raises the possibility that Neanderthals, Denisovans, and modern humans may have co-existed and interbred. The existence of this distant branch creates a much more complex picture of humankind during the Late Pleistocene than previously thought. Evidence has also been found that as much as 6% of the DNA of some modern Melanesians derive from Denisovans, indicating limited interbreeding in Southeast Asia.Alleles thought to have originated in Neanderthals and Denisovans have been identified at several genetic loci in the genomes of modern humans outside Africa. HLA haplotypes from Denisovans and Neanderthal represent more than half the HLA alleles of modern Eurasians, indicating strong positive selection for these introgressed alleles. Corinne Simoneti at Vanderbilt University, in Nashville and her team have found from medical records of 28,000 people of European descent that the presence of Neanderthal DNA segments may be associated with a higher rate of depression.The flow of genes from Neanderthal populations to modern humans was not all one way. Sergi Castellano of the Max Planck Institute for Evolutionary Anthropology reported in 2016 that while Denisovan and Neanderthal genomes are more related to each other than they are to us, Siberian Neanderthal genomes show more similarity to modern human genes than do European Neanderthal populations. This suggests Neanderthal populations interbred with modern humans around 100,000 years ago, probably somewhere in the Near East.Studies of a Neanderthal child at Gibraltar show from brain development and tooth eruption that Neanderthal children may have matured more rapidly than Homo sapiens.\\n\\nH. floresiensis\\nH. floresiensis, which lived from approximately 190,000 to 50,000 years before present (BP), has been nicknamed the hobbit for its small size, possibly a result of insular dwarfism. H. floresiensis is intriguing both for its size and its age, being an example of a recent species of the genus Homo that exhibits derived traits not shared with modern humans. In other words, H. floresiensis shares a common ancestor with modern humans, but split from the modern human lineage and followed a distinct evolutionary path. The main find was a skeleton believed to be a woman of about 30 years of age. Found in 2003, it has been dated to approximately 18,000 years old. The living woman was estimated to be one meter in height, with a brain volume of just 380 cm3 (considered small for a chimpanzee and less than a third of the H. sapiens average of 1400 cm3).However, there is an ongoing debate over whether H. floresiensis is indeed a separate species. Some scientists hold that H. floresiensis was a modern H. sapiens with pathological dwarfism. This hypothesis is supported in part, because some modern humans who live on Flores, the Indonesian island where the skeleton was found, are pygmies. This, coupled with pathological dwarfism, could have resulted in a significantly diminutive human. The other major attack on H. floresiensis as a separate species is that it was found with tools only associated with H. sapiens.The hypothesis of pathological dwarfism, however, fails to explain additional anatomical features that are unlike those of modern humans (diseased or not) but much like those of ancient members of our genus. Aside from cranial features, these features include the form of bones in the wrist, forearm, shoulder, knees, and feet. Additionally, this hypothesis fails to explain the find of multiple examples of individuals with these same characteristics, indicating they were common to a large population, and not limited to one individual.In 2016, fossil teeth and a partial jaw from hominins assumed to be ancestral to H. floresiensis were discovered at Mata Menge, about 74 km (46 mi) from Liang Bua. They date to about 700,000 years ago and are noted by Australian archaeologist Gerrit van den Bergh for being even smaller than the later fossils.\\n\\nH. luzonensis\\nA small number of specimens from the island of Luzon, dated 50,000 to 67,000 years ago, have recently been assigned by their discoverers, based on dental characteristics, to a novel human species, H. luzonensis.\\n\\nH. sapiens\\nH. sapiens (the adjective sapiens is Latin for \"wise\" or \"intelligent\") emerged in Africa around 300,000 years ago, likely derived from H. heidelbergensis or a related lineage. In September 2019, scientists reported the computerized determination, based on 260 CT scans, of a virtual skull shape of the last common human ancestor to modern humans/H. sapiens, representative of the earliest modern humans, and suggested that modern humans arose between 260,000 and 350,000 years ago through a merging of populations in East and South Africa.Between 400,000 years ago and the second interglacial period in the Middle Pleistocene, around 250,000 years ago, the trend in intra-cranial volume expansion and the elaboration of stone tool technologies developed, providing evidence for a transition from H. erectus to H. sapiens. The direct evidence suggests there was a migration of H. erectus out of Africa, then a further speciation of H. sapiens from H. erectus in Africa. A subsequent migration (both within and out of Africa) eventually replaced the earlier dispersed H. erectus. This migration and origin theory is usually referred to as the \"recent single-origin hypothesis\" or \"out of Africa\" theory. H. sapiens interbred with archaic humans both in Africa and in Eurasia, in Eurasia notably with Neanderthals and Denisovans.The Toba catastrophe theory, which postulates a population bottleneck for H. sapiens about 70,000 years ago, was controversial from its first proposal in the 1990s and by the 2010s had very little support. Distinctive human genetic variability has arisen as the result of the founder effect, by archaic admixture and by recent evolutionary pressures.\\n\\nAnatomical changes\\nSince Homo sapiens separated from its last common ancestor shared with chimpanzees, human evolution is characterized by a number of morphological, developmental, physiological, behavioral, and environmental changes. Environmental (cultural) evolution discovered much later during the Pleistocene played a significant role in human evolution observed via human transitions between subsistence systems. The most significant of these adaptations are bipedalism, increased brain size, lengthened ontogeny (gestation and infancy), and decreased sexual dimorphism. The relationship between these changes is the subject of ongoing debate. Other significant morphological changes included the evolution of a power and precision grip, a change first occurring in H. erectus.\\n\\nBipedalism\\nBipedalism is the basic adaptation of the hominid and is considered the main cause behind a suite of skeletal changes shared by all bipedal hominids. The earliest hominin, of presumably primitive bipedalism, is considered to be either Sahelanthropus or Orrorin, both of which arose some 6 to 7 million years ago. The non-bipedal knuckle-walkers, the gorillas and chimpanzees, diverged from the hominin line over a period covering the same time, so either Sahelanthropus or Orrorin may be our last shared ancestor. Ardipithecus, a full biped, arose approximately 5.6 million years ago.The early bipeds eventually evolved into the australopithecines and still later into the genus Homo. There are several theories of the adaptation value of bipedalism. It is possible that bipedalism was favored because it freed the hands for reaching and carrying food, saved energy during locomotion, enabled long-distance running and hunting, provided an enhanced field of vision, and helped avoid hyperthermia by reducing the surface area exposed to direct sun; features all advantageous for thriving in the new savanna and woodland environment created as a result of the East African Rift Valley uplift versus the previous closed forest habitat. A 2007 study provides support for the hypothesis that walking on two legs, or bipedalism, evolved because it used less energy than quadrupedal knuckle-walking. However, recent studies suggest that bipedality without the ability to use fire would not have allowed global dispersal. This change in gait saw a lengthening of the legs proportionately when compared to the length of the arms, which were shortened through the removal of the need for brachiation. Another change is the shape of the big toe. Recent studies suggest that australopithecines still lived part of the time in trees as a result of maintaining a grasping big toe. This was progressively lost in habilines.\\nAnatomically, the evolution of bipedalism has been accompanied by a large number of skeletal changes, not just to the legs and pelvis, but also to the vertebral column, feet and ankles, and skull. The femur evolved into a slightly more angular position to move the center of gravity toward the geometric center of the body. The knee and ankle joints became increasingly robust to better support increased weight. To support the increased weight on each vertebra in the upright position, the human vertebral column became S-shaped and the lumbar vertebrae became shorter and wider. In the feet the big toe moved into alignment with the other toes to help in forward locomotion. The arms and forearms shortened relative to the legs making it easier to run. The foramen magnum migrated under the skull and more anterior.The most significant changes occurred in the pelvic region, where the long downward facing iliac blade was shortened and widened as a requirement for keeping the center of gravity stable while walking; bipedal hominids have a shorter but broader, bowl-like pelvis due to this. A drawback is that the birth canal of bipedal apes is smaller than in knuckle-walking apes, though there has been a widening of it in comparison to that of australopithecine and modern humans, thus permitting the passage of newborns due to the increase in cranial size. This is limited to the upper portion, since further increase can hinder normal bipedal movement.The shortening of the pelvis and smaller birth canal evolved as a requirement for bipedalism and had significant effects on the process of human birth, which is much more difficult in modern humans than in other primates. During human birth, because of the variation in size of the pelvic region, the fetal head must be in a transverse position (compared to the mother) during entry into the birth canal and rotate about 90 degrees upon exit. The smaller birth canal became a limiting factor to brain size increases in early humans and prompted a shorter gestation period leading to the relative immaturity of human offspring, who are unable to walk much before 12 months and have greater neoteny, compared to other primates, who are mobile at a much earlier age. The increased brain growth after birth and the increased dependency of children on mothers had a major effect upon the female reproductive cycle, and the more frequent appearance of alloparenting in humans when compared with other hominids. Delayed human sexual maturity also led to the evolution of menopause with one explanation, the grandmother hypothesis, providing that elderly women could better pass on their genes by taking care of their daughter's offspring, as compared to having more children of their own.\\n\\nEncephalization\\nThe human species eventually developed a much larger brain than that of other primates\u2014typically 1,330 cm3 (81 cu in) in modern humans, nearly three times the size of a chimpanzee or gorilla brain. After a period of stasis with Australopithecus anamensis and Ardipithecus, species which had smaller brains as a result of their bipedal locomotion, the pattern of encephalization started with Homo habilis, whose 600 cm3 (37 cu in) brain was slightly larger than that of chimpanzees. This evolution continued in Homo erectus with 800\u20131,100 cm3 (49\u201367 cu in), and reached a maximum in Neanderthals with 1,200\u20131,900 cm3 (73\u2013116 cu in), larger even than modern Homo sapiens. This brain increase manifested during postnatal brain growth, far exceeding that of other apes (heterochrony). It also allowed for extended periods of social learning and language acquisition in juvenile humans, beginning as much as 2 million years ago. Encephalization may be due to a dependency on calorie-dense, difficult-to-acquire food.\\nFurthermore, the changes in the structure of human brains may be even more significant than the increase in size. Fossilized skulls shows the brain size in early humans fell within the range of modern humans 300,000 years ago, but only got its present-day brain shape between 100,000 and 35,000 years ago.  The temporal lobes, which contain centers for language processing, have increased disproportionately, as has the prefrontal cortex, which has been related to complex decision-making and moderating social behavior. Encephalization has been tied to increased starches and meat in the diet, however a 2022 meta study called into question the role of meat. Other factors are the development of cooking, and it has been proposed that intelligence increased as a response to an increased necessity for solving social problems as human society became more complex. Changes in skull morphology, such as smaller mandibles and mandible muscle attachments, allowed more room for the brain to grow.The increase in volume of the neocortex also included a rapid increase in size of the cerebellum. Its function has traditionally been associated with balance and fine motor control, but more recently with speech and cognition. The great apes, including hominids, had a more pronounced cerebellum relative to the neocortex than other primates. It has been suggested that because of its function of sensory-motor control and learning complex muscular actions, the cerebellum may have underpinned human technological adaptations, including the preconditions of speech.The immediate survival advantage of encephalization is difficult to discern, as the major brain changes from Homo erectus to Homo heidelbergensis were not accompanied by major changes in technology. It has been suggested that the changes were mainly social and behavioural, including increased empathic abilities, increases in size of social groups, and increased behavioral plasticity. Humans are unique in the ability to acquire information through social transmission and adapt that information. The emerging field of cultural evolution studies human sociocultural change from an evolutionary perspective.\\n\\nSexual dimorphism\\nThe reduced degree of sexual dimorphism in humans is visible primarily in the reduction of the male canine tooth relative to other ape species (except gibbons) and reduced brow ridges and general robustness of males. Another important physiological change related to sexuality in humans was the evolution of hidden estrus. Humans are the only hominoids in which the female is fertile year round and in which no special signals of fertility are produced by the body (such as genital swelling or overt changes in proceptivity during estrus).Nonetheless, humans retain a degree of sexual dimorphism in the distribution of body hair and subcutaneous fat, and in the overall size, males being around 15% larger than females. These changes taken together have been interpreted as a result of an increased emphasis on pair bonding as a possible solution to the requirement for increased parental investment due to the prolonged infancy of offspring.\\n\\nUlnar opposition\\nThe ulnar opposition\u2014the contact between the thumb and the tip of the little finger of the same hand\u2014is unique to the genus Homo, including Neanderthals, the Sima de los Huesos hominins and anatomically modern humans. In other primates, the thumb is short and unable to touch the little finger. The ulnar opposition facilitates the precision grip and power grip of the human hand, underlying all the skilled manipulations.\\n\\nOther changes\\nA number of other changes have also characterized the evolution of humans, among them an increased reliance on vision rather than smell (highly reduced olfactory bulb); a longer juvenile developmental period and higher infant dependency; a smaller gut and small, misaligned teeth; faster basal metabolism; loss of body hair; an increase in\\neccrine sweat gland density that is ten times higher than any other catarrhinian primates, yet humans uses 30% to 50% less water per day compared to chimps and gorillas; more REM sleep but less sleep in total; a change in the shape of the dental arcade from u-shaped to parabolic; development of a chin (found in Homo sapiens alone); styloid processes; and a descended larynx. As the human hand and arms adapted to the making of tools and were used less for climbing, the shoulder blades changed too. As a side effect, it allowed human ancestors to throw objects with greater force, speed and accuracy.\\n\\nUse of tools\\nThe use of tools has been interpreted as a sign of intelligence, and it has been theorized that tool use may have stimulated certain aspects of human evolution, especially the continued expansion of the human brain. Paleontology has yet to explain the expansion of this organ over millions of years despite being extremely demanding in terms of energy consumption. The brain of a modern human consumes, on average, about 13 watts (260 kilocalories per day), a fifth of the body's resting power consumption. Increased tool use would allow hunting for energy-rich meat products, and would enable processing more energy-rich plant products. Researchers have suggested that early hominins were thus under evolutionary pressure to increase their capacity to create and use tools.Precisely when early humans started to use tools is difficult to determine, because the more primitive these tools are (for example, sharp-edged stones) the more difficult it is to decide whether they are natural objects or human artifacts. There is some evidence that the australopithecines (4 Ma) may have used broken bones as tools, but this is debated.Many species make and use tools, but it is the human genus that dominates the areas of making and using more complex tools. The oldest known tools are flakes from West Turkana, Kenya, which date to 3.3 million years ago. The next oldest stone tools are from Gona, Ethiopia, and are considered the beginning of the Oldowan technology. These tools date to about 2.6 million years ago. A Homo fossil was found near some Oldowan tools, and its age was noted at 2.3 million years old, suggesting that maybe the Homo species did indeed create and use these tools. It is a possibility but does not yet represent solid evidence. The third metacarpal styloid process enables the hand bone to lock into the wrist bones, allowing for greater amounts of pressure to be applied to the wrist and hand from a grasping thumb and fingers. It allows humans the dexterity and strength to make and use complex tools. This unique anatomical feature separates humans from apes and other nonhuman primates, and is not seen in human fossils older than 1.8 million years.Bernard Wood noted that Paranthropus co-existed with the early Homo species in the area of the \"Oldowan Industrial Complex\" over roughly the same span of time. Although there is no direct evidence which identifies Paranthropus as the tool makers, their anatomy lends to indirect evidence of their capabilities in this area. Most paleoanthropologists agree that the early Homo species were indeed responsible for most of the Oldowan tools found. They argue that when most of the Oldowan tools were found in association with human fossils, Homo was always present, but Paranthropus was not.In 1994, Randall Susman used the anatomy of opposable thumbs as the basis for his argument that both the Homo and Paranthropus species were toolmakers. He compared bones and muscles of human and chimpanzee thumbs, finding that humans have 3 muscles which are lacking in chimpanzees. Humans also have thicker metacarpals with broader heads, allowing more precise grasping than the chimpanzee hand can perform. Susman posited that modern anatomy of the human opposable thumb is an evolutionary response to the requirements associated with making and handling tools and that both species were indeed toolmakers.\\n\\nTransition to behavioral modernity\\nAnthropologists describe modern human behavior to include cultural and behavioral traits such as specialization of tools, use of jewellery and images (such as cave drawings), organization of living space, rituals (such as grave gifts), specialized hunting techniques, exploration of less hospitable geographical areas, and barter trade networks, as well as more general traits such as language and complex symbolic thinking. Debate continues as to whether a \"revolution\" led to modern humans (\"big bang of human consciousness\"), or whether the evolution was more gradual.Until about 50,000\u201340,000 years ago, the use of stone tools seems to have progressed stepwise. Each phase (H. habilis, H. ergaster, H. neanderthalensis) marked a new technology, followed by very slow development until the next phase. Currently paleoanthropologists are debating whether these Homo species possessed some or many modern human behaviors. They seem to have been culturally conservative, maintaining the same technologies and foraging patterns over very long periods.\\nAround 50,000 BP, human culture started to evolve more rapidly. The transition to behavioral modernity has been characterized by some as a \"Great Leap Forward\", or as the \"Upper Palaeolithic Revolution\", due to the sudden appearance in the archaeological record of distinctive signs of modern behavior and big game hunting. Evidence of behavioral modernity significantly earlier also exists from Africa, with older evidence of abstract imagery, widened subsistence strategies, more sophisticated tools and weapons, and other \"modern\" behaviors, and many scholars have recently argued that the transition to modernity occurred sooner than previously believed.Other scholars consider the transition to have been more gradual, noting that some features had already appeared among archaic African Homo sapiens 300,000\u2013200,000 years ago. Recent evidence suggests that the Australian Aboriginal population separated from the African population 75,000 years ago, and that they made a 160 km (99 mi) sea journey 60,000 years ago, which may diminish the significance of the Upper Paleolithic Revolution.Modern humans started burying their dead, making clothing from animal hides, hunting with more sophisticated techniques (such as using pit traps or driving animals off cliffs), and cave painting. As human culture advanced, different populations innovated existing technologies: artifacts such as fish hooks, buttons, and bone needles show signs of cultural variation, which had not been seen prior to 50,000 BP. Typically, the older H. neanderthalensis populations did not vary in their technologies, although the Chatelperronian assemblages have been found to be Neanderthal imitations of H. sapiens Aurignacian technologies.\\n\\nRecent and ongoing human evolution\\nAnatomically modern human populations continue to evolve, as they are affected by both natural selection and genetic drift. Although selection pressure on some traits, such as resistance to smallpox, has decreased in the modern age, humans are still undergoing natural selection for many other traits. Some of these are due to specific environmental pressures, while others are related to lifestyle changes since the development of agriculture (10,000 years ago), urbanization (5,000), and industrialization (250 years ago). It has been argued that human evolution has accelerated since the development of agriculture 10,000 years ago and civilization some 5,000 years ago, resulting, it is claimed, in substantial genetic differences between different current human populations, and more recent research indicates that for some traits, the developments and innovations of human culture have driven a new form of selection that coexists with, and in some cases has largely replaced, natural selection.\\nParticularly conspicuous is variation in superficial characteristics, such as Afro-textured hair, or the recent evolution of light skin and blond hair in some populations, which are attributed to differences in climate. Particularly strong selective pressures have resulted in high-altitude adaptation in humans, with different ones in different isolated populations. Studies of the genetic basis show that some developed very recently, with Tibetans evolving over 3,000 years to have high proportions of an allele of EPAS1 that is adaptive to high altitudes.\\nOther evolution is related to endemic diseases: the presence of malaria selects for sickle cell trait (the heterozygous form of sickle cell gene), while in the absence of malaria, the health effects of sickle-cell anemia select against this trait. For another example, the population at risk of the severe debilitating disease kuru has significant over-representation of an immune variant of the prion protein gene G127V versus non-immune alleles. The frequency of this genetic variant is due to the survival of immune persons. Some reported trends remain unexplained and the subject of ongoing research in the novel field of evolutionary medicine: polycystic ovary syndrome (PCOS) reduces fertility and thus is expected to be subject to extremely strong negative selection, but its relative commonality in human populations suggests a counteracting selection pressure. The identity of that pressure remains the subject of some debate.Recent human evolution related to agriculture includes genetic resistance to infectious disease that has appeared in human populations by crossing the species barrier from domesticated animals, as well as changes in metabolism due to changes in diet, such as lactase persistence.\\nCulturally-driven evolution can defy the expectations of natural selection:  while human populations experience some pressure that drives a selection for producing children at younger ages, the advent of effective contraception, higher education, and changing social norms have driven the observed selection in the opposite direction. However, culturally-driven selection need not necessarily work counter or in opposition to natural selection:  some proposals to explain the high rate of recent human brain expansion indicate a kind of feedback whereupon the brain's increased social learning efficiency encourages cultural developments that in turn encourage more efficiency, which drive more complex cultural developments that demand still-greater efficiency, and so forth. Culturally-driven evolution has an advantage in that in addition to the genetic effects, it can be observed also in the archaeological record:  the development of stone tools across the Palaeolithic period connects to culturally-driven cognitive development in the form of skill acquisition supported by the culture and the development of increasingly complex technologies and the cognitive ability to elaborate them.In contemporary times, since industrialization, some trends have been observed: for instance, menopause is evolving to occur later. Other reported trends appear to include lengthening of the human reproductive period and reduction in cholesterol levels, blood glucose and blood pressure in some populations.\\n\\nHistory of study\\nBefore Darwin\\nThe word homo, the name of the biological genus to which humans belong, is Latin for \"human\". It was chosen originally by Carl Linnaeus in his classification system. The word \"human\" is from the Latin humanus, the adjectival form of homo. The Latin \"homo\" derives from the Indo-European root *dhghem, or \"earth\". Linnaeus and other scientists of his time also considered the great apes to be the closest relatives of humans based on morphological and anatomical similarities.\\n\\nDarwin\\nThe possibility of linking humans with earlier apes by descent became clear only after 1859 with the publication of Charles Darwin's On the Origin of Species, in which he argued for the idea of the evolution of new species from earlier ones. Darwin's book did not address the question of human evolution, saying only that \"Light will be thrown on the origin of man and his history.\"The first debates about the nature of human evolution arose between Thomas Henry Huxley and Richard Owen. Huxley argued for human evolution from apes by illustrating many of the similarities and differences between humans and other apes, and did so particularly in his 1863 book Evidence as to Man's Place in Nature. Many of Darwin's early supporters (such as Alfred Russel Wallace and Charles Lyell) did not initially agree that the origin of the mental capacities and the moral sensibilities of humans could be explained by natural selection, though this later changed. Darwin applied the theory of evolution and sexual selection to humans in his 1871 book The Descent of Man, and Selection in Relation to Sex.\\n\\nFirst fossils\\nA major problem in the 19th century was the lack of fossil intermediaries. Neanderthal remains were discovered in a limestone quarry in 1856, three years before the publication of On the Origin of Species, and Neanderthal fossils had been discovered in Gibraltar even earlier, but it was originally claimed that these were the remains of a modern human who had suffered some kind of illness. Despite the 1891 discovery by Eug\u00e8ne Dubois of what is now called Homo erectus at Trinil, Java, it was only in the 1920s when such fossils were discovered in Africa, that intermediate species began to accumulate. In 1925, Raymond Dart described Australopithecus africanus. The type specimen was the Taung Child, an australopithecine infant which was discovered in a cave. The child's remains were a remarkably well-preserved tiny skull and an endocast of the brain.\\nAlthough the brain was small (410 cm3), its shape was rounded, unlike that of chimpanzees and gorillas, and more like a modern human brain. Also, the specimen showed short canine teeth, and the position of the foramen magnum (the hole in the skull where the spine enters) was evidence of bipedal locomotion. All of these traits convinced Dart that the Taung Child was a bipedal human ancestor, a transitional form between apes and humans.\\n\\nThe East African fossils\\nDuring the 1960s and 1970s, hundreds of fossils were found in East Africa in the regions of the Olduvai Gorge and Lake Turkana. These searches were carried out by the Leakey family, with Louis Leakey and his wife Mary Leakey, and later their son Richard and daughter-in-law Meave, fossil hunters and paleoanthropologists. From the fossil beds of Olduvai and Lake Turkana they amassed specimens of the early hominins: the australopithecines and Homo species, and even H. erectus.\\nThese finds cemented Africa as the cradle of humankind. In the late 1970s and the 1980s, Ethiopia emerged as the new hot spot of paleoanthropology after \"Lucy\", the most complete fossil member of the species Australopithecus afarensis, was found in 1974 by Donald Johanson near Hadar in the desertic Afar Triangle region of northern Ethiopia. Although the specimen had a small brain, the pelvis and leg bones were almost identical in function to those of modern humans, showing with certainty that these hominins had walked erect. Lucy was classified as a new species, Australopithecus afarensis, which is thought to be more closely related to the genus Homo as a direct ancestor, or as a close relative of an unknown ancestor, than any other known hominid or hominin from this early time range. (The specimen was nicknamed \"Lucy\" after the Beatles' song \"Lucy in the Sky with Diamonds\", which was played loudly and repeatedly in the camp during the excavations.) The Afar Triangle area would later yield discovery of many more hominin fossils, particularly those uncovered or described by teams headed by Tim D. White in the 1990s, including Ardipithecus ramidus and A. kadabba.In 2013, fossil skeletons of Homo naledi, an extinct species of hominin assigned (provisionally) to the genus Homo, were found in the Rising Star Cave system, a site in South Africa's Cradle of Humankind region in Gauteng province near Johannesburg. As of September 2015, fossils of at least fifteen individuals, amounting to 1,550 specimens, have been excavated from the cave. The species is characterized by a body mass and stature similar to small-bodied human populations, a smaller endocranial volume similar to Australopithecus, and a cranial morphology (skull shape) similar to early Homo species. The skeletal anatomy combines primitive features known from australopithecines with features known from early hominins. The individuals show signs of having been deliberately disposed of within the cave near the time of death. The fossils were dated close to 250,000 years ago, and thus are not a direct ancestor but a contemporary with the first appearance of larger-brained anatomically modern humans.\\n\\nThe genetic revolution\\nThe genetic revolution in studies of human evolution started when Vincent Sarich and Allan Wilson measured the strength of immunological cross-reactions of blood serum albumin between pairs of creatures, including humans and African apes (chimpanzees and gorillas). The strength of the reaction could be expressed numerically as an immunological distance, which was in turn proportional to the number of amino acid differences between homologous proteins in different species. By constructing a calibration curve of the ID of species' pairs with known divergence times in the fossil record, the data could be used as a molecular clock to estimate the times of divergence of pairs with poorer or unknown fossil records.\\nIn their seminal 1967 paper in Science, Sarich and Wilson estimated the divergence time of humans and apes as four to five million years ago, at a time when standard interpretations of the fossil record gave this divergence as at least 10 to as much as 30 million years. Subsequent fossil discoveries, notably \"Lucy\", and reinterpretation of older fossil materials, notably Ramapithecus, showed the younger estimates to be correct and validated the albumin method.\\nProgress in DNA sequencing, specifically mitochondrial DNA (mtDNA) and then Y-chromosome DNA (Y-DNA) advanced the understanding of human origins. Application of the molecular clock principle revolutionized the study of molecular evolution.\\nOn the basis of a separation from the orangutan between 10 and 20 million years ago, earlier studies of the molecular clock suggested that there were about 76 mutations per generation that were not inherited by human children from their parents; this evidence supported the divergence time between hominins and chimpanzees noted above. However, a 2012 study in Iceland of 78 children and their parents suggests a mutation rate of only 36 mutations per generation; this datum extends the separation between humans and chimpanzees to an earlier period greater than 7 million years ago (Ma). Additional research with 226 offspring of wild chimpanzee populations in eight locations suggests that chimpanzees reproduce at age 26.5 years on average; which suggests the human divergence from chimpanzees occurred between 7 and 13 mya. And these data suggest that Ardipithecus (4.5 Ma), Orrorin (6 Ma) and Sahelanthropus (7 Ma) all may be on the hominid lineage, and even that the separation may have occurred outside the East African Rift region.\\nFurthermore, analysis of the two species' genes in 2006 provides evidence that after human ancestors had started to diverge from chimpanzees, interspecies mating between \"proto-human\" and \"proto-chimpanzees\" nonetheless occurred regularly enough to change certain genes in the new gene pool:\\n\\nA new comparison of the human and chimpanzee genomes suggests that after the two lineages separated, they may have begun interbreeding... A principal finding is that the X chromosomes of humans and chimpanzees appear to have diverged about 1.2 million years more recently than the other chromosomes.The research suggests:\\n\\nThere were in fact two splits between the human and chimpanzee lineages, with the first being followed by interbreeding between the two populations and then a second split. The suggestion of a hybridization has startled paleoanthropologists, who nonetheless are treating the new genetic data seriously.\\n\\nThe quest for the earliest hominin\\nIn the 1990s, several teams of paleoanthropologists were working throughout Africa looking for evidence of the earliest divergence of the hominin lineage from the great apes. In 1994, Meave Leakey discovered Australopithecus anamensis. The find was overshadowed by Tim D. White's 1995 discovery of Ardipithecus ramidus, which pushed back the fossil record to 4.2 million years ago.\\nIn 2000, Martin Pickford and Brigitte Senut discovered, in the Tugen Hills of Kenya, a 6-million-year-old bipedal hominin which they named Orrorin tugenensis. And in 2001, a team led by Michel Brunet discovered the skull of Sahelanthropus tchadensis which was dated as 7.2 million years ago, and which Brunet argued was a bipedal, and therefore a hominid\u2014that is, a hominin (cf Hominidae; terms \"hominids\" and hominins).\\n\\nHuman dispersal\\nAnthropologists in the 1980s were divided regarding some details of reproductive barriers and migratory dispersals of the genus Homo. Subsequently, genetics has been used to investigate and resolve these issues. According to the Sahara pump theory evidence suggests that the genus Homo have migrated out of Africa at least three and possibly four times (e.g. Homo erectus, Homo heidelbergensis and two or three times for Homo sapiens). Recent evidence suggests these dispersals are closely related to fluctuating periods of climate change.Recent evidence suggests that humans may have left Africa half a million years earlier than previously thought. A joint Franco-Indian team has found human artifacts in the Siwalk Hills north of New Delhi dating back at least 2.6 million years. This is earlier than the previous earliest finding of genus Homo at Dmanisi, in Georgia, dating to 1.85 million years. Although controversial, tools found at a Chinese cave strengthen the case that humans used tools as far back as 2.48 million years ago. This suggests that the Asian \"Chopper\" tool tradition, found in Java and northern China may have left Africa before the appearance of the Acheulian hand axe.\\n\\nDispersal of modern Homo sapiens\\nUp until the genetic evidence became available, there were two dominant models for the dispersal of modern humans. The multiregional hypothesis proposed that the genus Homo contained only a single interconnected population as it does today (not separate species), and that its evolution took place worldwide continuously over the last couple of million years. This model was proposed in 1988 by Milford H. Wolpoff. In contrast, the \"out of Africa\" model proposed that modern H. sapiens speciated in Africa recently (that is, approximately 200,000 years ago) and the subsequent migration through Eurasia resulted in the nearly complete replacement of other Homo species. This model has been developed by Chris Stringer and Peter Andrews.\\nSequencing mtDNA and Y-DNA sampled from a wide range of indigenous populations revealed ancestral information relating to both male and female genetic heritage, and strengthened the \"out of Africa\" theory and weakened the views of multiregional evolutionism. Aligned in genetic tree differences were interpreted as supportive of a recent single origin.\"Out of Africa\" has thus gained much support from research using female mitochondrial DNA and the male Y chromosome. After analysing genealogy trees constructed using 133 types of mtDNA, researchers concluded that all were descended from a female African progenitor, dubbed Mitochondrial Eve. \"Out of Africa\" is also supported by the fact that mitochondrial genetic diversity is highest among African populations.A broad study of African genetic diversity, headed by Sarah Tishkoff, found the San people had the greatest genetic diversity among the 113 distinct populations sampled, making them one of 14 \"ancestral population clusters\". The research also located a possible origin of modern human migration in southwestern Africa, near the coastal border of Namibia and Angola. The fossil evidence was insufficient for archaeologist Richard Leakey to resolve the debate about exactly where in Africa modern humans first appeared. Studies of haplogroups in Y-chromosomal DNA and mitochondrial DNA have largely supported a recent African origin. All the evidence from autosomal DNA also predominantly supports a Recent African origin. However, evidence for archaic admixture in modern humans, both in Africa and later, throughout Eurasia has recently been suggested by a number of studies.Recent sequencing of Neanderthal and Denisovan genomes shows that some admixture with these populations has occurred. All modern human groups outside Africa have 1\u20134% or (according to more recent research) about 1.5\u20132.6% Neanderthal alleles in their genome, and some Melanesians have an additional 4\u20136% of Denisovan alleles. These new results do not contradict the \"out of Africa\" model, except in its strictest interpretation, although they make the situation more complex. After recovery from a genetic bottleneck that some researchers speculate might be linked to the Toba supervolcano catastrophe, a fairly small group left Africa and interbred with Neanderthals, probably in the Middle East, on the Eurasian steppe or even in North Africa before their departure. Their still predominantly African descendants spread to populate the world. A fraction in turn interbred with Denisovans, probably in southeastern Asia, before populating Melanesia. HLA haplotypes of Neanderthal and Denisova origin have been identified in modern Eurasian and Oceanian populations. The Denisovan EPAS1 gene has also been found in Tibetan populations. Studies of the human genome using machine learning have identified additional genetic contributions in Eurasians from an \"unknown\" ancestral population potentially related to the Neanderthal-Denisovan lineage.\\nThere are still differing theories on whether there was a single exodus from Africa or several. A multiple dispersal model involves the Southern Dispersal theory, which has gained support in recent years from genetic, linguistic and archaeological evidence. In this theory, there was a coastal dispersal of modern humans from the Horn of Africa crossing the Bab el Mandib to Yemen at a lower sea level around 70,000 years ago. This group helped to populate Southeast Asia and Oceania, explaining the discovery of early human sites in these areas much earlier than those in the Levant. This group seems to have been dependent upon marine resources for their survival.\\nStephen Oppenheimer has proposed a second wave of humans may have later dispersed through the Persian Gulf oases, and the Zagros mountains into the Middle East. Alternatively it may have come across the Sinai Peninsula into Asia, from shortly after 50,000 yrs BP, resulting in the bulk of the human populations of Eurasia. It has been suggested that this second group possibly possessed a more sophisticated \"big game hunting\" tool technology and was less dependent on coastal food sources than the original group. Much of the evidence for the first group's expansion would have been destroyed by the rising sea levels at the end of each glacial maximum. The multiple dispersal model is contradicted by studies indicating that the populations of Eurasia and the populations of Southeast Asia and Oceania are all descended from the same mitochondrial DNA L3 lineages, which support a single migration out of Africa that gave rise to all non-African populations.On the basis of the early date of Badoshan Iranian Aurignacian, Oppenheimer suggests that this second dispersal may have occurred with a pluvial period about 50,000 years before the present, with modern human big-game hunting cultures spreading up the Zagros Mountains, carrying modern human genomes from Oman, throughout the Persian Gulf, northward into Armenia and Anatolia, with a variant travelling south into Israel and to Cyrenicia.Recent genetic evidence suggests that all modern non-African populations, including those of Eurasia and Oceania, are descended from a single wave that left Africa between 65,000 and 50,000 years ago.\\n\\nEvidence\\nThe evidence on which scientific accounts of human evolution are based comes from many fields of natural science. The main source of knowledge about the evolutionary process has traditionally been the fossil record, but since the development of genetics beginning in the 1970s, DNA analysis has come to occupy a place of comparable importance. The studies of ontogeny, phylogeny and especially evolutionary developmental biology of both vertebrates and invertebrates offer considerable insight into the evolution of all life, including how humans evolved. The specific study of the origin and life of humans is anthropology, particularly paleoanthropology which focuses on the study of human prehistory.\\n\\nEvidence from genetics\\nThe closest living relatives of humans are bonobos and chimpanzees (both genus Pan) and gorillas (genus Gorilla). With the sequencing of both the human and chimpanzee genome, as of 2012 estimates of the similarity between their DNA sequences range between 95% and 99%. By using the technique called the molecular clock which estimates the time required for the number of divergent mutations to accumulate between two lineages, the approximate date for the split between lineages can be calculated.\\nThe gibbons (family Hylobatidae) and then the orangutans (genus Pongo) were the first groups to split from the line leading to the hominins, including humans\u2014followed by gorillas (genus Gorilla), and, ultimately, by the chimpanzees (genus Pan). The splitting date between hominin and chimpanzee lineages is placed by some between 4 to 8 million years ago, that is, during the Late Miocene. Speciation, however, appears to have been unusually drawn out. Initial divergence occurred sometime between 7 to 13 million years ago, but ongoing hybridization blurred the separation and delayed complete separation during several millions of years. Patterson (2006) dated the final divergence at 5 to 6 million years ago.Genetic evidence has also been employed to compare species within the genus Homo, investigating gene flow between early modern humans and Neanderthals, and to enhance the understanding of the early human migration patterns and splitting dates. By comparing the parts of the genome that are not under natural selection and which therefore accumulate mutations at a fairly steady rate, it is possible to reconstruct a genetic tree incorporating the entire human species since the last shared ancestor.\\nEach time a certain mutation (single-nucleotide polymorphism) appears in an individual and is passed on to his or her descendants, a haplogroup is formed including all of the descendants of the individual who will also carry that mutation. By comparing mitochondrial DNA which is inherited only from the mother, geneticists have concluded that the last female common ancestor whose genetic marker is found in all modern humans, the so-called mitochondrial Eve, must have lived around 200,000 years ago.\\nHuman evolutionary genetics studies how human genomes differ among individuals, the evolutionary past that gave rise to them, and their current effects. Differences between genomes have anthropological, medical and forensic implications and applications. Genetic data can provide important insight into human evolution.\\nIn May 2023, scientists reported a more complicated pathway of human evolution than previously understood. According to the studies, humans evolved from different places and times in Africa, instead of from a single location and period of time.\\n\\nEvidence from the fossil record\\nThere is little fossil evidence for the divergence of the gorilla, chimpanzee and hominin lineages. The earliest fossils that have been proposed as members of the hominin lineage are Sahelanthropus tchadensis dating from 7 million years ago, Orrorin tugenensis dating from 5.7 million years ago, and Ardipithecus kadabba dating to 5.6 million years ago. Each of these have been argued to be a bipedal ancestor of later hominins but, in each case, the claims have been contested. It is also possible that one or more of these species are ancestors of another branch of African apes, or that they represent a shared ancestor between hominins and other apes.\\nThe question then of the relationship between these early fossil species and the hominin lineage is still to be resolved. From these early species, the australopithecines arose around 4 million years ago and diverged into robust (also called Paranthropus) and gracile branches, one of which (possibly A. garhi) probably went on to become ancestors of the genus Homo. The australopithecine species that is best represented in the fossil record is Australopithecus afarensis with more than 100 fossil individuals represented, found from Northern Ethiopia (such as the famous \"Lucy\"), to Kenya, and South Africa. Fossils of robust australopithecines such as Au. robustus (or alternatively Paranthropus robustus) and Au./P. boisei are particularly abundant in South Africa at sites such as Kromdraai and Swartkrans, and around Lake Turkana in Kenya.\\nThe earliest member of the genus Homo is Homo habilis which evolved around 2.8 million years ago. H. habilis is the first species for which we have positive evidence of the use of stone tools. They developed the Oldowan lithic technology, named after the Olduvai Gorge in which the first specimens were found. Some scientists consider Homo rudolfensis, a larger bodied group of fossils with similar morphology to the original H. habilis fossils, to be a separate species, while others consider them to be part of H. habilis\u2014simply representing intraspecies variation, or perhaps even sexual dimorphism. The brains of these early hominins were about the same size as that of a chimpanzee, and their main adaptation was bipedalism as an adaptation to terrestrial living.\\nDuring the next million years, a process of encephalization began and, by the arrival (about 1.9 million years ago) of H. erectus in the fossil record, cranial capacity had doubled. H. erectus were the first of the hominins to emigrate from Africa, and, from 1.8 to 1.3 million years ago, this species spread through Africa, Asia, and Europe. One population of H. erectus, also sometimes classified as separate species H. ergaster, remained in Africa and evolved into H. sapiens. It is believed that H. erectus and H. ergaster were the first to use fire and complex tools. In Eurasia, H. erectus evolved into species such as H. antecessor, H. heidelbergensis and H. neanderthalensis. The earliest fossils of anatomically modern humans are from the Middle Paleolithic, about 300\u2013200,000 years ago such as the Herto and Omo remains of Ethiopia, Jebel Irhoud remains of Morocco, and Florisbad remains of South Africa; later fossils from the Skhul Cave in Israel and Southern Europe begin around 90,000 years ago (0.09 million years ago).\\nAs modern humans spread out from Africa, they encountered other hominins such as H. neanderthalensis and the Denisovans, who may have evolved from populations of H. erectus that had left Africa around 2 million years ago. The nature of interaction between early humans and these sister species has been a long-standing source of controversy, the question being whether humans replaced these earlier species or whether they were in fact similar enough to interbreed, in which case these earlier populations may have contributed genetic material to modern humans.This migration out of Africa is estimated to have begun about 70\u201350,000 years BP and modern humans subsequently spread globally, replacing earlier hominins either through competition or hybridization. They inhabited Eurasia and Oceania by 40,000 years BP, and the Americas by at least 14,500 years BP.\\n\\nInter-species breeding\\nThe hypothesis of interbreeding, also known as hybridization, admixture or hybrid-origin theory, has been discussed ever since the discovery of Neanderthal remains in the 19th century. The linear view of human evolution began to be abandoned in the 1970s as different species of humans were discovered that made the linear concept increasingly unlikely. In the 21st century with the advent of molecular biology techniques and computerization, whole-genome sequencing of Neanderthal and human genome were performed, confirming recent admixture between different human species. In 2010, evidence based on molecular biology was published, revealing unambiguous examples of interbreeding between archaic and modern humans during the Middle Paleolithic and early Upper Paleolithic. It has been demonstrated that interbreeding happened in several independent events that included Neanderthals and Denisovans, as well as several unidentified hominins. Today, approximately 2% of DNA from all non-African populations (including Europeans, Asians, and Oceanians) is Neanderthal, with traces of Denisovan heritage. Also, 4\u20136% of modern Melanesian genetics are Denisovan. Comparisons of the human genome to the genomes of Neandertals, Denisovans and apes can help identify features that set modern humans apart from other hominin species. In a 2016 comparative genomics study, a Harvard Medical School/UCLA research team made a world map on the distribution and made some predictions about where Denisovan and Neanderthal genes may be impacting modern human biology.For example, comparative studies in the mid-2010s found several traits related to neurological, immunological, developmental, and metabolic phenotypes, that were developed by archaic humans to European and Asian environments and inherited to modern humans through admixture with local hominins.Although the narratives of human evolution are often contentious, several discoveries since 2010 show that human evolution should not be seen as a simple linear or branched progression, but a mix of related species. In fact, genomic research has shown that hybridization between substantially diverged lineages is the rule, not the exception, in human evolution. Furthermore, it is argued that hybridization was an essential creative force in the emergence of modern humans.\\n\\nStone tools\\nStone tools are first attested around 2.6 million years ago, when hominins in Eastern Africa used so-called core tools, choppers made out of round cores that had been split by simple strikes. This marks the beginning of the Paleolithic, or Old Stone Age; its end is taken to be the end of the last Ice Age, around 10,000 years ago. The Paleolithic is subdivided into the Lower Paleolithic (Early Stone Age), ending around 350,000\u2013300,000 years ago, the Middle Paleolithic (Middle Stone Age), until 50,000\u201330,000 years ago, and the Upper Paleolithic, (Late Stone Age), 50,000\u201310,000 years ago.\\nArchaeologists working in the Great Rift Valley in Kenya have discovered the oldest known stone tools in the world. Dated to around 3.3 million years ago, the implements are some 700,000 years older than stone tools from Ethiopia that previously held this distinction.The period from 700,000 to 300,000 years ago is also known as the Acheulean, when H. ergaster (or erectus) made large stone hand axes out of flint and quartzite, at first quite rough (Early Acheulian), later \"retouched\" by additional, more-subtle strikes at the sides of the flakes. After 350,000 BP the more refined so-called Levallois technique was developed, a series of consecutive strikes, by which scrapers, slicers (\"racloirs\"), needles, and flattened needles were made. Finally, after about 50,000 BP, ever more refined and specialized flint tools were made by the Neanderthals and the immigrant Cro-Magnons (knives, blades, skimmers). Bone tools were also made by H. sapiens in Africa by 90\u201370,000 years ago and are also known from early H. sapiens sites in Eurasia by about 50,000 years ago.\\n\\nSpecies list\\nThis list is in chronological order across the table by genus. Some species/subspecies names are well-established, and some are less established \u2013 especially in genus Homo. Please see articles for more information.\\n\\nSee also\\nNotes\\nReferences\\nSources\\nFurther reading\\nExternal links\\n\\n\"Race, Evolution and the Science of Human Origins\" by Allison Hopper, Scientific American (July 5, 2021).\\n\"The evolution of man\". BBC Science & Nature. Retrieved May 6, 2015.\\n\"Becoming Human\". Arizona State University's Institute of Human Origins. Retrieved May 6, 2015.\\n\"Bones, Stones and Genes: The Origin of Modern Humans\" (Video lecture series). Howard Hughes Medical Institute. Archived from the original on April 24, 2015. Retrieved May 6, 2015.\\n\"Evolution Figures: Chapter 25\". Cold Spring Harbor Laboratory Press. Retrieved May 6, 2015. \u2013 Illustrations from the book Evolution (2007)\\n\"Human Evolution\". Smithsonian Institution's Human Origins Program. Retrieved June 24, 2013.\\n\"Human Evolution Timeline\". ArchaeologyInfo.com. Archived from the original on June 18, 2013. Retrieved June 24, 2013.\\n\"Human Trace\" video (2015) Normandy University UNIHAVRE, CNRS, IDEES, E.Laboratory on Human Trace Unitwin Complex System Digital Campus UNESCO.\\nLambert, Tim (Producer) (June 24, 2015). First Peoples. London: Wall to Wall Television. OCLC 910115743. Retrieved July 18, 2015.\\nShaping Humanity Video 2013 Yale University\\nHuman Timeline (Interactive) \u2013 Smithsonian, National Museum of Natural History (August 2016).\\nHuman Evolution, BBC Radio 4 discussion with Steve Jones, Fred Spoor & Margaret Clegg (In Our Time, February 16, 2006)\\nEvolutionary Timeline of Home Sapiens \u2212 Smithsonian (February 2021)\\nHistory of Human Evolution in the United States \u2013 Salon (August 24, 2021)"}
{"article_name": "Steve_Jobs", "link": "https://en.wikipedia.org/wiki/Steve_Jobs", "text_content": "Steven Paul Jobs (February 24, 1955 \u2013 October 5, 2011) was an American businessman, inventor, and investor best known for co-founding the technology giant Apple Inc. Jobs was also the founder of NeXT and chairman and majority shareholder of Pixar. He was a pioneer of the personal computer revolution of the 1970s and 1980s, along with his early business partner and fellow Apple co-founder Steve Wozniak.\\nJobs was born in San Francisco in 1955 and adopted shortly afterwards. He attended Reed College in 1972 before withdrawing that same year. In 1974, he traveled through India, seeking enlightenment before later studying Zen Buddhism. He and Wozniak co-founded Apple in 1976 to further develop and sell Wozniak's Apple I personal computer. Together, the duo gained fame and wealth a year later with production and sale of the Apple II, one of the first highly successful mass-produced microcomputers. Jobs saw the commercial potential of the Xerox Alto in 1979, which was mouse-driven and had a graphical user interface (GUI). This led to the development of the unsuccessful Apple Lisa in 1983, followed by the breakthrough Macintosh in 1984, the first mass-produced computer with a GUI. The Macintosh introduced the desktop publishing industry in 1985 with the addition of the Apple LaserWriter, the first laser printer to feature vector graphics.\\nIn 1985, Jobs departed Apple after a long power struggle with the company's board and its then-CEO, John Sculley. That same year, Jobs took some Apple employees with him to found NeXT, a computer platform development company that specialized in computers for higher-education and business markets, serving as its CEO. In 1986, he helped develop the visual effects industry by funding the computer graphics division of Lucasfilm that eventually spun off independently as Pixar, which produced the first 3D computer-animated feature film Toy Story (1995) and became a leading animation studio, producing over 27 films since.\\nIn 1997, Jobs returned to Apple as CEO after the company's acquisition of NeXT. He was largely responsible for reviving Apple, which was on the verge of bankruptcy. He worked closely with British designer Jony Ive to develop a line of products and services that had larger cultural ramifications, beginning with the \"Think different\" advertising campaign, and leading to the iMac, iTunes, Mac OS X, Apple Store, iPod, iTunes Store, iPhone, App Store, and iPad. In 2003, Jobs was diagnosed with a pancreatic neuroendocrine tumor. He died of respiratory arrest related to the tumor in 2011, and in 2022, was posthumously awarded the Presidential Medal of Freedom.\\n\\nEarly life\\nFamily\\nSteven Paul Jobs was born in San Francisco, California, on February 24, 1955, to Joanne Carole Schieble and Abdulfattah \"John\" Jandali (Arabic: \u0639\u0628\u062f \u0627\u0644\u0641\u062a\u0627\u062d \u0627\u0644\u062c\u0646\u062f\u0644\u064a). Abdulfattah Jandali was born in a Muslim household to wealthy Syrian parents, the youngest of nine siblings. After obtaining his undergraduate degree at the American University of Beirut, Jandali pursued a PhD in political science at the University of Wisconsin. There, he met Joanne Schieble, an American Catholic of Swiss-German descent whose parents owned a mink farm and real estate. The two fell in love but faced opposition from Schieble's father due to Jandali's Muslim faith. When Schieble became pregnant, she arranged for a closed adoption, and travelled to San Francisco to give birth.Schieble requested that her son be adopted by college graduates. A lawyer and his wife were selected, but they withdrew after discovering that the baby was a boy, so Jobs was instead adopted by Paul Reinhold and Clara (n\u00e9e Hagopian) Jobs. Paul Jobs was the son of a dairy farmer; after dropping out of high school, he worked as a mechanic, then joined the U.S. Coast Guard. When his ship was decommissioned, he met Clara Hagopian, an American of Armenian descent, and the two were engaged ten days later, in March 1946, and married that same year. The couple moved to Wisconsin, then Indiana, where Paul Jobs worked as a machinist and later as a car salesman. Since Clara missed San Francisco, she convinced Paul to move back. There, Paul worked as a repossession agent, and Clara became a bookkeeper. In 1955, after having an ectopic pregnancy, the couple looked to adopt a child. Since they lacked a college education, Schieble initially refused to sign the adoption papers, and went to court to request that her son be removed from the Jobs household and placed with a different family, but changed her mind after Paul and Clara promised to pay for their son's college tuition.\\n\\nInfancy\\nIn his youth, Jobs's parents took him to a Lutheran church. When Steve was in high school, Clara admitted to his girlfriend, Chrisann Brennan, that she \"was too frightened to love [Steve] for the first six months of his life ... I was scared they were going to take him away from me. Even after we won the case, Steve was so difficult a child that by the time he was two I felt we had made a mistake. I wanted to return him.\" When Chrisann shared this comment with Steve, he stated that he was already aware, and later said that he had been deeply loved and indulged by Paul and Clara. Many years later, Jobs's wife Laurene also noted that \"he felt he had been really blessed by having the two of them as parents\". Jobs would \"bristle\" when Paul and Clara were referred to as his \"adoptive parents\", and he regarded them as his parents \"1,000%\". Jobs referred to his biological parents as \"my sperm and egg bank. That's not harsh, it's just the way it was, a sperm bank thing, nothing more.\"\\n\\nChildhood\\nPaul Jobs worked in several jobs that included a try as a machinist, several other jobs, and then \"back to work as a machinist\".\\nPaul and Clara adopted Jobs's sister Patricia in 1957, and by 1959 the family had moved to the Monta Loma neighborhood in Mountain View, California. Paul built a workbench in his garage for his son in order to \"pass along his love of mechanics\". Jobs, meanwhile, admired his father's craftsmanship \"because he knew how to build anything. If we needed a cabinet, he would build it. When he built our fence, he gave me a hammer so I could work with him ... I wasn't that into fixing cars ... but I was eager to hang out with my dad.\" By the time he was ten, Jobs was deeply involved in electronics and befriended many of the engineers who lived in the neighborhood. He had difficulty making friends with children his own age, however, and was seen by his classmates as a \"loner\".\\nJobs had difficulty functioning in a traditional classroom, tended to resist authority figures, frequently misbehaved, and was suspended a few times. Clara had taught him to read as a toddler, and Jobs stated that he was \"pretty bored in school and [had] turned into a little terror... you should have seen us in the third grade, we basically destroyed the teacher\". He frequently played pranks on others at Monta Loma Elementary School in Mountain View. His father Paul (who was abused as a child) never reprimanded him, however, and instead blamed the school for not challenging his brilliant son.Jobs would later credit his fourth grade teacher, Imogene \"Teddy\" Hill, with turning him around: \"She taught an advanced fourth grade class, and it took her about a month to get hip to my situation. She bribed me into learning. She would say, 'I really want you to finish this workbook. I'll give you five bucks if you finish it.' That really kindled a passion in me for learning things! I learned more that year than I think I learned in any other year in school. They wanted me to skip the next two years in grade school and go straight to junior high to learn a foreign language, but my parents very wisely wouldn't let it happen.\" Jobs skipped the 5th grade and transferred to the 6th grade at Crittenden Middle School in Mountain View, where he became a \"socially awkward loner\". Jobs was often \"bullied\" at Crittenden Middle, and in the middle of 7th grade, he gave his parents an ultimatum: either they would take him out of Crittenden or he would drop out of school.The Jobs family was not affluent, and only by expending all their savings were they able to buy a new home in 1967, allowing Steve to change schools. The new house (a three-bedroom home on Crist Drive in Los Altos, California) was in the better Cupertino School District, Cupertino, California, and was embedded in an environment even more heavily populated with engineering families than the Mountain View area was. The house was declared a historic site in 2013, as the first site of Apple Computer. As of 2013, it was owned by Jobs's sister, Patty, and occupied by his stepmother, Marilyn.When he was 13, in 1968, Jobs was given a summer job by Bill Hewlett (of Hewlett-Packard) after Jobs cold-called him to ask for parts for an electronics project.\\n\\nHomestead High\\nThe location of the Los Altos home meant that Jobs would be able to attend nearby Homestead High School, which had strong ties to Silicon Valley. He began his first year there in late 1968 along with Bill Fernandez, who introduced Jobs to Steve Wozniak, and would become Apple's first employee. Neither Jobs nor Fernandez (whose father was a lawyer) came from engineering households and thus decided to enroll in John McCollum's Electronics I class. Jobs had grown his hair long and become involved in the growing counterculture, and the rebellious youth eventually clashed with McCollum and lost interest in the class.Jobs underwent a change during mid-1970: \"I got stoned for the first time; I discovered Shakespeare, Dylan Thomas, and all that classic stuff. I read Moby Dick and went back as a junior taking creative writing classes.\" Jobs later noted to his official biographer that \"I started to listen to music a whole lot, and I started to read more outside of just science and technology \u2014 Shakespeare, Plato. I loved King Lear ... when I was a senior I had this phenomenal AP English class. The teacher was this guy who looked like Ernest Hemingway. He took a bunch of us snowshoeing in Yosemite.\" During his last two years at Homestead High, Jobs developed two different interests: electronics and literature. These dual interests were particularly reflected during Jobs's senior year, as his best friends were Wozniak and his first girlfriend, the artistic Homestead junior Chrisann Brennan.In 1971, after Wozniak began attending University of California, Berkeley, Jobs would visit him there a few times a week. This experience led him to study in nearby Stanford University's student union. Instead of joining the electronics club, Jobs put on light shows with a friend for Homestead's avant-garde jazz program. He was described by a Homestead classmate as \"kind of brain and kind of hippie ... but he never fit into either group. He was smart enough to be a nerd, but wasn't nerdy. And he was too intellectual for the hippies, who just wanted to get wasted all the time. He was kind of an outsider. In high school everything revolved around what group you were in, and if you weren't in a carefully defined group, you weren't anybody. He was an individual, in a world where individuality was suspect.\" By his senior year in late 1971, he was taking a freshman English class at Stanford and working on a Homestead underground film project with Chrisann Brennan.Around that time, Wozniak designed a low-cost digital \"blue box\" to generate the necessary tones to manipulate the telephone network, allowing free long-distance calls. He was inspired by an article titled \"Secrets of the Little Blue Box\" from the October 1971 issue of Esquire. Jobs decided then to sell them and split the profit with Wozniak. The clandestine sales of the illegal blue boxes went well and perhaps planted the seed in Jobs's mind that electronics could be both fun and profitable. In a 1994 interview, he recalled that it took six months for him and Wozniak to design the blue boxes. Jobs later reflected that had it not been for Wozniak's blue boxes, \"there wouldn't have been an Apple\". He states it showed them that they could take on large companies and beat them.By his senior year of high school, Jobs began using LSD. He later recalled that on one occasion he consumed it in a wheat field outside Sunnyvale, and experienced \"the most wonderful feeling of my life up to that point\". In mid-1972, after graduation and before leaving for Reed College, Jobs and Brennan rented a house from their other roommate, Al.\\n\\nReed College\\nIn September 1972, Jobs enrolled at Reed College in Portland, Oregon. He insisted on applying only to Reed, although it was an expensive school that Paul and Clara could ill afford. Jobs soon befriended Robert Friedland, who was Reed's student body president at that time. Brennan remained involved with Jobs while he was at Reed.\\nAfter just one semester, Jobs dropped out of Reed College without telling his parents. Jobs later explained this was because he did not want to spend his parents' money on an education that seemed meaningless to him. He continued to attend by auditing his classes, including a course on calligraphy that was taught by Robert Palladino. In a 2005 commencement speech at Stanford University, Jobs stated that during this period, he slept on the floor in friends' dorm rooms, returned Coke bottles for food money, and got weekly free meals at the local Hare Krishna temple. In that same speech, Jobs said: \"If I had never dropped in on that single calligraphy course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts\".\\n\\n1974\u20131985\\nPre-Apple\\nIn February 1974, Jobs returned to his parents' home in Los Altos and began looking for a job. He was soon hired by Atari, Inc. in Los Gatos, California, as a computer technician. Back in 1973, Steve Wozniak designed his own version of the classic video game Pong and gave its electronics board to Jobs. According to Wozniak, Atari only hired Jobs because he took the board down to the company, and they thought that he had built it himself. Atari's cofounder Nolan Bushnell later described him as \"difficult but valuable\", pointing out that \"he was very often the smartest guy in the room, and he would let people know that\".Jobs traveled to India in mid-1974 to visit Neem Karoli Baba at his Kainchi ashram with his Reed friend (and eventual Apple employee) Daniel Kottke, searching for spiritual teachings. When they got to the Neem Karoli ashram, it was almost deserted because Neem Karoli Baba had died in September 1973. Then they made a long trek up a dry riverbed to an ashram of Haidakhan Babaji.After seven months, Jobs left India and returned to the US ahead of Daniel Kottke. Jobs had changed his appearance; his head was shaved, and he wore traditional Indian clothing. During this time, Jobs experimented with psychedelics, later calling his LSD experiences \"one of the two or three most important things [he had] done in [his] life\". He spent a period at the All One Farm, a commune in Oregon that was owned by Robert Friedland.\\nDuring this time period, Jobs and Brennan both became practitioners of Zen Buddhism through the Zen master K\u014dbun Chino Otogawa. Jobs engaged in lengthy meditation retreats at the Tassajara Zen Mountain Center, the oldest S\u014dt\u014d Zen monastery in the US. He considered taking up monastic residence at Eihei-ji in Japan, and maintained a lifelong appreciation for Zen, Japanese cuisine, and artists such as Hasui Kawase.Jobs returned to Atari in early 1975, and that summer, Bushnell assigned him to create a circuit board for the arcade video game Breakout in as few chips as possible, knowing that Jobs would recruit Wozniak for help. During his day job at HP, Wozniak drew sketches of the circuit design; at night, he joined Jobs at Atari and continued to refine the design, which Jobs implemented on a breadboard. According to Bushnell, Atari offered $100 (equivalent to about $500 in 2022) for each TTL chip that was eliminated in the machine. Jobs made a deal with Wozniak to split the fee evenly between them if Wozniak could minimize the number of chips. Much to the amazement of Atari engineers, within four days Wozniak reduced the TTL count to 45, far below the usual 100, though Atari later re-engineered it to make it easier to test and add a few missing features. According to Wozniak, Jobs told him that Atari paid them only $750 (instead of the actual $5,000), and that Wozniak's share was thus $375. Wozniak did not learn about the actual bonus until ten years later but said that if Jobs had told him about it and explained that he needed the money, Wozniak would have given it to him.Jobs and Wozniak attended meetings of the Homebrew Computer Club in 1975, which was a steppingstone to the development and marketing of the first Apple computer.According to a document released by the DoD, circa 1975, Steve Jobs claims he was arrested in Eugene, Oregon after being questioned for being a minor in possession of alcohol. Jobs alleges that he \"didn't have any alcohol\", but police questioned him, and subsequently determined that he had an outstanding arrest warrant for an unpaid speeding ticket. Jobs claims he then paid the approximately $50 fine. The arrest allegedly occurred \"behind a store\".\\n\\nApple (1976\u20131985)\\nBy March 1976, Wozniak completed the basic design of the Apple I computer and showed it to Jobs, who suggested that they sell it; Wozniak was at first skeptical of the idea but later agreed. In April of that same year, Jobs, Wozniak, and administrative overseer Ronald Wayne founded Apple Computer Company (now called \"Apple Inc.\") as a business partnership in Jobs's parents' Crist Drive home on April 1, 1976. The operation originally started in Jobs's bedroom and later moved to the garage. Wayne stayed briefly, leaving Jobs and Wozniak as the active primary cofounders of the company.The two decided on the name \"Apple\" after Jobs returned from the All One Farm commune in Oregon and told Wozniak about his time in the farm's apple orchard. Jobs originally planned to produce bare printed circuit boards of the Apple I and sell them to computer hobbyists for $50 (equivalent to about $260 in 2022) each. To fund the first batch, Wozniak sold his HP scientific calculator and Jobs sold his Volkswagen van. Later that year, computer retailer Paul Terrell purchased 50 fully assembled Apple I units for $500 each. Eventually about 200 Apple I computers were produced in total.\\nA neighbor on Crist Drive recalled Jobs as an odd individual who would greet his clients \"with his underwear hanging out, barefoot and hippie-like\". Another neighbor, Larry Waterland, who had just earned his PhD in chemical engineering at Stanford, recalled dismissing Jobs's budding business compared to the established industry of giant mainframe computers with big decks of punch cards: \"Steve took me over to the garage. He had a circuit board with a chip on it, a DuMont TV set, a Panasonic cassette tape deck and a keyboard. He said, 'This is an Apple computer.' I said, 'You've got to be joking.' I dismissed the whole idea.\" Jobs's friend from Reed College and India, Daniel Kottke, recalled that as an early Apple employee, he \"was the only person who worked in the garage ... Woz would show up once a week with his latest code. Steve Jobs didn't get his hands dirty in that sense.\" Kottke also stated that much of the early work took place in Jobs's kitchen, where he spent hours on the phone trying to find investors for the company.They received funding from a then-semi-retired Intel product marketing manager and engineer named Mike Markkula. Scott McNealy, one of the cofounders of Sun Microsystems, said that Jobs broke a \"glass age ceiling\" in Silicon Valley because he'd created a very successful company at a young age. Markkula brought Apple to the attention of Arthur Rock, which, after looking at the crowded Apple booth at the Home Brew Computer Show, started with a $60,000 investment and went on the Apple board. Jobs was not pleased when Markkula recruited Mike Scott from National Semiconductor in February 1977 to serve as the first president and CEO of Apple.\\n\\nAfter Brennan returned from her own journey to India, she and Jobs fell in love again, as Brennan noted changes in him that she attributes to Kobun (whom she was also still following). It was also at this time that Jobs displayed a prototype Apple II computer for Brennan and his parents in their living room. Brennan notes a shift in this time period, where the two main influences on Jobs were Apple Inc. and Kobun.\\nIn April 1977, Jobs and Wozniak introduced the Apple II at the West Coast Computer Faire. It is the first consumer product to have been sold by Apple Computer. Primarily designed by Wozniak, Jobs oversaw the development of its unusual case and Rod Holt developed the unique power supply. During the design stage, Jobs argued that the Apple II should have two expansion slots, while Wozniak wanted eight. After a heated argument, Wozniak threatened that Jobs should \"go get himself another computer\". They later agreed on eight slots. The Apple II became one of the first highly successful mass-produced microcomputer products in the world.As Jobs became more successful with his new company, his relationship with Brennan grew more complex. In 1977, the success of Apple was now a part of their relationship, and Brennan, Daniel Kottke, and Jobs moved into a house near the Apple office in Cupertino. Brennan eventually took a position in the shipping department at Apple. Brennan's relationship with Jobs deteriorated as his position with Apple grew, and she began to consider ending the relationship. In October 1977, Brennan was approached by Rod Holt, who asked her to take \"a paid apprenticeship designing blueprints for the Apples\". Both Holt and Jobs believed that it would be a good position for her, given her artistic abilities. Holt was particularly eager that she take the position and puzzled by her ambivalence toward it. Brennan's decision, however, was overshadowed by the fact that she realized she was pregnant, and that Jobs was the father. It took her a few days to tell Jobs, whose face, according to Brennan, \"turned ugly\" at the news. At the same time, according to Brennan, at the beginning of her third trimester, Jobs said to her: \"I never wanted to ask that you get an abortion. I just didn't want to do that.\" He also refused to discuss the pregnancy with her.Brennan turned down the internship and decided to leave Apple. She stated that Jobs told her \"If you give up this baby for adoption, you will be sorry\" and \"I am never going to help you\". According to Brennan, Jobs \"started to seed people with the notion that I slept around, and he was infertile, which meant that this could not be his child\". A few weeks before she was due to give birth, Brennan was invited to deliver her baby at the All One Farm. She accepted the offer. When Jobs was 23 (the same age as his biological parents when they had him) Brennan gave birth to her baby, Lisa Brennan, on May 17, 1978.Jobs went there for the birth after he was contacted by Robert Friedland, their mutual friend and the farm owner. While distant, Jobs worked with her on a name for the baby, which they discussed while sitting in the fields on a blanket. Brennan suggested the name \"Lisa\" which Jobs also liked and notes that Jobs was very attached to the name \"Lisa\" while he \"was also publicly denying paternity\". She would discover later that during this time, Jobs was preparing to unveil a new kind of computer that he wanted to give a female name (his first choice was \"Claire\" after St. Clare). She stated that she never gave him permission to use the baby's name for a computer and he hid the plans from her. Jobs worked with his team to come up with the phrase, \"Local Integrated Software Architecture\" as an alternative explanation for the Apple Lisa. Decades later, however, Jobs admitted to his biographer Walter Isaacson that \"obviously, it was named for my daughter\".When Jobs denied paternity, a DNA test established him as Lisa's father. It required him to pay Brennan $385 (equivalent to about $1,100 in 2022) monthly in addition to returning the welfare money she had received. Jobs paid her $500 (equivalent to about $1,500 in 2022) monthly at the time when Apple went public and made him a millionaire. Later, Brennan agreed to interview with Michael Moritz for Time magazine for its Time Person of the Year special, released on January 3, 1983, in which she discussed her relationship with Jobs. Rather than name Jobs the Person of the Year, the magazine named the generic personal computer the \"Machine of the Year\". In the issue, Jobs questioned the reliability of the paternity test, which stated that the \"probability of paternity for Jobs, Steven... is 94.1%\". He responded by arguing that \"28% of the male population of the United States could be the father\". Time also noted that \"the baby girl and the machine on which Apple has placed so much hope for the future share the same name: Lisa\".In 1978, at age 23, Jobs was worth over $1 million (equivalent to $4.49 million in 2022). By age 25, his net worth grew to an estimated $250 million (equivalent to $805 million in 2022). He was also one of the youngest \"people ever to make the Forbes list of the nation's richest people\u2014and one of only a handful to have done it themselves, without inherited wealth\".In 1982, Jobs bought an apartment on the top two floors of The San Remo, a Manhattan building with a politically progressive reputation. Although he never lived there, he spent years renovating it thanks to I. M. Pei.\\nIn 1983, Jobs lured John Sculley away from Pepsi-Cola to serve as Apple's CEO, asking, \"Do you want to spend the rest of your life selling sugared water, or do you want a chance to change the world?\".In 1984, Jobs bought the Jackling House and estate and resided there for a decade. Thereafter, he leased it out for several years until 2000 when he stopped maintaining the house, allowing weathering to degrade it. In 2004, Jobs received permission from the town of Woodside to demolish the house to build a smaller, contemporary styled one. After a few years in court, the house was finally demolished in 2011, a few months before he died.\\n\\nJobs took over development of the Macintosh in 1981, from early Apple employee Jef Raskin, who had conceived the project. Wozniak and Raskin had heavily influenced the early program, and Wozniak was on leave during this time due to an airplane crash earlier that year, making it easier for Jobs to take over the project. On January 22, 1984, Apple aired a Super Bowl television commercial titled \"1984\", which ended with the words: \"On January 24th, Apple Computer will introduce Macintosh. And you'll see why 1984 won't be like 1984.\" On January 24, 1984, an emotional Jobs introduced the Macintosh to a wildly enthusiastic audience at Apple's annual shareholders meeting held in the Flint Auditorium at De Anza College. Macintosh engineer Andy Hertzfeld described the scene as \"pandemonium\". The Macintosh was inspired by the Lisa (in turn inspired by Xerox PARC's mouse-driven graphical user interface), and it was widely acclaimed by the media with strong initial sales. However, its low performance and limited range of available software led to a rapid sales decline in the second half of 1984.Sculley's and Jobs's respective visions for the company greatly differed. Sculley favored open architecture computers like the Apple II, targeting education, small business, and home markets less vulnerable to IBM. Jobs wanted the company to focus on the closed architecture Macintosh as a business alternative to the IBM PC. President and CEO Sculley had little control over chairman of the board Jobs's Macintosh division; it and the Apple II division operated like separate companies, duplicating services. Although its products provided 85% of Apple's sales in early 1985, the company's January 1985 annual meeting did not mention the Apple II division or employees. Many left, including Wozniak, who stated that the company had \"been going in the wrong direction for the last five years\" and sold most of his stock. Though frustrated with the company's and Jobs's dismissal of the Apple II in favor of the Macintosh, Wozniak left amicably and remained an honorary employee of Apple, maintaining a lifelong friendship with Jobs.\\nBy early 1985, the Macintosh's failure to defeat the IBM PC became clear, and it strengthened Sculley's position in the company. In May 1985, Sculley\u2014encouraged by Arthur Rock\u2014decided to reorganize Apple, and proposed a plan to the board that would remove Jobs from the Macintosh group and put him in charge of \"New Product Development\". This move would effectively render Jobs powerless within Apple. In response, Jobs then developed a plan to get rid of Sculley and take over Apple. However, Jobs was confronted after the plan was leaked, and he said that he would leave Apple. The Board declined his resignation and asked him to reconsider. Sculley also told Jobs that he had all of the votes needed to go ahead with the reorganization. A few months later, on September 17, 1985, Jobs submitted a letter of resignation to the Apple Board. Five additional senior Apple employees also resigned and joined Jobs in his new venture, NeXT.The Macintosh's struggle continued after Jobs left Apple. Though marketed and received in fanfare, the expensive Macintosh was hard to sell.:\u200a308\u2013309\u200a In 1985, Bill Gates's then-developing company, Microsoft, threatened to stop developing Mac applications unless it was granted \"a license for the Mac operating system software. Microsoft was developing its graphical user interface ... for DOS, which it was calling Windows and didn't want Apple to sue over the similarities between the Windows GUI and the Mac interface.\":\u200a321\u200a Sculley granted Microsoft the license which later led to problems for Apple.:\u200a321\u200a In addition, cheap IBM PC clones that ran Microsoft software and had a graphical user interface began to appear. Although the Macintosh preceded the clones, it was far more expensive, so \"through the late 1980s, the Windows user interface was getting better and better and was thus taking increasingly more share from Apple\".:\u200a322\u200a Windows-based IBM-PC clones also led to the development of additional GUIs such as IBM's TopView or Digital Research's GEM,:\u200a322\u200a and thus \"the graphical user interface was beginning to be taken for granted, undermining the most apparent advantage of the Mac...it seemed clear as the 1980s wound down that Apple couldn't go it alone indefinitely against the whole IBM-clone market\".:\u200a322\\n\\n1985\u20131997\\nNeXT computer\\nFollowing his resignation from Apple in 1985, Jobs founded NeXT Inc. with $7 million. A year later he was running out of money, and he sought venture capital with no product on the horizon. Eventually, Jobs attracted the attention of billionaire Ross Perot, who invested heavily in the company. The NeXT computer was shown to the world in what was considered Jobs's comeback event, a lavish invitation-only gala launch event that was described as a multimedia extravaganza. The celebration was held at the Louise M. Davies Symphony Hall, San Francisco, California, on Wednesday, October 12, 1988. Steve Wozniak said in a 2013 interview that while Jobs was at NeXT he was \"really getting his head together\".NeXT workstations were first released in 1990 and priced at $9,999 (equivalent to about $22,000 in 2022). Like the Apple Lisa, the NeXT workstation was technologically advanced and designed for the education sector but was largely dismissed as cost prohibitive. The NeXT workstation was known for its technical strengths, chief among them its object-oriented software development system. Jobs marketed NeXT products to the financial, scientific, and academic community, highlighting its innovative, experimental new technologies, such as the Mach kernel, the digital signal processor chip, and the built-in Ethernet port. Making use of a NeXT computer, English computer scientist Tim Berners-Lee invented the World Wide Web in 1990 at CERN in Switzerland.The revised, second generation NeXTcube was released in 1990. Jobs touted it as the first \"interpersonal\" computer that would replace the personal computer. With its innovative NeXTMail multimedia email system, NeXTcube could share voice, image, graphics, and video in email for the first time. \"Interpersonal computing is going to revolutionize human communications and groupwork\", Jobs told reporters. Jobs ran NeXT with an obsession for aesthetic perfection, as evidenced by the development of and attention to NeXTcube's magnesium case. This put considerable strain on NeXT's hardware division, and in 1993, after having sold only 50,000 machines, NeXT transitioned fully to software development with the release of NeXTSTEP/Intel. The company reported its first yearly profit of $1.03 million in 1994. In 1996, NeXT Software, Inc. released WebObjects, a framework for Web application development. After NeXT was acquired by Apple Inc. in 1997, WebObjects was used to build and run the Apple Store, MobileMe services, and the iTunes Store.\\n\\nPixar and Disney\\nIn 1986, Jobs funded the spinout of The Graphics Group (later renamed Pixar) from Lucasfilm's computer graphics division for the price of $10 million, $5 million of which was given to the company as capital and $5 million of which was paid to Lucasfilm for technology rights.\\nThe first film produced by Pixar with its Disney partnership, Toy Story (1995), with Jobs credited as executive producer, brought financial success and critical acclaim to the studio when it was released. Over the course of Jobs's life, under Pixar's creative chief John Lasseter, the company produced box-office hits A Bug's Life (1998), Toy Story 2 (1999), Monsters, Inc. (2001), Finding Nemo (2003), The Incredibles (2004), Cars (2006), Ratatouille (2007), WALL-E (2008), Up (2009), Toy Story 3 (2010), and Cars 2 (2011). Brave (2012), Pixar's first film to be produced since Jobs's death, honored him with a tribute for his contributions to the studio. Finding Nemo, The Incredibles, Ratatouille, WALL-E, Up, Toy Story 3, and Brave each received the Academy Award for Best Animated Feature, an award introduced in 2001.In 2003 and 2004, as Pixar's contract with Disney was running out, Jobs and Disney chief executive Michael Eisner tried but failed to negotiate a new partnership, and in January 2004, Jobs announced that he would never deal with Disney again. Pixar sought a new partner to distribute its films after its contract expired.In October 2005, Bob Iger replaced Eisner at Disney, and Iger quickly worked to mend relations with Jobs and Pixar. On January 24, 2006, Jobs and Iger announced that Disney had agreed to purchase Pixar in an all-stock transaction worth $7.4 billion. When the deal closed, Jobs became The Walt Disney Company's largest single shareholder with approximately seven percent of the company's stock. Jobs's holdings in Disney far exceeded those of Eisner, who holds 1.7%, and of Disney family member Roy E. Disney, who until his 2009 death held about 1% of the company's stock and whose criticisms of Eisner\u2014especially that he soured Disney's relationship with Pixar\u2014accelerated Eisner's ousting. Upon completion of the merger, Jobs received 7% of Disney shares, and joined the board of directors as the largest individual shareholder. Upon Jobs's death his shares in Disney were transferred to the Steven P. Jobs Trust led by Laurene Jobs.After Jobs's death, Iger recalled in 2019 that many warned him about Jobs, \"that he would bully me and everyone else\". Iger wrote, \"Who wouldn't want Steve Jobs to have influence over how a company is run?\", and that as an active Disney board member \"he rarely created trouble for me. Not never but rarely.\" He speculated that they would have seriously considered merging Disney and Apple had Jobs lived. Floyd Norman, of Pixar, described Jobs as a \"mature, mellow individual\" who never interfered with the creative process of the filmmakers. In early June 2014, Pixar cofounder and Walt Disney Animation Studios President Edwin Catmull revealed that Jobs once advised him to \"just explain it to them until they understand\" in disagreements. Catmull released the book Creativity, Inc. in 2014, in which he recounts numerous experiences of working with Jobs. Regarding his own manner of dealing with Jobs, Catmull writes:\\nIn all the 26 years with Steve, Steve and I never had one of these loud verbal arguments, and it's not my nature to do that. ... but we did disagree fairly frequently about things. ... I would say something to him and he would immediately shoot it down because he could think faster than I could. ... I would then wait a week ... I'd call him up, and I give my counterargument to what he had said, and he'd immediately shoot it down. So I had to wait another week, and occasionally this went on for months. But ultimately one of three things happened. About a third of the time he said, \"Oh, I get it, you're right\", and that was the end of it. And it was another third of the time in which [I'd] say, \"Actually I think he is right\". The other third of the time, where we didn't reach consensus, he just let me do it my way, never said anything more about it.\\n\\n1997\u20132011\\nReturn to Apple\\nIn 1996, Jobs's former company Apple was struggling and its survival depended on completing its next operating system. After failed negotiations to purchase Be Inc., Apple eventually came to a deal with NeXT in December for $400 million; the deal was finalized in February 1997, bringing Jobs back to the company he had cofounded. Jobs became de facto chief after then-CEO Gil Amelio was ousted in July 1997. He was formally named interim chief executive on September 16. In March 1998, to concentrate Apple's efforts on returning to profitability, Jobs terminated several projects, such as Newton, Cyberdog, and OpenDoc. In the coming months, many employees developed a fear of encountering Jobs while riding in the elevator, \"afraid that they might not have a job when the doors opened. The reality was that Jobs's summary executions were rare, but a handful of victims was enough to terrorize a whole company.\" Jobs changed the licensing program for Macintosh clones, making it too costly for the manufacturers to continue making machines.\\nWith the purchase of NeXT, much of the company's technology found its way into Apple products, most notably NeXTSTEP, which evolved into Mac OS X. Under Jobs's guidance, the company increased sales significantly with the introduction of the iMac and other new products; since then, appealing designs and powerful branding have worked well for Apple. At the 2000 Macworld Expo, Jobs officially dropped the \"interim\" modifier from his title at Apple and became permanent CEO. Jobs quipped at the time that he would be using the title \"iCEO\".The company subsequently branched out, introducing and improving upon other digital appliances. With the introduction of the iPod portable music player, iTunes digital music software, and the iTunes Store, the company made forays into consumer electronics and music distribution. On June 29, 2007, Apple entered the cellular phone business with the introduction of the iPhone, a multi-touch display cell phone, which also included the features of an iPod and, with its own mobile browser, revolutionized the mobile browsing scene. While nurturing open-ended innovation, Jobs also reminded his employees that \"real artists ship\".Jobs had a public war of words with Dell Computer CEO Michael Dell, starting in 1987, when Jobs first criticized Dell for making \"un-innovative beige boxes\". On October 6, 1997, at a Gartner Symposium, when Dell was asked what he would do if he ran the then-troubled Apple Computer company, he said: \"I'd shut it down and give the money back to the shareholders\". Then, in 2006, Jobs emailed all employees when Apple's market capitalization rose above Dell's. It read:\\n\\nTeam, it turned out that Michael Dell wasn't perfect at predicting the future. Based on today's stock market close, Apple is worth more than Dell. Stocks go up and down, and things may be different tomorrow, but I thought it was worth a moment of reflection today. Steve.\\nJobs was both admired and criticized for his consummate skill at persuasion and salesmanship, which has been dubbed the \"reality distortion field\" and was particularly evident during his keynote speeches (colloquially known as \"Stevenotes\") at Macworld Expos and at Apple Worldwide Developers Conferences.Jobs usually went to work wearing a black long-sleeved mock turtleneck made by Issey Miyake, Levi's 501 blue jeans, and New Balance 991 sneakers. Jobs told his biographer Walter Isaacson \"...he came to like the idea of having a uniform for himself, both because of its daily convenience (the rationale he claimed) and its ability to convey a signature style\".Jobs was a board member at Gap Inc. from 1999 to 2002.\\nIn 2001, Jobs was granted stock options in the amount of 7.5 million shares of Apple with an exercise price of $18.30. It was alleged that the options had been backdated, and that the exercise price should have been $21.10. It was further alleged that Jobs had thereby incurred taxable income of $20,000,000 that he did not report, and that Apple overstated its earnings by that same amount. As a result, Jobs potentially faced a number of criminal charges and civil penalties. The case was the subject of active criminal and civil government investigations, though an independent internal Apple investigation completed on December 29, 2006, found that Jobs was unaware of these issues and that the options granted to him were returned without being exercised in 2003.In 2005, Jobs responded to criticism of Apple's poor recycling programs for e-waste in the US by lashing out at environmental and other advocates at Apple's annual meeting in Cupertino in April. A few weeks later, Apple announced it would take back iPods for free at its retail stores. The Computer TakeBack Campaign responded by flying a banner from a plane over the Stanford University graduation at which Jobs was the commencement speaker. The banner read \"Steve, don't be a mini-player\u2014recycle all e-waste\".In 2006, he further expanded Apple's recycling programs to any US customer who buys a new Mac. This program includes shipping and \"environmentally friendly disposal\" of their old systems.The success of Apple's unique products and services provided several years of stable financial returns, propelling Apple to become the world's most valuable publicly traded company in 2011.Jobs was perceived as a demanding perfectionist who always aspired to position his businesses and their products at the forefront of the information technology industry by foreseeing and setting innovation and style trends. He summed up this self-concept at the end of his keynote speech at the Macworld Conference and Expo in January 2007, by quoting ice hockey player Wayne Gretzky:\\n\\nThere's an old Wayne Gretzky quote that I love. \"I skate to where the puck is going to be, not where it has been\". And we've always tried to do that at Apple. Since the very, very beginning. And we always will.\\nOn July 1, 2008, a $7 billion class action suit was filed against several members of the Apple board of directors for revenue lost because of alleged securities fraud.In a 2011 interview with biographer Walter Isaacson, Jobs revealed that he had met with US President Barack Obama, complained about the nation's shortage of software engineers, and told Obama that he was \"headed for a one-term presidency\". Jobs proposed that any foreign student who got an engineering degree at a US university should automatically be offered a green card. After the meeting, Jobs commented, \"The president is very smart, but he kept explaining to us reasons why things can't get done . . . . It infuriates me\".\\n\\nHealth problems\\nIn October 2003, Jobs was diagnosed with cancer. In mid-2004, he announced to his employees that he had a cancerous tumor in his pancreas. The prognosis for pancreatic cancer is usually very poor; Jobs stated that he had a rare, much less aggressive type, known as islet cell neuroendocrine tumor.Jobs resisted his doctors' recommendations for medical intervention for nine months, in favor of alternative medicine. Other doctors agree that Jobs's diet was insufficient to address his disease. However, cancer researcher and alternative medicine critic David Gorski wrote that \"it's impossible to know whether and by how much he might have decreased his chances of surviving his cancer through his flirtation with woo. My best guess was that Jobs probably only modestly decreased his chances of survival, if that.\" Barrie R. Cassileth, the chief of Memorial Sloan Kettering Cancer Center's integrative medicine department, on the other hand, said, \"Jobs's faith in alternative medicine likely cost him his life ... He had the only kind of pancreatic cancer that is treatable and curable ... He essentially committed suicide.\" According to biographer Walter Isaacson, \"for nine months he refused to undergo surgery for his pancreatic cancer \u2013 a decision he later regretted as his health declined\". \"Instead, he tried a vegan diet, acupuncture, herbal remedies, and other treatments he found online, and even consulted a psychic. He was also influenced by a doctor who ran a clinic that advised juice fasts, bowel cleansings and other unproven approaches, before finally having surgery in July 2004.\" He underwent a pancreaticoduodenectomy (or \"Whipple procedure\") that appeared to remove the tumor successfully. Jobs did not receive chemotherapy or radiation therapy. During Jobs's absence, Tim Cook, head of worldwide sales and operations at Apple, ran the company.In January 2006, only Jobs's wife, his doctors, and Iger knew that his cancer had returned. Jobs told Iger privately that he hoped to live to see his son Reed's high school graduation in 2010. In early August 2006, Jobs delivered the keynote for Apple's annual Worldwide Developers Conference. His \"thin, almost gaunt\" appearance and unusually \"listless\" delivery, together with his choice to delegate significant portions of his keynote to other presenters, inspired a flurry of media and internet speculation about the state of his health. In contrast, according to an Ars Technica journal report, Worldwide Developers Conference (WWDC) attendees who saw Jobs in person said he \"looked fine\". Following the keynote, an Apple spokesperson said that \"Steve's health is robust\".Two years later, similar concerns followed Jobs's 2008 WWDC keynote address. Apple officials stated that Jobs was victim to a \"common bug\" and was taking antibiotics, while others surmised his cachectic appearance was due to the Whipple procedure. During a July conference call discussing Apple earnings, participants responded to repeated questions about Jobs's health by insisting that it was a \"private matter\". Others said that shareholders had a right to know more, given Jobs's hands-on approach to running his company. Based on an off-the-record phone conversation with Jobs, The New York Times reported, \"While his health problems amounted to a good deal more than 'a common bug', they weren't life-threatening and he doesn't have a recurrence of cancer\".On August 28, 2008, Bloomberg mistakenly published a 2500-word obituary of Jobs in its corporate news service, containing blank spaces for his age and cause of death. News carriers customarily stockpile up-to-date obituaries to facilitate news delivery in the event of a well-known figure's death. Although the error was promptly rectified, many news carriers and blogs reported on it, intensifying rumors concerning Jobs's health. Jobs responded at Apple's September 2008 Let's Rock keynote by paraphrasing Mark Twain: \"The reports of my death are greatly exaggerated.\" At a subsequent media event, Jobs concluded his presentation with a slide reading \"110/70\", referring to his blood pressure, stating he would not address further questions about his health.On December 16, 2008, Apple announced that marketing vice-president Phil Schiller would deliver the company's final keynote address at the Macworld Conference and Expo 2009, again reviving questions about Jobs's health. In a statement given on January 5, 2009, on Apple.com, Jobs said that he had been suffering from a \"hormone imbalance\" for several months.On January 14, 2009, Jobs wrote in an internal Apple memo that in the previous week he had \"learned that my health-related issues are more complex than I originally thought\". He announced a six-month leave of absence until the end of June 2009, to allow him to better focus on his health. Tim Cook, who previously acted as CEO in Jobs's 2004 absence, became acting CEO of Apple, with Jobs still involved with \"major strategic decisions\".In 2009, Tim Cook offered a portion of his liver to Jobs, since both share a rare blood type, and the donor liver can regenerate tissue after such an operation. Jobs yelled, \"I'll never let you do that. I'll never do that.\"In April 2009, Jobs underwent a liver transplantation at Methodist University Hospital Transplant Institute in Memphis, Tennessee. Jobs's prognosis was described as \"excellent\".\\n\\nResignation\\nOn January 17, 2011, a year and a half after Jobs returned to work following the liver transplant, Apple announced that he had been granted a medical leave of absence. Jobs announced his leave in a letter to employees, stating his decision was made \"so he could focus on his health\". As it did at the time of his 2009 medical leave, Apple announced that Tim Cook would run day-to-day operations and that Jobs would continue to be involved in major strategic decisions at the company. While on leave, Jobs appeared at the iPad 2 launch event on March 2, the WWDC keynote introducing iCloud on June 6, and before the Cupertino City Council on June 7.On August 24, 2011, Jobs announced his resignation as Apple's CEO, writing to the board, \"I have always said if there ever came a day when I could no longer meet my duties and expectations as Apple's CEO, I would be the first to let you know. Unfortunately, that day has come.\" Jobs became chairman of the board and named Tim Cook as his successor as CEO. Jobs continued to work for Apple until the day before his death six weeks later.\\n\\nDeath\\nJobs died at his Palo Alto, California, home around 3 p.m. (PDT) on October 5, 2011, due to complications from a relapse of his previously treated islet-cell pancreatic neuroendocrine tumor, which resulted in respiratory arrest. He had lost consciousness the day before and died with his wife, children, and sisters at his side. His sister, Mona Simpson, described his death thus: \"Steve's final words, hours earlier, were monosyllables, repeated three times. Before embarking, he'd looked at his sister Patty, then for a long time at his children, then at his life's partner, Laurene, and then over their shoulders past them. Steve's final words were: 'Oh wow. Oh wow. Oh wow.' \" He then lost consciousness and died several hours later. A small private funeral was held on October 7, 2011, the details of which, out of respect for Jobs's family, were not made public.Both Apple and Pixar issued announcements of his death. Apple announced on the same day that they had no plans for a public service, but were encouraging \"well-wishers\" to send their remembrance messages to an email address created to receive such messages. Apple and Microsoft both flew their flags at half-staff throughout their respective headquarters and campuses.Bob Iger ordered all Disney properties, including Walt Disney World and Disneyland, to fly their flags at half-staff from October 6 to 12, 2011. For two weeks following his death, Apple displayed on its corporate Web site a simple page that showed Jobs's name and lifespan next to his portrait in grayscale. On October 19, 2011, Apple employees held a private memorial service for Jobs on the Apple campus in Cupertino. It was attended by Jobs's widow, Laurene, and by Tim Cook, Bill Campbell, Norah Jones, Al Gore, and Coldplay. Some of Apple's retail stores closed briefly so employees could attend the memorial. A video of the service was uploaded to Apple's website.California Governor Jerry Brown declared Sunday, October 16, 2011, to be \"Steve Jobs Day\". On that day, an invitation-only memorial was held at Stanford University. Those in attendance included Apple and other tech company executives, members of the media, celebrities, politicians, and family and close friends of Jobs. Bono, Yo-Yo Ma, and Joan Baez performed at the service, which lasted longer than an hour. There was high security with guards at all of the university's gates, and a helicopter overhead from an area news station. Each attendee was given a small brown box as a \"farewell gift\" from Jobs, containing a copy of the Autobiography of a Yogi (1946) by Paramahansa Yogananda.Childhood friend and fellow Apple co-founder Steve Wozniak, former owner of what would become Pixar, George Lucas, his competitor Microsoft co-founder Bill Gates, and President Barack Obama all made statements in response to his death.\\nAt his request, Jobs was buried in an unmarked grave at Alta Mesa Memorial Park, the only nonsectarian cemetery in Palo Alto.\\n\\nInnovations and designs\\nJobs's design aesthetic was influenced by philosophies of Zen and Buddhism. In India, he experienced Buddhism while on his seven-month spiritual journey, and his sense of intuition was influenced by the spiritual people with whom he studied. Jobs gained insights regarding industrial designs from Richard Sapper.According to Apple co-founder Steve Wozniak, \"Steve didn't ever code. He wasn't an engineer and he didn't do any original design...\". Daniel Kottke, one of Apple's earliest employees and a college friend of Jobs, stated: \"Between Woz and Jobs, Woz was the innovator, the inventor. Steve Jobs was the marketing person.\"He is listed as either primary inventor or co-inventor in 346 United States patents or patent applications related to a range of technologies from actual computer and portable devices to user interfaces (including touch-based), speakers, keyboards, power adapters, staircases, clasps, sleeves, lanyards, and packages. His contributions to most of his patents were to \"the look and feel of the product\". He and his industrial design chief Jonathan Ive are named for 200 of the patents. Most of these are design patents as opposed to utility patents or inventions; they are specific product designs such as both original and lamp-style iMacs, and PowerBook G4 Titanium. He holds 43 issued US patents on inventions. The patent on the Mac OS X Dock user interface with \"magnification\" feature was issued the day before he died. Although Jobs had little involvement in the engineering and technical side of the original Apple computers, Jobs later used his CEO position to directly involve himself with product design.Involved in many projects throughout his career was his long-time marketing executive and confidant Joanna Hoffman, known as one of the few employees at Apple and NeXT who could successfully stand up to Jobs while also engaging with him.Even while terminally ill in the hospital, Jobs sketched new devices that would hold the iPad in a hospital bed. He despised the oxygen monitor on his finger, and suggested ways to revise the design for simplicity.Since his death, he has won 141 patents. He holds over 450 patents in total.\\n\\nApple I\\nThe Apple I was designed entirely by Steve Wozniak, but Steve Jobs had the idea of selling the computer, which led to the founding of Apple Computer in 1976. Jobs and Wozniak constructed several of the Apple I prototypes by hand, funded by selling some of their belongings. Eventually, 200 units were produced.\\n\\nApple II\\nThe Apple II is an 8-bit home computer, one of the world's first highly successful mass-produced microcomputer products, designed primarily by Wozniak. Jobs oversaw the development of the Apple II's unusual case and Rod Holt developed the unique power supply. It was introduced in 1977 at the West Coast Computer Faire by Jobs and Wozniak as the first consumer product sold by Apple.\\n\\nLisa\\nThe Lisa is a personal computer developed by Apple from 1978 and sold in the early 1980s to business users. It is the first personal computer with a graphical user interface. The Lisa sold poorly at 100,000 units.In 1982, after Jobs was forced out of the Lisa project, he took over the Macintosh project, adding inspiration from Lisa. The final Lisa 2/10 was modified and sold as the Macintosh XL.\\n\\nMacintosh\\nOnce he joined the Macintosh team, Jobs took over the project after Wozniak had experienced a traumatic airplane accident and temporarily left the company. Jobs launched the Macintosh on January 24, 1984, as the first mass-market personal computer featuring an integral graphical user interface and mouse. This first model was later renamed to Macintosh 128k among the prolific series. Since 1998, Apple has phased out the Macintosh name in favor of \"Mac\", though the product family has been nicknamed \"Mac\" or \"the Mac\" since inception. The Macintosh was introduced by a US$1.5 million Ridley Scott television commercial, \"1984\". It aired during the third quarter of Super Bowl XVIII on January 22, 1984, received as a \"watershed event\" and a \"masterpiece\". Regis McKenna called the ad \"more successful than the Mac itself\". It uses an unnamed heroine to represent the coming of the Macintosh (indicated by a Picasso-style picture of the computer on her white tank top) to save humanity from the conformity of IBM's domination of the computer industry. The ad alludes to George Orwell's novel Nineteen Eighty-Four, which describes a dystopian future ruled by a televised \"Big Brother\".The Macintosh, however, was expensive, which hindered its ability to be competitive in a market already dominated by the Commodore 64 for consumers, and the IBM Personal Computer and its accompanying clone market for businesses. Macintosh systems still found success in education and desktop publishing and kept Apple as the second-largest PC manufacturer for the next decade.\\n\\nNeXT Computer\\nAfter Jobs was forced out of Apple in 1985, he started NeXT, a workstation computer company. The NeXT Computer was introduced in 1988 at a lavish launch event. Using the NeXT Computer, Tim Berners-Lee created the world's first web browser, the WorldWideWeb. The NeXT Computer's operating system, named NeXTSTEP, begat Darwin, which is now the foundation of most of Apple's operating systems such as Macintosh's macOS and iPhone's iOS.\\n\\niMac\\nApple's iMac G3 was introduced in 1998 and its innovative design is directly the result of Jobs's return to Apple. Apple boasted \"the back of our computer looks better than the front of anyone else's\". Described as \"cartoonlike\", the first iMac, clad in Bondi Blue plastic, was unlike any personal computer that came before. In 1999, Apple introduced the Graphite gray Apple iMac and since has varied the shape, color and size considerably while maintaining the all-in-one design. Design ideas were intended to create a connection with the user such as the handle and a \"breathing\" light effect when the computer went to sleep. The Apple iMac sold for $1,299 at that time. The iMac's forward-thinking changes include eschewing the floppy disk drive and moving exclusively to USB for connecting peripherals. Through the iMac's success, USB was popularized among third-party peripheral makers\u2014as evidenced by the fact that many early USB peripherals were made of translucent plastic to match the iMac design.\\n\\niTunes\\niTunes is a media player, media library, online radio broadcaster, and mobile device management application developed by Apple. It is used to play, download, and organize digital audio and video (plusother types of media on the iTunes Store) on personal computers running the macOS and Microsoft Windows operating systems. The iTunes Store is also available on the iPod Touch, iPhone, and iPad.\\nThrough the iTunes Store, users can purchase and download music, music videos, television shows, audiobooks, podcasts, movies, and movie rentals in some countries, and ringtones, available on the iPhone and iPod Touch (fourth generation onward). Application software for the iPhone, iPad and iPod Touch can be downloaded from the App Store.\\n\\niPod\\nThe first generation of iPod was released October 23, 2001. The major innovation of the iPod was its small size achieved by using a 1.8\" hard drive compared to the 2.5\" drives common to players at that time. The capacity of the first-generation iPod ranged from 5 GB to 10 GB. The iPod sold for US$399 and more than 100,000 iPods were sold before the end of 2001. The introduction of the iPod resulted in Apple becoming a major player in the music industry. Also, the iPod's success prepared the way for the iTunes music store and the iPhone. After the first few generations of iPod, Apple released the touchscreen iPod Touch, the reduced-size iPod Mini and iPod Nano, and the screenless iPod Shuffle in the following years.\\n\\niPhone\\nApple began work on the first iPhone in 2005 and the first iPhone was released on June 29, 2007. The iPhone created such a sensation that a survey indicated six out of ten Americans were aware of its release. Time declared it \"Invention of the Year\" for 2007 and included it in the All-TIME 100 Gadgets list in 2010, in the category of Communication. The completed iPhone had multimedia capabilities and functioned as a quad-band touch screen smartphone. A year later, the iPhone 3G was released in July 2008 with three key features: support for GPS, 3G data and tri-band UMTS/HSDPA. In June 2009, the iPhone 3GS, whose improvements included voice control, a better camera, and a faster processor, was introduced by Phil Schiller. The iPhone 4 was thinner than previous models, had a five megapixel camera capable of recording video in 720p HD, and added a secondary front-facing camera for video calls. A major feature of the iPhone 4S, introduced in October 2011, was Siri, a virtual assistant capable of voice recognition.\\n\\niPad\\nThe iPad is an iOS-based line of tablet computers designed and marketed by Apple. The first iPad was released on April 3, 2010. The user interface is built around the device's multi-touch screen, including a virtual keyboard. The iPad includes built-in Wi-Fi and cellular connectivity on select models. As of April 2015, more than 250 million iPads have been sold.\\n\\nPersonal life\\nMarriage\\nIn 1989, Jobs first met his future wife, Laurene Powell, when he gave a lecture at the Stanford Graduate School of Business, where she was a student. Soon after the event, he stated that Laurene \"was right there in the front row in the lecture hall, and I couldn't take my eyes off of her ... kept losing my train of thought, and started feeling a little giddy\". After the lecture, he met her in the parking lot and invited her out to dinner. From that point forward, they were together, with a few minor exceptions, for the rest of his life.Jobs proposed on New Year's Day 1990 with \"a fistful of freshly picked wildflowers\". They married on March 18, 1991, in a Buddhist ceremony at the Ahwahnee Hotel in Yosemite National Park. Fifty people, including Jobs's father, Paul, and his sister Mona, attended. The ceremony was conducted by Jobs's guru, Kobun Chino Otogawa. The vegan wedding cake was in the shape of Yosemite's Half Dome, and the wedding ended with a hike and Laurene's brothers' snowball fight. Jobs reportedly said to Mona: \"You see, Mona [...], Laurene is descended from Joe Namath, and we're descended from John Muir\".Jobs's and Powell's first child, a son named Reed, was born in 1991. Jobs's father, Paul, died a year and a half later, on March 5, 1993. Jobs's childhood home remains a tourist attraction and is currently owned by his stepmother (Paul's second wife), Marilyn Jobs.Jobs and Powell had two more children, daughters Erin (b. 1995) and Eve Jobs (b. 1998), who is a fashion model. The family lived in Palo Alto, California.Although a billionaire, Jobs made it known that, like Bill Gates, he had stipulated that most of his monetary fortune would not be left to his children. Both men had limited their children's access, age appropriate, to social media, computer games, and the Internet.\\n\\nFamily\\nChrisann Brennan notes that after Jobs was forced out of Apple, \"he apologized many times over for his behavior\" towards her and Lisa. She said Jobs \"said that he never took responsibility when he should have, and that he was sorry\". By this time, Jobs had developed a strong relationship with Lisa and when she was nine, Jobs had her name on her birth certificate changed from \"Lisa Brennan\" to \"Lisa Brennan-Jobs\". Jobs and Brennan developed a working relationship to co-parent Lisa, a change which Brennan credits to the influence of his newly found biological sister, Mona Simpson, who worked to repair the relationship between Lisa and Jobs. Jobs had found Mona after first finding his birth mother, Joanne Schieble Simpson, shortly after he left Apple.Jobs did not contact his birth family during his adoptive mother Clara's lifetime, however. He would later tell his official biographer Walter Isaacson: \"I never wanted [Paul and Clara] to feel like I didn't consider them my parents, because they were totally my parents [...] I loved them so much that I never wanted them to know of my search, and I even had reporters keep it quiet when any of them found out\". However, in 1986, when Jobs was 31, Clara was diagnosed with lung cancer. He began to spend a great deal of time with her and learned more details about her background and his adoption, information that motivated him to find his biological mother. Jobs found on his birth certificate the name of the San Francisco doctor to whom Schieble had turned when she was pregnant. Although the doctor did not help Jobs while he was alive, he left a letter for Jobs to be opened upon his death. As he died soon afterwards, Jobs was given the letter which stated that \"his mother had been an unmarried graduate student from Wisconsin named Joanne Schieble\".Jobs only contacted Schieble after Clara died in early 1986 and after he received permission from his father, Paul. In addition, out of respect for Paul, he asked the media not to report on his search. Jobs stated that he was motivated to find his birth mother out of both curiosity and a need \"to see if she was okay and to thank her, because I'm glad I didn't end up as an abortion. She was twenty-three and she went through a lot to have me.\" Schieble was emotional during their first meeting (though she wasn't familiar with the history of Apple or Jobs's role in it) and told him that she had been pressured into signing the adoption papers. She said that she regretted giving him up and repeatedly apologized to him for it. Jobs and Schieble would develop a friendly relationship throughout the rest of his life and would spend Christmas together.During this first visit, Schieble told Jobs that he had a sister, Mona, who was not aware that she had a brother. Schieble then arranged for them to meet in New York where Mona worked. Her first impression of Jobs was that \"he was totally straightforward and lovely, just a normal and sweet guy\". Simpson and Jobs then went for a long walk to get to know each other. Jobs later told his biographer that \"Mona was not completely thrilled at first to have me in her life and have her mother so emotionally affectionate toward me ... As we got to know each other, we became really good friends, and she is my family. I don't know what I'd do without her. I can't imagine a better sister. My adopted sister, Patty, and I were never close.\"\\n\\nJobs then learned his family history. Six months after he was given up for adoption, Schieble's father died, she wed Jandali, and they had a daughter, Mona. Jandali states that after finishing his PhD he returned to Syria to work, and then Schieble left him. They divorced in 1962 and he said then he lost contact with Mona for a time:\\n\\nI also bear the responsibility for being away from my daughter when she was four years old, as her mother divorced me when I went to Syria, but we got back in touch after 10 years. We lost touch again when her mother moved and I didn't know where she was, but since 10 years ago we've been in constant contact, and I see her three times a year. I organized a trip for her last year to visit Syria and Lebanon and she went with a relative from Florida.\\nA few years later, Schieble married an ice-skating teacher, George Simpson. Mona Jandali took her stepfather's last name, as Mona Simpson. In 1970, after divorcing her second husband, Schieble took Mona to Los Angeles and raised her alone.When Simpson found that their father, Abdulfattah Jandali, was living in Sacramento, California, Jobs had no interest in meeting him as he believed Jandali didn't treat his children well and according to the San Francisco Chronicle, this was because of finding a Seattle Times article about Jandali's abandonment of his students on a trip to Egypt in 1974. Simpson went to Sacramento alone and met Jandali, who worked in a small restaurant. They spoke for several hours, and he told her that he had left teaching for the restaurant business. He said he and Schieble had given another child away for adoption but that \"we'll never see that baby again. That baby's gone.\" He said he once managed a Mediterranean restaurant near San Jose and that \"all of the successful technology people used to come there. Even Steve Jobs ... oh yeah, he used to come in, and he was a sweet guy and a big tipper\". At the request of Jobs, Simpson did not tell Jandali that she had met his son.After hearing about the visit, Jobs recalled that \"it was amazing ... I had been to that restaurant a few times, and I remember meeting the owner. He was Syrian. Balding. We shook hands.\" However, Jobs still did not want to meet Jandali because \"I was a wealthy man by then, and I didn't trust him not to try to blackmail me or go to the press about it ... I asked Mona not to tell him about me\". Jandali later discovered his relationship to Jobs through an online blog. He then contacted Simpson and asked, \"what is this thing about Steve Jobs?\". Simpson told him that it was true and later commented, \"My father is thoughtful and a beautiful storyteller, but he is very, very passive ... He never contacted Steve\". Because Simpson herself researched her Syrian roots and began to meet the family, she assumed that Jobs would eventually want to meet their father, but he never did. Jobs also never showed an interest in his Syrian heritage or the Middle East. Simpson fictionalized the search for their father in her 1992 novel The Lost Father. Malek Jandali is their cousin.\\n\\nPhilanthropy\\nJobs's views and actions on philanthropy and charity are a public mystery. He maintained privacy even over what few of these actions were publicly known. He has been a key figure in public discussions about societal obligations of the wealthy and powerful. Through his career, the media investigated and criticized him and Apple as unusually and inexplicably mysterious or absent among powerful leaders and especially billionaires. His name is absent from the Million Dollar List of all large global philanthropy. Some have speculated about his possible secret role in large anonymous donations.Mark Vermilion, former charitable leader for Joan Baez, Apple, and Jobs, attributed Jobs's lifelong minimization of direct charity to his perfectionism and limited time. Jobs, Vermilion, and supporters said over the years that corporate products were Jobs's superior contributions to culture and society instead of direct charity. In 1985, Jobs said, \"You know, my main reaction to this money thing is that it's humorous, all the attention to it, because it's hardly the most insightful or valuable thing that's happened to me.\"Shortly after leaving Apple, he formed the charitable Steven P. Jobs Foundation, led by Mark Vermilion, hired away from Apple's community leadership. Jobs wanted a focus on nutrition and vegetarianism, but Vermilion wanted social entrepreneurship. That year, Jobs soon launched NeXT and closed the foundation with no results. Upon his 1997 return to Apple, Jobs optimized the failing company to the core, such as eliminating all philanthropic programs, never to be restored. In 2007, Stanford Social Innovation Review magazine listed Apple among \"America's least philanthropic companies\". A few months after another unflattering news report, Apple started a program to match employees' charitable gifts. Jobs declined to sign The Giving Pledge, launched in 2010 by Warren Buffett and Bill Gates for fellow billionaires. He donated $50 million to Stanford hospital and contributed to efforts to cure AIDS. Bono reported \"tens of millions of dollars\" given by Apple while Jobs was CEO, to AIDS and HIV relief programs in Africa, which inspired other companies to join.\\n\\nHonors and awards\\n1985: awarded National Medal of Technology (with Steve Wozniak) by US President Ronald Reagan, the country's highest honor for technological achievements\\n1987: Jefferson Award for Public Service\\n1989: Entrepreneur of the Decade by Inc.\\n1991: Howard Vollum Award from Reed College\\n2004\u20132010: listed among the Time 100 Most Influential People in the World on five separate occasions\\n2007: named the most powerful person in business by Fortune magazine\\n2007: inducted into the California Hall of Fame, located at The California Museum for History, Women and the Arts\\n2012: Grammy Trustees Award, an award for those who have influenced the music industry in areas unrelated to performance\\n2012: posthumously honored with an Edison Achievement Award for his commitment to innovation throughout his career\\n2013: posthumously inducted as a Disney Legend\\n2017: Steve Jobs Theater opens at Apple Park\\n2022: posthumously awarded the Presidential Medal of Freedom by US President Joe Biden, the country's highest civilian honor\\n\\nIn popular culture\\nSee also\\nSeva Foundation\\nTimeline of Steve Jobs media\\n\\nReferences\\nBibliography\\nBrennan, Chrisann (2013). The Bite in the Apple: A Memoir of My Life with Steve Jobs. New York: St. Martin's Press. ISBN 978-1-250-03876-0.\\nIsaacson, Walter (2011). Steve Jobs (1st ed.). New York: Simon & Schuster. ISBN 978-1-4516-4853-9.\\nLinzmayer, Owen W. (2004). Apple Confidential 2.0: The Definitive History of the World's Most Colorful Company. No Starch Press. ISBN 978-1-59327-010-0.\\nSchlender, Brent; Tetzeli, Rick (2015). Becoming Steve Jobs: The Evolution of a Reckless Upstart into a Visionary Leader. Crown Business. ISBN 978-0-7710-7914-6.\\nSmith, Alexander (2020). They Create Worlds: The Story of the People and Companies That Shaped the Video Game Industry, Volume 1: 1971\u20131982. Boca Raton, FL: CRC Press. ISBN 978-1-138-38992-2.\\n\\nExternal links\\n\\nSteve Jobs official memorial page at Apple\\nSteve Jobs discography at Discogs\\nSteve Jobs at IMDb\\nSteve Jobs profile at Forbes\\nSteven Paul Jobs The Vault at FBI Records\\nSteve Jobs at Andy Hertzfeld's The Original Macintosh (folklore.org)\\nSteve Jobs at Steve Wozniak's woz.org\\n2011: \"Steve Jobs: From Garage to World's Most Valuable Company.\" Computer History Museum\\n2005: Steve Jobs commencement speech at Stanford University\\n1995: Steve Jobs, Founder, NeXT Computer, excerpts from an Oral History Interview at Smithsonian Institution, April 20, 1995\\n1994: Steve Jobs in 1994: The Rolling Stone Interview in Rolling Stone\\n1990: Steve Jobs Archived December 16, 2014, at the Wayback Machine \u2013 memory and imagination \u201cWhat a computer is to me is it\u2019s the most remarkable tool that we\u2019ve ever come up with, and it\u2019s the equivalent of a bicycle for our minds\u201d\\n1983: The \"Lost\" Steve Jobs Speech from 1983; Foreshadowing Wireless Networking, the iPad, and the App Store (audio clip)\\n History of Steve Jobs (Full Documentary) on YouTube"}
